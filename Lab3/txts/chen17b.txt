Adaptive MultipleArm Identi cation

Jiecao Chen     Xi Chen     Qin Zhang     Yuan Zhou    

Abstract

We study the problem of selecting   arms with
the highest expected rewards in   stochastic narmed bandit game  This problem has   wide
range of applications           testing  crowdsourcing  simulation optimization  Our goal is
to develop   PAC algorithm  which  with probability at least       identi es   set of   arms
with the aggregate regret at most   The notion of
aggregate regret for multiplearm identi cation
was  rst introduced in Zhou et al      which
is de ned as the difference of the averaged expected rewards between the selected set of arms
and the best   arms  In contrast to Zhou et al 
  that only provides instanceindependent
sample complexity  we introduce   new hardness
parameter for characterizing the dif culty of any
given instance  We further develop two algorithms and establish the corresponding sample
complexity in terms of this hardness parameter 
The derived sample complexity can be signi 
cantly smaller than stateof theart results for  
large class of instances and matches the instanceindependent lower bound upto   log  factor
in the worst case  We also prove   lower bound
result showing that the extra log  is necessary for instancedependent algorithms using the
introduced hardness parameter 

  Introduction
Given   set of alternatives with different quality  identifying high quality alternatives via   sequential experiment is

Jiecao Chen  jiecchen umail iu edu 

 Equal contribution  Computer Science Department  Indiana University  Bloomington  IN  USA  Stern School of Business  New York University  New York  NY  USA  Correspondence to 
supported
in part by NSF CCF  and IIS  Xi Chen
 xchen stern nyu edu  supported by Google Faculty Research
Fellowship  Qin Zhang  qzhangcs indiana edu  supported
in part by NSF CCF  and IIS  Yuan Zhou
 yzhoucs indiana edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

an important problem in multiarmed bandit  MAB  literature  which is also known as the  pureexploration  problem  This problem has   wide range of applications  For
example  consider the       testing problem with multiple
website designs  where each candidate design corresponds
to an alternative  In order to select highquality designs 
an agent could display different designs to website visitors
and measure the attractiveness of an design  The question
is  how should the agent adaptively select which design to
be displayed next so that the highquality designs can be
quickly and accurately identi ed  For another example  in
crowdsourcing  it is critical to identify highquality workers from   pool of   large number of noisy workers  An
effective strategy is testing workers by gold questions      
questions with the known answers provided by domain experts  Since the agent has to pay    xed monetary reward
for each answer from   worker  it is important to implement
  costeffective strategy for to select the top workers with
the minimum number of tests  Other applications include
simulation optimization  clinical trials  etc 
More formally  we assume that there are   alternative arms 
where the ith arm is associated with an unknown reward
distribution Di with mean     For the ease of illustration 
we assume each Di is supported on     In practice  it
is easy to satisfy this assumption by   proper scaling  For
example  the traf   of   website or the correctness of an
answer for   crowd worker  which simply takes the value
either   or   can be scaled to     The mean reward   
characterizes the quality of the ith alternative  The agent
sequentially pulls an arm  and upon each pulling of the ith arm  the        reward from Di is observed  The goal
of  topK arm identi cation  is to design an adaptive arm
pulling strategy so that the top   arms with the largest
mean rewards can be identi ed with the minimum number of trials  In practice  identifying the exact topK arms
usually requires   large number of arm pulls  which could
be wasteful  In many applications       crowdsourcing  it
is suf cient to  nd an  approximate set  of topK arms 
To measure the quality of the selected arms  we adopt the
notion of aggregate regret  or regret for short  from Zhou
et al    In particular  we assume that arms are ordered
by their mean                so that the set of the
best   arms is              For the selected arm set   with

Adaptive MultipleArm Identi cation

the size          the aggregate regret RT is de ned as 

 cid 

 cid    cid 

  

    cid 

   

RT  

 
 

  

 

 

 

 

 cid 

 cid cid 

 cid   

    ln  

The set of arms   with the aggregate regret less than  
predetermined tolerance level         RT     is called
 topK arms  In this paper  we consider the  topK arm
problem in the  xedcon dence  setting  given   target
con dence level       the goal is to  nd   set of  topK
arms with the probability at least       This is also known
as the PAC  probably approximately correct  learning setting  We are interested in achieving this goal with as few
arm pulls  sample complexity  as possible 
To solve this problem  Zhou et al    proposed the
OptMAI algorithm and established its sample complexity
  which is shown to be asymptotically
 
optimal  However  the algorithm and the corresponding
sample complexity in Zhou et al    are nonadaptive
to the underlying instance  In other words  the algorithm
does not utilize the information obtained in known samples to adjust its future sampling strategy  and as   result 
the sample complexity only involves the parameters      
  and   but is independent of     
   Chen et al   
developed the CLUCBPAC algorithm and established an
instancedependent sample complexity for   more general
class of problems  including the  topK arm identi cation
problem as one of the key examples  When applying the
CLUCBPAC algorithm to identify  topK arms  the sample complexity becomes   log       log     
   min                
for                     for        The reason why
we adopt the notation     will be clear from Section
  However  this bound may be improved for the following two reasons  First  intuitively  the hardness parameter     is the total number of necessary pulls needed
for each arm to identify whether it is among the topK
arms or the rest so that the algorithm can decide whether
to accept or reject the arm  when the arm   mean is  
close to the boundary between the topK arms and the
rest arms  it can be either selected or rejected  However  in many cases  even if an arm   mean is  far from
the boundary  we may still be vague about the comparison between its mean and the boundary       either selecting or rejecting the arm satis es the aggregate regret
bound  This may lead to fewer number of pulls and  
smaller hardness parameter for the same instance  Second  the worstcase sample complexity for CLUCBPAC
becomes   log     log     log     When   is  
constant  this bound is log   times more than the best nonadaptive algorithm in Zhou et al   
In this paper  we explore towards the above two directions and introduce new instancesensitive algorithms for

where      cid  

rameter  cid   used in the literature  in many natural instances 

the problem of identifying  topK arms  These algorithms
signi cantly improve the sample complexity by CLUCBPAC for many common instances and almost match the best
nonadaptive algorithm in the worst case 
Speci cally  we  rst introduce   new parameter   to characterize the hardness of   given instance  This new hardness parameter   could be smaller than the hardness paFor example  we show in Lemma   that when     
  
are sampled from   continuous distribution with bounded
probability density function  which is   common assumption in Bayesian MAB and natural for many applications 
for        with       our hardness parameter is
        

  while  cid        

 

to

 

an easyto implement

  cid cid log log    log     log  cid    cid 

that the algorithm uses   cid cid log     log  cid    cid  pulls to

Using this new hardness parameter    we  rst proalgorithm  ADAPTIVEpose
TOPK and relate its sample complexity to   
In
Theorem   we
show that ADAPTIVETOPK uses
identify
 topK arms with probability at least       Note that
this bound has   similar form as the one in Chen et al 
  but as mentioned above  we have an
   factor
improvement in the hardness parameter for those instances
where Lemma   applies 
We then propose the second algorithm  IMPROVEDTOPK 
with even less sample complexity  which removes the log  
factor in the sample complexity  In Theroem   we show
identify  topK arms with probability       Since  
is always      which will be clear when the   is de 
 ned in Section   the worstcase sample complexity of
IMPROVEDTOPK matches the best instanceindependent
bound shown in Zhou et al    up to an extra log 
factor  for constant   We are also able to show that
this extra log  factor is   necessary expense by being
instanceadaptive  Theorem   It is also noteworthy that
as   byproduct of establishing IMPROVEDTOPK  we developed an algorithm that approximately identi es the kth
best arm  which may be of independent interest  Details are
deferred to the full version of this paper   
We are now ready to introduce our new hardness parameters and summarize the main results in technical details 

  Summary of Main Results

Following the existing literature  see       Bubeck et al 
  we  rst de ne the gap of the ith arm

       

        
       

if      
if          

 

 cid 

 Full version of this paper is available online at https 

arxiv org abs 

Adaptive MultipleArm Identi cation

 

Note that when             becomes        for all
      and             When   is clear from
the context  we simply use    for       One commonly
used hardness parameter for quantifying the sample complexity in the existing literature  see       Bubeck et al 
  If there

  Karnin et al    is  cid    cid   cid  
is an extremely small gap     the value of  cid   and thus the

    

corresponding sample complexity can be super large  This
hardness parameter is natural when the goal is to identify
the exact topK arms  where   suf cient gap between an
arm and the boundary          and     is necessary 
However  in many applications        nding highquality
workers in crowdsourcing  it is an overkill to select the exact topK arms  For example  if all the topM arms with
      have very close means  then any subset of them
of size   forms an  topK set in terms of the aggregate
regret in   Therefore  to quantify the sample complexity
when the metric is the aggregate regret  we need to construct   new hardness parameter 
Given   and an error bound   let us de ne           to
be the largest                         such that

             

              

and

 
Note that                           upperbounds
the total gap of the   worst arms in the top   arms and
                           upperbounds the total
gap of the   best arms in the nontop   arms  Intuitively 
the de nition in   means that we can tolerate exchanging
at most   best arms in the nontop   arms with the   worst
arms in the topK arms 
Given           we de ne

and

     min           

 

    max     

 

 

We now introduce the following parameter to characterize
the hardness of   given instance 

  cid 

           

min     

  

 

  

It is worthwhile to note that no matter how small the gap
      we always have            We
   is  since  
also note that since    is nondecreasing in          is also
nonincreasing in   
Our  rst result is an easyto implement algorithm  see Algorithm   that identi es  topK arms with sample complexity related to      

Theorem   There is an algorithm that computes  topK
arms with probability at least       and pulls the arms

at most   cid cid log log     log     log  cid       cid  times 

We also develop   more sophisticated algorithm with an
improved sample complexity  the details of which are deferred to the full version of this paper 

Since  

Theorem   There is an algorithm that computes  topK
arms with probability at least       and pulls the arms

at most   cid cid log     log  cid       cid  times 
complexity by Theorem   is   cid   

      and            the worstcase sample

 
instanceindependent
While the asymptotically optimal
 by Zhou et al 
sample complexity is  
  we show that the log   factor in Theorem   is
necessary for instancedependent algorithms using      
as   hardness parameter  In particular  we establish the following lowerbound result  the detailed proof of which is
deferred to the full version of this paper 

 cid log     log  cid cid 
 cid cid 

    ln  

 cid   

 cid 

 

 

Theorem   For any      such that         and any    
    there exists an instance on   arms so that        
    and it requires    log   pulls to identify   set of
 topK arms with probability at least  

Note that since             in our lower bound instances  our Theorem   shows that the sample complexity has to be at least        log   in these instances 
In other words  our lower bound result shows that for
any instancedependent algorithm  and any        
there exists an instance where sample complexity has to be
       log   While Theorem   shows the necessity
of the log   factor in Theorem   it is not   lower bound
for every instance of the problem 

  Review of and Comparison with Related Works

The problem of identifying the single best arm      
the topK arms with       has been studied extensively  EvenDar et al    Mannor   Tsitsiklis 
  Audibert et al    Gabillon et al     
Karnin et al    Jamieson et al    Kaufmann
et al    Garivier   Kaufmann    Russo   
Chen et al      More speci cally 
in the special
case when       our problem reduces to identifying
an  best arm 
an arm whose expected reward is
different from the best arm by an additive error of at most
  with probability at least       For this problem 
EvenDar et al    showed an algorithm with an

instanceindependent sample complexity   cid   

  log  cid 

    

 and this was proved to be asymptotically optimal by
Mannor   Tsitsiklis   An instancedependent algorithm for this problem was given by Bubeck et al   
and an improved algorithm was given by Karnin et al 
  with an instancedependent sample complexity of

   max     log     log log max     cid 

  cid cid  

Adaptive MultipleArm Identi cation

In

the

worst

this

case 

bound

almost

becomes
matching
the instanceindependent bound in EvenDar et al 
  When       we have           and thus

   log     log log  cid 
  cid   
               cid cid  
  log     log         cid   

   max     cid  There 
   log     log  cid  in

fore  the sample complexity in our Theorem   becomes

the worstcase  almost matching the bound by Karnin et al 
 
For the problem of identifying topK arms with    
  different notions of  optimal solution have been proposed  One popular metric is the misidenti cation probability  MISPROB       Pr    cid               In the PAC
setting       controlling MISPROB less than   with probability at least     many algorithms have been developed
recently       Bubeck et al    in the  xed budget setting and Chen et al    for both  xed con dence and
 xed budget settings  Gabillon et al    further improved the sample complexity in Chen et al    however the current implementation of their algorithm has an
exponential running time  As argued in Zhou et al   
the MISPROB requires to identify the exact topK arms 
which might be too stringent for some applications      
crowdsourcing  The MISPROB requires   certain gap between    and     to identify the topK arms  and this
requirement is not unnecessary when using the aggregate
regret  As shown in Zhou et al    when the gap of
any consecutive pair between    and     among the  rst
   arms is      the sample complexity has to be huge
    to make the MISPROB less than   while any  
arms among the  rst    form   desirably set of  topK
arms in terms of aggregate regret  Therefore  we follow
Zhou et al    and adopt the aggregate regret to de ne
the approximate solution in this paper 
Kalyanakrishnan et al    proposed the socalled
EXPLOREK metric  which requires for each arm   in the
selected set   to satisfy               where    is the
mean of the Kth best arm  Cao et al    proposed
  more restrictive notion of optimality ELEMENTWISE 
 OPTIMAL  which requires the mean reward of the ith
best arm in the selected set   be at least        for    
       It is clear that the ELEMENT WISE OPTIMAL is
  stronger guarantee than our  topK in regret  while the
latter is stronger than EXPLOREK  Chen et al     
further extended Cao et al    to pure exploration problems under matroid constraints  Audibert et al    and
Bubeck et al    considered expected aggregate regret
  where the expectation
       
 
is taken over the randomness of the algorithm  Note that
this notion of expected aggregate regret is   weaker objective than the aggregate regret 
Moreover  there are some other recent works studying the

 cid cid  
          cid cid 

 cid cid 

      

least   using   cid cid log     log    cid     cid  pulls 

problem of bestarm identi cation in different setups      
linear contextual bandit  Soare et al    batch arm pulls
 Jun et al   
For our  topK arm problem  the stateof theart instancedependent sample complexity was given by Chen et al 
   see Section    in Appendix of their paper  More
speci cally  Chen et al    proposed CLUCBPAC
algorithms that  nds  topK arms with probability at
Since                   and        
  
our Theorem   is not worse than the bound in Chen et al 
  Indeed  in many common settings        can be
much smaller than     so that Theorem    and therefore
Theorem   requires much less sample complexity  We explain this argument in more details as follows 
In many realworld applications  it is common to assume
the arms    are sampled from   prior distribution   over
    with cumulative distribution function FD 
In
fact  this is the most fundamental assumption in Bayesian
multiarmed bandit literature       bestarm identi cation
in Bayesian setup  Russo    In crowdsourcing applications  Chen et al    and AbbasiYadkori et al   
also made this assumption for modeling workers  accuracy 
which correspond to the expected rewards  Under this assumption  it is natural to let    be the    
    quantile of the
    If the prior distribution    
distribution                 
probability density function fD   dFD
   has bounded value
   few common examples include uniform distribution over
    Beta distribution  or the truncated Gaussian distribution  the arms  mean rewards     
   can be characterized
by the following property with       
De nition   We call   set of   arms               
cspread  for some       if for all            we have

          cid     

cn         

 

 cid 

 

The following lemma upperbounds       for   spread
arms  and shows the improvement of our algorithms compared to Chen et al    on   spread arms  The proof
of Lemma   is based on simple calculations and is deferred
to the full version of this paper 
Lemma   Given   set of   cspread arms  let         
    When        and       we have        
  In contrast            for   spread
    
arms and every        

 

 

  An Instance Dependent Algorithm for

 topK Arms

In this section  we show Theorem   by providing Algorithm   and proving the following theorem 

Algorithm   ADAPTIVETOPK          
Input     number of arms    and   parameters in  topK

arms    error probability

Output   topK arms
  Let   denote the current round  initialized to be   Let Sr  
    denote the set of candidate arms at round       is
initialized to be     Set         
        
  while                       do

 

 

         
Pull each arm in Sr by   ln  nr 
be the empiricalmean
      th largest empiricalmeans in Sr  and de ne

times  and let  cid  
De ne cid   Sr  and cid   Sr  be the             th and
 cid cid  
   cid   Sr cid   Sr   cid  
 cid   Sr    max
while maxi Sr  cid   Sr          do
    arg maxi Sr  cid   Sr 
   cid   Sr  then
if cid  

 cid 

 

 

           

else

           

Sr   Sr   

Sr    Sr
      

 

 

 

 

 

 

 

 

 

 

 

 

Adaptive MultipleArm Identi cation

are within   small neighborhood of their true means  happens with probability at least        See De nition   and
Claim   Note that   is de ned for all rounds and the
length of the neighborhood becomes smaller as the algorithm proceeds  We are able to prove that when   happens 
the algorithm returns the desired set of  topK arms and
has small query complexity 
To prove the correctness of the algorithm  we  rst show
that when conditioning on    the algorithm always accepts
  topK arm in    Lemma   and rejects   nontop   arm
in    Lemma   The key observation here is that our algorithm never introduces any regret due to arms in   and
   We then use the key Lemma   to upper bound the regret
that may be introduced due to the remaining arms  Once
this upper bound is not more than          the total budget
for regret  we can choose the remaining          arms
without further samplings  Details about this analysis can
be found in Section  
We analyze of the query complexity of our algorithm in
Section   We establish datadependent bound by relating
the number of pulls to each arms to both their      and
      Lemma   and Lemma  

  Correctness of Algorithm  
We  rst de ne an event   which we will condition on in
the rest of the analysis 

De nition   Let   be the event that  cid  

             for all

      and     Sr 
Claim   Pr           

 cid 

Proof   By Hoeffding   inequality  we can show that for any
 nr   
 xed   and    Pr
By   union bound 

             cid       
 cid cid  
 nr       
             cid   
 cid cid  
 cid 
 cid 

Pr     

 cid 

Pr

  

  Sr

  

 

       
 cid 

The following lemma will be   very useful tool for our analysis  the proof of which is deferred to the full version of this
paper 
Lemma   Given                and       assuming

that  cid          for all         and letting              yn
be the sorted version of  cid         cid    we have  yi        

  for all        
We now prove that conditioned on    the algorithm always
accepts   desired arm in   

  Set   cid  as the          arms with the largest empiricalmeans in Sr 
  return       cid 

 cid cid 

 cid    cid 

  

Theorem   Algorithm   computes  topK arms with
probability at least       and pulls the arms at most

 

log log 

     log

 
 

min     

  

times  where                         is the largest integer
satisfying               and  

    max       

     

     

Note that Theorem   implies Theorem   because of the following reasons      de ned in Theorem   is always at least
      de ned in   and    
Algorithm   is similar to the acceptreject types of algorithms in for example Bubeck et al    The algorithm
goes by rounds for                   and keeps at set of undecided arms Sr       at Round    All other arms  in
      Sr  are either accepted  in    or rejected  in    At
each round  all undecided arms are pulled by equal number of times  This number is chosen to ensure that the
event    which is de ned as the empirical means of all arms

Adaptive MultipleArm Identi cation

Combining     and the de nitions of cid   Sr  and    

the lemma follows 

 cid 

With   similar argument
Lemma   we can show that

 cid   Sr   cid  

 by symmetry and using

                     

 

  

Lemma   Conditioned on    during the run of Algorithm                      that is  all arms in   are
among the topK arms 

Proof   We prove by induction on the round    The lemma
holds trivially when              Now      round
      and let   be the arm that is added to   at Line   of
Algorithm   By the induction hypothesis  assuming that
before round   all arms in   are in     our goal is to show
       
By the inner while condition we have

 cid  
   cid   Sr           

 
For any                 Sr  let   be the arm of the
mth largest truemean in Sr  and   cid  be the arm of the mth
largest empiricalmean in Sr  Since                 we

  cid   cid   Sr  By Lemma   we also

must have    cid      and cid  
have  cid  
    cid  

  cid              We thus have
      

   cid   Sr        cid  

  cid            
That is  at least  Sr        arms in Sr have truemeans
smaller than arm    On the other hand   Sr       arms
in Sr are not in     We therefore conclude that   must be
 cid 
in    

by  

By symmetry  we also have the following lemma  stating
that when   happens  the algorithm always rejects   nontop   arm in    We omit the proof because it is almost
identical to the proof of Lemma  
Lemma   Conditioning on    during the run of Algorithm                              
Lemma   Conditioned on    for all rounds   and     Sr 

   cid   Sr                     
 cid   Sr   cid  
                     

it holds that cid  
Consequently  we have cid   Sr         for all rounds

  and     Sr 
Proof   We look at   particular round    Let   be the arm
with             th largest truemean in Sr  Since by
Lemma   we have           it holds that           By
have for any     Sr

Lemma   we also have  cid   Sr            We therefore
 cid  
   cid   Sr                      

 

and

 

Now we are ready to prove the correctness of Theorem  
By Lemma   all the arms that we add into the set   at
Line   are in     The rest of our job is to look at the
arms in the set   cid 
When the algorithm exits the outer while loop  at round
       and arrives at Line   we have by the condition of
the outer while loop that

                        

 
Let             and                           im 
be the          empiricalmeans of the arms that we pick
at Line   Note that it is not necessary that             
jm  By Lemma   and    for any              we have
  By the triangle

where                   im  Let cid       cid               cid jm
 cid js    is       

and  cid js    js       
 js    is           

 
We thus can bound the error introduced by arms in   cid  by

 

inequality  it holds that

 cid 

      cid 

    

      cid 

    

 cid 

   

    cid 

    cid 

  

by                     

by      

  Query Complexity of Algorithm  

 in the statement of Theorem  

Recall
that
                    is the largest integer satisfying

              

   

 

Lemma   If the algorithm exits the outer while loop at
round        then we must have

               

 

The proof is deferred to the full version of this paper 

Lemma   For any arm    let ri be the round where arm
  is removed from the candidate set if this ever happens 
otherwise set ri      We must have
     ri      

 

The proof is deferred to the full version of this paper 
With Lemma   and Lemma   we are ready to analyze the
query complexity of the algorithm in Theorem   We can
bound the number of pulls on each arm   by at most

     log nj      cid log ri         ri cid   

ri cid 

 

Adaptive MultipleArm Identi cation

Now let us upperbound the RHS of   First  if       
then by   we know that ri   log   
       Second 
by   we have ri        log   
       Third  since
         otherwise the algorithm will exit the outer
while loop  we have ri        log         To summarize  we have ri   log  min 
        
 
       
   
  
We
 recall
thus
by

   
max       
of
the RHS
      min     

  cid log log 

 
upperbound
     log  

  cid   

that  
 

 

The total cost is   summation over all   arms 

 

log  min 

 

can

Remark   As we stated in Theorem   the log   factor
from Theorem   can be removed  On the other hand  our
lower bound result  see Theorem   shows that an extra
log  in Theorem   is necessary when we make the algorithm adaptive  The proofs of Theorem   and Theorem  
are deferred to the full version of this paper 

  Experiments
In this section we present the experimental results  While
our theorems are presented in the PAC form  it is in general
dif cult to verify them directly because the parameter   is
merely an upper bound and the actual aggregate regret may
deviate from it  In our experiment  we convert our Algorithm   to the  xedbudget version  that is     the budget of
the number of pulls and calculate the aggregate regret  We
compare our Algorithm    AdaptiveTopK   with two stateof theart methods   OptMAI in Zhou et al    and
CLUCBPAC in Chen et al    The comparison between OptMAI  CLUCBPAC and previous methods      
the methods in Bubeck et al    and Kalyanakrishnan
et al    have already been demonstrated in Zhou et al 
  and Chen et al    and thus are omitted due to
space constraints  To convert our algorithm to the  xedbudget version  we remove the outer while loop of Algorithm   As   replacement  we keep track of the total number of pulls  and stop pulling the arms once the budget is
exhausted 
We test our algorithm on both synthetic and real datasets
 due to space constraints  our results on real datasets are
deferred to the full version of this paper  as described as
follows 

  TWOGROUP  the mean reward for the top   arms is
set to   and that for the rest of the arms is set to  

  for           

  UNIFORM  we set           
  SYNTHETICp  we set           
    
for each       and           
      
for each        Note that SYNTHETIC  is identical
to UNIFORM  When   is larger than   arms are made

         
       

       
         

 

closer to the boundary that separates the topK from
the rest            
    When   is smaller than   arms
are made farther to the boundary  We normalize all the
arms such that the mean values of the arms still span
the whole interval     We consider          

We set the total number of arms         the tolerance
parameter       and vary the parameter    In AdaptiveTopK and CLUCBPAC  another parameter         the
failure probability  is required and we set      
For each dataset  we  rst    the budget  total number of
pulls allowed  and run each algorithm   times  For each
algorithm  we calculate the empirical probability  over  
runs  that the aggregate regret of the selected arms is above
the tolerance threshold       which is called failure
probability    smaller failure probability means better performance  For each dataset and different    we plot the
curve of failure probability by varying the number of pulls 
The results are shown in Figure  
It can be observed from the experimental results that AdaptiveTopK  Algorithm   outperforms CLUCBPAC in almost all the datasets  When   is relatively small  OptMAI has the best performance in most datasets  When  
is large  AdaptiveTopK outperforms OptMAI   The details
of the experimental results are elaborated as follows 

  For TWOGROUP dataset  see Figure   AdaptiveTopK outperforms other algorithms signi cantly for
all values of    The advantage comes from the adaptivity of our algorithm  In the TWOGROUP dataset 
topK arms are very well separated from the rest 
Once our algorithm identi es this situation  it need
only   few pulls to classify the arms  In details  the
inner while loop  Line   of Algorithm   make it possible to accept reject   large number of arms in one
round as long as the algorithm is con dent 

  As   increases  the advantage of AdaptiveTopK over
other algorithms  OptMAI in particular  becomes
more signi cant  This can be explained by the de 
nition of                 usually becomes bigger
as   grows  leading to   smaller hardness parameter
     

    comparison between SYNTHETIC  UNIFORM 
SYNTHETIC  reveals that the advantage of AdaptiveTopK over other algorithms  OptMAI in particular  becomes signi cant in both extreme scenarios 
     when arms are very well separated     cid    and
when arms are very close to the separation boundary
    cid   

Adaptive MultipleArm Identi cation

         

         

         

Figure   TWOGROUP dataset

         

         

         

Figure   SYNTHETIC  dataset

         

         

         

Figure   UNIFORM dataset

         

         

         

Figure   SYNTHETIC  dataset

  Conclusion and Future Work
In this paper  we proposed two algorithms for   PAC
version of the multiplearm identi cation problem in  
stochastic multiarmed bandit  MAB  game  We introduced   new hardness parameter for characterizing the dif 
 culty of an instance when using the aggregate regret as the
evaluation metric  and established the instancedependent
sample complexity based on this hardness parameter  We
also established lower bound results to show the optimality of our algorithm in the worst case  Although we only
consider the case when the reward distribution is supported
on     it is straightforward to extend our results to subGaussian reward distributions 
For future directions  it is worthwhile to consider more gen 

eral problem of pure exploration of MAB under matroid
constraints  which includes the multiplearm identi cation
as   special case  or other polynomialtime computable
combinatorial constraints such as matchings  It is also interesting to extend the current work to  nding topK arms
in   linear contextual bandit framework 

References
AbbasiYadkori  Yasin  Bartlett  Peter  Chen  Xi  and
Malek  Alan  Largescale markov decision problems
with KL control cost and its application to crowdsourcing  In Proceedings of International Conference on Machine Learning  ICML   

Audibert       Bubeck     and Munos     Best arm iden 

Adaptive MultipleArm Identi cation

Garivier     and Kaufmann     Optimal bestarm identi 
cation with  xed con dence  In Proceedings of the Conference on Learning Theory  COLT   

Jamieson  Kevin  Malloy  Matthew  Nowak  Robert  and
Bubeck    ebastien  UCB   An optimal exploration algorithm for multiarmed bandits  In Proceedings of the
Conference on Learning Theory  COLT   

Jun  KwangSung  Jamieson  Kevin  Nowak  Robert  and
Zhu  Xiaojin  Top arm identi cation in multiarmed bandits with batch arm pulls  In Proceedings of the International Conference on Arti cial Intelligence and Statistics
 AISTATS   

Kalyanakrishnan  Shivaram  Tewari  Ambuj  Auer  Peter 
and Stone  Peter  PAC subset selection in stochastic
In Proceedings of International
multiarmed bandits 
Conference on Machine Learning  ICML   

Karnin  Zohar  Koren  Tomer  and Somekh  Oren  Almost
optimal exploration in multiarmed bandits  In Proceedings of International Conference on Machine Learning
 ICML   

Kaufmann  Emilie  Capp    Olivier  and Garivier  Aur elien 
On the complexity of best arm identi cation in multiarmed bandit models  Journal of Machine Learning Research     

Mannor  Shie and Tsitsiklis  John    The sample complexity of exploration in the multiarmed bandit problem  Journal of Machine Learning Research   
 

Russo  Daniel  Simple bayesian algorithms for best arm
In Proceedings of the Conference on

identi cation 
Learning Theory  COLT   

Soare  Marta  Lazaric  Alessandro  and Munos  Remi 
Bestarm identi cation in linear bandits  In Proceedings
of Advances in Neural Information Processing Systems
 NIPS   

Zhou  Yuan  Chen  Xi  and Li  Jian  Optimal PAC multiple arm identi cation with applications to crowdsourcing  In Proceedings of International Conference on Machine Learning  ICML   

ti cation in multiarmed bandits  In Proceedings of the
Conference on Learning Theory  COLT   

Bubeck  Sebastian  Wang  Tengyao  and Viswanathan 
Nitin  Multiple identi cations in multiarmed bandits 
In Proceedings of the International Conference on Machine Learning  ICML   

Cao  Wei  Li  Jian  Tao  Yufei  and Li  Zhize  On topk selection in multiarmed bandits and hidden bipartite
graphs  In Proceedings of Advances in Neural Information Processing Systems  NIPS   

Chen  Lijie  Gupta  Anupam  and Li  Jian  Pure exploration
of multiarmed bandit under matroid constraints  In Proceedings of the Conference on Learning Theory  COLT 
   

Chen  Lijie  Li  Jian  and Qiao  Mingda  Towards instance optimal bounds for best arm identi cation  arXiv
preprint arXiv     

Chen  Shouyuan  Lin  Tian  King  Irwin  Lyu  Michael   
and Chen  Wei  Combinatorial pure exploration of multiIn Proceedings of Advances in Neural
armed bandits 
Information Processing Systems  NIPS   

Chen  Xi  Lin  Qihang  and Zhou  Dengyong  Statistical
decision making for optimal budget allocation in crowd
labeling  Journal of Machine Learning Research   
   

EvenDar  Eyal  Mannor  Shie  and Mansour  Yishay  PAC
bounds for multiarmed bandit and markov decision proIn Proceedings of the Annual Conference on
cesses 
Learning Theory  COLT   

EvenDar  Eyal  Mannor  Shie  and Mansour  Yishay  Action elimination and stopping conditions for the multiarmed bandit and reinforcement
learning problems 
Journal of machine learning research   
 

Gabillon  Victor  Ghavamzadeh  Mohammad  Lazaric 
Alessandro  and Bubeck    ebastien  Multibandit best
arm identi cation  In Proceedings of Advances in Neural Information Processing Systems  NIPS   

Gabillon  Victor  Ghavamzadeh  Mohammad  and Lazaric 
Alessandro  Best arm identi cation    uni ed approach
In Proceedings
to  xed budget and  xed con dence 
of Advances in Neural Information Processing Systems
 NIPS   

Gabillon  Victor  Lazaric  Alessandro  Ghavamzadeh  Mohammad  Ortner  Ronald  and Bartlett  Peter  Improved
learning complexity in combinatorial pure exploration
bandits  In Proceedings of the International Conference
on Arti cial Intelligence and Statistics   

