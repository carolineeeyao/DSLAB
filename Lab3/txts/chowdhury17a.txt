On Kernelized Multiarmed Bandits

Sayak Ray Chowdhury   Aditya Gopalan  

Abstract

We consider the stochastic bandit problem with
  continuous set of arms  with the expected reward function over the arms assumed to be  xed
but unknown  We provide two new Gaussian
processbased algorithms for continuous bandit
optimization   Improved GPUCB  IGPUCB 
and GPThomson sampling  GPTS  and derive
corresponding regret bounds  Speci cally  the
bounds hold when the expected reward function
belongs to the reproducing kernel Hilbert space
 RKHS  that naturally corresponds to   Gaussian process kernel used as input by the algorithms  Along the way  we derive   new selfnormalized concentration inequality for vectorvalued martingales of arbitrary  possibly in nite 
dimension  Finally  experimental evaluation and
comparisons to existing algorithms on synthetic
and realworld environments are carried out that
highlight the favorable gains of the proposed
strategies in many cases 

  Introduction
Optimization over large domains under uncertainty is an
important subproblem arising in   variety of sequential decision making problems  such as dynamic pricing in economics  Besbes   Zeevi    reinforcement learning
with continuous state action spaces  Kaelbling et al   
Smart   Kaelbling    and power control in wireless
communication  Chiang et al      typical feature of
such problems is   large  or potentially in nite  domain of
decision points or covariates  prices  actions  transmit powers  together with only partial and noisy observability of
the associated outcomes  demand  state reward  communication rate  reward loss information is revealed only for
decisions that are chosen  This often makes it hard to bal 
 Department of Electrical Communication EngineerIndian Institute of Science  Bengaluru   
India 
Sayak Ray Chowdhury  srchowd 

ing 
Correspondence
hury ece iisc ernet in 

to 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

ance exploration and exploitation  as available knowledge
must be transferred ef ciently from    nite set of observations so far to estimates of the values of in nitely many
decisions    classic case in point is that of the canonical
stochastic MAB with  nitely many arms  where the effort
to optimize scales with the total number of arms or decisions  the effect of this is catastrophic for large or in nite
arm sets 
With suitable structure in the values or rewards of arms 
however  the challenge of sequential optimization can be
ef ciently addressed  Parametric bandits  especially linearly parameterized bandits  Rusmevichientong   Tsitsiklis    represent   wellstudied class of structured decision making settings  Here  every arm corresponds to  
known   nite dimensional vector  its feature vector  and
its expected reward is assumed to be an unknown linear
function of its feature vector  This allows for   large  or
even in nite  set of arms all lying in space of  nite dimension  say    and   rich line of work gives algorithms that
attain sublinear regret with   polynomial dependence on
the dimension       Con dence Ball  Dani et al   
OFUL  AbbasiYadkori et al       strengthening of
Con dence Ball  and Thompson sampling for linear bandits  Agrawal   Goyal    The insight here is that even
though the number of arms can be large  the number of unknown parameters  or degrees of freedom  in the problem
is really only    which makes it possible to learn about the
values of many other arms by playing   single arm 
  different approach to modelling bandit problems with  
continuum of arms is via the framework of Gaussian processes  GPs   Rasmussen   Williams    GPs are
   exible class of nonparametric models for expressing
uncertainty over functions on rather general domain sets 
which generalize multivariate Gaussian random vectors 
GPs allow tractable regression for estimating an unknown
function given   set of  noisy  measurements of its values
at chosen domain points  The fact that GPs  being distributions on functions  can also help quantify function uncertainty makes it attractive for basing decision making strategies on them  This has been exploited to great advantage to
 Roughly  for rewards bounded in     these algorithms
  where      hides polylog    

 
 

 cid 

 cid 

 

achieve optimal regret   
factors 

On Kernelized Multiarmed Bandits

build nonparametric bandit algorithms  such as GPUCB
 Srinivas et al    GPEI and GPPI  Hoffman et al 
  In fact  GP models for bandit optimization  in terms
of their kernel maps  can be viewed as the parametric linear
bandit paradigm pushed to the extreme  where each feature
vector associated to an arm can have in nite dimension  
Against this backdrop  our work revisits the problem of
bandit optimization with stochastic rewards  Speci cally 
we consider stochastic multiarmed bandit  MAB  problems
with   continuous arm set  and whose  unknown  expected
reward function is assumed to lie in   reproducing kernel
Hilbert space  RKHS  with bounded RKHS norm   this
effectively enforces smoothness on the function  We make
the following contributions 

  We design   new algorithm   Improved Gaussian
ProcessUpper Con dence Bound  IGPUCB    for
stochastic bandit optimization  The algorithm can be
viewed as   variant of GPUCB  Srinivas et al   
but uses   signi cantly reduced con dence interval
width resulting in an orderwise improvement in regret compared to GPUCB  IGPUCB also shows  
markedly improved numerical performance over GPUCB 

 

 cid 

 cid 

  We develop   nonparametric version of Thompson
sampling  called Gaussian Process Thompson sampling  GPTS  and show that enjoys   regret bound
of   
  Here    is the total time horizon and
   is   quantity depending on the RKHS containing
the reward function  This is  to our knowledge  the
 rst known regret bound for Thompson sampling in
the agnostic setup with nonparametric structure 

dT

  

  We prove   new selfnormalized concentration inequality for in nitedimensional vectorvalued martingales  which is not only key to the design and
analysis of the IGPUCB and GPTS algorithms  but
also potentially of independent interest  The inequality generalizes   corresponding selfnormalized bound
for martingales in  nite dimension proven by AbbasiYadkori et al   

  Empirical comparisons of the algorithms developed
above  with other GPbased algorithms  are presented 
over both synthetic and realworld setups  demonstrating performance improvements of the proposed algorithms  as well as their performance under misspeci 
cation 

 The completion of the linear span of all feature vectors  images of the kernel map  is precisely the reproducing kernel Hilbert
space  RKHS  that characterizes the GP 

 Kernels  and their associated RKHSs 

  Problem Statement
We consider the problem of sequentially maximizing  
 xed but unknown reward function           over  
 potentially in nite  set of decisions     Rd  also called
actions or arms  An algorithm for this problem chooses  at
each round    an arm xt      and subsequently observes
  reward yt      xt        which is   noisy version of the
function value at xt  The arm xt is chosen causally depending upon the arms played and rewards obtained upto
round      denoted by the history Ht     xs  ys       
             We assume that the noise sequence    
   is
conditionally Rsub Gaussian for    xed constant      
 cid 
    

                cid 

     cid cid  Ft 

 cid    exp

 cid     

 

 

 

RT  cid  

where Ft  is the  algebra generated by the random variables  xs       
   and xt This is   mild assumption on the
noise  it holds  for instance  for distributions bounded in
       and is standard in the bandit literature  AbbasiYadkori et al    Agrawal   Goyal   
Regret  The goal of an algorithm is to maximize its cumulative reward or alternatively minimize its cumulative
regret   the loss incurred due to not knowing     maximum point beforehand  Let   cid    argmaxx         be
  maximum point of    assuming the maximum is attained  The instantaneous regret incurred at time   is
rt        cid       xt  and the cumulative regret in   time
horizon    not necessarily known   priori  is de ned to be
   rt    sublinear growth of RT in   signi es
that RT        as       or vanishing perround regret 
Regularity Assumptions  Attaining sublinear regret is
impossible in general for arbitrary reward functions   and
domains    and thus some regularity assumptions are in
order  In what follows  we assume that   is compact  The
smoothness assumption we make on the reward function  
is motivated by Gaussian processes  and their associated
reproducing kernel Hilbert spaces  RKHSs  see Sch olkopf
  Smola   Speci cally  we assume that   has small
norm in the RKHS of functions        with positive
semide nite kernel function              This RKHS 
denoted by Hk    is completely speci ed by its kernel
function    and viceversa  with an inner product  cid cid  
obeying the reproducing property           cid        cid   for
all     Hk    In other words  the kernel plays the role
of delta functions to represent the evaluation map at each
point       via the RKHS inner product  The RKHS

norm  cid   cid      cid cid      cid   is   measure of the smoothness 

 Other work has also studied continuumarmed bandits with
weaker smoothness assumptions such as Lipschitz continuity  
see Related work for details and comparison 

 One way to see this is that

for every element   in
                cid               cid   

the RKHS 
 cid   cid    cid            cid   by CauchySchwarz 

On Kernelized Multiarmed Bandits

of    with respect to the kernel function    and satis es 
    Hk    if and only if  cid   cid      
We assume   known bound on the RKHS norm of the unknown target function   cid   cid        Moreover  we assume
bounded variance by restricting             for all       
Two common kernels that satisfy bounded variance property are Squared Exponential and Mat ern  de ned as

kSE     

kM at ern     

 cid 

 cid 

    exp
 
 

   

 cid        cid 
 cid   
 cid 

 

 

 
 

  

 cid   

 

 
 

 cid 

 

where       and       are hyperparameters     
 cid       cid cid  encodes the similarity between two points
     cid       and    is the modi ed Bessel function  Generally the bounded variance property holds for any stationary kernel       kernels for which        cid            cid  for
all      cid    Rd  These assumptions are required to make
the regret bounds scalefree and are standard in the literature  Agrawal   Goyal    Instead if             or
 cid   cid     cB  then our regret bounds would increase by  
factor of   

  Algorithms
Design philosophy  Both the algorithms we propose
use Gaussian likelihood models for observations  and
Gaussian process  GP  priors for uncertainty over reward functions    Gaussian process over    denoted
by GPD     is   collection of random variables
           one for each        such that every  nite
subcollection of random variables     xi  
   is jointly
Gaussian with mean       xi     xi  and covariance
      xi     xi    xj     xj      xi  xj     
                 The algorithms use GPD      
      as an initial prior distribution for the unknown reward function   over    where    is the kernel function associated with the RKHS Hk    in which   is assumed to have  small  norm at most    The algorithms
also assume that the noise variables      yt      xt 
are drawn independently  across    from         with
      Thus  the prior distribution for each       is assumed to be                      Moreover  given
  set of sampling points At               xt  within    it
follows under the assumption that the corresponding vector of observed rewards                   yt   has the multivariate Gaussian distribution       Kt       where
Kt           cid     cid At is the kernel matrix at time    Then 
by the properties of GPs  we have that     and       are
jointly Gaussian given At 

 cid      
 cid 

   

 cid 

 cid          

   

 

 cid cid 

 

  kt    

  kt   

  Kt      

 This is analogous to the bound on the weight   typically as 

sumed in regret analyses of linear parametric bandits 

where kt                         xt        Therefore conditioned on the history Ht  the posterior distribution over  
is GPD      kt  where

     

 
        kt      

        kt      Kt          

 
kt      cid           cid    kt      Kt      kt   cid 
 
Thus for every        the posterior distribution of      
given Ht  is           
Remark  Note that the GP prior and Gaussian likelihood
model described above is only an aid to algorithm design 
and has nothing to do with the actual reward distribution
or noise model as in the problem statement  Section  
The reward function   is    xed  unknown  member of the
RKHS Hk    and the true sequence of noise variables   
is allowed to be   conditionally Rsub Gaussian martingale
difference sequence  Equation   In general  thus  this represents   misspeci ed prior and noise model  also termed
the agnostic setting by Srinivas et al   
The proposed algorithms  to follow  assume the knowledge
of only the subGaussianity parameter    kernel function  
and upper bound   on the RKHS norm of    Note that     
are free parameters  possibly timedependent  that can be
set speci   to the algorithm 

  Improved GPUCB  IGPUCB  Algorithm

We introduce the IGPUCB algorithm  Algorithm   that
uses   combination of the current posterior mean      
and standard deviation        to     construct an upper
con dence bound  UCB  envelope for the actual function
  over    and     choose an action to maximize it  Specifically it chooses  at each round    the action

xt   argmax

   

               

 

with the scale parameter   set to be   Such   rule
trades off exploration  picking points with high uncertainty
      with exploitation  picking points with high re 

ward       with            cid          ln 

being the parameter governing the tradeoff  which we later
show is related to the width of the con dence interval for  
at round            is   free con dence parameter used
by the algorithm  and    is the maximum information gain
at time    de ned as 

     max

       

  yA  fA 

Here    yA  fA  denotes the mutual information between
fA             and yA   fA       where     
          and quanti es the reduction in uncertainty
about   after observing yA at points           is
  problem dependent quantity and can be found given
the knowledge of domain   and kernel function    For

On Kernelized Multiarmed Bandits

  compact subset   of Rd     is   ln       and
             ln     respectively  for the Squared
Exponential and Mat ern kernels  Srinivas et al    depending only polylogarithmically on the time    

Algorithm   ImprovedGP UCB  IGPUCB 

Input  Prior GP      parameters          
for                   do

Set            cid          ln 

               

Choose xt   argmax
Observe reward yt      xt       
Perform update to get    and    using     and  

   

end for

 cid 

Discussion  Srinivas et al    have proposed the GPUCB algorithm  and Valko et al    the KernelUCB
algorithm  for sequentially optimizing reward functions lying in the RKHS Hk    Both algorithms play an arm
at time   using the rule  xt   argmaxx          
        GPUCB uses the exploration parameter     
          ln    with   set to   where   is
additionally assumed to be   known  uniform       almostsure  upper bound on all noise variables     Srinivas et al 
  Theorem   Compared to GPUCB  IGPUCB  Algorithm   reduces the width of the con dence interval by
  factor roughly   ln     at every round    and  as we
will see  this small but critical adjustment leads to much
better theoretical and empirical performance compared to
GPUCB  In KernelUCB     is set as   where   is
the exploration parameter and   is the regularization constant  Thus IGPUCB can be viewed as   special case of
KernelUCB where        

  Gaussian Process Thompson Sampling  GPTS 

  cid          ln  and operates as follows  At

Our second algorithm  GPTS  Algorithm  
inspired
by the success of Thompson sampling for standard and
parametric bandits  Agrawal   Goyal    Kaufmann
et al    Gopalan et al    Agrawal   Goyal 
  uses the timevarying scale parameter vt      
each round    GPTS samples   random function ft  from
the GP with mean function     and covariance function
  kt  Next  it chooses   decision set Dt      and
  
plays the arm xt   Dt that maximizes ft
  We call it GPThompson Sampling as it falls under the general framework of Thompson Sampling           assume   prior on the
underlying parameters of the reward distribution      play
the arm according to the prior probability that it is optimal 

 If Dt     for all    then this is simply exact Thompson
sampling  For technical reasons  however  our regret bound is
valid when Dt is chosen as   suitable discretization of    so we
include Dt as an algorithmic parameter 

and     observe the outcome and update the prior  However 
note that the prior is nonparametric in this case 

Algorithm   GPThompson Sampling  GPTS 
Input  Prior GP      parameters          
for                   do

Set vt         cid          ln 

  kt 

Sample ft  from GPD      
Choose the current decision set Dt     
Choose xt   argmax
Observe reward yt      xt       
Perform update to get    and kt using   and  

ft   

  Dt

end for

  Main Results
We begin by presenting two key concentration inequalities
which are essential in bounding the regret of the proposed
algorithms 
Theorem   Let  xt 
   be an Rdvalued discrete time
stochastic process predictable with respect to the  ltration
 Ft 
        xt is Ft measurable        Let    
be   realvalued stochastic process such that for some    
  and for all          is     Ftmeasurable  and     Rsub 
Gaussian conditionally on Ft  Let     Rd Rd     be  
symmetric  positivesemide nite kernel  and let          
For   given       with probability at least       the following holds simultaneously over all      

  

 cid det         Kt 

 Kt            ln

 cid   cid 
 
 
 Here  Kt denotes the       matrix Kt           xi  xj 
             and for any     Rt and     Rt     cid   cid    
 
xT Ax  Moreover  if Kt is positive de nite        with
probability   then the conclusion above holds with      

 

Theorem   represents   selfnormalized concentration inequality  the  size  of the increasinglength sequence     
of martingale differences is normalized by the growing
quantity  Kt            that explicitly depends on
the sequence  The following lemma helps provide an alternative  abstract  view of the selfnormalized process of
Theorem   based on the feature space representation induced by   kernel 
Lemma   Let     Rd   Rd     be   symmetric  positivesemide nite kernel  with associated feature map     Rd  
Hk and the reproducing kernel Hilbert space   RKHS  Hk 
 Such   pair   Hk  always exists  see      Rasmussen  

Williams  

Letting St    cid  
mensional  matrix  Vt     cid  

whenever Kt is positive de nite  that

      xs  and the  possibly in nite dis   xs xs     we have 

On Kernelized Multiarmed Bandits

denotes the norm of

 cid cid  Ft 

 cid   

 cid   cid  

 cid cid cid  

     cid St cid  

 

 
 

 
     
 
 
St in the RKHS Hk 

where  cid St cid  
 
 
 

Observe that St is Ftmeasurable and also   cid St

 
 

 

St

 cid cid cid Hk

 

St  The process  St    is thus   martingale with values  in the RKHS    which can possibly be in nitedimensional  and moreover  whose deviation is measured
by the norm weighted by    
  which is itself derived from
St  Theorem   represents the kernelized generalization
of the  nitedimensional result of AbbasiYadkori et al 
  and we recover their result under the special case
of   linear kernel          for all     Rd 
We remark that when   is   mapping to    nitedimensional
Hilbert space  the argument of AbbasiYadkori et al   
Theorem   can be lifted to establish Theorem   but
it breaks down in the generalized 
in nitedimensional
RKHS setting  as the selfnormalized bound in their paper has an explicit  growing dependence on the feature dimension  Speci cally  the method of mixtures  de la Pena
et al    or Laplace method  as dubbed by Maillard
  fails to hold in in nite dimension  The primary reason for this is that the mixture distribution for  nite dimensional spaces can be chosen independently of time  but in  
nonparametric setup like ours  where the dimensionality of

the selfnormalizing factor cid   

      cid  itself grows with

time  the use of  random  stopping times  precludes using
timedependent mixtures  We get around this dif culty by
applying   novel  double mixture  construction  in which  
pair of mixtures on     the space of realvalued functions on
Rd       the support of   Gaussian process  and     on real
sequences is simultaneously used to obtain   more general
result  of potentially independent interest 
Our next result shows that how the posterior mean is concentrated around the unknown reward function   
Theorem   Under the same hypotheses as those of Theorem   let     Rd  and           be   member of the
RKHS of realvalued functions on   with kernel    with
RKHS norm bounded by    Then  with probability at least
 cid 
      cid          ln 
      the following holds for all       and      

               cid 

     
where     is the maximum information gain after      
rounds and        
     are mean and variance of
 More formally  Vt   Hk   Hk is the linear operator de ned

by Vt         cid  

    xs cid xs    cid       Hk 

 We ignore issues of measurability here 

posterior distribution de ned as in Equation       with  
set to       and         

Theorem   of Maillard   states   similar result on
the estimation of the unknown reward function from the
RKHS  We improve upon it in the sense that the con dence
bound in Theorem   is simultaneous over all        while
the bound has been shown only for   single   xed   in the
Kernel Leastsquares setting  We are able to achieve this
result by virtue of Theorem  

  Regret Bound of IGPUCB
Theorem   Let          cid   cid       and    is condition 
 cid 
 cid 
ally Rsub Gaussian  Running IGPUCB for   function  
lying in the RKHS Hk    we obtain   regret bound of
with high probability  More preO
 cid 
 cid           ln 
cisely  with probability at least     RT    

         

      

 cid 

    

 

 

 

 

 

    

 cid 

 cid 

Improvement over GPUCB  Srinivas et al    in
the course of analyzing the GPUCB algorithm  show
that when the reward function lies in the RKHS Hk   
        ln    
GPUCB obtains regret  
with high probability  see Theorem   therein for the exact bound  Furthermore  they assume that the noise   
is uniformly bounded by   while our subGaussianity assumption  see Equation   is slightly more general  and
we are able to obtain     ln      multiplicative factor
improvement in the  nal regret bound thanks to the new
selfnormalized inequality  Theorem   Additionally  in
our numerical experiments  we observe   signi cantly improved performance of IGPUCB over GPUCB  both on
synthetically generated function  and on realworld sensor
measurement data  see Section  
Comparison with KernelUCB  Valko et al    show
that the cumulative regret of KernelUCB is    
where     de ned as the effective dimension  measures  in
  sense  the number of principal directions over which
the projection of the data in the RKHS is spread  They
show that    is at least as good as      precisely     
 
     ln ln     and thus the regret bound of KernelUCB is
roughly    
   factor better than IGPUCB  However  KernelUCB requires the number of actions
to be  nite  so the regret bound is not applicable for in nite
or continuum action spaces 

 cid   dT  

       which is

 

  Regret Bound of GPTS

For technical reasons  we will analyze the following version of GPTS  At each round    the decision set used
by GPTS is restricted to be   unique discretization Dt

On Kernelized Multiarmed Bandits

of   with the property that                       
for all        where      is the closest point to   in
Dt  This can always be achieved by choosing   compact and convex domain           and discretization
Dt with size  Dt     BLrdt   such that  cid          cid   
rd BLrdt     BLt  for all        where    
  This implies  for every    
sup
   
  

 cid         

 cid 

      

sup
    

 pj  qj

                    cid   cid     cid          cid       

 
as any     Hk    is Lipschitz continuous with constant
 cid   cid      De Freitas et al    Lemma  
Theorem    Regret bound for GPTS  Let        
          be compact and convex   cid   cid       and
       conditionally Rsub Gaussian sequence  Running GPTS for   function   lying in the RKHS Hk   
and with decision sets Dt chosen as above  with probthe regret of GPTS satisability at
 es RT    
      

 cid 
 cid cid     ln   ln BdT  
 cid cid 
  cid   ln 

least      

 

 

  factor away from the bound     

Comparison with IGPUCB  Observe that regret scal 
 
ing of GPTS is     
dT   which is   multiplicative
    obtained for
IGPUCB and similar behavior is re ected in our simulations on synthetic data  The additional multiplicative fac 

tor of  cid   ln BdT   in the regret bound of GPTS is es 

 

sentially   consequence of discretization  How to remove
this extra logarithmic dependency  and make the analysis
discretizationindependent  remains an open question 
Remark  The regret bound for GPTS is inferior compared
to IGPUCB in terms of the dependency on dimension   
but to the best of our knowledge  Theorem   is the  rst
 frequentist  regret guarantee of Thompson Sampling in the
agnostic  nonparametric setting of in nite action spaces 
Linear Models and   Matching Lower Bound 
If the
if there exists  
mean rewards are perfectly linear      
    Rd such that              for all        then we
are in the parametric setup  and one way of casting this
in the kernelized framework is by using the linear kernel
       cid    xT   cid  For this kernel           ln     and the
regret scaling of IGPUCB is     
    and that of GPTS
is      
    which recovers the regret bounds of their
linear  parametric analogues OFUL  AbbasiYadkori et al 
  and Linear Thompson sampling  Agrawal   Goyal 
  respectively  Moreover  in this case         thus
  factor away from that of Kerthe regret of IGPUCB is
nelUCB  But the regret bound of KernelUCB also depends
on the number of arms    and if   is exponential in   
then it also suffers     
    regret  We remark that   sim 

 

 

 

 

ilar   ln      factor improvement  as obtained by IGPUCB over GPUCB  was achieved in the linear parametric
setting by  AbbasiYadkori et al    in the OFUL algorithm  over its predecessor Con denceBall  Dani et al 
  Finally we see that the for linear bandit problem
 
with in nitely many actions  IGPUCB attains the inforT    see  Dani et al 
mation theoretic lower bound of   
  but GPTS is   factor of

  away from it 

 

   

 cid 

    exp  

 tg      

 cid 
   cid     cid 

  Overview of Techniques
We brie   outline here the key arguments for all the theorems in Section   See Chowdhury   Gopalan   for
complete proofs 
Proof Sketch for Theorem  
It is convenient to assume that Kt  the induced kernel matrix at time    is invertible  since this is where the crux of the argument lies 
First we show that for any function           and
for all       thanks to the subGaussian property  
is   nonthe process
negative supermartingale with respect to the  ltration Ft 
where    
                  xt   and in fact satis es
        The chief dif culty is to handle the behavE     
ior of Mt at    random  stopping time  since the sizes of
quantities such as    at the stopping time will be random 
We next construct   mixture martingale Mt by mixing    
  over   drawn from an independent GPD    
Gaussian process  which is   measure over   large
space of functions 
Then  by  
change of measure argument  we show that this induces
  mixture distribution which is essentially     Kt  over
any desired  nite dimension   
thus obtaining Mt  
 
  Next from the fact
 
 
 
that             and from Markov   inequality  for any
        we obtain

 cid   
   cid   cid 

the space RD 

det   Kt 

 cid 

    

exp

    

 

 cid cid det         

 cid cid     

  cid cid cid 

          ln
 

  

    

     

Finally  we lift this bound for all   through   standard stopping time construction as in AbbasiYadkori et al   
Proof Sketch for Theorem   Here we sketch the
special case of      
Observe that               is upper bounded by sum of

two terms       cid cid kt      Kt      
 cid cid  and    
 cid cid kt      Kt                cid cid  Now we observe that
vation to show that      cid cid       
 cid cid 
           cid cid  which are in turn upand      cid cid       

            and use this obsert   
per bounded by the terms      cid St cid  
and  cid   cid        
respectively  Then the result follows using Theorem  
along with the assumption that  cid   cid       and the fact that
  ln det     Kt            when Kt is invertible 

 
               

          

 
 

 

On Kernelized Multiarmed Bandits

Proof Sketch for Theorem   First from Theorem   and
the choice of xt in Algorithm   we show that the instantaneous regret rt at round   is upper bounded by      xt 
with probability at least       Then the result follows by

bounding the term cid  

      xt  by   

      

 

Proof Sketch for Theorem   We follow   similar approach given in Agrawal   Goyal   to prove the regret bound of GPTS  First observe that from our choice of
discretization sets Dt  the instantaneous regret at round  
is given by rt        cid         cid           cid         xt   
        xt  where              cid            and    cid  
 
is the closest point to   cid  in Dt  Now at each round    after an action is chosen  our algorithm improves the con 
dence about true reward function    via an update of    
and kt  However  if we play   suboptimal arm  the regret suffered can be much higher than the improvement of
our knowledge  To overcome this dif culty  at any round
   we divide the arms  in the present discretization Dt 
into two groups  saturated arms  St  de ned as those with
        ct      and unsaturated otherwise  where ct
is an appropriate constant  The idea is to show that the
probability of playing   saturated arm is small and then
bound the regret of playing an unsaturated arm in terms
of standard deviation  This is useful because the inequality
       allows us to bound the total

 cid  
      xt      

 

 cid cid     cid 

xt   Dt   St

     cid 

regret due to unsaturated arms 
First we lower bound the probability of playing an unsaturated arm at round    We de ne    ltration    cid 
   as the history Ht  up to round       and prove that for  most   in
  high probability sense     cid 
 
     where       
  This observation  along with
concentration bounds for ft    and       and  smoothness 
of    allow us to show that the expected regret at round
  is upper bounded in terms of    xt      
in terms
of regret due to playing an unsaturated arm  More precisely  we show that for  most     cid 
     

 cid 
  cid 
  and use it to prove
  
that Xt  cid  rt    ct
        is  
     xt       
along with the bound on cid  
supermartingale difference sequence adapted to  ltration
    cid 
     Now  using the AzumaHoeffding inequality 
      xt  we obtain the de 

   xt cid cid     cid 

     cid 

 cid   

 cid cid     cid 

 cid   

  

 ct

 

rt

  

  

  

sired highprobability regret bound 

  Experiments
In this section we provide numerical results on both synthetically generated test functions and functions from realworld data  We compare GPUCB  IGPUCB and GPTS
with GPEI and GPPI 

 GPEI and PI perform similarly and thus are not separately

distinguishable in the plots 

   

   

Figure   Cumulative regret for functions lying in the RKHS corresponding to     Squared Exponential kernel and     Mat ern kernel 

   

   

Figure   Cumulative regret for functions lying in the GP corresponding to     Squared Exponential kernel and     Mat ern kernel 
Synthetic Test Functions  We use the following procedure
to generate test functions from the RKHS  First we sample
  points uniformly from the interval     and use that as
our decision set  Then we compute   kernel matrix   on
those points and draw reward vector            Finally 
the mean of the resulting posterior distribution is used as
the test function    We set noise parameter    to be  
of function range and use        We used Squared Exponential kernel with lengthscale parameter       and
Mat ern kernel with parameters             Parameters         vt of IGPUCB  GPUCB and GPTS are
chosen as given in Section   with                Kf
and    set according to theoretical upper bounds for corresponding kernels  We run each algorithm for      
iterations  over   independent trials  samples from the
RKHS  and plot the average cumulative regret along with
standard deviations  Figure   We see   signi cant improvement in the performance of IGPUCB over GPUCB 
In fact IGPUCB performs the best in the pool of competitors  while GPTS also fares reasonably well compared to
GPUCB and GPEI GPPI 
We next sample   random functions from the GP     
and perform the same experiment  Figure   for both kernels with exactly same set of parameters  The relative performance of all methods is similar to that in the previous
experiment  which is the arguably harder  agnostic  setting
of    xed  unknown target function 
Standard Test Functions  We consider   wellknown

       RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB       RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB       RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB       RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCBOn Kernelized Multiarmed Bandits

   

   

   

   

Figure   Cumulative regret for     Rosenbrock and     Hartman 
benchmark function 

Figure   Cumulative regret plots for     temperature data and    
light sensor data 

synthetic benchmark functions for Bayesian Optimization 
Rosenbrock and Hartman   see Azimi et al    for exact analytical expressions  We sample     points uniformly from the domain of each benchmark function    being the dimension of respective domain  as the decision set 
We consider the Squared Exponential kernel with      
and set all parameters exactly as in previous experiment 
The cumulative regret for   independent trials on Rosenbrock and Hartman  benchmarks is shown in Figure   We
see GPEI PI perform better than the rest  while IGPUCB
and GPTS show competitive performance  Here no algorithm is aware of the underlying kernel function  hence
we conjecture that the UCBand TSbased algorithms are
somewhat less robust on the choice of kernel than EI PI 
Temperature Sensor Data  We use temperature data 
collected from   sensors deployed in the Intel Berkeley
Research lab between February  th and April  th   
with samples collected at   second intervals  We tested all
algorithms in the context of learning the maximum reading of the sensors collected between   am to   am  We
take measurements of  rst   consecutive days  starting Feb 
 th   to learn algorithm parameters  Following Srinivas et al    we calculate the empirical covariance matrix of the sensor measurements and use it as the kernel
matrix in the algorithms  Here    is set to be   of the
average empirical variance of sensor readings and other algorithm parameters is set similarly as in the previous experiment with         found via crossvalidation  The functions for testing consist of one set of measurements from all
sensors in the two following days and the cumulative regret
is plotted over all such test functions  From Figure   we
see that IGPUCB and GPUCB performs the same  while
GPTS outperforms all its competitors 
Light Sensor Data  We take light sensor data collected
in the CMU Intelligent Workplace in Nov   which is
available online as Matlab structure  and contains locations of   sensors    train samples and   test samples 

 http db csail mit edu labdata labdata 

html

 http www cs cmu edu guestrin Class 

   projects lightsensor zip

  

We compute the kernel matrix  estimate the noise and set
other algorithm parameters exactly as in the previous experiment  Here also GPTS is found to perform better than
the others  with IGPUCB performing better than GPEI PI
 Figure  
Related work  An alternative line of work pertaining to
   armed bandits  Kleinberg et al    Bubeck et al 
  Carpentier   Valko    Azar et al    studies continuumarmed bandits with smoothness structure 
For instance  Bubeck et al    show that with   Lipschitzness assumption on the reward function  algorithms
based on discretizing the domain yield nontrivial regret
     in Rd  Other Bayesian
guarantees  of order   
approaches to function optimization are GPEI  Mo ckus 
  GPPI  Kushner    GPEST  Wang et al 
  and GPUCB  including the contextual  Krause  
Ong    highdimensional  Djolonga et al    Wang
et al    timevarying  Bogunovic et al    safetyaware  Gotovos et al    budgetconstraint  Hoffman
et al    and noisefree  De Freitas et al    settings  Other relevant work focuses on best arm identi cation problem in the Bayesian setup considering pure exploration  Gr unew alder et al    For Thompson sampling
 TS  Russo   Van Roy   analyze the Bayesian regret
of TS  which includes the case where the target function is
sampled from   GP prior  Our work obtains the  rst frequentist regret of TS for unknown   xed functions from an
RKHS 

  Conclusion
For bandit optimization  we have improved upon the existing GPUCB algorithm  and introduced   new GPTS algorithm  The proposed algorithms perform well in practice
both on synthetic and realworld data  An interesting case
is when the kernel function is also not known to the algorithms   priori and needs to be learnt adaptively  Moreover 
one can consider classes of time varying functions from the
RKHS  and general reinforcement learning with GP techniques  There are also important questions on computational aspects of optimizing functions drawn from GPs 

    RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB    RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB    RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCB       RoundsCumulativeRegret  GPPIGP EIGPTSGP UCBIGPUCBOn Kernelized Multiarmed Bandits

Acknowledgement
Aditya Gopalan was supported by the DST INSPIRE faculty grant IFA ENG  The authors are grateful to   
   Maillard for helpful discussions  and to anonymous reviewers for providing useful comments 

References
AbbasiYadkori  Yasin    al    avid  and Szepesv ari  Csaba 
Improved algorithms for linear stochastic bandits  In Advances in Neural Information Processing Systems  pp 
   

Agrawal  Shipra and Goyal  Navin  Analysis of thompson
sampling for the multiarmed bandit problem  In COLT 
pp     

Dani  Varsha  Hayes  Thomas    and Kakade  Sham   
Stochastic linear optimization under bandit feedback  In
COLT  pp     

De Freitas  Nando  Smola  Alex  and Zoghi  Masrour 
Exponential regret bounds for gaussian process banarXiv preprint
dits with deterministic observations 
arXiv   

de la Pena  Victor    Lai  Tze Leung  and Shao  QiMan 
Selfnormalized processes  probability and its applications   

Djolonga  Josip  Krause  Andreas  and Cevher  Volkan 
Highdimensional gaussian process bandits  In Advances
in Neural Information Processing Systems  pp   
   

Agrawal  Shipra and Goyal  Navin  Thompson sampling
for contextual bandits with linear payoffs  In ICML  pp 
   

Gopalan  Aditya  Mannor  Shie  and Mansour  Yishay 
In

Thompson sampling for complex online problems 
ICML  volume   pp     

Azar  Mohammad Gheshlaghi  Lazaric  Alessandro  and
Brunskill  Emma  Online stochastic optimization under
In ICML  pp   
correlated bandit feedback 
 

Azimi  Javad  Jalali  Ali  and Fern  Xiaoli  Hybrid batch
bayesian optimization  arXiv preprint arXiv 
 

Besbes  Omar and Zeevi  Assaf  Dynamic pricing without
knowing the demand function  Risk bounds and nearoptimal algorithms  Operations Research   
   

Bogunovic  Ilija  Scarlett  Jonathan  and Cevher  Volkan 
Timevarying gaussian process bandit optimization 
arXiv preprint arXiv   

Bubeck    ebastien  Munos    emi  Stoltz  Gilles  and
Szepesv ari  Csaba  Xarmed bandits  Journal of Machine Learning Research   May   

Carpentier  Alexandra and Valko  Michal  Simple regret for
in nitely many armed bandits  In ICML  pp   
 

Gotovos  Alkis  CH  ETHZ  and Burdick  Joel    Safe
exploration for optimization with gaussian processes 
 

Gr unew alder  Steffen  Audibert  JeanYves  Opper  Manfred  and ShaweTaylor  John  Regret bounds for gaussian process bandit problems  In AISTATS  pp   
 

Hoffman  Matthew    Brochu  Eric  and de Freitas  Nando 
Portfolio allocation for bayesian optimization  In UAI 
pp     

Hoffman  Matthew    Shahriari  Bobak  and de Freitas 
Nando  Exploiting correlation and budget constraints
arXiv
in bayesian multiarmed bandit optimization 
preprint arXiv   

Kaelbling  Leslie Pack  Littman  Michael    and Moore 
Andrew    Reinforcement learning    survey  Journal
of arti cial intelligence research     

Kaufmann  Emilie  Korda  Nathaniel  and Munos    emi 
Thompson sampling  An asymptotically optimal  nitetime analysis  In International Conference on Algorithmic Learning Theory  pp    Springer   

Chiang  Mung  Hande  Prashanth  Lan  Tian  and Tan 
Chee Wei  Power control in wireless cellular networks 
Foundations and Trends in Networking   
  ISSN     doi   

Kleinberg  Robert  Slivkins  Aleksandrs  and Upfal  Eli 
Multiarmed bandits in metric spaces  In Proceedings of
the fortieth annual ACM symposium on Theory of computing  pp    ACM   

Chowdhury  Sayak Ray and Gopalan  Aditya 

kernelized multiarmed bandits 
arXiv   

On
arXiv preprint

Krause  Andreas and Ong  Cheng    Contextual gaussian
process bandit optimization  In Advances in Neural Information Processing Systems  pp     

On Kernelized Multiarmed Bandits

Kushner  Harold      new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise  Journal of Basic Engineering   
   

Maillard  OdalricAmbrym  Selfnormalization techniques

for streaming con dent regression   

Mo ckus     On bayesian methods for seeking the exIn Optimization Techniques IFIP Technical

tremum 
Conference  pp    Springer   

Rasmussen  Carl Edward and Williams  Christopher KI 

Gaussian processes for machine learning   

Rusmevichientong  Paat and Tsitsiklis  John    Linearly
parameterized bandits  Math  Oper  Res   
  May  

Russo  Daniel and Van Roy  Benjamin  Learning to optimize via posterior sampling  Mathematics of Operations
Research     

Sch olkopf  Bernhard and Smola  Alexander    Learning
with kernels  support vector machines  regularization 
optimization  and beyond  MIT press   

Smart  William   and Kaelbling  Leslie Pack  Practical
reinforcement learning in continuous spaces  In ICML 
pp     

Srinivas  Niranjan  Krause  Andreas  Kakade  Sham    and
Seeger  Matthias  Gaussian process optimization in the
bandit setting  No regret and experimental design  arXiv
preprint arXiv   

Valko  Michal  Korda  Nathaniel  Munos    emi  Flaounas 
Finitetime analysis
arXiv preprint

Ilias  and Cristianini  Nelo 
of kernelised contextual bandits 
arXiv   

Wang  Zi  Zhou  Bolei  and Jegelka  Stefanie  Optimization
as estimation with gaussian processes in bandit settings 
In International Conf  on Arti cial and Statistics  AISTATS   

Wang  Ziyu  Zoghi  Masrour  Hutter  Frank  Matheson  David  Freitas     et al  Bayesian optimization
in high dimensions via random embeddings  AAAI
Press International Joint Conferences on Arti cial Intelligence   

