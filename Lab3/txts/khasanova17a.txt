Graphbased Isometry Invariant Representation Learning

Renata Khasanova   Pascal Frossard  

Abstract

Learning transformation invariant
representations of visual data is an important problem in
computer vision  Deep convolutional networks
have demonstrated remarkable results for image
and video classi cation tasks  However  they
have achieved only limited success in the classi 
 cation of images that undergo geometric transformations 
In this work we present   novel
Transformation Invariant Graphbased Network
 TIGraNet  which learns graphbased features
that are inherently invariant to isometric transformations such as rotation and translation of input
images  In particular  images are represented as
signals on graphs  which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformation 
Our experiments show high performance on rotated and translated images from the test set compared to classical architectures that are very sensitive to transformations in the data  The inherent
invariance properties of our framework provide
key advantages  such as increased resiliency to
data variability and sustained performance with
limited training sets 

  Introduction
Deep convolutional networks  ConvNets  have achieved
impressive results for various computer vision tasks  such
as image classi cation  Krizhevsky et al    and segmentation  Ronneberger et al    However  they still
suffer from the potentially high variability of data in highdimensional image spaces  In particular  ConvNets that are
trained to recognize an object from   given perspective or

 Ecole Polytechnique   ed erale de Lausanne  EPFL  Lausanne  Switzerland  Correspondence to  Renata Khasanova
 renata khasanova ep ch 
 pascal frossard ep ch 

Frossard

Pascal

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

 
 
 
 

 
 
 

 
 
 
 
 
 
 
 

Figure   Illustrative transformationinvariant handwritten digit
classi cation task  Rotated test images  along with their classi cation label obtained from ConvNets  Conv   Boureau et al 
  SpatialTransformer Network  STN   Jaderberg et al 
  and our method   best seen in color 

camera viewpoint  will likely fail when the viewpoint is
changed or the image of the object is simply rotated  In
order to overcome this issue the most natural step is to
extend the training dataset with images of the same objects but seen from different perspectives  This however
increases the complexity of data collection and more importantly leads to the growth of the training dataset when
the variability of the data is high 
Instead of simply augmenting the training set  which may
not always be feasible  one can try to solve the aforementioned problem by making the classi cation architecture invariant to transformations of the input signal as illustrated
in Fig    In that perspective  we propose to represent input
images as signals on the grid graph instead of simple matrices of pixel intensities  The bene ts of this representation
is that graph signals do not carry   strict notion of orientation  while at the same time  signals on   grid graph stay invariant to translation  We exploit these properties to create
features that are invariant to isometric transformations and
we design new graphbased convolutional and pooling layers  which replace their counterparts used in the classical
deep learning settings  This permits preserving the transformation equivariance of each intermediate feature representation under both translation and rotation of the input
signals  Speci cally  our convolutional layer relies on  lters that are polynomials of the graph Laplacian for effective signal representation without computing eigendecompositions of the graph signals  We further introduce   new

Graphbased Isometry Invariant Representation Learning

statistical layer that is placed right before the  rst fullyconnected layer of the network prior to the classi cation 
This layer is speci   to our graph signal representation  and
in turn permits combining the rotation and translation invariance features along with the power of fullyconnected
layers that are essential for solving the classi cation task 
We  nally design   complete architecture for   deep neural
network called TIGraNet  which ef ciently combines spectral convolutional  dynamic pooling  statistical and fullyconnected layers to process images represented on grid
graphs  We train our network in order to learn isometric transformation invariant features  These features are
used in sample transformationinvariant image classi cation tasks  where our solution outperforms the stateof theart algorithms for handwritten digit recognition and classi 
 cation of objects seen from different viewpoints 
In summary  we propose the following contributions 

work that learns isometric invariant features 

  We design   new graphbased deep learning frame 
  We propose   new sta tistical layer that leads to effective transformationinvariant classi cation of images
described by graphbased features 
  Through experiments  we show that our method correctly classi es rotated or translated images even if
such deformations are not present in the training data 
The remainder of the paper is organized as follows  In Section   we describe the related work  Section   reviews elements of graph signal processing  which are later used to
design graph  lters  Our new graphbased architecture is
presented in details in Section   Finally  our experiments
and their analysis are presented in Section  

  Related work
Most of the recent architectures  LeCun et al   
Krizhevsky et al    have been very successful in processing natural images  but not necessarily in properly handling geometric transformations in the data  We describe
below some of the recent attempts that have been proposed
to construct transformationinvariant architectures  We further quickly review the recent works that extend deep learning data represented on graphs or networks 

  Transformationinvariant deep learning

One intuitive way to make the classi cation architectures
more robust to isometric transformations is to augment the
training set with transformed data        Dyk   Meng 
  which however  increases both the training set and
training time  Alternatively  there have been works that
incorporate sort of data augmentation inside the network
learning framework  The authors in  Fasel   GaticaPerez 
  construct deep neural networks that operate in paral 

lel on the original and transformed images simultaneously
with weightshared convolutional  lters  Then  the authors
in  Laptev et al    propose to use maxpooling to combine the outputs of these networks    different approach
was proposed in  Jaderberg et al    where the authors
introduce   new spatial transformer layer that deforms images according to   prede ned transformation class  Then 
the work in  Marcos et al    suggests using rotated  lter banks and   special max pooling operation to combine
their outcomes and improve invariance to transformations 
The authors in  Cohen   Welling    propose   generalization of the ConvNets and introduce equivariance to  
rotations and  ips  Finally  the authors in  Dieleman et al 
  exploit rotation symmetry in the Convolutional Network for the speci   problem of galaxy morphology prediction  This work has been extended in  Dieleman et al 
  which introduces an additional layer that makes the
network to be partially invariant to rotations  All the above
methods  however  still need to be trained on   large dataset
of randomly rotated images in order to be rotation invariant
and achieve effective performance 
Contrary to the previous methods  we propose to directly
learn feature representations that are invariant to isometric
data transformations  With such features  our architecture
preserves all the advantages of deep networks  but additionally provides invariance to isometric geometric transformations  The methods in  Oyallon   Mallat    Bruna  
Mallat    Worrall et al    are the closest in spirit
to ours  In order to be invariant to local transformation  the
works in  Oyallon   Mallat    Bruna   Mallat   
propose to replace the classical convolutional layers with
wavelets  which are stable to some deformations  The latter achieves high performance on texture classi cation task 
however it does not improve the performance of supervised
ConvNets on natural images  due to the fact that the  nal
feature representations are too rigid and unable to adapt to
  speci   task  Further   Mathieu et al    Rippel et al 
  propose to use convolutional  lters in Fourier domain to reduce complexity  The latter introduces spectral
pooling to truncate the representation in the frequency domain  Finally    recent work  Worrall et al    proposes
  so called Harmonic Network  which uses speci cally designed complex valued  lters to make feature representations equivariant to rotations  This method  however  still
requires the training dataset to contain examples of rotated
images to achieve its full potential  On the other hand  we
propose building features that are inherently invariant to
isometric transformations  which allows us to train more
compact networks and achieve stateof theart results 

  Deep learning and graph signal processing

While there has been   lot of research efforts related to
the application of deep learning methods to traditional data

Graphbased Isometry Invariant Representation Learning

like    speech signals or    images  it is only recently
that researchers have started to consider the analysis of
network or graph data with such architectures  Kipf  
Welling    Henaff et al    Duvenaud et al   
Jain et al    The work in  Bruna et al    has
been among the pioneering efforts in trying to bridge the
gap between graphbased learning and deep learning methods  The authors calculate the projection of graph signals
onto the space de ned by the eigenvectors of the Laplacian matrix of the input graph  which itself describes the
geometry of the data  It however requires an expensive calculation of the graph eigendecomposition  which can be  
strong limitation for large graphs  as it requires       operations with   being the number of nodes in the graph 
The authors in  Defferrard et al    later propose an alternative to analyse network data  which is built on   vertex
domain feature representation and on fast spectral convolutional  lters  Both methods directly integrate the graph
features into   fullyconnected layer similarly to classical ConvNets  which is however not directly amenable to
transformationinvariant image classi cation 
To the best of our knowledge  the current approaches to
deep learning on graphs do not provide transformationinvariance in image classi cation  At the same time  the
methods that speci cally target transformation invariance
in image datasets mostly rely on data augmentation  which
largely remains an art  We propose to bridge this gap and
present   novel method that uses the power of graph signal
processing to add translation and rotation invariance to the
image feature representation learned by deep networks 

  Graph signal processing elements
We now brie   review some elements of graph signal processing that are important in the construction of our novel
framework  We represent an input image as   signal   vn 
on the nodes  vn  of the grid graph    In more details 
             is an undirected  weighted and connected
graph  where   is   set of   vertices       the image pixels    is   set of edges and   is   weighted adjacency matrix  An edge   vi  vj  that connects two nodes vi and vj
is associated with the weight aij   aji  which is usually
chosen to capture the distance between both vertices  The
edge weight is set to zero for pairs of nodes that are not
connected  and all the edge weights together build the adjacency matrix    Every vertex vn of   carries the luminance value of the corresponding image pixel  Altogether 
the valued vertices de ne   graph signal   vn          
Similarly to regular    or    signals  the graph signals
can be ef ciently analysed via harmonic analysis and processed in the spectral domain  Shuman et al    In that
respect  we  rst consider the normalized graph Laplacian

       

and

  vn 

   vn 

 

  cid 
  cid 

  

  cid 

operator of the graph    de ned as

          AD 

 cid  

where   is   diagonal degree matrix with elements di  
    cid   Ani  The Laplacian operator is   real symmetric and positive semide nite matrix  which has   set of
orthonormal eigenvectors and corresponding eigenvalues 
Let                     denote these eigenvectors and
                    denote the corresponding
eigenvalues with        max     for the normalized
Laplacian    The eigenvectors form   Fourier basis and the
eigenvalues carry   notion of frequencies as in the classical Fourier analysis  The Graph Fourier Transform       at
frequency    for signal   and respectively the inverse graph
Fourier transform for the vertex vn     are thus de ned as 

  

  vn   

       vn 

 
where the superscript   denotes the complex conjugate 
Equipped with the above notion of Graph Fourier Transform  we can denote the generalized convolution of two
graph signals    and    with help of the graph Laplacian
eigenvectors as

        vn   

             vn 

 

  

By comparing the previous relations  we can see that the
convolution in the vertex domain is equivalent to the multiplication in the graph spectral domain  Graph spectral  ltering can further be de ned as

 yf                

 

where       is the spectral representation of the graph  lter
  vn  and  yf     is the Graph Fourier Transform of the
 ltered signal yf   In   matrix form  the graph  lter can be
denoted by     RN                  where    is  
diagonal matrix constructed on the spectral representation
of the graph  lter 

     diag                 

 

The graph  ltering process becomes yf   Hy  with the
vectors   and yf being the graph signal and its  ltered version in the vertex domain  Finally  we can de ne the generalized translation operator Tvn for   graph signal   as the
convolution of   with   delta function  vn centered at vertex
vn  Thanou et al   

 
 

        vn 

  cid   

Tvn    
 

        

   vn   

 

Graphbased Isometry Invariant Representation Learning

More details about the above graph signal processing operators can be found in  Shuman et al   

  Graphbased convolutional network
We now present the overview of our new architecture 
which is illustrated in Fig    The input to our system
can be characterized by   normalized Laplacian matrix
  computed on the grid graph   and the signal     
                vN   where   vj  is the intensity of the
pixel   in the input image and   is the number of pixels
in the images  Our network eventually returns   class label
for each input signal 
In more details  our deep learning architecture consists
of an alternation of spectral convolution     and dynamic
pooling     layers  They are followed by   statistical layer
  and   sequence of fullyconnected layers that precedes
  softmax operator that produces   categorical distribution over labels to classify the input data  Both the spectral convolution and the dynamic pooling layers contain
Kl operators denoted by    
                  Kl  respectively  Each    
  is speci cally designed to compute
transformationinvariant features on grid graphs  The dynamic pooling layer follows the same principles as the
classical ConvNet   maxpooling operation but preserves
the graph structure in the signal representation  Finally 
the statistical layer   is   new layer designed speci cally
to achieve invariance to isometric transformations on grid
graphs  It does not have any correspondent in the classical
ConvNets architectures  We discuss more thoroughly each
of these layers in the remainder of this section 

  and    

  Spectral convolutional layer

Similarly to the convolutional layers in classical architectures  the spectral convolutional layer   in our network
consists of Kl convolutional  lters    
    as illustrated in
Fig    However  each  lter   operates in the graph spectral domain  In order to avoid computing the graph eigendecomposition that is required to perform  ltering through
Eq    we choose to design our graph  lters as smooth
polynomial  lters of order    Thanou et al   

  cid 

  

  cid 

the training of the network  for each spectral convolutional
layer    Each column of this       operator corresponds
to an instance of the graph  lter centered at   different vertex of the graph  Thanou et al    The support of each
graph  lter is directly controlled by the degree   of the
polynomial kernel  as the  lter takes values only on vertices that are less than Mhop away from the  lter center  Larger values of   require more parameters but allow
training more complex  lters  Therefore    can be seen as
  counterpart of the  lter   size in the classical ConvNets 
The  ltering operation then simply consists in multiplying
the graph signal by the transpose of the operator de ned in
Eq    namely

 cid    

 cid  

 yl
     

      

 

yl
  

 

  and  yl

In particular    

    are the kth graph signals at the input
where yl
and respectively the output of the lth spectral convolutional layer  see Fig   
       is the
input image for the  rst level  lter  while at the next levels
  is rather one of the feature maps outof the network yl
put by the lower layers  We  nally use the notation      
to represent an operator that preserves the columns of the
matrix    which have an index in the set    
    and set all
the other columns to zero  This operator permits computing the  ltering operations only on speci   vertices of the
graphs  It is important to note that the spectral graph convolutional  lter permits equivariance to isometric transformations  which is   key property for designing   classi er
that is invariant to rotation and translation 
Finally  the output of the lth spectral convolutional layer
is   set of Kl feature maps zl
   Each ith feature map is
computed as   linear combination of the outputs of the corresponding polynomial  lter as follows 

 

zl
   

  
   yl

    

 

  

    are the outputs of the ith polywhere the set of signals  yl
nomial  lter applied on the Kl  input signals of the spectral convolutional layer with Eq    The vector of parameters   
   for each spectral convolutional layer   is learned
during the training of the network  The operations in the
spectral convolutional layer are illustrated in Fig    Lastly 
the complexity of spectral  ltering can be computed based
on the fact that   and thus the  lters are sparse matrices 
Then  the complexity is   EM     where  EM  is   maximum number of nonzero elements in the columns of    
   

Kl cid 

       

    
   

 

Following the notation of Eq    each  lter operator in the
spectral convolutional layer   can be written as

   
   

  mLm 
  

 

  Dynamic pooling layer

  

where Lm denotes the Laplacian matrix of power    The
polynomial coef cients   
     have to be learned during

In classical ConvNets the goal of pooling layers is to summarize the outputs of  lters for each operator at the previous convolutional layer  Inspired by  Kalchbrenner et al 

Graphbased Isometry Invariant Representation Learning

Figure   TIGraNet architecture  The network is composed of an alternation of spectral convolution layers     and dynamic pooling
layers      followed by   statistical layer    multiple fullyconnected layers  FC  and   softmax operator  SM  The input of the network
is an image that is represented as   signal    on the gridgraph with Laplacian matrix    The output of the system is   label that
corresponds to the most likely class for the input sample 

Figure   Spectral convolutional layer     in TIGraNet  The outputs of the previous layer       are fed to   set of  lter operators
   
    The outputs of    
  are then linearly combined to get the  lter
maps zl

  that are further passed to the dynamic pooling layer 

  we introduce   novel layer that we refer to as dynamic pooling layer  which consists in preserving only the
most important features at each level of the network 
In more details  we perform   dynamic pooling operation 
which is essentially driven by the set of graph vertices of
interest     This set is initialised to include all the nodes of
graph              It is then successively re ned along
the progression through the multiple layers of the network 
More particularly  for each dynamic pooling layer    we select the Jl vertices that are part of     and that have the
highest values in zl
   The indexes of these largest valued
vertices form   set of nodes    
    The union of these sets for
the different features maps zl
  form the new set         

Kl cid 

  

Figure   Pooling process  with succession of dynamic pooling
layers with operators    
  that each selects the vertices with maximum intensity according to Eq   

classical maxpooling operator is that our dynamic pooling layer is not limited to   small neighbourhood around
each node  Instead  it considers the set of nodes of interest
   which is selected over all graph   nodes  The dynamic
pooling operator     is thus equivariant to the isometric
transformations    similarly to the spectral convolutional
layers  which is   key property in building   transformationinvariant classi cation architecture  The complexity of    
is comparable with the classical pooling operator as the task
of     is equivalent to  nding Jl highest statistics  Using the
selection algorithm  Knuth    we can reach the average
computational complexity of      

    

   
   

 

  Upper layers

The sets    drives the pooling operations at the next dynamic pooling layer      We note that  by construction  the different sets    are embedded  namely we have
                  Fig    illustrates the effect of the
pooling process through the different network levels 
The sets    
  are used to control the  ltering process at the
next layer  The spectral convolutional  lters     
compute
the output of  lters centred on the nodes in    
  that are
selected by the dynamic pooling layer  and not necessarily
for all the nodes in the graph  The  ltering operation is
given by Eq   
Finally  we note that one of the major differences with the

 

After the series of alternating spectral convolutional and
dynamic pooling layers  we add output layers that compute
the label probability distributions for the input images  Instead of connecting directly   fullyconnected layer as in
ConvNet architectures  we  rst insert   new statistical layer 
whose output is fed to fullyconnected layers  see Fig   
The main motivation for the statistical layer resides in our
objective of designing   transformationinvariant classi 
cation architecture  If fullyconnected layers are added directly on top of the last dynamic pooling layers  their neurons would have to memorize large amounts of information
corresponding to the different positions and rotation of the
visual objects  Instead  we propose to insert   new statis 

Graphbased Isometry Invariant Representation Learning

 

tical layer  which computes transformationinvariant statistics of the input signal distributions 
In more details  the statistical layer estimates the distribution of values on the active nodes after the last pooling
layer  The inputs of the statistical layer   are denoted as
 zi  which correspond to the outputs zj 
of the last pooling layer      where the values on nonactive nodes      
the nodes in    
    are set to zero  We then calculate multiscale statistics of these input features maps using Chebyshev polynomials of the graph Laplacian  These polynomials have two important bene ts  First  they permit to capture the relation between different neighbors of the graph
nodes  In particular  polynomials of order   consider direct
neighbors  polynomials of order   include second neighbors and so on  Gathering all this information permits to ef 
 ciently discriminate different objects  As the statistics are
calculated from the entire feature map  the  nal feature representation is independent of the actual signal transformation  Secondly  Chebyshev polynomials can be calculated
in an iterative manner  which make them readily amenable
to effective computation   Shuman et al    In order
to construct these polynomials  we  rst shift the spectrum
of the Laplacian   to the interval     which is the original support of Chebyshev polynomials  Equivalently  we
set            
As suggested in  Defferrard et al    for each input
feature map  zi we iteratively construct   set of signals ti  
using Chebyshev polynomials of order    with     Kmax 

ti        Lti      ti   

  Kmax

              Kmax    

 
with ti     zi and ti       zi  We  nally compute
  feature vector that gathers the  rst order statistics of
the magnitude of these signals  namely the mean     
    for each signal  ti    This forms  
and variance  
feature vector    of  Kmax     elements 
         
  We choose these partic 
     
ular statistics as they are prone to ef cient gradient computation  which is important during back propagation  Furthermore  we note that such feature vectors are inherently
invariant to transformation such as translation or rotation 
The feature vectors      are eventually sent to   series of
fullyconnected layers similarly to classical ConvNet architectures  However  since our feature vectors are transformation invariant  the fullyconnected layers will also bene   from these properties  This is in opposition to their
counterparts in classical ConvNet systems  which need to
compute positiondependent parameters  The details about
fullyconnected layer parameters are given in the Section  
The output of the fullyconnected layers is then fed to  
softmax layer  Bishop    which  nally returns the
probability distribution of   given input sample to belong
to   given set of classes 

  Experiments
In this section we compare our network to the stateof theart transformationinvariant classi cation algorithms 

  Experimental settings

We run experiments with different numbers of layers and
parameters  For each architecture  the network is trained
using backpropagation with Adam  Kingma   Ba   
optimization  The exact formulas of the partial derivatives and explanation about the initialization of the network parameters are provided in the supplementary material  Our architecture has been trained and tested on different datasets  namely 

  MNIST  This is   small subset of the MNIST
dataset  LeCun   Cortes    It includes   training    validation and   test images selected randomly from the MNIST images with labels    
and   This small dataset permits studying the behavior of our network in detail and to analyze the in 
 uence of each of the layers on the performance 
  Rotated and translated MNIST  To test the invariance to rotation and translation of the objects in an image we create MNISTrot and MNISTtrans datasets
respectively  Both of these datasets contain    training     validation and    test images  We use all
MNIST digits  LeCun   Cortes    except   as
it is rotated version resembles   In order to be able
to apply transformation to the digits  we resize the
MNISTrot to the size       and MNISTtrans to
the       The training and validation data of these
datasets contain images of digits without any transformation  However  the testing set of MNISTrot
contains randomly rotated digits by angles in range
    while the testing set of MNISTtrans comprises randomly translated MNIST examples up to  
pixels in both vertical and horizontal directions 
  ETH  The dataset  Leibe   Schiele    contains images of   objects that belong to   classes 
Each object is represented by   images captured from
different viewpoints located on   hemisphere  The
dataset shows   real life example where isometric
transformation invariant features are useful for the object classi cation  We resize the images to      
and randomly select     of them as the training 
validation sets and we use the rest of them for testing 
For all these datasets  we de ne   as   grid graph where
each node corresponds to   pixel location and is connected
with   its nearest neighbors with   weight that is equal to
  The pixel luminance values  nally de ne the signal   on
the graph   for each image 

Graphbased Isometry Invariant Representation Learning

Method
Experiments on MNIST 

ConvNet  Boureau et al   
STN  Jaderberg et al   
TIGraNet

Other experiments

Architecture

        FC FC FC 
  ST   ST FC FC FC 
SC   DP SC   DP   FC FC FC 

ConvNet  Boureau et al   
STN  Jaderberg et al   
DeepScat  Oyallon   Mallat   
HarmNet  Worrall et al   
TIGraNet

        FC FC FC 
  ST   ST FC FC FC 
    PCA 
HRC   HCN HRC   HRC   HCN HRC   
SC   DP SC   DP   FC FC FC 

Table   Architectures used for the experiments on  Leibe   Schiele    We use the following notations to describe the architectures
of the networks            FC    correspond to the convolutional  pooling and fullyconnected layers respectively  with   
being the number of        lters       the size of the maxpooling area and      the number of hidden units  ST    denotes the
spatial transform layer with    af ne transformation parameters          and PCA    denote the parameters of DeepScat network
with waveletbased  lters of order   and maximum scales    with dimension of the af ne PCA classi er    HRC       depicts the
harmonic cross correlation  lter operating on the    neighborhood with    feature maps  HCN    is the complex nonlinearity layer
of HarmNet with    parameters  Finally  SC Kl     is   spectral convolutional layer with Kl  lters of degree    DP Jl  is   dynamic
pooling that retains Jl most important values    Kmax  is   statistical layer with Kmax the maximum order of Chebyshev polynomials 

  Performance evaluation

Here  we compare TIGraNet to stateof the art algorithms
for transformationinvariant image classi cation tasks      
ConvNet  Boureau et al    Spatial Transformer Network  STN   Jaderberg et al    Deep Scattering
 DeepScat   Oyallon   Mallat    and Harmonic Networks  HarmNet   Worrall et al    Brie    ConvNet
is   classical convolutional deep network that is invariant
to small image translations  STN compensates for image
transformations by learning the af ne transformation matrix  Further  DeepScat uses  lters based on rich wavelet
representation to achieve transformation invariance  however  it does not contain any parameters for the convolutional layers  Finally  HarmNet trains complex valued  lters that are equivariant to signal rotations  For the sake of
fairness in our comparisons  we use versions of these architectures that have roughly the same number of parameters 
which means that each of the approaches learns features
with   comparable complexity  For the DeepScat we use
the default architecture  Further for the HarmNet we preserve the default network structure  keeping the same number of complex harmonic  lters  as the number of spectral
convolutional  lters that we have in TIGraNet 
We  rst compare the performance of our algorithm to
the ones of ConvNet and STN for the small digit dataset
MNIST  The speci   architectures used in this experiments are given in Table   The results of this  rst experiment are presented in Table    We can see that if we train
the methods on the dataset that does not contain rotated images and test on the rotated images of digits  our approach
achieves   signi cant increase in performance        

Training set

Validation set

Rotated test set

Training set with data augmentation
 
 

ConvNet
STN

Training set without data augmentation

ConvNet
STN
TIGraNet

 
 
 

 
 

 
 
 

     
     

     
     
     

Table   Classi cation accuracy of ConvNet  STN and TIGraNet
on MNIST  averaged over   runs 

ConvNet
STN
TIGraNet

MNISTrot MNISTtrans

 
 
 

 
 
 

Table   Evaluation of the accuracy of the ConvNet  STN and
TIGraNet on the MNISTrot and MNISTtrans datasets  All the
methods are trained on sets without transformed images 

due to its inherent transformation invariant characteristics 
We further run experiments where   simple augmentation
of the training set is implemented with randomly rotated
each image of digits  This permits increasing the performance of all algorithms  as expected  possibly at the price
of more complex training  Still  due to the rotation invariant nature of its features  TIGraNet is still able to achieve
higher classi cation accuracy than all its competitors 
We then run experiments on the MNISTrot and MNISTtrans datasets  Note that both of them do not contain any

Graphbased Isometry Invariant Representation Learning

 
 
 
 
 

 
 
 
 

 
 
 
 
 
 
 
 
 
 
 

Figure   Network feature maps visualization  Each row shows
the feature maps of different digits after the  rst and the second spectral convolutional layers  The misclassi ed images are
marked by red bounding boxes   best seen in color 

STN  Jaderberg et al   
ConvNet  Boureau et al   
DeepScat  Oyallon   Mallat   
HarmNet  Worrall et al   
TIGraNet

 
 
 
 
 

Table   Classi cation accuracy of ConvNet  STN  DeepScat 
HarmNet and TIGraNet on the ETH  dataset 

isometric transformation in training and validation sets  but
the test set contains transformed images  For all the methods we have used the architectures de ned in Table   Table   shows that our algorithm signi cantly outperforms
the competitor methods on both datasets due to its transformation invariant features  The other architectures have only
limited capabilities with respect to such transformation as
rotation  Additionally  we run experiments for our MNISTrot with different types of data augmentation  We have tried
several settings  when input image is rotated by an angle
that is   multiple of   degrees  with   being        
and   As expected  the accuracy of ConvNets increases to
          respectively with the
increasing amount of data augmentation  We observe similar dynamics for STN method and its accuracy matches our
approach for       degrees rotations 
To further analyze the performance of our network we illustrate several sample feature maps for the different  lters
of the  rst two spectral convolutional layers of TIGraNet
in Fig    for the MNISTrot and MNISTtrans datasets  We
can see   few examples of misclassi cation of our network 
for example  the algorithm predicts label   for the digit
  This mostly happens due to the border artifacts 
if
an isometric transformation shifts the digit too close to the
border  the neighborhood of some nodes may change  This
problem can be solved by increasing the image borders or
applying  lters only to the central pixel locations 
Finally  we evaluate the performance of our algorithm in

more realistic settings where the objective is to classify images of objects that are captured from different viewpoints 
This task requires having   classi er that is invariant to isometric transformations of the input signal  We therefore run
experiments on the ETH  dataset and compare the classi cation performance of TIGraNet to those of ConvNet 
STN  DeepScat and HarmNet  The architectures of the different methods are described in Table  
Table   shows the classi cation results in this experiment 
We can see that our approach outperforms the stateof theart methods due to its transformation invariant features 
The closest performance is achieved by Harmonic Networks  since this architecture also learns equivariant features  It is important to note that the ETH  dataset contains less training examples than other publicly available
datasets that are commonly used for training of deep neural
networks  This likely results in decrease of accuracy for
such methods as ConvNet and STN  On the contrary  our
method is able to achieve good accuracy even with small
amounts of training data  due to its inherent invariance to
isometric transformations 
Overall  all the above experiments con rm the bene  
of our transformation invariant classi cation architecture 
which learns features that are invariant to transformation
by construction  Classi cation performance improves with
these features  such that the algorithm reaches sustained
performance even if the training set is relatively small  or
does not contain similar transformed images as the test set 
These are very important advantages in practice 

  Conclusion
In this paper we present   new transformation invariant
classi cation architecture  which combines the power of
deep networks and graph signal processing  which allows
developing  lters that are equivariant to translation and rotation    novel statistical layer further renders our full
network invariant to the isometric transformations  This
permits outperforming stateof theart algorithms on various illustrative benchmarks  Having inherently invariant
to transformation features gives our network the ability to
learn well from   few training examples and to generalize
to unseen transformations  This con rms its high potential
in practical settings where the training sets are limited but
where the data is expected to present high variability 

Acknowledgments
The authors thank Dr Dorina Thanou  Damian Foucard and
Dr Andreas Loukas for comments that help to improve
the paper and we gratefully acknowledge the support of
NVIDIA Corporation with the donation of the Tesla   
GPU used for this research 

Graphbased Isometry Invariant Representation Learning

References
Bishop        Pattern Recognition and Machine Learning 

Springer   

Boureau        Ponce     and LeCun       Theoretical
In

Analysis of Feature Pooling in Visual Recognition 
International Conference on Machine Learning   

Bruna     and Mallat    

Invariant scattering convolution
IEEE Transactions on Pattern Analysis and

networks 
Machine Intelligence     

Bruna     Zaremba     Szlam     and LeCun     Spectral
Networks and Locally Connected Networks on Graphs 
In International Conference for Learning Representations   

Cohen        and Welling     Group equivariant convolu 

tional networks  arXiv preprint   

Defferrard     Bresson     and Vandergheynst     Convolutional Neural Networks on Graphs with Fast Localized
In Advances in Neural Information
Spectral Filtering 
Processing Systems  pp     

Dieleman     Willett        and Dambre     Rotationinvariant convolutional neural networks for galaxy morphology prediction  Monthly notices of the royal astronomical society     

Dieleman     Fauw        and Kavukcuoglu     Exploiting
In

cyclic symmetry in convolutional neural networks 
International Conference on Machine Learning   

Duvenaud        Maclaurin     Iparraguirre     Bombarell     Hirzel     AspuruGuzik     and Adams 
      Convolutional networks on graphs for learning
molecular  ngerprints  In Advances in Neural Information Processing Systems  pp     

Dyk        and Meng       The art of data augmentation 
Journal of Computational and Graphical Statistics   
   

Fasel     and GaticaPerez     Rotationinvariant neoperceptron  In International Conference on Pattern Recognition  volume   pp     

Henaff     Bruna     and LeCun     Deep convolutional
networks on graphstructured data  arXiv preprint   

Jaderberg     Simonyan     Zisserman    

and
Kavukcuoglu     Spatial Transformer Networks  arXiv
Preprint   

Jain     Zamir        Savarese     and Saxena 
   Structuralrnn  Deep learning on spatiotemporal
graphs  arXiv Preprint   

Kalchbrenner     Grefenstette     and Blunsom      
Convolutional Neural Network for Modelling Sentences 
arXiv Preprint   

Kingma     and Ba     Adam    method for stochastic

optimization  arXiv Preprint   

Kipf        and Welling     Semisupervised classi cation with graph convolutional networks  arXiv preprint 
 

Knuth        The Art of Computer Programming  Sorting
and Searching  Addison Wesley Longman Publishing
Co  Inc   

Krizhevsky     Sutskever     and Geoffrey       

ImageNet Classi cation with Deep Convolutional Neural
Networks  In Advances in Neural Information Processing Systems  pp     

Laptev     Savinov     Buhmann       and Pollefeys    
TIPooling  TransformationInvariant Pooling for Feature Learning in Convolutional Neural Networks 
In
Conference on Computer Vision and Pattern Recognition   

LeCun     and Cortes     MNIST handwritten digit
database    URL http yann lecun com 
exdb mnist 

LeCun     Bottou     Bengio     and Haffner     GradientBased Learning Applied to Document Recognition  In
Intelligent Signal Processing  pp     

Leibe     and Schiele     Analyzing appearance and contour based methods for object categorization  In Conference on Computer Vision and Pattern Recognition  volume   pp     

Marcos     Volpi     and Tuia     Learning rotation
invariant convolutional  lters for texture classi cation 
arXiv preprint   

Mathieu     Henaff     and Lecun     Fast training of
In International

convolutional networks through ffts 
Conference on Learning Representations   

Oyallon     and Mallat     Deep rototranslation scattering for object classi cation  In Conference on Computer
Vision and Pattern Recognition  pp     

Rippel     Snoek     and Adams        Spectral representations for convolutional neural networks  In Advances
in Neural Information Processing Systems   pp   
  Curran Associates  Inc   

Ronneberger     Fischer     and Brox     Unet  Convolutional networks for biomedical image segmentation 
In Medical Image Computing and ComputerAssisted Intervention  volume   pp     

Graphbased Isometry Invariant Representation Learning

Shuman        Vandergheynst     and Frossard     Chebyshev polynomial approximation for distributed signal
processing  In IEEE International Conference on Distributed Computing in Sensor Systems  pp     

Shuman        Narang        Frossard     Ortega     and
Vandergheynst     The emerging  eld of signal processing on graphs  Extending highdimensional data analysis to networks and other irregular domains  IEEE Signal
Processing Magazine     

Thanou     Shuman        and Frossard     Learning parametric dictionaries for signals on graphs  IEEE Transactions on Signal Processing     

Worrall        Garbin        Turmukhambetov     and
Brostow        Harmonic networks  Deep translation
and rotation equivariance  arXiv Preprint   

