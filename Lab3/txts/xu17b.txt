Learning Hawkes Processes from Short DoublyCensored Event Sequences

Hongteng Xu   Dixin Luo   Hongyuan Zha  

Abstract

Many realworld applications require robust algorithms to learn point processes based on   type
of incomplete data   the socalled short doublycensored  SDC  event sequences  We study this
critical problem of quantitative asynchronous
event sequence analysis under the framework
of Hawkes processes by leveraging the idea of
data synthesis  Given SDC event sequences observed in   variety of time intervals  we propose   samplingstitching data synthesis method 
sampling predecessors and successors for each
SDC event sequence from potential candidates
and stitching them together to synthesize long
training sequences  The rationality and the feasibility of our method are discussed in terms
of arguments based on likelihood  Experiments
on both synthetic and realworld data demonstrate that the proposed data synthesis method
improves learning results indeed for both timeinvariant and timevarying Hawkes processes 

  Introduction
Realworld interactions among multiple entities are often
recorded as asynchronous event sequences  such as user behaviors in social networks  job hunting and hopping among
companies  and diseases and their complications  The entities or event types in the sequences often exhibit selftriggering and mutuallytriggering patterns  For example 
  tweet of   twitter user may trigger further responses from
her friends  Zhao et al      disease of   patient may
trigger other complications  Choi et al    Hawkes
processes  an important kind of temporal point process
model  Hawkes   Oakes    have capability to describe the triggering patterns quantitatively and capture the
infectivity network of the entities 

 Georgia Institute of Technology  Atlanta  Georgia  USA
 University of Toronto  Toronto  Ontario  Canada  Correspondence to  Hongteng Xu  hxu gatech edu  Dixin Luo
 dixin luo utoronto ca 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Figure   For each SDC sequence       incomplete disease history
of   person in his lifetime  we design   mechanism to select other
SDC sequences as predecessors successors and synthesize   long
sequence  Then  we can estimate the unobserved triggering patterns among diseases       the red dashed arrows  and construct  
disease network 

Despite the usefulness of Hawkes processes  robust learning of Hawkes processes often needs many event sequences
with events occurring over   long observation window  Unfortunately  the observation window is likely to be very
short and sequencespeci   in many important practical applications       within an imagined universal window  each
sequence is only observed with   corresponding short subinterval of it  and the events outside this subinterval are
not observed   we call them short doublycensored  SDC 
event sequences  Existing learning algorithms of Hawkes
processes directly applied to SDCs may suffer from over 
 tting  and what is worse  the triggering patterns between
historical events and current ones are lost  so that the triggering patterns learned from SDC event sequences are often unreliable  This problem is   thorny issue in several practical applications  especially in those having timevarying triggering patterns  For example  the disease networks of patients should evolve with the increase of age 
However  it is very hard to track and record people   diseases on   lifetime scale  Instead  we can only obtain their
several admissions  even only one admission  in   hospital during one or two years  which are just SDC event
sequences  Therefore  it is highly desirable to propose  
method to learn Hawkes processes having   longtime support from   collection of SDC event sequences
In this paper  we propose   novel and simple data synthesis
method to enhance the robustness of learning algorithms
for Hawkes processes  Fig    illustrates the principle of our
method  Given   set of SDC event sequences  we sample
predecessor for each event sequence from potential candidates and stitch them together as new training data  In
the sampling step  the distribution of predecessor  and successor  is estimated according to the similarities between

Learning Hawkes Processes from Short DoublyCensored Event Sequences

current sequence and its candidates  and the similarity is
de ned based on the information of time stamps and  optional  features of event sequences  We analyze the rationality and the feasibility of our data synthesis method and
discuss the necessary condition for using the method  Experimental results show that our data synthesis method indeed helps to improve the robustness of various learning
algorithms for Hawkes processes  Especially in the case
of timevarying Hawkes processes  applying our method in
the learning phase achieves much better results than learning directly from SDC event sequences  which is meaningful for many practical applications       constructing dynamical disease network  and learning longterm infectivity among different IT companies 

  Related Work
An event sequence can be represented as      ti  ci  
  
where time stamps ti   are in an observation window
 Tb  Te  and events ci   are in   set of event types    
         point process  Nc     is   random process model taking event sequences as instances  where
Nc    Nc        Tb  Te  and Nc    is the number of
typec events occurring at or before time      point process can be characterized via its conditional intensity function           dNc   HC
   
 ti  ci ti      ci      is the set of history  It represents
the expected instantaneous happening rate of events given
historical record  Daley   VereJones    The intensity is often modeled with certain parameters   to capture
the phenomena of interests       selftriggering  Hawkes  
Oakes    or selfcorrecting  Xu et al    Based on
          the likelihood of an event sequence   is

   dt  where       and HC

 cid cid 

 cid  Te

 

Tb

 cid 

     ds

 

 

 cid 

        

 ci ti  exp

 

that the impact function is shiftinvariant        cc cid        
 cc cid              which limits their applications on longtime scale  Recently  the timedependent Hawkes process
 TiDeH  in  Kobayashi   Lambiotte    and the neural
networkbased Hawkes process in  Mei   Eisner   
learn very  exible Hawkes processes with complicated intensity functions  Because they highly depend on the size
and the quality of data  they may fail in the case of SDC
event sequences 
Learning from Imperfect Observations  In practice  we
need to learn sequential models from imperfect observations       interleaved  Xu et al      aggregated  Luo
et al    and extremelyshort sequences  Xu et al 
    Multiple imputation  MI   Rubin    is   general framework to build surrogate observations from the
current model  For time series  bootstrap method  Efron 
  Politis   Romano    Gonc alves   Kilian   
and its variants  Paparoditis   Politis    Guan   Loh 
  have been used to improve learning results when observations are insuf cient  In survival analysis  many techniques have been made to deal with truncated and censored
data  Turnbull    De Gruttola   Lagakos    Klein
  Moeschberger    Van den Berg   Drepper   
For point processes  the global  Streit    or local  Fan 
  likelihood maximization estimators  MLE  are used
to learn Poisson processes  Nonparametric approaches
for nonhomogeneous Poisson processes use the pseudo
MLE  Sun   Kalb eisch    or full MLE  Wellner  
Zhang    The bootstrap methods above are also used
to learn point processes  Cowling et al    Guan   Loh 
  Kirk   Stumpf    To learn Hawkes processes
robustly  structural constraints       lowrank  Luo et al 
  and groupsparse regularizers  Xu et al      are
introduced  However  all of these methods do not consider
the case of SDC event sequences for Hawkes processes 

 cid  

 cid   

  cid 

 

Hawkes Processes  Hawkes processes  Hawkes   Oakes 
  have   particular form of intensity 

 cc cid      dNc cid   

 

            

history while cid   

where    is the exogenous base intensity independent of the
   cc cid      dNc cid    is the endogenous intensity capturing the in uence of historical events on typec
ones at time    Xu et al      Here   cc cid          
is called impact function 
It quanti es the in uence of
the typec cid  event at time   to the typec event at time   
Hawkes processes provide us with   physicallymeaningful
model to capture the infectivity among various events 
which are used in social network analysis  Zhou et al 
    Zhao et al    behavior analysis  Yang   Zha 
  Luo et al    and  nancial analysis  Bacry et al 
  However  the methods in these references assume

  Learning from SDC Event Sequences
Suppose that the original complete event sequences are
in   long observation window  However  the observation
window in practice might be segmented into several intere   
vals     
   and we can only observe Kn SDC seb      
quences  sn
  Kn
   in the nth interval             Although we can still apply maximum likelihood estimator to
learn Hawkes processes      

min   cid 

log   sn

     

   

 

the SDC event sequences would lead to over tting problem and the loss of triggering patterns  Can we do better in
such   situation  In this work  we propose   data synthesis
method based on   samplingstitching mechanism  which
extends SDC event sequences to longer ones and enhances
the robustness of learning algorithms 

Learning Hawkes Processes from Short DoublyCensored Event Sequences

min   cid 

  Data Synthesis via SamplingStitching

Denote the kth SDC event sequence in the nth interval as
   Because its predecessor is unavailable  if we learn the
sn
parameters of our model via   directly  we actually impose   strong assumption on our data that there is no event
   or previous events are too far away
happening before sn
from sn
   Obviously  this assumption is questionable   it is likely that there are in uential
events happening before sn
     more reasonable strategy is
enumerating potential predecessors and maximizing the expected loglikelihood over the whole observation window 

  to have in uences on sn

 
  HC
   
 

   

 log      sn

     

 

   
 

means all possible history before    

Here Ex         represents the expectation of function
      with random variable   yielding to   distribution
       HC
    and
     sn
      is the likelihood of stitched sequence     sn
   
    can be generated via samThe stitched sequence     sn
pling SDC sequence   from previous  st          th intervals and stitching   to sn
   The sampling process yields
to the probabilistic distribution of the stitched sequences 
Given sn
   we can compute its similarity between its potential predecessor sn cid 

 cid 

        cid 
  cid  in      cid 
  when     cid 
        cid 
     

    as
       
        cid 
        

 

  sn cid 

  cid    sn

     

  cid        

 

Here            exp cid       cid 
    is   prede ned similarity function with parameter        
  is the feature of
   which is available in some applications  Note that the
sn
availability of feature is optional   even if the feature of
sequence is unavailable  we can still de ne the similarity
measurement purely based on time stamps  The normalk   provides us with the probability that sn cid 
ized    sn cid 
  cid    sn
  cid 
          sn cid 
appears before sn
    Then  we
can sample sn cid 
  cid  according to the categorical distribution 
  cid    Category    sn
     sn cid 
We can apply such   samplingstitching mechanism  
times iteratively to the SDC sequences in both backward
and forward directions and get long stitched event sequences  Speci cally  we represent   stitched event sequence as sstitch              sl    sn
      
           whose probability is

        sn cid 

  cid sn

  cid    sn

   

  sstitch     cid  

  

  sl  sl 

 

Note that our data synthesis method naturally contains two
variants  When the starting  the ending  point of time window is unavailable  we use the time stamp of the  rst  the
last  event of SDC sequence instead  Additionally  we can

       

relax the constraint     cid 
  in   and allow   SDC sequence to have an overlap with its predecessor successor 
In this case  we preserve the overlap part randomly either
from itself or its predecessor successor before applying our
samplingstitching method  These two variants ensure that
our data synthesis method is doable in practice  which are
used in the following experiments on realworld data 

  Justi cation

After applying our data synthesis method  we obtain many
stitched event sequences  which can be used as instances
for estimating  
      Speci cally 
taking advantage of stitched sequences  we can rewrite the
learning problem in   approximately as

 log      sn

  HC
   
 

  sstitch  log   sstitch   

 

sstitch  

min   cid 

which is actually the minimum crossentropy estimation 
  sstitch  represents the  true  probability that the stitched
sequence happens  which is estimated via the prede ned
similarity measurement and the sampling mechanism  The
likelihood   sstitch    represents the  unnatural  probability that the stitched sequence happens  which is estimated based on the de nition in   Our data synthesis
method takes advantage of the information of time stamps
and  optional  features and makes   sstitch  suitable for
practical situations  For example  the likelihood of   sequence generally reduces with the increase of observation
time window  The proposed probability   sstitch  yields to
the same pattern   according to   the longer   stitched
sequence is  the smaller its probability becomes 
The set of all possible stitched sequences       the   in  
   Kn 
In practice  we cannot and do not need to enumerate all
possible combinations  An empirical setting is making the
number of stitched sequences comparable to that of orign  Kn 
stitched sequences  In the following experiments  we just
apply      trials and generate   stitched sequences for
each original SDC event sequence  which achieves   tradeoff between computational complexity and performance 

is very large  whose cardinality is         cid  
inal SDC event sequences       generating   cid  

  Feasibility

It should be noted that our data synthesis method is only
suitable for those complicated point processes whose historical events have in uences on current and future ones 
Speci cally  we analyze the feasibility of our method for
several typical point processes 
Poisson Processes  Our data synthesis method cannot improve learning results if the event sequences are generated
via Poisson processes  For Poisson processes  the happening rate of future events is independent of historical

Learning Hawkes Processes from Short DoublyCensored Event Sequences

events  In other words  the intensity function of each interval can be learned independently based on the SDC event
sequences  The stitched sequences do not provide us with
any additional information 
Hawkes Processes  For Hawkes processes  whose intensity function is de ned as   our data synthesis method
can enhance the robustness of learning algorithm generally 
In particular  consider    long  event sequence generated
via   Hawkes process in the time window  Tb  Te  If we
divide the time window into   intervals        Tb      and
    Te  the intensity function corresponding to the second
interval can be written as

            

 cci    ti   

 cci    ti 

 

 cid 

   ti Te

 cid 

ti  

If the events in the  rst interval are unobserved  we just
have   SDC event sequence  and the second term in   is
unavailable  Learning Hawkes processes directly from the
SDC event sequence ignores the information of the second
term  which has   negative in uence on learning results 
Our data synthesis method leverages the information from
other potential predecessors and generates multiple candidate long sequences  As   result  we obtain multiple intensity functions sharing the second interval and maximize
the weighted sum of their loglikelihood functions       an
estimated expectation of the loglikelihood of the real long
sequence  as   does 
Compared with learning from SDC event sequences directly  applying our data synthesis method can improve learning results
the term
ti    cci    ti  is ignorable  Speci cally  we can model
the impact functions  cc cid          cid   of Hawkes processes based on basis representation 
          

in general  unless

 cid 

 cid   cid cid   cid 

Triggering kernel

 

 cc cid          cc cid   

 cid   cid cid   cid 
 cid  
Infectivity  cc cid     cid  

Infectivity

 

  

Here  we decompose impact functions into two parts   
   acc cid        represents the infectivity of event type   cid  to   at time      Triggering kernel
       exp    measures the time decay of infectivity  It
means that the infectivity of   historical event to current
one reduces exponentially with the increase of temporal
distance between them  When   is very large   cc cid      
decays rapidly with the increase of        and the events
happening long ago can be ignored  In such   situation  our
data synthesis method is unable to improve learning results 
 When       and           we obtain the simplest timeinvariant Hawkes process  Relaxing the shiftinvariant assumption             and       is Gaussian  we obtain    exible
timevarying Hawkes process model 

acc cid               

  Implementation for Hawkes Processes
Hawkes process is   kind of physicallyinterpretable model
for many natural and social phenomena  The proposed
model in   re ects many common properties of realworld event sequences  First  the infectivity among various event types often changes smoothly in practice  in social networks  the interaction between two users changes
smoothly  which is not established or blocked suddenly 
in disease networks  the infectivity among diseases should
change smoothly with the increase of patient   age  Applying Gaussian basis representation guarantees the smoothness of infectivity function  Second  the triggering kernel measures the decay of infectivity over time  According to existing work 
the decay of infectivity is exponential approximately  which has been veri ed in many
realworld data  Zhou et al      Kobayashi   Lambiotte    Choi et al    For learning Hawkes
processes from SDC event sequences  we combine our
data synthesis method with an EMbased learning algorithm of Hawkes processes  Applying our data synthesis method  we obtain   set of stitched event sequences
     sn  and their appearance probabilities  pn  where
       and pn is calsn    tn
culated based on   According to     we can learn
target Hawkes process via

  tn
   In

        

    cn

       

    cn

  

min

pn log   sn           

 
    
Here          represents the parameters of our model 
The vector         and the tensor      acc cid    are nonnegative  Based on     the loglikelihood function is

   cid   

 cid 
 cid 

 

 

 

log   sn   

  

 cid In
 cid In
   cid  

  

 

  

 cid     
log  ci ti     cid  
 cid 
 cid 
 cid 
 cid 
 cid 
 cid In
        cid 
    Gij    cid  tn

    
ij 

 cn

log

   
 

  

   

 

 

 

 

  

     ds

acn

      tn
   

  cn

   

accn

  mGij
           tn

    tn
       

  

tn
 

   ds 
where    
ij   tn
         represents the regularizer
and         
of parameters  whose weight is   Following existing
work in  Luo et al    Zhou et al      Xu et al 
    we assume the infectivity connections among different event types to be sparse and impose    cid norm regularizer on the coef cient tensor                 cid   cid   

 cid 
    cid    acc cid   

We can solve the problem via an EM algorithm  Specifically  when sparse regularizer is applied  we take advantage of ADMM method  introducing auxiliary variable
     zcc cid    and dual variable      ucc cid    for   and

Learning Hawkes Processes from Short DoublyCensored Event Sequences

   cid 

 

rewriting the objective function in   as

pn log   sn       cid       cid 

 

   tr   cid           cid   cid 

Here   controls the weights of regularization terms  which
increases with the number of EM iterations  tr  computes
the trace of matrix  Then  we can update         and
  alternatively 
Update   and    Given the parameters in the kth itern log   sn   

ation  we apply Jensen   inequality to  cid 
      cid 

and obtain   surrogate objective function for   and   

          Ak  Zk      

      tn
   

ij acn

    

qijm log

pn

 cid cid 
 cid  In cid 
    cid 

  

   

 

 cn
qi

  cid 
  cid 

  

 cid 

  

  qi log

   
   cid     Zk       cid 
   

  

  

 cid 

  cn
qijm

    

  cid 

  

 cid 

accn

  mGij

Algorithm   Learning Algorithm of Hawkes Processes
  Input  Event sequences    The threshold     Prede 

 ned parameters     and  
  Output  Parameters   and  
  Initialize Ak and    randomly  Zk   Ak         

           

  repeat
Obtain Ak  and     via  
 
Obtain Zk  via  
 
Obtain      via  
 
               
 
  until  cid Ak   Ak cid      
      Ak         

In summary  Algorithm   shows the scheme of our learning
method  Note that the algorithm can be applied to SDC
event sequences directly via ignoring pn   

  

  Experiments
  Implementation Details

    

  
cn
 
 tn

ij  ak
cn
 
  
cn
 

    tn
   
cn
 
 tn
   

 tn

  
cn
 

where qi  

    and qijm  

  and
    is calculated based on    and Ak  Then  we can
       Both of

  
cn
      and   
update   and   via solving   
 
 cid 
these two equations have closedform solution 

 

  pn

  pn  

     qi
cn

 cid 
 cid 
 cid            
 cid 
 cid 

 

 

   

   

ak 
cc cid    

where

     uk

     cid 

 cid 
cc cid     zk

pn

 

 

Gij 

cc cid     

pn

 

cn
      cn

     cid     

cn
      cn

     cid     

qijm 

Update    Given Ak  and      we can update   via
solving the following optimization problem 

minZ  cid   cid     cid Ak            cid 
   

Applying softthresholding method  we have

 

Zk       

 Ak        

 
where        sign    min          is the softthresholding function 
Update    Given Ak  and Zk  we can further update
dual variable as

              Ak    Zk 

 

To demonstrate the usefulness of our data synthesis
method  we combine it with various learning algorithms of
Hawkes processes and learn different models accordingly
from SDC event sequences  For timeinvariant Hawkes
processes  we consider two learning algorithms   our EMbased learning algorithm and the least squares  LS  algorithm in  Eichler et al    For timevarying Hawkes
processes  we apply our EMbased learning algorithm  In
the following experiments  we use Gaussian basis functions          exp     tm  with center tm and
bandwidth   The number and the bandwidth of basis can
be set according to the basis selection method proposed
in  Xu et al      Additionally  we set      
      and        in our algorithm  Given SDC event
sequences  we learn Hawkes processes in three ways   
learning directly from SDC event sequences    applying the stationary bootstrap method in  Politis   Romano 
  to generate more synthetic SDC event sequences
and learning from these sequences accordingly    learning from stitched sequences generated via our data synthesis method  For realworld data  whose SDC sequences do
not have prede ned starting and ending time stamps  we
applied the variants of our method mentioned in the end of
Section  

  Synthetic Data

The synthetic SDC event sequences are generated via the
following method    complete event sequences are simulated in the time window     based on    dimensional
Hawkes process  The base intensity    
   are randomly
generated in the range     The parameter of trigger 

Learning Hawkes Processes from Short DoublyCensored Event Sequences

    Our learning algorithm

Figure   Comparisons on loglikelihood and relative error 

    Least squares algorithm

Figure   Comparisons on loglikelihood and relative error 

ing kernel    is set to be   For timeinvariant Hawkes
processes  we set the infectivity  cc cid    to be   constants
randomly generated in the range     For timevarying
Hawkes processes  we set  cc cid        cos   cc cid 
    
where  cc cid  are randomly generated in the range    
Given these complete event sequences  we select   sequences as testing set while the remaining   sequences
as training set  To generate SDC event sequences  we segment time window into   intervals  and just randomly preserve the data in one interval for each training sequences 
We test all methods in   trials and compare them on the
relative error between real parameters   and their estima 
  and the loglikelihood of test 

tion results  cid        cid cid cid 

 cid cid 

ing sequences 
Timeinvariant Hawkes Processes  Fig    shows the comparisons on loglikelihood and relative error for various
methods  In Fig      we can  nd that compared with the
learning results based on complete event sequences  the results based on SDC event sequences degrade   lot  lower
loglikelihood and higher relative error  because of the loss
of information  Our data synthesis method improves the
learning results consistently with the increase of training
sequences  which outperforms its bootstrapbased competitor  Politis   Romano    as well  To demonstrate the
universality of our method  besides our EMbased algorithm  we apply our method to the Least Squares  LS  algo 

Figure   Comparisons on infectivity functions  cc cid      The
number of original SDC sequences is   and stitched via our
method once 

rithm  Eichler et al    Fig      shows that our method
also improves the learning results of the LS algorithm in
the case of SDC event sequences  Both the loglikelihood
and the relative error obtained from the stitched sequences
approach to the results learned from complete sequences 
Timevarying Hawkes Processes  Fig    shows the comparisons on loglikelihood and relative error for various
methods  Similarly  the learning results are improved because of applying our method   higher loglikelihood and
lower relative error are obtained and their standard deviation  the error bars associated with curves  is shrunk  In
this case  applying our method twice achieves better results
than applying once  which veri es the usefulness of the iterative framework in our samplingstitching algorithm  Besides objective measurements  in Fig    we visualize the
infectivity functions  cc cid    It is easy to  nd that the
infectivity functions learned from stitched sequences  red
curves  are comparable to those learned from complete
event sequences  yellow curves  which have small estimation errors of the ground truth  black curves 
Note that our iterative framework is useful  especially
for timevarying Hawkes processes  when the number of
stitches is not very large 
In our experiments  we  xed
the maximum number of synthetic sequences  As   result 
Figs    and   show that the likelihoods  rst increase      
stitching once or twice  and then decrease       stitching
more than three times  while the relative errors have opponent changes        the number of stitches  These phenomena imply that too many stitches introduce too much unreliable interdependency among events  Therefore  we   

Learning Hawkes Processes from Short DoublyCensored Event Sequences

    LinkedIn data

    LinkedIn data

    MIMIC III data

Figure   Comparisons on loglikelihood 

the number of stitches to   in the following experiments 

    MIMIC III data

  RealWorld Data

Besides synthetic data  we also test our method on realworld data  including the LinkedIn data collected by ourselves and the MIMIC III data set  Johnson et al   
LinkedIn Data  The LinkedIn data we collected online
contain job hopping records of     LinkedIn users in  
IT companies  For each user  her his checkin time stamps
corresponding to different companies are recorded as an
event sequence  and her his pro le       education background  skill list  etc  is treated as the feature associated
with the sequence  For each person  the attractiveness of
  company is always timevarying  For example    young
man may be willing to join in startup companies and increase his income via jumping between different companies  With the increase of age  he would more like to stay
in the same company and achieve internal promotions  In
other words  the infectivity network among different companies should be dynamical       
the age of employees 
Unfortunately  most of the records in LinkedIn are short
and doublycensored   only the job hopping events in recent years are recorded  How to construct the dynamical infectivity network among different companies from the SDC
event sequences is still an open problem 
Applying our data synthesis method  we can stitch different users  job hopping sequences based on their ages  time
stamps  and their pro le  feature  and learn the dynamical
network of company over time  In particular  we select  
users with relatively complete job hopping history       the
range of their working experience is over   years  as testing set  The remaining     users are randomly selected
as training set  The loglikelihood of testing set in   trials
is shown in Fig      We can  nd that the loglikelihood
obtained from stitched sequences is higher than that obtained from original SDC sequences or that obtained from
the sequences generated via the bootstrap method  Politis
  Romano    and its standard deviation is bounded

Figure   Comparisons on infectivity functions  cc cid     

stably  Fig      visualizes the adjacent matrix of infectivity network  The properties of the network veri es the
rationality of our results    the diagonal elements of the
adjacent matrix are larger than other elements in general 
which re ects the fact that most employees would like to
stay in the same company and achieve   series of internal
promotions    with the increase of age  the infectivity network becomes sparse  which re ects the fact that users are
more likely to try different companies in the early stages of
their careers 
MIMIC III Data  The MIMIC III data contain admission records of over     patients in the Beth Israel
Deaconess Medical Center between   and   For
each patient  her his admission time stamps and diseases
 represented via the ICD  codes  Deyo et al    are
recorded as an event sequence  and her his pro le  including gender  race and chronic history  is represented as binary feature of the sequence  As aforementioned  some
work  Choi et al    has been done to extract timeinvariant disease network from admission records  However  the real disease network should be timevarying       
the age of patient  Similar to the LinkedIn data  here we
only obtain SDC event sequences   the ranges of most
admission records are just   or   years 
Applying our data synthesis method  we can leverage the
information from different patients and stitch their sequences based on their ages and their pro le  Focusing on
  common diseases in   categories  we select    
patients  admission records randomly as training set and
    patients with relatively complete records as testing set  Fig      shows that applying our data synthesis
method indeed helps to improve loglikelihood of testing
data  Compared with our bootstrapbased competitor  our
data synthesis method gets more obvious improvements 

Learning Hawkes Processes from Short DoublyCensored Event Sequences

 cid 

  cid   cc cid      The width of edge is  cc cid     

Figure   The diseases  nodes  are labeled with ICD  codes  The colors indicate their subcategories  The size of the cth node is

Furthermore  we visualize the adjacent matrix of dynamical network of disease categories in Fig      We can  nd
that    with the increase of age the disease network becomes dense  which re ects the fact that the complications
of diseases are more and more common when people become old    the networks show that neoplasms and the
diseases of circulatory  respiratory  and digestive systems
have strong selftriggering patterns because the treatments
of these diseases often include several phases and require
patients to make admission multiple times    for kids and
teenagers  their disease networks        Age   and  Age
  networks  are very sparse  and their common diseases
mainly include neoplasms and the diseases of circulatory 
respiratory  and digestive systems    for middleaged people  the reasons for their admissions are diverse and complicated so that their disease networks are dense and include many mutuallytriggering patterns    for longevity
people  their disease networks        Age   and  Age  
networks  are relatively sparser than those of middleaged
people  because their admissions are generally caused by
elderly chronic diseases 
Additionally  we visualize the dynamical networks of the
diseases of circulatory systems in Fig    and  nd some interesting triggering patterns  For example  for kids  Age
  network  the typical circulatory diseases are  diseases
of mitral and aortic valves   ICD    and  cardiac dysrhythmias   ICD    which are common for premature
babies and the kids having congenital heart disease  For
the old  Age   network  the network becomes dense 
We can  nd that   as   main cause of death   heart failure   ICD    is triggered via multiple other diseases 
especially  secondary hypertension   ICD       sec 

ondary hypertension  is also likely to cause  other and illde ned cerebrovascular disease   ICD       Hemorrhoids   ICD    as   common disease with strong
selftriggering pattern  will cause frequent admissions of
patients  In summary  the analysis above veri es the rationality of our result   the dynamical disease networks we
learned indeed re ect the properties of human   health trajectory  The list of ICD  codes and the complete enlarged
network over age are shown in the supplementary  le 

  Conclusion
In this paper  we propose   novel data synthesis method to
learn Hawkes processes from SDC event sequences  With
the help of temporal information and optional features 
we measure the similarities among different SDC event
sequences and estimate the distribution of potential long
event sequences  Applying   samplingstitching mechanism  we successfully synthesize   large amount of long
event sequences and learn point processes robustly  We
test our method for both timeinvariant and timevarying
Hawkes processes  Experiments show that our data synthesis method improves the robustness of learning algorithms
for various models  In the future  we plan to provide more
theoretical and quantitative analysis to our data synthesis
method and apply it to more applications 

Acknowledgements
This work is supported in part via NSF IIS 
DMS  NIH    GM  NSFC  
   and the Key Program of Shanghai Science and
Technology Commission  JC 

Learning Hawkes Processes from Short DoublyCensored Event Sequences

References
Bacry  Emmanuel  Delattre  Sylvain  Hoffmann  Marc  and
Muzy  JeanFrancois  Some limit theorems for hawkes
processes and application to  nancial statistics  Stochastic Processes and their Applications   
 

Choi  Edward  Du  Nan  Chen  Robert  Song  Le  and Sun 
Jimeng  Constructing disease network and temporal progression model via contextsensitive hawkes process  In
ICDM   

Cowling  Ann  Hall  Peter  and Phillips  Michael    Bootstrap con dence regions for the intensity of   poisson
point process  Journal of the American Statistical Association     

Daley  Daryl   and VereJones  David  An introduction to
the theory of point processes  volume II  general theory and structure  Springer Science   Business Media 
 

De Gruttola  Victor and Lagakos  Stephen    Analysis of
doublycensored survival data  with application to aids 
Biometrics  pp     

Deyo  Richard    Cherkin  Daniel    and Ciol  Marcia   
Adapting   clinical comorbidity index for use with icd 
 cm administrative databases  Journal of clinical epidemiology     

Efron  Bradley  The jackknife  the bootstrap and other re 

sampling plans  volume   SIAM   

Eichler  Michael  Dahlhaus  Rainer  and Dueck  Johannes 
Graphical modeling for multivariate hawkes processes
with nonparametric link functions  Journal of Time Series Analysis   

Fan  ChunPo Steve 

Local Likelihood for Intervalcensored and Aggregated Point Process Data  PhD thesis  University of Toronto   

Gonc alves    lvia and Kilian  Lutz  Bootstrapping autoregressions with conditional heteroskedasticity of unknown form  Journal of Econometrics   
 

Guan  Yongtao and Loh  Ji Meng    thinned block bootstrap variance estimation procedure for inhomogeneous
spatial point patterns  Journal of the American Statistical
Association     

Johnson  Alistair EW  Pollard  Tom    Shen  Lu  Lehman 
Liwei    Feng  Mengling  Ghassemi  Mohammad 
Moody  Benjamin  Szolovits  Peter  Celi  Leo Anthony 
and Mark  Roger    Mimiciii    freely accessible critical care database  Scienti   data     

Kirk  Paul DW and Stumpf  Michael PH  Gaussian process regression bootstrapping  exploring the effects of
uncertainty in time course data  Bioinformatics   
   

Klein  John   and Moeschberger  Melvin   

Survival
analysis  techniques for censored and truncated data 
Springer Science   Business Media   

Kobayashi  Ryota and Lambiotte  Renaud  Tideh  Timedependent hawkes process for predicting retweet dynamics  arXiv preprint arXiv   

Luo  Dixin  Xu  Hongteng  Zhen  Yi  Ning  Xia  Zha 
Hongyuan  Yang  Xiaokang  and Zhang  Wenjun  Multitask multidimensional hawkes processes for modeling
event sequences  In IJCAI   

Luo  Dixin  Xu  Hongteng  Zhen  Yi  Dilkina  Bistra  Zha 
Hongyuan  Yang  Xiaokang  and Zhang  Wenjun  Learning mixtures of markov chains from aggregate data with
structural constraints  Transactions on Knowledge and
Data Engineering     

Mei  Hongyuan and Eisner  Jason  The neural hawkes process    neurally selfmodulating multivariate point process  arXiv preprint arXiv   

Paparoditis  Efstathios and Politis  Dimitris    Tapered

block bootstrap  Biometrika     

Politis  Dimitris   and Romano  Joseph    The stationary
bootstrap  Journal of the American Statistical association     

Rubin  Donald    Multiple Imputation for Nonresponse in

Surveys  volume   John Wiley   Sons   

Streit  Roy    Poisson point processes  imaging  tracking 
and sensing  Springer Science   Business Media   

Sun    and Kalb eisch  JD  Estimation of the mean function
of point processes based on panel count data  Statistica
Sinica  pp     

Turnbull  Bruce    Nonparametric estimation of   survivorship function with doubly censored data  Journal of
the American Statistical Association   
 

Hawkes  Alan   and Oakes  David    cluster process representation of   selfexciting process  Journal of Applied
Probability  pp     

Van den Berg  Gerard   and Drepper  Bettina  Inference for
sharedfrailty survival models with lefttruncated data 
Econometric Reviews     

Learning Hawkes Processes from Short DoublyCensored Event Sequences

Wellner  Jon   and Zhang  Ying  Two estimators of the
mean of   counting process with panel count data  Annals of Statistics  pp     

Xu  Hongteng  Zhen  Yi  and Zha  Hongyuan  Trailer generation via   point processbased visual attractiveness
model  In IJCAI   

Xu  Hongteng  Farajtabar  Mehrdad  and Zha  Hongyuan 
In

Learning granger causality for hawkes processes 
ICML     

Xu  Hongteng  Ning  Xia  Zhang  Hui  Rhee  Junghwan 
and Jiang  Guofei  Pinfer  Learning to infer concurrent request paths from system kernel events  In ICAC 
   

Xu  Hongteng  Wu  Weichang  Nemati  Shamim  and Zha 
Hongyuan 
Icu patient  ow prediction via discriminative learning of mutuallycorrecting processes  arXiv
preprint arXiv     

Yang  ShuangHong and Zha  Hongyuan  Mixture of muIn ICML 

tually exciting processes for viral diffusion 
 

Zhao  Qingyuan  Erdogdu  Murat    He  Hera    Rajaraman  Anand  and Leskovec  Jure  Seismic    selfexciting point process model for predicting tweet popularity  In KDD   

Zhou  Ke  Zha  Hongyuan  and Song  Le  Learning social infectivity in sparse lowrank networks using multidimensional hawkes processes  In AISTATS     

Zhou  Ke  Zha  Hongyuan  and Song  Le  Learning triggering kernels for multidimensional hawkes processes  In
ICML     

