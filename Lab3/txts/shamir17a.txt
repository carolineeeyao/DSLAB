Online Learning with Local Permutations and Delayed Feedback

Ohad Shamir     Liran Szlak    

Abstract

We propose an Online Learning with Local Permutations  OLLP  setting  in which the learner
is allowed to slightly permute the order of the
loss functions generated by an adversary  On one
hand  this models natural situations where the exact order of the learner   responses is not crucial 
and on the other hand  might allow better learning and regret performance  by mitigating highly
adversarial loss sequences  Also  with random
permutations  this can be seen as   setting interpolating between adversarial and stochastic
losses  In this paper  we consider the applicability of this setting to convex online learning with
delayed feedback  in which the feedback on the
prediction made in round   arrives with some de 
 
lay   With such delayed feedback  the best possible regret bound is wellknown to be   
     
We prove that by being able to permute losses by
  distance of at most    for       the regret
 
can be improved to   
ing   MirrorDescent based algorithm which can
be applied for both Euclidean and nonEuclidean
geometries  We also prove   lower bound  show 
 
ing that for         it is impossible to improve
the standard   
      regret bound by more than
constant factors  Finally  we provide some experiments validating the performance of our algorithm 

     cid       us 

  Introduction
Online learning is traditionally posed as   repeated game
where the learner has to provide predictions on an arbitrary sequence of loss functions  possibly even generated
adversarially  Although it is often possible to devise algorithms with nontrivial regret guarantees  these have to cope
with arbitrary loss sequences  which makes them conserva 

 Equal contribution

 Weizmann Institute of Science  ReLiran Szlak  li 

Correspondence to 

hovot 
ran szlak weizmann ac il 

Israel 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

     

tive and in some cases inferior to algorithms not tailored to
cope with worstcase behavior  Indeed  an emerging line of
work considers how better online learning can be obtained
on  easy  data  which satis es some additional assumptions  Some examples include losses which are sampled
       from some distribution  change slowly in time  have
  consistently bestperforming predictor across time  have
some predictable structure  mix adversarial and stochastic
losses  etc 
 Sani et al    Karnin and Anava 
  Bubeck and Slivkins    Seldin and Slivkins 
  Hazan and Kale    Chiang et al    Steinhardt and Liang    Hazan and Kale    Rakhlin and
Sridharan    Seldin and Slivkins   
In this paper  we take   related but different direction 
Rather than explicitly excluding highly adversarial loss sequences  we consider how slightly perturbing them can mitigate their worstcase behavior  and lead to improved performance  Conceptually  this resembles smoothed analysis  Spielman and Teng    in which one considers the
worstcase performance of some algorithm  after performing some perturbation to their input  The idea is that if the
worstcase instances are isolated and brittle  then   perturbation will lead to easier instances  and better re ect the
attainable performance in practice 
Speci cally  we propose   setting  in which the learner
is allowed to slightly reorder the sequence of losses generated by an adversary  Assuming the adversary chooses
losses            hT   and before any losses are revealed  the
learner may choose   permutation   on              satisfying maxt              for some parameter   
and then play   standard online learning game on losses
                 We denote this as the Online Learning
with Local Permutations  OLLP  setting  Here    controls
the amount of power given to the learner        means
that no reordering is performed  and the setting is equivalent to standard adversarial online learning  At the other
extreme        means that the learner can reorder the
losses arbitrarily  For example  the learner may choose to
order the losses uniformly at random  making it   quasistochastic setting  the only difference compared to       
losses is that they are sampled withoutreplacement rather
than withreplacement 
We argue that allowing the learner some  exibility in the

Online Learning with Local Permutations and Delayed Feedback

order of responses is   natural assumption  For example 
when the learner needs to provide rapid predictions on  
highfrequency stream of examples  it is often immaterial
if the predictions are not provided in the exact same order at
which the examples arrived  Indeed  by buffering examples
for   few rounds before being answered  one can simulate
the local permutations discussed earlier 
We believe that this setting can be useful in various online learning problems  where it is natural to change   bit
the order of the loss functions  In this paper  we focus on
one wellknown problem  namely online learning with delayed feedback 
In this case  rather than being provided
with the loss function immediately after prediction is made 
the learner only receives the loss function after   certain
number       of rounds  This naturally models situations where the feedback comes much more slowly than
the required frequency of predictions  To give   concrete
example  consider   web advertisement problem  where an
algorithm picks an ad to display  and then receives   feedback from the user in the form of   click  It is likely that
the algorithm will be required to choose ads for new users
while still waiting for the feedback from the previous user 
Web advertisement  answering user queries and many other
regimes where the feedback come from   user  are all relevant to this setting  It is also plausible that the distribution
of examples in the above scenarios is not stochastic neither
is it adversarial  and thus the proposed setting of Online
Learning With Local Permutation is relevant to these cases 
For convex online learning with delayed feedback  in  
 
standard adversarial setting  it is known that the attain 
      and this is also the
able regret is on the order of   
best possible in the worst case  Weinberger and Ordentlich 
  Mesterharm    Langford et al    Joulani
et al    Quanrud and Khashabi    On the other
hand  in   stochastic setting where the losses are sampled
       from some distribution   Agarwal and Duchi   
 
show that the attainable regret is much better  on the order
of   
      This gap between the worstcase adversarial
setting  and the milder        setting  hints that this problem
is   good    for our OLLP framework 
Thus  in this paper  we focus on online learning with feedback delayed up to   rounds  in the OLLP framework
where the learner is allowed to locally permute the loss
functions  up to   distance of    First  we devise an algorithm  denoted as Delayed Permuted Mirror Descent  and
prove that it achieves an expected regret bound of order

  cid            assuming       As   increases

compared to   this regret bound interpolates between the
  regret 
standard adversarial
typical of        losses  As its name implies  the algorithm
is based on the wellknown online mirror descent  OMD 
algorithm  see  Hazan et al    ShalevShwartz et al 

    regret  and   milder

 

 

  and works in the same generality  involving both
Euclidean and nonEuclidean geometries  The algorithm
is based on dividing the entire sequence of functions into
blocks of size   and performing   random permutation
within each block  Then  two copies of OMD are ran
on different parts of each block  with appropriate parameter settings    careful analysis  mixing adversarial and
stochastic elements  leads to the regret bound 
In addition  we provide   lower bound complementing our
upper bound analysis  showing that when   is signi 
cantly smaller than    speci cally      then even with
local permutations  it is impossible to obtain   worsecase
      matching  up to constants  the
regret better than  
attainable regret in the standard adversarial setting where
no permutations are allowed  Finally  we provide some experiments validating the performance of our algorithm 
The rest of the paper is organized as follows  in section  
we formally de ne the Online Learning with Local Permutation setting  section   describes the Delayed Permuted
Mirror Descent algorithm and outlines its regret analysis 
section   discusses   lower bound for the delayed setting
with limited permutation power  section   shows experiments  and  nally section   provides concluding remarks 
discussion  and open questions  Appendix   contains most
of the proofs 

 

  Setting and Notation
Convex Online Learning  Convex online learning is posed
as   repeated game between   learner and an adversary
 assumed to be oblivious in this paper  First  the adversary chooses   convex losses            hT which are
functions from   convex set   to    At each iteration
                   the learner makes   prediction wt  and
suffers   loss of ht  wt  To simplify the presentation  we
use the same notation  ht    to denote either   gradient
of ht at    if the loss is differentiable  or   subgradient at
  otherwise  and refer to it in both cases as   gradient  We
assume that both       and the gradients of any function ht in any point       are bounded        some norm 
Given   norm  cid     cid  with   dual norm  cid     cid  we assume that
the diameter of the space   is bounded by    and that
                    hT     cid      cid       The
purpose of the learner is to minimize her  expected  regret 
    

         

 cid 

ht    

 cid    cid 

  

ht  wt      cid 
  cid 

  

where      argmin
   

ht    

  

where the expectation is with respect to the possible randomness of the algorithm 

Online Learning with Local Permutations and Delayed Feedback

  cid cid  

 cid 
   ft   

   ft wt   cid  

Learning with Local Permutations  In this paper  we introduce and study   variant of this standard setting  which
gives the learner   bit more power  by allowing her to
slightly modify the order in which the losses are processed 
thus potentially avoiding highly adversarial but
brittle loss constructions  We denote this setting as the
Online Learning with Local Permutations  OLLP  setting 
Formally  letting   be   permutation window parameter  the learner is allowed  at the beginning of the game 
and before any losses are revealed  to permute            hT
to                  where   is   permutation from
the set   erm                         After this
permutation is performed  the learner is presented with
the permuted sequence as in the standard online learning setting  with the same regret as before  To simplify notation  we let ft        so the learner is
presented with the loss sequence            fT   and the regret is the same as the standard regret              
  Note that if      
then we are in the fully adversarial setting  no permutation is allowed  At the other extreme  if       and  
is chosen uniformly at random  then we are in   stochastic
setting  with   uniform distribution over the set of functions
chosen by the adversary  note that this is close but differs  
bit from   setting of        losses  In between  as   varies 
we get an interpolation between these two settings 
Learning with Delayed Feedback  The OLLP setting can
be useful in many applications  and can potentially lead to
improved regret bounds for various tasks  compared to the
standard adversarial online learning  In this paper  we focus
on studying its applicability to the task of learning from
delayed feedback 
Whereas in standard online learning  the learner gets to observe the loss ft immediately at the end of iteration    here
we assume that at round    she only gets to observe ft  for
some delay parameter        and if       no feedback
is received  For simplicity  we focus on the case where
  is  xed  independent of    although our results can be
easily generalized  as discussed in subsection   We emphasize that this is distinct from another delayed feedback
scenario sometimes studied in the literature  Agarwal and
Duchi    Langford et al    where rather than receiving ft  the learner only receives    sub gradient of
ft  at wt    This is   more dif cult setting  which is relevant for instance when the delay is due to the time it takes
to compute the gradient 

  Algorithm and Analysis
Our algorithmic approach builds on the wellestablished
online mirror descent framework  Thus  we begin with  
short reminder of the Online Mirror Descent algorithm  For

  more extensive explanation refer to  Hazan et al   
Readers who are familiar with the algorithm are invited to
skip to Subsection  
The online mirror descent algorithm is   generalization of
online gradient descent  which can handle nonEuclidean
geometries  The general idea is the following  we start
with some point wt      where   is our primal space 
We then map this point to the dual space using    strictly
convex and continuously differentiable  mirror map       
   wt       then perform the gradient update in the
dual space  and  nally map the resulting new point back
to our primal space   again       we want to  nd   point
wt              wt       wt        gt where gt
the point satisfydenotes the gradient  Denoting by wt   
       wt        gt  it can be shown that
ing  wt   
       wt        gt  where   is the dual
wt   
  might lie outside our hyfunction of   This point  wt   
pothesis class    and thus we might need to project it back
to our space    We use the Bregman divergence associated
to   to do this 

 

 

 

 

wt    argmin

   

 cid    wt   

 

 

where the Bregman divergence   is de ned as

 cid                            cid          cid 

Speci   choices of the mirror map   leads to speci   instantiations of the algorithms for various geometries  Per 
 cid   cid 
haps the simplest example is          
  with associated Bregman divergence  cid            
     cid       cid  This
leads us to the standard and wellknown online gradient descent algorithm  where wt  is the Euclidean projection on
the set   of

         cid  
 cid     Rn
   cid  

Another example is the negative entropy mirror map
   xi   log  xi  which is  strongly convex with respect to the  norm on the simplex    

   xi    cid  In that case  the resulting algo 

rithm is the wellknown multiplicative updates algorithm 
where

wt       gt 

  cid 

wt     wt     exp gt   

wt     exp gt   

  

Instead of the  norm on the simplex  one can also consider
   where   is the
arbitrary pnorms  and take        
dual norm  satisfying            

   cid   cid 

  The Delayed Permuted Mirror Descent Algorithm

Before describing the algorithm  we note that we will focus
here on the case where the permutation window parameter

Online Learning with Local Permutations and Delayed Feedback

 

  is larger than the delay parameter   If       then our
regret bound is generally no better than the   
      obtainable by   standard algorithm without any permutations 
and this is actually tight as shown in Section  
We now turn to present our algorithm  denoted as The Delayed Permuted Mirror Descent algorithm  see algorithm  
below as well as  gure   for   graphical illustration  First 
the algorithm splits the time horizon   into   consecutive blocks  and performs   uniformly random permutation
on the loss functions within each block  Then  it runs two
online mirror descent algorithms in parallel  and uses the
delayed gradients in order to update two separate predictors   wf and ws  where wf is used for prediction in the
 rst   rounds of each block  and ws is used for prediction
in the remaining       rounds  here    stands for  rst 
and   stands for  second  The algorithm maintaining ws
crucially relies on the fact that the gradient of any two functions in   block  at some point    is equal  in expectation
over the random permutation within each block  This allows us to avoid most of the cost incurred by delays within
each block  since the expected gradient of   delayed function and the current function are equal    complicating factor is that at the  rst   rounds of each block  no losses from
the current block has been revealed so far  To tackle this 
we use another algorithm  maintaining wf   speci cally to
deal with the losses at the beginning of each block  This
algorithm does not bene   from the random permutation 
and its regret scales the same as standard adversarial online learning with delayed feedback  However  as the block
size   increases  the proportion of losses handled by wf
decreases  and hence its in uence on the overall regret diminishes 
The above refers to how the blocks are divided for purposes of prediction  For purposes of updating the predictor
of each algorithm  we need to use the blocks   bit differently  Speci cally  we let    and    be two sets of indices 
   includes all indices from the  rst   time points of every block  and is used to update wf      includes the  rst
    indices of every block  and is used to update ws  see
 gure   Perhaps surprisingly  note that    and    are not
disjoint  and their union does not cover all of             
The reason is that due to the random permutation in each
block  the second algorithm only needs to update on some
of the loss functions in each block  in order to obtain an
expected regret bound on all the losses it predicts on 

  Analysis

The regret analysis of the Delayed Permuted Mirror Descent algorithm is based on   separate analysis of each
of the two mirror descent subalgorithms  where in the
 rst subalgorithm the delay parameter   enters multiplicatively  but doesn   play   signi cant role in the regret of

Algorithm   Delayed Permuted Mirror Descent

      jf   js    

Input            
Init  wf
      ws
Divide   to consecutive blocks of size    and permute
the losses uniformly at random within each block  Let
           fT denote the resulting permuted losses 
for         do

if      rst   rounds of the block then

Predict using wf
jf
Receive   loss function from   places back 
ft     fT jf   
If none exists  in the  rst  
iterations  take the   function 
Compute   fT jf   
jf 
Update  wf
 
Project  wjf     argmin
jf   jf    

 cid 
 cid 
 cid       fT jf   
 cid 

 cid 

 cid cid 

   wf

 cid 

   

jf 

 cid 

 cid 

 cid 

jf    
 

 

wf
jf

wf

jf    
 

wf

else

Predict using ws
js
Receive   loss function from   places back  ft   
fT js 
Compute   ft 
Update  ws
 

 cid     fT js 
 cid 
 cid ws
 cid ws
 cid          fT js 
 cid cid 
 cid ws
 cid 
 cid 

 cid cid ws

js   
 

js

js

js

js

 cid 

   ws

js   
 

Project  wjs    argmin
js   js    

   

end if
end for

the second subalgorithm  which utilizes the stochastic nature of the permutations  Combining the regret bound of
the two subalgorithms  and using the fact that the portion
of losses predicted by the second algorithm increases with
   leads to an overall regret bound improving in   
In the proof  to analyze the effect of delay  we need  
bound on the distance between any two consequent predictors wt  wt  generated by the subalgorithm  This depends on the mirror map and Bregman divergence used for
the update  and we currently do not have   bound holding
in full generality  Instead  we let        be some upper
bound on  cid wt    wt cid  where the update is using stepsize
   and gradients of norm      Using        we prove  
general bound for all mirror maps  In Lemmas   and   in
Appendix    we show that for two common mirror maps
 corresponding to online gradient descent and multiplicative weights                    for some numerical con 

stant    leading to   regret bound of   cid           

Also  we prove theorem   for  strongly convex mirror

Online Learning with Local Permutations and Delayed Feedback

Figure   Scheme of predictions and updates of both parallel algorithms  best viewed in color  see text for details  Top color bars mark
which iterations are in     purple lines  and which are in     green lines  Top timeline shows which predictor  wf or ws  is used to
predict in each iteration  Middle timeline shows where gradients for updating wf come from  rst   iterations of the previous block 
and lower timeline shows where gradients for updating ws come from  rst       iterations of the same block  each gradient from
exactly   rounds back 

maps  although it can be generalized to any  strongly convex mirror map by scaling 
Theorem   Given   norm  cid     cid  suppose that we run the
Delayed Permuted Mirror Descent algorithm using   mirror map   which is  strongly convex         cid     cid  over  
domain   with diameter          the bregman divergence
of                cid            and such that the
 sub gradient   of each loss function on any       satis es  cid   cid       where  cid     cid  is the dual norm of  cid     cid 
Then the expected regret  given   delay parameter   and
step sizes         satis es 

 cid 

ft  wt    ft    

 cid    cid 

  

 

    
  

 

     
 

          
 

    
 
  
              
  
    
 

 

                   

Furthermore  if                   for some constant   
and     
  the regret
is bounded by

  
 
      
  

  
 
    

  cid 

     

      

  

 cid 

  BG

 

 cid 

   
 
   

   

 cid   
 cid cid 

 

 cid 
 cid cid 

         

   
 

   

           

 

  BG

 

   ft wf
   ft  ws

      
      
  and   

When          this bound is   
similar to
     
 
the standard adversarial learning case  However  as   increases  the regret gradually improves to   
      which
is the regret attainable in   purely stochastic setting with
       losses  The full proof can be found in appendix   
and we sketch below the main ideas 
First  using the de nition of regret  we show that it is
enough to upperbound the regret of each of the two subalgorithms separately  Then  by   standard convexity argument  we reduce this to bounding sums of terms of the
   cid  for the  rst subalgorithm 
form   cid wf
   cid  for the second subalgorithm
and    cid ws
 where   
  are the best  xed points in hindsight
for the losses predicted on by the  rst and second subalgorithms  respectively  and where for simplicity we assume the losses are differentiable 
In contrast  we can
use the standard analysis of mirror descent  using delayed gradients  to get   bound for the somewhat differt   cid  for the  rst subent terms   cid wf
      
algorithm  and    cid ws
   cid  for the second
subalgorithm  Thus  it remains to bridge between these
terms 
Starting with the second subalgorithm  we note that since
we performed   random permutation within each block  the
expected value of all loss functions within   block  in expectation over the block  and evaluated at    xed point  is
equal  Moreover  at any time point  the predictor ws maintained by the second subalgorithm does not depend on the

   ft   wf
      

   ft   ws

                     Predictions Updates for               Block   Block   Block                         Updates for                   Online Learning with Local Permutations and Delayed Feedback

delayed nor the current loss function  Therefore  condit   and in expectation over the random permutationed on ws
tion in the block  we have that

  ft ws

        ft   ws
   

      

from which it can be shown that
   cid ws

   ft ws

      

   ft wf

   ft   ws

   cid       cid ws

   cid  and   cid wf

   cid 
Thus  up to   negligible factor having to do with the  rst
few rounds of the game  the second subalgorithm   expected regret does not suffer from the delayed feedback 
For the  rst subalgorithm  we perform an analysis which
does not rely on the random permutation 
Speci 
cally  we  rst show that since we care just about the
it is suf cient to bound the differsum of the losses 
ence between   cid wf
      
    
   ft wf
   cid  Using CauchyShwartz  this difference
  
   cid  which
can be upper bounded by  cid wf
in turn is at most                using our assumptions on the
gradients of the losses and the distance between consecutive predictors produced by the  rst subalgorithm 
Overall  we get two regret bounds  one for each subalgorithm  The regret of the  rst subalgorithm scales
with   similar to the nopermutation setting  but the subalgorithm handles only   small fraction of the iterations  the
 rst   in every block of size    In the rest of the iterations 
where we use the second subalgorithm  we get   bound
that resembles more the stochastic case  without such dependence on   Combining the two  the result stated in
Theorem   follows 

  cid cid ft wf

   wf

  Handling Variable Delay Size

So far  we discussed   setting where the feedback arrives
with    xed delay of size   However  in many situations
the feedback might arrive with   variable delay size    at
any iteration    which may raise   few issues 
First  feedback might arrive in an asynchronous fashion 
causing us to update our predictor using gradients from
time points further in past after already using more recent
gradients  This complicates the analysis of the algorithm 
  second  algorithmic problem  is that we could also possibly receive multiple feedbacks simultaneously  or no feedback at all  in certain iterations  since the delay is of variable size  One simple solution is to use buffering and reduce the problem to   constant delay setting  Speci cally 
we assume that all delays are bounded by some maximal
delay size   We would like to use one gradient to update our predictor at every iteration  this is mainly for ease
of analysis  practically one could update the predictor with
multiple loss functions in   single iteration 
In order to
achieve this  we can use   buffer to store loss functions that

were received but have not been used to update the predictors yet  We de ne Gradf and Grads  two buffers that
will contain gradients from time points in    or    correspondingly  Each buffer is of size   If we denote by Ft
the set of function that have arrived in time    we can simply store loss functions that have arrived asynchronously
in the buffers de ned above  sort them in ascending order 
and take the delayed loss function from exactly   iterations
back in the update step  This loss function must be in the
appropriate buffer since the maximal delay size is   From
this moment on  the algorithm can proceed as usual and its
analysis still applies 

 cid 

 cid 

  Lower Bound
In this section  we give   lower bound in the setting where
  with all feedback having delay of exactly   We
     
will show that for this case  the regret bound cannot be improved by more than   constant factor over the bound of
the adversarial online learning problem with    xed delay
of size   namely  
for   sequence of length    
We hypothesize that this regret bound also cannot be signi cantly improved for any           and not just    
However  proving this remains an open problem 
Theorem   For every  possible randomized  algorithm  
with   permutation window of size      
    there exists  
choice of linear   Lipschitz functions over         
such that the expected regret of   after   rounds  with respect to the algorithm   randomness  is

   

 cid 
  cid 

  

 cid    cid 

 

ft  wt      cid 

 cid 

 cid 

ft    

   

   

  

  

where      argmin
   

ft    

 

For completeness  we we also provide in appendix     
proof that when             no permutations allowed 
then the worstcase regret is no better than  
      This
is of course   special case of Theorem   but applies to
the standard adversarial online setting  without any local
permutations  and the proof is simpler  The proof sketch
for the setting where no permutation is allowed was already
provided in  Langford et al    and our contribution is
in providing   full formal proof 
The proof in the case where       is based on linear
losses of the form ft        wt over     where
         Without permutations  it is possible to
 
      lower bound by dividing the   iterations
prove    
into blocks of size   where the   values of all losses at
each block is the same and randomly chosen to equal either
  or   Since the learner does not obtain any informa 

Online Learning with Local Permutations and Delayed Feedback

tion about this value until the block is over  this reduces to
adversarial online learning over     rounds  where the regret at each round scales linearly with   and overall regret

at least  cid          

     

 

In the proof of theorem   we show that by using   similar
construction  even with permutations  having   permutation
window less than     still means that the   values would
still be unknown until all loss functions of the block are
processed  leading to the same lower bound up to constants 
The formal proof appears in the appendix  but can be
sketched as follows   rst  we divide the   iterations into
blocks of size     Loss functions within each block are
identical  of the form ft        wt  and the value of   per
block is chosen uniformly at random from     as
before  Since here  the permutation window   is smaller
than     then even after permutation  the time difference
between the  rst and last time we encounter an   that originated from   single block is less than   This means that
by the time we get any information on the   in   given
block  the algorithm already had to process all the losses
in the block  which leads to the same dif culty as the nopermutation setting  Speci cally  since the predictors chosen by the algorithm when handling the losses of the block
do not depend on the   value in that block  and that   is
chosen randomly  we get that the expected loss of the algorithm at any time point   equals   Thus  the cumulative
loss across the entire loss sequence is also   In contrast 
for    the optimal predictor in hindsight over the entire
sequence  we can prove an expected accumulated loss of
 
      after   iterations  using Khintchine inequality
and the fact that the    were randomly chosen per block 
 
This leads us to   lower bound of expected regret of order
      for any algorithm with   local permutation window
of size        

 

  Experiments
We consider the adversarial setting described in section  
where an adversary chooses   sequence of functions such
that every   functions are identical  creating blocks of size
  of identical loss functions  of the form ft wt         wt
where    is chosen randomly in     for each block 
In all experiments we use       rounds    delay parameter of       set our step sizes according to the
theoretical analysis  and report the mean regret value over
  repetitions of the experiments 
In our  rst experiment  we considered the behavior of our
Delayed Permuted Mirror Descent algorithm  for window
sizes       ranging from       to     In this experiment 
we chose the   values randomly  while ensuring   gap of
  between the number of blocks with   values and the
number of blocks with   values  this ensures that the op 

 

timal    is   suf ciently strong competitor  since otherwise
the setting is too  easy  and the algorithm can attain negative regret in some situations  The results are shown in
Figures   and   where the  rst  gure presents the accumulated regret of our algorithm over time  whereas the second
 gure presents the overall regret after   rounds  as   function of the window size   
When applying our algorithm in this setting with different values of       ranging from           and up
to         we get   regret that scales from the order of
the adversarial bound to the order of the stochastic bound
depending on the window size  as expected by our analysis  For all window sizes greater than       we get   regret
that is in the order of the stochastic bound   this is not surprising  since after the permutation we get   sequence of
 
functions that is very close to an        sequence  in which
    regret
case any algorithm can be shown to achieve   
in expectation  Note that this performance is better than
that predicted by our theoretical analysis  which implies an
    behavior only when         It is an open
  
and interesting question whether it means that our analysis
can be improved  or whether there is   harder construction
leading to   tighter lower bound 
In our second experiment  we demonstrate the brittleness
of the lower bound construction for standard online learning with delayed feedback  focusing on the       regime 
Speci cally  we create loss functions with blocks as before
 where following the lower bound construction  the   values in each block of size       is chosen uniformly at
random  Then  we perform   random permutation over
consecutive windows of size    ranging from       up
to      
    Finally  we run standard
 
Online Gradient Descent with delayed gradients  and  xed
step size  
    on the permuted losses  The results are
presented in Figure  
For window sizes      
  we see that the regret is close to
the adversarial bound  whereas as we increase the window
size the regret decreases towards the stochastic bound  This
experiment evidently shows that this hardness construction
is indeed brittle  and easily breaks in the face of local permutations  even for window sizes      

    in intervals of  

  Discussion
We presented the OLLP setting  where   learner can locally
permute the sequence of examples from which she learns 
This setting can potentially allow for improved learning in
many problems  where the worstcase regret is based on
highly adversarial yet brittle constructions  In this paper 
we focused on the problem of learning from delayed feedback in the OLLP setting  and showed how it is possible to
improve the regret by allowing local permutations  Also 

Online Learning with Local Permutations and Delayed Feedback

 
Figure   Regret of the Delayed Permuted Mirror Descent algorithm  with local permutation in window sizes ranging from          
to           pink   indicates the order of the stochastic bound  
      and   red   indicates the order of the adversarial bound
 
 

      Regret is averaged over   repetitions  Best viewed in color 

Figure   Regret of the Delayed Permuted Mirror Descent algorithm for different window sizes  after       iterations  with
local permutation window sizes ranging from           to
 
        Red dashed line  top  indicates the order of the adver 
      and green dashed line  bottom  indicates the
sarial bound  
order of the stochastic bound  
      Regret is averaged over
  repetitions  error bars indicate standard error of the mean 
Best viewed in color 

 

we proved   lower bound in the situation where the permutation window is signi cantly smaller than the feedback
delay  and showed that in this case  permutations cannot
allow for   better regret bound than the standard adversarial setting  We also provided some experiments  demonstrating the power of the setting as well as the feasibility
of the proposed algorithm  An interesting open question
is what minimal permutation size allows nontrivial regret
improvement  and whether our upper bound in Theorem  
is tight  As suggested by our empirical experiments  it
is possible that even small local permutations are enough
to break highly adversarial sequences and improve performance in otherwise worstcase scenarios  Another interest 

Figure   Regret of the standard Online Gradient Descent algorithm  in   adversarialy designed setting as described in   and
with local permutation in window sizes ranging from       to
 
    Red dashed line  top  indicates the order of the adverM    
      and green dashed line  bottom  indicates the
sarial bound  
order of the stochastic bound  
      Regret is averaged over
  repetitions  error bars indicate standard error of the mean 
Best viewed in color 

 

ing direction is to extend our results to   partial feedback
      bandit  setting  Finally  it would be interesting to study
other cases where local permutations allow us to interpolate
between fully adversarial and more benign online learning
scenarios 

Acknowledgements

OS is supported in part by an FP  Marie Curie CIG grant 
the Intel ICRICI Institute  and Israel Science Foundation
grant   LS is an ISEF fellow 

Online Learning with Local Permutations and Delayed Feedback

Yevgeny Seldin and Aleksandrs Slivkins  One practical algorithm for both stochastic and adversarial bandits  In
Proceedings of the  st International Conference on Machine Learning  ICML  pages    

Shai ShalevShwartz et al  Online learning and online convex optimization  Foundations and Trends   cid  in Machine
Learning     

Daniel   Spielman and ShangHua Teng  Smoothed analysis of algorithms  Why the simplex algorithm usually
takes polynomial time  Journal of the ACM  JACM   
   

Jacob Steinhardt and Percy Liang  Adaptivity and optimism  An improved exponentiated gradient algorithm 
In ICML  pages    

Marcelo   Weinberger and Erik Ordentlich  On delayed
prediction of individual sequences  IEEE Transactions
on Information Theory     

References
Alekh Agarwal and John   Duchi  Distributed delayed
In Advances in Neural Infor 

stochastic optimization 
mation Processing Systems  pages    

  ebastien Bubeck and Aleksandrs Slivkins  The best of
In

both worlds  Stochastic and adversarial bandits 
COLT  pages    

ChaoKai Chiang  Tianbao Yang  ChiaJung Lee  Mehrdad
Mahdavi  ChiJen Lu  Rong Jin  and Shenghuo Zhu 
Online optimization with gradual variations  In COLT 
pages    

Elad Hazan and Satyen Kale  Extracting certainty from uncertainty  Regret bounded by variation in costs  Machine
learning     

Elad Hazan and Satyen Kale  Better algorithms for benign bandits  Journal of Machine Learning Research   
 Apr   

Elad Hazan et al  Introduction to online convex optimization  Foundations and Trends   cid  in Optimization   
   

Pooria Joulani  Andr as Gy orgy  and Csaba Szepesv ari  OnIn ICML  

line learning under delayed feedback 
pages    

Zohar   Karnin and Oren Anava  Multiarmed bandits 

Competing with optimal sequences  In NIPS   

John Langford  Alexander Smola  and Martin Zinkevich 
Slow learners are fast  arXiv preprint arXiv 
 

Ishai Menache  Ohad Shamir  and Navendu Jain  Ondemand  spot  or both  Dynamic resource allocation for
executing batch jobs in the cloud  In  th International
Conference on Autonomic Computing  ICAC   pages
   

Chris Mesterharm  Online learning with delayed label
In International Conference on Algorithmic

feedback 
Learning Theory  pages   Springer   

Kent Quanrud and Daniel Khashabi  Online learning with
adversarial delays  In Advances in Neural Information
Processing Systems  pages    

Alexander Rakhlin and Karthik Sridharan  Online learning
with predictable sequences  In COLT  pages  
 

Amir Sani  Gergely Neu  and Alessandro Lazaric  ExploitIn Advances in
ing easy data in online optimization 
Neural Information Processing Systems  pages  
 

