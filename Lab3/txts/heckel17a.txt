The Sample Complexity of Online OneClass Collaborative Filtering

Reinhard Heckel   Kannan Ramchandran  

Abstract

We consider the online oneclass collaborative
 ltering  CF  problem that consists of recommending items to users over time in an online
fashion based on positive ratings only  This problem arises when users respond only occasionally
to   recommendation with   positive rating  and
never with   negative one  We study the impact of the probability of   user responding to
  recommendation  pf  on the sample complexity       the number of ratings required to make
 good  recommendations  and ask whether receiving positive and negative ratings  instead of
positive ratings only  improves the sample complexity  Both questions arise in the design of
recommender systems  We introduce   simple
probabilistic user model  and analyze the performance of an online userbased CF algorithm  We
prove that after an initial cold start phase  where
recommendations are invested in exploring the
user   preferences  this algorithm makes up to
  fraction of the recommendations required for
updating the user   preferences perfect recommendations  The number of ratings required for
the cold start phase is nearly proportional to  pf 
and that for updating the user   preferences is essentially independent of pf  As   consequence
we  nd that  receiving positive and negative ratings instead of only positive ones improves the
number of ratings required for initial exploration
by   factor of  pf  which can be signi cant 

  Introduction
Recommender systems seek to identify the subset of   large
collection of items that   user likes  Aggarwal    In
practice  recommender systems often use collaborative  ltering  CF   Ekstrand et al    to identify items   given

 University of California  Berkeley  California  USA  Corre 

spondence to  Reinhard Heckel  heckel berkeley edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

user likes  based on ratings that this user and   large number of other users have provided in the past  To this end 
  userbased CF algorithm  rst identi es similar users  and
then predicts the ratings of   given user from the ratings
provided by similar users  In practice  recommender systems typically operate in an online fashion       items are
recommended to users over time  and the ratings obtained
in response to recommendations are used to improve future
recommendations 
However  in many application areas of recommender systems  users only occasionally rate what they  like  and
never what they  dislike       in ecommerce  such as
Amazon   recommender system  an item  or   set of items 
is recommended to   user  and the user either purchases
the item  which indicates    like  or the user does not purchase the item  Not purchasing the item  however  does
not necessarily indicate    dislike  since the user might not
even have considered the recommendation  Other examples of such feedback include implicit ratings such as viewing   webpage and listening to   song  Hu et al    and
businessto business recommender systems  Heckel et al 
  The problem of generating recommendations based
on positive ratings only is known as oneclass CF  Pan
et al    The lack of negative ratings is often considered to make this problem challenging  Pan et al   
However  it is unclear whether it is fundamentally more
dif cult in the absence of negative ratings to identify the
user   preferences  in the sense that the sample complexity
      the number of ratings required to make good recommendations  is fundamentally larger  Additionally  there is
little theoretical understanding on how the probability of  
user responding to   recommendation  pf  affects the sample complexity of   oneclass CF algorithm and in particular its cold start time       the number of recommendations
the algorithm needs to invest in learning the user   preferences before being able to make good recommendations 
In this paper  we address those two questions  that turn out
to be closely related 
To this end  we introduce   probabilistic model for   oneclass online recommender system and   corresponding online userbased CF algorithm  termed UserCF  and analyze its performance  Our model  and elements of our
algorithm  are inspired by   related model and algorithm
by Bresler et al    for the twoclass CF problem      

Online OneClass Collaborative Filtering

for   setup where positive and negative ratings are available 
In   nutshell  each user in our model has   latent
probability preference vector which describes the extent
to which she likes or dislikes each item  Similar users
have similar preference vectors  At   given time step
              the UserCF algorithm recommends   single
item to each user  typically different for each user  With
probability speci ed by   corresponding preference vector 
the user likes or dislikes the recommended item  If the user
likes the item  the user rates it with probability pf  and if
the user does not like the item  no rating is given  An item
that has been rated cannot be recommended again  since  
rating often corresponds to consuming an item  and there is
little point in       recommending   product that has been
previously purchased in the past for   second time  While
in practice the probability pf could be different for each
user  for ease of presentation  we assume that pf is constant over all users  The goal of the UserCF algorithm is
to maximize the number of recommendations that   users
likes 
The UserCF algorithm consists of an exploitation step that
recommends items that similar users have rated positively 
and two kinds of exploration steps  one to learn the preferences of the users and the other to explore similarity between users 
Our main result  stated in Section   guarantees that after
  certain cold start time in which the UserCF algorithm
  items to each
recommends the order of  log      
   
user    fraction     pf of the remaining recommendations
given by the UserCF algorithm are optimal  Here    is  
learning rate that can be chosen very close to zero    is
the number of users  and     numerical constant  The cold
start time is required to identify similar users and learn their
preferences regarding   few items  We also show that any
algorithm has to make on the order of    
  recommendations before it can make good recommendations  therefore
the UserCF algorithm is near optimal  The fraction   pf
of the remaining time steps is associated with learning the
preferences of the users  This  cost  of   pf does not have
to be paid upfront  but is paid continuously  After the cold
start time  the UserCF algorithm starts exploiting successfully  Again    fraction of the recommendations proportional to  pf is necessary to learn the preference of the
users  Our numerical results in Section   show that even if
our data is not generated from the probabilistic model  but
is based on real data  the cold start time and the fraction of
time steps required to learn the preferences of the users are
nearly proportional to    
As   consequence of this result  we  nd that obtaining positive and negative ratings instead of only positive ones  improves the number of ratings required for the initial cold
start period by   factor of pf  To see this  note that the ex 

  and  pf  respectively 

 

pected number of ratings obtained by   user in   given number of time steps or equivalently after   given number of
recommendations is proportional to pf  Thus  the number
of ratings required for the initial cold start time is inversely
proportional to pf  and the number of ratings required for
continuously learning the preferences is independent of pf 
Since pf     corresponds to users giving positive and negative feedback  no positive feedback implies dislike when
pf     the number of ratings required for the coldstart
time is by   factor of  pf larger than the number of ratings
required by   userbased CF algorithm that obtains positive
and negative ratings 
Those  ndings are relevant for the design of recommender
systems  since both pf and whether positive  or negative
and positive ratings are obtained can often be incorporated
in the design of   recommender system  Therefore an understanding of the associated bene ts and costs in terms
of sample complexity  as provided in this paper  is important  We  nally note that the goal of this paper is not to
improve upon stateof the art algorithms  but rather to inform the design of algorithms and what to expect in terms
of sample complexity as   function of the various parameters involved 

Related literature  While to the best of our knowledge 
this is the  rst work that analytically studies oneclass CF
in an online setting  theoretical results have been established for the two or multiple class CF problems  One
of the  rst analytical results on userbased CF algorithms 
an asymptotic performance guarantee under   probabilistic model  was established by Biau et al    Most
related to our approach is the CollaborativeGreedy algorithm studied by Bresler et al    for the online twoclass CF problem  The CollaborativeGreedy algorithm
differs from our UserCF algorithm in selecting the nearest
neighbors based on thresholding similarity  instead of selecting the   most similar users  and in the way preferences
of the users are explored  This difference in the exploration
steps is crucial for establishing that after the cold start period  our UserCF algorithm makes optimal recommendations in   fraction       pf of the remaining time steps 
Dabeer   studies   probabilistic model in an online
setup  and Barman   Dabeer   study   probabilistic
model in an of ine setup  and state performance guarantees
for   twoclass userbased CF algorithm  Closely related to
userbased CF is itembased CF  Itembased CF exploits
similarity in item space by recommending items similar to
those   given user has rated positively in the past  Our results do not extend trivially to itembased CF  since   corresponding analysis requires assumptions on the similarity
in item space  and additionally the exploration strategies of
itembased CF algorithms are considerably different  We
do not discuss item based CF algorithms here  but refer
to  Bresler et al    for   recent analysis of an item

Online OneClass Collaborative Filtering

based CF algorithm for the twoclass CF problem  Next 
we note that Deshpande   Montanari   study recommender systems in the context of multiarmed bandits
 Bubeck   CesaBianchi    Speci cally  Deshpande
  Montanari   consider   model where the  continuous  ratings are described by the inner product of   user and
item feature vector  and assume the item feature vectors to
be given 
  conceptually related online learning problem are multiarmed bandits with dependent arms  Pandey et al   
Speci cally  in this variant of the multiarmed bandit problem  the arms are grouped into clusters  and the arms within
each cluster are dependent  The assignments of arms to
clusters are assumed known  In our paper  we assume that
users cluster in user types that have similar distributions 
Therefore  the learning problem in our paper can be viewed
as an multiarmed bandit problem with dependent arms  but
the assignment of the arms to clusters is unknown 
Finally  we note that   class of learning problems reminiscent to that considered here is partial monitoring  Bart  
et al    While partial monitoring has been studied in
the context of recommender systems  Kveton et al   
we are not aware of papers on partial monitoring in collaborative  ltering 

Outline 
In Section   we formally specify our model 
motivate it  and state the CF problem  Sections   and   contain the UserCF algorithm and corresponding performance
guarantee  respectively  In Section   we provide numerical
results on real data  The proof of our main result can be
found in the supplementary material 
  Model and learning problem
In this section we introduce the probabilistic model and
learning problem considered in this paper  As mentioned
previously  this model is inspired by that in  Bresler et al 
  for the twoclass CF problem 

Model  Consider   users and   items    user may like
an item   or dislike an item   Associated with each
user is an  unknown  latent preference vector pu       
whose entries pui are the probabilities of user   liking item
   We assume that an item   is either  likable  for user   
     pui         for some         or  not likable       pui         The hidden ranking Rhidden
is
obtained at random as Rhidden
     like  with probability
     dislike  with probability     pui 
pui  and Rhidden
The ratings are stochastic to model that users are not fully
consistent in their rating  the parameter   quanti es the inconsistency  or uncertainty or noise  The oneclass aspect
is incorporated in our model by assuming that users never
reveal that they dislike an item 
Speci cally  an CF algorithm operates on the model as fol 

ui

ui

ui

lows  At each time step               the algorithm recommends   single item             to each user   typically
this item is different for each user and obtains an realization of the binary random variable
Zui   Bernoulli pf 
 

if Rhidden
if Rhidden

   
   

 cid 

Rui  

ui

ui

ui

ui

in response  independently across   and    It follows that
   Rui       puipf and    Rui           puipf   Here 
pf corresponds to the probability of   user reporting   positive rating  As mentioned before  while one might treat
the slightly more general case of the probability pf being
different for each user  for ease of presentation  we assume
that it is constant over the users  If Rui     user   consumes item    and   will not be recommended to   in subsequent time steps  Note that Rui     means that either user
    or user   did not
  does not like item    Rhidden
respond to the recommendation  Therefore  if Rui      
may be recommended to   again in subsequent time steps 
Finally  observe that if pf     the user provides positive
    implies Rui    
and negative ratings  since Rhidden
if pf    
In order to make recommendations based on the user   preferences  we must assume some relation between the users 
Following  Bresler et al    we assume that each user
belongs to one of       user types  Two users   and  
belong to the same type if they  nd the same items likable 
     if  pui            pvi         for all
items    This does not require the preference vectors pu and
pv of two users corresponding to the same user type to be
equivalent  We note that this assumption could be relaxed
by only assuming that users of the same type share   large
fraction of the items that they  nd likable  We assume that
the preference vectors belonging to the same type are more
similar than those belonging to other types  Speci cally 
assume that for all                                   and
for some        
  min
  Tu

 
where Tu        is the subset of all users that are of the
same type as    The smaller   the more distinct users
of the same type are from users of another type  We further assume that each user likes at least   fraction   of the
items  This assumption is made to avoid degenerate situations were   user   does not like any item  Assuming that
users cluster in the useritem space in different user types
is common and is implicitly used by userbased CF algorithms  Sarwar et al    which perform well in practice  To further justify this assumption empirically  we plot
in Figure   the clustering of user ratings of the Movielens
  Million dataset  Harper   Konstan    Figure  
shows that the user   ratings cluster both in user and in item
space 

 cid pu  pv cid    max
   Tu

 cid pu  pv cid   

Online OneClass Collaborative Filtering

and exploiting       recommending items predicted to be
likable based on previous ratings  To this end  the UserCF algorithm  formally introduced below  performs at time
              either an preference exploration  similarity
exploration  or exploitation step 
An exploitation step  rst identi es the   most similar users
in terms of their rating vectors rv          for   given
user    The rating vectors consist of the responses Rui of
users to recommendations        made by the UserCF algorithm at previous time steps  The exploitation step proceeds
by recommending the item that has received the largest
number of positive ratings from the nearest neighbors of
  in previous time steps  For an exploitation step to be
successful  it is crucial to  nd similar users and learn their
preferences effectively  This is accomplished with similarity exploration steps  that recommend the same items to
all users  and preference exploration steps that recommend
random items to certain subsets of the users  Before formally stating the UserCF algorithm  we illustrate its main
steps using   toy example 

Example   Consider       users and       items  with
preference vectors pu and rating vectors ru at time      

Users       are of the same type as they  nd items      
likable  and users       belong to   second type as they
 nd items     likable  The preference vectors are obtained
by executing at time step     preference exploration step 
that recommends the randomly chosen items            
to users               respectively  and   similarity exploration step that recommends item   to all users  The responses Rui obtained from the similarity and preference
exploration step are marked with rectangles and circles  respectively  Consider recommending an item to user   with
an exploitation step at time   The       nearest neighbors of       are Nu        cid    rv cid      for        
rvi is
maximized for        rvi is the ith entry of ru  item  
is recommended to user    which happens to be   likable

and  cid    rv cid      for           Since  cid 

  Nu

Figure   The useritems rating matrix consisting of   subset of
the Movielens   Million dataset corresponding to the   most
rated movies  columns  and the   users  rows  that rated most
movies  The Movielens dataset consists of   Million movie ratings in           we took the ratings     as   ratings     as
  and missing ratings as   depicted in black  white  and gray 

Learning problem and reward  The goal of   CF algorithm is to maximize reward    reasonable reward for the
online CF problem is the expected number of recommendations that   user rates positively       the pseudoreward

  cid 

  cid 

  

  

  cid Rui     

 cid   

ui

Here          is the item recommended to   at time    In
an ecommerce setting this corresponds to the number of
recommended products that   user buys  Note that due to
the uncertainty of   user liking an item  the random rating
might be   even when   is likable by    we canRhidden
not expect to do better than maximizing the pseudoreward 
In this paper our focus is on recommending likable items 
Following  Bresler et al    we therefore consider the
closely related accumulated reward de ned as the expected
total number of likable items  pui     that are recommended by an algorithm up to time    

  cid 

  cid 

  cid Xui     

 cid   

 

   reward      

  

  

Here  Xui         pui     is the indicator random
variable that is equal to one if item         recommended
to user   at time   is likable and zero otherwise  note that
item   is chosen by the CF algorithm as   function of the
responses Ru cid   cid  to recommendations    cid    cid  made at previous time steps  and is therefore   random variable 

  UserCF algorithm
In this section we present our userbased CF algorithm
 UserCF  In order to maximize reward the UserCF algorithm balances exploring       learning about the users 

given by  
 

   
 
 
   

 
 
 
 
 
 

pT
 
pT
 
pT
 
pT
 
pT
 
pT
 

rT
 
rT
 
rT
 
rT
 
rT
 
rT
 

 
 
 
 
 
 

 
 
 
 
 
 

 
 
 

 
 
 

 
 
 
 
 
 

 
 
 
 

 
 

 
 
 
 
 
 

 
 
 
 
 
 

 
 
 
 
 
 

 

 
 
 
 
 

   
   

Online OneClass Collaborative Filtering

item  as desired 

We next formally describe the UserCF algorithm  and explain the intuition behind the speci   steps  Input parameters of the UserCF algorithm are learning rates   and
                    relevant for similarity and preference exploration steps  respectively    batch size   relevant
for preference exploration steps  and  nally the number of
nearest neighbors    relevant for exploitation steps  Our results guarantee that for   range of input parameters that depends on properties of the model such as the number of user
types and pf  the UserCF algorithm performs essentially
optimally  While we may or may not have prior knowledge
of those model parameters  in practice  we can optimize for
the hyperparameters of the UserCF algorithm by using
cross validation 
At initialization  the UserCF algorithm generates   random
permutation   of the items      required by the similarity
exploration step  Furthermore  it splits the item space into
    random  and equally sized  subsets of cardinality  
 batches  denoted by Qq                             
At time steps      cid Qq cid                        the UserCF algorithm performs preference exploration steps  At
all other time steps  with probabilities pJ  
           
 cid     cid  and pE       pJ  the algorithm performs similarity exploration and exploitation steps  respectively 
Similarity exploration step  For each user    recommend
the  rst item   in the permutation   that has not been recommended to user   in previous steps of the algorithm  This
step explores the item space and its important for selecting  good  neighborhoods  Performing   suf cient number
of similarity exploration steps allows to guarantee that the
nearest neighbors of   given user   are of the same type 
Preference exploration step  At time      cid Qq cid  recommend to each user   an item  chosen independently and
uniformly at random from Qq  that has not been rated by  
in previous time steps  This step is important to learn the
preferences of users 
Exploitation step  For all users    estimate the probability
of   liking   given item   as

 

 cid   

 cid 

 pui  

nui
 

  Nu

Rvi 

if nui    
if nui    

 

 cid rsim

 cid             Here  rsim

Here  Rvi is the rating of user   for item   obtained in previous time steps  we use the convention Rvi     if no
rating was obtained at   previous time step  Next  Nu is
the set of users corresponding to the   largest values of
         is the vector
    rsim
 We assume for simplicity that   is divisible by    if this is
not the case  batch  cid     cid      may simply contain less than  
items 

 

containing only the responses Rui of user   to recommendations   given in previous similarity exploration steps up
to time    and is zero otherwise  Moreover  nui is the number of users in Nu that received recommendation    Finally 
for each user    recommend an item   that maximizes  pui cid 
over all items   cid  that have not been rated yet 
The idea behind the UserCF algorithm is as follows  An
exploitation step recommends likable items to   if    most
of the neighbors of   are of the same user type as    and
if    the items are suf ciently well explored so that  pui indicates whether   is likable by         pui     or not 
for all      large portion of the  rst few steps is likely to
be spent on similarity exploration  This is sensible  as we
need to ensure that    is satis ed in order to make good
recommendations  As time evolves  the UserCF algorithm
randomly explores batches of items  one batch at   time  in
order to estimate the preferences of the users regarding the
items in the corresponding batches  Note that if the UserCF algorithm would explore the entire item space at once 
     by recommending an item chosen at random from all
items  the time required for the algorithm to make  good 
recommendations would grow linearly in    and   might
be very large  By splitting the item space into batches Qq 
the UserCF algorithm can start exploiting without having
learned the preferences of the users regarding all items  Finally note that the UserCF algorithm may recommend the
same item at several time steps  unless the item is rated by
the user  this is sensible in particular if pf is small 
  Main result
Our main result  stated below  shows that after   certain
cold start time  the UserCF algorithm produces essentially
optimal recommendations 

Theorem   Suppose that there are at least  
   users of the
same type  for all user types  and that condition   holds
for some         which ensures that user types are distinct  Moreover  assume that at least   fraction   of all
items is likable to   given user  for all users  Pick      
and suppose that there are suf ciently many users per user
type 

 
 

   

 pf   log    log 

Set

Tstart  cid     log   

       
  

 cid   
 cid 

    max

 cid   

 

 

 
 

  log   

pf  

 

 cid cid 

 

where    is   numerical constant  Then  for appropriate
choices  of the parameters      and    the expected reward accumulated by the UserCF algorithm up to time

  Speci cally        

      

 
   

and    

Online OneClass Collaborative Filtering

     pf   satis es

     Tstart   
   reward    

   

 cid 

 

    Tstart    

         Tstart 
       
     

 cid 

 
  log   

 

   
 

pf  

Proposition   Suppose that there are more items than user
types              Fix         Then there is   set of
   users of the same type  for each user
users with at least  
type  with preference vectors such that for all      
  the
expected reward of any online algorithm is upper bounded
by

  reward    

       
   

   

  
 

pf  

  log   

Theorem   states that after an initial cold start time on the
order of Tstart  the UserCF algorithm recommends only
likable items up to   fraction  
of the time steps 
 
This follows since   oracle that only recommends likable
items obtains an reward of    reward             This
yields the claim from the introduction  that after the cold
start time    fraction     pf of all recommendations made
by the UserCF algorithm are likable  Note that condition   allows the number of user types     to be near
linear in the number of users    
We note that the particular choice of the parameters of the
UserCF algorithm in Theorem   is mainly out of expositional convenience  the supplementary material contains  
more general statement 
Theorem   is proven by showing that after the initial cold
start time  exploration steps recommend likable items with
very high probability  An exploration step recommends  
likable item to user   provided that
   most of the nearest neighbors of   are of the same user

type  and

   the items are suf ciently well explored so that the maximum of  pui over items not rated yet corresponds to  
likable item 

For    we use that the user types are suf ciently distinct
and that most of the nearest neighbors of   are of the
same user type  The former is ensured by condition  
and the latter holds after the initial cold start time which
ensures that suf ciently many similarity exploration steps
have been executed  After the initial cold start time  most
of the nearest neighbors of   are of the same user type  and
essentially no further cost is required to learn the neighborhoods  This is re ected in the lower bound   by the
terms depending on   becoming negligible as   becomes
large compared to Tstart  Note the dependence of Tstart on
  the more similar the user types are       the closer   is
to   the longer it takes till UserCF is guaranteed to  nd
good neighborhoods 
  Dependence on pf is nearly optimal
The cold start time of the UserCF algorithm guaranteed by
    For small learnTheorem   is proportional to    
   
ing rates   this scaling can not be improved signi cantly 
as the following results shows 

 

  

kpf  
log      for numerical constants       and   

 

pf  

  log   

Proposition   shows that if the cold start time is signi 
cantly smaller than    
    then there are problem instances
for which any algorithm mostly recommends nonlikable
items  The proposition is   consequence of the fact that
after making on the order of    
  recommendations  for
many users we did not obtain any rating    consequence
of the proposition is that the cold start time of the UserCF
algorithm is near optimal 
Recall that even after the initial cold start time    constant
of the recommendations might be
fraction of  
 
nonlikable  This fraction is the cost for establishing   
Speci cally  in order to ensure    the UserCF algorithm
needs to recommend suf ciently many items to the   neighbors of   so that  pui indicates whether user   likes item   or
not  or more precisely such that the maximum of  pui over
items not rated yet corresponds to   likable item  This is established by showing that  pui   pf   for all likable items
    Qq               
       and  pui   pf   for all other
items  Since the expected number of positive ratings per
recommendation is proportional to pf  the number of ratings required to ensure that pui   pf   is proportional to
 pf 
  One versus two class CF
Recall that pf     implies that users provide positive and
negative ratings  and that the UserCF algorithm is nearly
optimal in pf  Since the expected number of ratings obtained by   user in   given number of time steps is proportional to pf    consequence of our result is that receiving
positive and negative ratings instead of only positive ones
improves the number of ratings required for initial exploration by   factor of  pf  which can be signi cant 
We  nally note that Bresler et al    proved   performance guarantee for   closely related twoclass collaborative CF algorithm termed CollaborativeGreedy  Bresler
et al    consider the regime where the number of
users is much larger than the number of items          
             and additionally the number of user types
obeys        KM   For this regime  Theorem   particularized to pf     essentially reduces to Theorem   in
 Bresler et al     there are some further minor differences  However  our result particularized to the twoclass
case also holds when the number of items is much larger
than the number of users  and allows the number of user
types to be near linear in the number of users  This improvement is due to differences in the preference explo 

Online OneClass Collaborative Filtering

ration strategies of the algorithms 
  Alternative exploration strategies
While there are other sensible preference exploration
strategies  the essential element of our approach is to split
up the item space into subsets of items            start by
exploring    then allow for exploitation steps  continue
with exploring    again allow for exploitation steps and
so forth  If one explores instead the whole item space     
at the beginning  the learning time required for  pui to indicate whether an item is likable or not  is proportional to
   and can therefore be very large  To see this  consider  
preference exploration step that recommends   single item
to all users  chosen uniformly at random from the set of
all items      The expected number of ratings obtained
by executing Tr such preference exploration steps relevant
for estimating whether pui     is the expected number
of neighbors of   to which   has been recommend  and is
therefore proportional to Trk    To ensure that this expectation is larger than   Tr has to be on the order or  
 provided that the other parameters are  xed 
  Numerical results
In this section  we simulate an online recommender system
based on realworld data in order to understand whether
the UserCF algorithm behaves as predicted by Theorem
  even when the data is not generated by the probabilistic
model  but is based on real data  While an ideal dataset
to validate our algorithm would consist of the ratings from
all users for all items  the vast majority of ratings in standard CF datasets such as the Net ix or Movielens dataset
 consisting of movie ratings  are unknown  To obtain
  dataset with   higher proportion of ratings  following
 Bresler et al    we consider the subset of the Movielens dataset corresponding to frequently rated items and to
users that have rated many items  The Movielens dataset
consists of   Million movie ratings in           we
took the ratings     as   ratings     as   and missing ratings as   Many of the items  movies  in the dataset
have   signi cant bias towards   positive or negative rating  To make sure our results are not due to exploiting such
biases  we only select frequently rated items out of the  approximately  unbiased items  Note that   nearest neighbor based algorithm  like the UserCF algorithm  performs
well in case the item ratings are very biased even when
the neighborhoods are randomly selected  Of the resulting
dataset  denoted by RML           of
the ratings are     are   and the remaining ones are
unknown and therefore set to  

One class versus two class CF  We start with comparing the qualitative behavior of the UserCF algorithm to  
twoclass version of the UserCF algorithm  The twoclass
version of the UserCF algorithm differs from the oneclass
version in taking into account the negative ratings  Specif 

 
 
 
 
 
 
 
 
 
 
 
 
 

 

 

 

oneclass
twoclass

 

 

 

 

 

 

 

Figure   Comparison of one and two class recommenders 

ically  the ratings Rvi in   for the twoclass version or
the UserCF algorithm are set to     and   if   negative  none  or   positive rating was obtained as   response
to   recommendation  We performed the following experiment  If the UserCF algorithm recommends item   to user
   it obtains the rating Rui     in response provided that
 RML ui      RML ui denotes the       th entry of RML 
and Rui     otherwise  while the twoclass UserCF algorithm obtains Rui    RML ui in response  We allow both
algorithms to only recommend an item to   given user once 
so after       time steps  all items have been recommend to all users  We measure performance in terms of the
accumulated reward  de ned as

accreward      

reward   

  cid 
  cid 

  

  

reward     

 
 

 RML ui     

 

where         is the item recommended to user   by the corresponding variant of the UserCF algorithm  The results 
depicted in Figure   show that the twoclass recommender
performs better  as expected  since it obtains signi cantly
more ratings  Speci cally  the expected number of ratings
it obtains is almost twice the expected number of ratings
the oneclass UserCF algorithm obtains  After having recommend most of the likable items  mostly nonlikable are
left to recommend  which explains the inverse Ushape in
Figure  

Dependence of UserCF on pf  We next validate empirically that the cold start time and number of preference
exploration steps  needed to learn the preferences of the
users  scale as    
  and  pf  respectively  We start with
the former  To this end  we split the items into two random disjoint sets           and           of equal cardinality  We then perform the following experiment for

Online OneClass Collaborative Filtering

 
 
 
 
 
 
 
 
 
 

 

 

 

 

 

 

 
 
 
 
 
 
 
 
 
 

 

 

 

 

 

 
Ts   
 

 

 

pf    

pf    
pf    

 

 
Tr pf

Figure   Left  Reward obtained from   single exploitation step 
after performing Ts similarity exploration steps and    xed number of preference exploration steps  Right  Reward obtained from
  single exploration step  after performing Tr preference exploration steps and    xed number of similarity exploration steps 

kpf

pf         We start by recommending   
items 
chosen uniformly at random from    to each user  and  provided the corresponding rating is positive  RML ui    
we provide this rating to the UserCF algorithm with probability pf  The expected number of positive ratings obtained
is therefore independent of pf  Those preference exploration steps make sure that the preferences of the items in
   are explored well  We then perform Ts similarity exploration steps on the items in the sets                  iM 
by recommending item it to user   at               Ts    
If  RML uit     then we provide the rating  RML uit to the
UserCF algorithm with probability pf  After Ts such similarity exploration steps  we perform an exploitation step 
In Figure   we plot the reward de ned in   obtained by
    The results con rm that
the exploitation step  over Ts   
the cold start time required to  nd  good  neighborhoods
scales inversely proportional to   
    since all three curves
lie on top of each other 
Next  we demonstrate that the number of preference exploration steps required to learn the preferences of the users
is proportional to  pf  To this end  we perform the same
experiment as above  this time  however  we  rst perform
  similarity exploration steps on the items in the
Ts      
set    and then perform Tr preference exploration steps
by recommending Tr items  chosen uniformly at random
from    to each user  As before  if  RML ui     the rating
 RML ui is provided to the algorithm with probability pf 
In Figure   we plot the reward obtained from performing
  single exploitation step after Tr such preference exploration steps over Tr pf  The results indicate that  as predicted by our theory  the number of preference exploration
steps required to learn the preferences is proportional to pf 
as the curves for different pf lie on top of each other  As
mentioned previously  this is not surprising  as the number
of positive ratings obtained is proportional to pf 

References
Aggarwal  Charu    Recommender systems  The textbook 

Springer   

Bardenet    mi and Maillard  OdalricAmbrym  Concentration inequalities for sampling without replacement 
Bernoulli     

Barman  Kishor and Dabeer  Onkar  Analysis of   collaborative  lter based on popularity amongst neighbors 
IEEE Trans  Inf  Theory     

Bart      bor  Foster  Dean           vid  Rakhlin 
Alexander  and Szepesv ri  Csaba  Multiarmed bandit
problems with dependent arms  Math  Oper  Res   
  June  

Biau    rard  Cadre  Beno    and Rouvi re  Laurent  Statistical analysis of knearest neighbor collaborative recommendation  Ann  Stat     

Bresler  Guy  Chen  George    and Shah  Devavrat    latent source model for online collaborative  ltering 
In
Advances in Neural Information Processing Systems  pp 
   

Bresler  Guy  Shah  Devavrat  and Voloch  Luis    Regret guarantees for itemitem collaborative  ltering 
arXiv   

Bubeck    bastien and CesaBianchi  Nicol  Regret analysis of stochastic and nonstochastic multiarmed bandit
problems  Foundations and Trends in Machine Learning     

Dabeer     Adaptive collaborating  ltering  The low noise
regime  In IEEE International Symposium on Information Theory  pp     

Deshpande  Yash and Montanari  Andrea  Linear bandits
in high dimension and recommendation systems  In Annual Allerton Conference on Communication  Control 
and Computing  pp    October  

Ekstrand  Michael    Riedl  John    and Konstan 
Joseph    Collaborative  ltering recommender systems  Found  Trends Hum Comput  Interact   
   

Harper     Maxwell and Konstan  Joseph    The MovieLens datasets  History and context  ACM Trans  Interact  Intell  Syst     

Heckel  Reinhard  Vlachos  Michail  Parnell  Thomas  and
Scalable and interpretable prodD nner  Celestine 
uct recommendations via overlapping coclustering  In
IEEE International Conference on Data Engineering 
 

Online OneClass Collaborative Filtering

Hu  Yifan  Koren  Yehuda  and Volinsky  Chris  CollaboIn IEEE
rative  ltering for implicit feedback datasets 
International Conference on Data Mining  pp   
 

Kveton  Branislav  Szepesvari  Csaba  Wen  Zheng  and
Ashkan  Azin  Cascading Bandits  Learning to Rank
in the Cascade Model  In International Conference on
Machine Learning  pp     

Pan  Rong  Zhou  Yunhong  Cao  Bin  Liu       Lukose 
   Scholz     and Yang  Qiang  Oneclass collaborative  ltering  In IEEE International Conference on Data
Mining  pp     

Pandey  Sandeep  Chakrabarti  Deepayan  and Agarwal 
Deepak  Multiarmed Bandit Problems with Dependent
Arms  In International Conference on Machine Learning  ICML   pp    New York  NY  USA 
 

Sarwar  Badrul  Karypis  George  Konstan  Joseph  and
Riedl  John  Analysis of recommendation algorithms for
In ACM Conference on Electronic Come commerce 
merce  pp     

