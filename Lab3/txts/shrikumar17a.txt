Learning Important Features Through Propagating Activation Differences

Avanti Shrikumar   Peyton Greenside   Anshul Kundaje  

Abstract

The purported  black box  nature of neural
networks is   barrier to adoption in applications where interpretability is essential  Here
we present DeepLIFT  Deep Learning Important FeaTures    method for decomposing the
output prediction of   neural network on   speci   input by backpropagating the contributions
of all neurons in the network to every feature
of the input  DeepLIFT compares the activation of each neuron to its  reference activation 
and assigns contribution scores according to the
difference  By optionally giving separate consideration to positive and negative contributions 
DeepLIFT can also reveal dependencies which
are missed by other approaches  Scores can
be computed ef ciently in   single backward
pass  We apply DeepLIFT to models trained
on MNIST and simulated genomic data  and
show signi cant advantages over gradientbased
methods  Video tutorial  http goo gl 
qKb pL  code  http goo gl RM jvH 

  Introduction
As neural networks become increasingly popular 
their
black box reputation is   barrier to adoption when interpretability is paramount  Here  we present DeepLIFT
 Deep Learning Important FeaTures    novel algorithm
to assign importance score to the inputs for   given output  Our approach is unique in two regards  First  it
frames the question of importance in terms of differences
from    reference  state  where the  reference  is chosen
according to the problem at hand 
In contrast to most
gradientbased methods  using   differencefrom reference
allows DeepLIFT to propagate an importance signal even
in situations where the gradient is zero and avoids artifacts
caused by discontinuities in the gradient  Second  by op 

 Stanford University  Stanford  California  USA  Correspon 

dence to    Kundaje  akundaje stanford edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

tionally giving separate consideration to the effects of positive and negative contributions at nonlinearities  DeepLIFT
can reveal dependencies missed by other approaches  As
DeepLIFT scores are computed using   backpropagationlike algorithm  they can be obtained ef ciently in   single
backward pass after   prediction has been made 

  Previous Work
This section provides   review of existing approaches to assign importance scores for   given task and input example 

  PerturbationBased Forward Propagation

Approaches

These approaches make perturbations to individual inputs
or neurons and observe the impact on later neurons in the
network  Zeiler   Fergus  Zeiler   Fergus    occluded
different segments of an input image and visualized the
change in the activations of later layers   Insilico mutagenesis   Zhou   Troyanskaya    introduced virtual
mutations at individual positions in   genomic sequence
and quanti ed the their impact on the output  Zintgraf et
al 
 Zintgraf et al    proposed   clever strategy for
analyzing the difference in   prediction after marginalizing
over each input patch  However  such methods can be computationally inef cient as each perturbation requires   separate forward propagation through the network  They may
also underestimate the importance of features that have saturated their contribution to the output  Fig   

  BackpropagationBased Approaches

Unlike perturbation methods  backpropagation approaches
propagate an importance signal from an output neuron
backwards through the layers to the input in one pass  making them ef cient  DeepLIFT is one such approach 

  GRADIENTS  DECONVOLUTIONAL NETWORKS

AND GUIDED BACKPROPAGATION

Simonyan et al 
 Simonyan et al    proposed using
the gradient of the output        pixels of an input image
to compute    saliency map  of the image in the context
of image classi cation tasks  The authors showed that this
was similar to deconvolutional networks  Zeiler   Fergus 

DeepLIFT  Learning Important Features Through Propagating Activation Differences

tor to an elementwise product between the saliency maps of
Simonyan et al  and the input  in other words  gradient  
input  In our experiments  we compare DeepLIFT to gradient   input as the latter is easily implemented on   GPU 
whereas LRP does not currently have GPU implementations available to our knowledge 
While gradient   input is often preferable to gradients
alone as it leverages the sign and strength of the input  it
still does not address the saturation problem in Fig    or
the thresholding artifact in Fig   

  INTEGRATED GRADIENTS

Instead of computing the gradients at only the current value
of the input  one can integrate the gradients as the inputs
are scaled up from some starting value  eg  all zeros  to
their current value  Sundararajan et al    This addressess the saturation and thresholding problems of Fig 
  and Fig    but numerically obtaining highquality integrals adds computational overhead  Further  this approach
can still give misleading results  see Section  

  GradCAM and Guided CAM

GradCAM  Selvaraju et al    computes   coarsegrained featureimportance map by associating the feature
maps in the  nal convolutional layer with particular classes
based on the gradients of each class        each feature
map  and then using the weighted activations of the feature maps as an indication of which inputs are most important  To obtain more  negrained feature importance  the
authors proposed performing an elementwise product between the scores obtained from GradCAM and the scores
obtained from Guided Backpropagation  termed Guided
GradCAM  However  this strategy inherits the limitations
of Guided Backpropagation caused by zeroing out negative gradients during backpropagation  It is also speci   to
convolutional neural networks 

  The DeepLIFT Method
  The DeepLIFT Philosophy

DeepLIFT explains the difference in output from some  reference  output in terms of the difference of the input from
some  reference  input  The  reference  input represents
some default or  neutral  input that is chosen according to
what is appropriate for the problem at hand  see Section
  for more details  Formally  let   represent some target output neuron of interest and let         xn represent
some neurons in some intermediate layer or set of layers
that are necessary and suf cient to compute    Let    represent the reference activation of    We de ne the quantity
   to be the differencefrom reference  that is           
DeepLIFT assigns contribution scores   xi   to  xi     

Figure   Perturbationbased approaches and gradientbased
approaches fail to model saturation  Illustrated is   simple network exhibiting saturation in the signal from its inputs  At the
point where        and        perturbing either    or    to   will
not produce   change in the output  Note that the gradient of the
output       the inputs is also zero when            

  except for the handling of the nonlinearity at recti ed
linear units  ReLUs  When backpropagating importance
using gradients  the gradient coming into   ReLU during
the backward pass is zero   out if the input to the ReLU
during the forward pass is negative  By contrast  when
backpropagating an importance signal in deconvolutional
networks  the importance signal coming into   ReLU during the backward pass is zero   out if and only if it is negative  with no regard to sign of the input to the ReLU during the forward pass  Springenberg et al   Springenberg
et al    combined these two approaches into Guided
Backpropagation  which zero   out the importance signal
at   ReLU if either the input to the ReLU during the forward pass is negative or the importance signal during the
backward pass is negative  Guided Backpropagation can be
thought of as equivalent to computing gradients  with the
caveat that any gradients that become negative during the
backward pass are discarded at ReLUs  Due to the zeroing
out of negative gradients  both guided backpropagation and
deconvolutional networks can fail to highlight inputs that
contribute negatively to the output  Additionally  none of
the three approaches would address the saturation problem
illustrated in Fig    as the gradient of            is negative
 causing Guided Backprop and deconvolutional networks
to assign zero importance  and the gradient of         both
   and    is zero when              causing both gradients
and Guided Backprop to be zero  Discontinuities in the
gradients can also cause undesirable artifacts  Fig   

  LAYERWISE RELEVANCE PROPAGATION AND

GRADIENT   INPUT

Bach et al   Bach et al    proposed an approach for
propagating importance scores called Layerwise Relevance
Propagation  LRP  Shrikumar et al  and Kindermans et al 
 Shrikumar et al    Kindermans et al    showed
that absent modi cations to deal with numerical stability 
the original LRP rules were equivalent within   scaling fac 

  cid 

  xi       

 

  

We call Eq    the summationto delta property    xi  
can be thought of as the amount of differencefrom 
reference in   that is attributed to or  blamed  on the
differencefrom reference of xi  Note that when   neuron  
transfer function is wellbehaved  the output is locally linear in its inputs  providing additional motivation for Eq   
is zero  This alC xi   can be nonzero even when   
 xi
lows DeepLIFT to address   fundamental limitation of gradients because  as illustrated in Fig      neuron can be signaling meaningful information even in the regime where its
gradient is zero  Another drawback of gradients addressed
by DeepLIFT is illustrated in Fig    where the discontinuous nature of gradients causes sudden jumps in the importance score over in nitesimal changes in the input  By contrast  the differencefrom reference is continuous  allowing
DeepLIFT to avoid discontinuities caused by bias terms 

Figure   Discontinuous gradients can produce misleading importance scores  Response of   single recti ed linear unit with  
bias of   Both gradient and gradient input have   discontinuity at       at           gradient input assigns   contribution of       to   and   to the bias term   is   small positive
number  When       contributions on   and the bias term are
both   By contrast  the differencefrom reference  red arrow  top
 gure  gives   continuous increase in the contribution score 

  Multipliers and the Chain Rule

  DEFINITION OF MULTIPLIERS

For   given input neuron   with differencefrom reference
    and target neuron   with differencefrom reference   
that we wish to compute the contribution to  we de ne the
multiplier       as 

       

     

  

 

In other words  the multiplier       is the contribution of
   to    divided by     Note the close analogy to the

DeepLIFT  Learning Important Features Through Propagating Activation Differences

 cid 

   is the
idea of partial derivatives  the partial derivative   
in nitesimal change in   caused by an in nitesimal change
in    divided by the in nitesimal change in    The multiplier is similar in spirit to   partial derivative  but over  nite
differences instead of in nitesimal ones 

  THE CHAIN RULE FOR MULTIPLIERS

Assume we have an input layer with neurons      xn   
hidden layer with neurons      yn  and some target output neuron    Given values for   xi yj and   yj    
the following de nition of   xi   is consistent with the
summationto delta property in Eq     see Appendix   for
the proof 

  xi    

  xi yj   yj   

 

 

We refer to Eq    as the chain rule for multipliers  Given
the multipliers for each neuron to its immediate successors 
we can compute the multipliers for any neuron to   given
target neuron ef ciently via backpropagation   analogous
to how the chain rule for partial derivatives allows us to
compute the gradient        the output via backpropagation 

  De ning the Reference
When formulating the DeepLIFT rules described in Section   we assume that the reference of   neuron is its
activation on the reference input  Formally  say we have  
neuron   with inputs         such that               
Given the reference activations   
    of the inputs  we
can calculate the reference activation    of the output as 

    

          

    

   

 

     references for all neurons can be found by choosing  
reference input and propagating activations through the net 
The choice of   reference input is critical for obtaining
insightful results from DeepLIFT  In practice  choosing  
good reference would rely on domainspeci   knowledge 
and in some cases it may be best to compute DeepLIFT
scores against multiple different references  As   guiding
principle  we can ask ourselves  what am   interested in
measuring differences against  For MNIST  we use   reference input of allzeros as this is the background of the images  For the binary classi cation tasks on DNA sequence
inputs  strings over the alphabet           we obtained
sensible results using either   reference input containing the
expected frequencies of ACGT in the background  Fig   
or by averaging the results over multiple reference inputs
for each sequence that are generated by shuf ing each original sequence  Appendix    For CIFAR  data  we found
that using   blurred version of the original image as the

DeepLIFT  Learning Important Features Through Propagating Activation Differences
 wi xi    wi xi
 wi xi    wi   

     

 

 cid 
 cid 

 

       
   

reference highlighted outlines of key objects  while an allzeros reference highlighted hardto interpret pixels in the
background  Appendix   
It is important to note that gradient input implicitly uses  
reference of allzeros  it is equivalent to    rstorder Taylor
approximation of gradient input where   is measured
       an input of zeros  Similary  integrated gradients
 Section   requires the user to specify   starting point
for the integral  which is conceptually similar to specifying   reference for DeepLIFT  While Guided Backprop and
pure gradients don   use   reference  we argue that this is
  limitation as these methods only describe the local behaviour of the output at the speci   input value  without
considering how the output behaves over   range of inputs 

  Separating Positive and Negative Contributions
We will see in Section   that  in some situations  it is
essential to treat positive and negative contributions differently  To do this  for every neuron    we will introduce
    and     to represent the positive and negative components of     such that 

              

                     

For linear neurons      and     are found by writing   
as   sum of terms involving its inputs  xi and grouping
positive and negative terms together  The importance of
this will become apparent when applying the RevealCancel
rule  Section   where for   given target neuron   we
may  nd that       and       differ  However  when
applying only the Linear or Rescale rules  Section  
and Section                         

  Rules for Assigning Contribution Scores

We present the rules for assigning contribution scores for
each neuron to its immediate inputs  In conjunction with
the chain rule for multipliers  Section   these rules can
be used to  nd the contributions of any input  not just the
immediate inputs  to   target output via backpropagation 

  THE LINEAR RULE

This applies to Dense and Convolutional layers  excluding
nonlinearities  Let   be   linear function of its inputs xi
  wi xi 

  wixi  We have       cid 

We de ne the positive and negative parts of    as 

such that        cid 
 cid 
 cid 

     

 

 

 

 

Which leads to the following choice for the contributions 
    
   
 
    
   
 

         wi xi    wi   
         wi xi    wi   
         wi xi    wi   
         wi xi    wi   

 

 

 

 

 

 

           

           

We can then  nd multipliers using the de nition in Section
         wi xi  
  which gives     
         wi xi    wi 
 wi and     
What about when  xi     While setting multipliers to  
in this case would be consistent with summationto delta 
it is possible that    
  are nonzero  and cancel
each other out  in which case setting the multiplier to  
would fail to propagate importance to them  To avoid this 
         wi when  xi is  
we set     
 similarly for     See Appendix   for how to compute
these multipliers using standard neural network ops 

            

  and    

  THE RESCALE RULE

This rule applies to nonlinear transformations that take  
single input  such as the ReLU  tanh or sigmoid operations 
Let neuron   be   nonlinear transformation of its input  
such that           Because   has only one input  we
have by summationto delta that             and consequently           
    For the Rescale rule  we set    
and     proportional to     and     as follows 

     
     

  
  
  
  

            
            

Based on this  we get 

                         

  
  

dx  where the dy

In the case where        we have        and       
The de nition of the multiplier approaches the derivative 
             dy
dx is evaluated at       
We can thus use the gradient instead of the multiplier when
  is close to its reference to avoid numerical instability issues caused by having   small denominator 
Note that the Rescale rule addresses both the saturation
and the thresholding problems illustrated in Fig    and
Fig   
      then
at             we have        and        giving

In the case of Fig    if   

      

 wi xi    wi xi
 wi xi    wi   

       
   

DeepLIFT  Learning Important Features Through Propagating Activation Differences

                         as is done for the
Rescale rule  we de ne them as follows 

       even though dy

          
dh      in other words 
using differencefrom reference allows information to  ow
even when the gradient is zero  In the case of Fig    assuming             at           we have       
  and                       
giving          
By contrast  gradient input assigns   contribution of  
to   and   to the bias term  DeepLIFT never assigns importance to bias terms 
As revealed in previous work  Lundberg   Lee   
there is   connection between DeepLIFT and Shapely values  Brie   
the Shapely values measure the average
marginal effect of including an input over all possible orderings in which inputs can be included  If we de ne  including  an input as setting it to its actual value instead of
its reference value  DeepLIFT can be thought of as   fast
approximation of the Shapely values  At the time  Lundberg   Lee cited   preprint of DeepLIFT which described
only the Linear and Rescale rules with no separate treatment of positive and negative contributions 

  AN IMPROVED APPROXIMATION OF THE

SHAPELY VALUES  THE REVEALCANCEL RULE

the multiplier        is    
   

While the Rescale rule improves upon simply using gradients  there are still some situations where it can provide
misleading results  Consider the min       operation depicted in Fig    with reference values of        and       
Using the Rescale rule  all importance would be assigned
either to    or to     whichever is smaller  This can obscure
the fact that both inputs are relevant for the min operation 
To understand why this occurs  consider the case when
        We have                   and     
max          By the Linear rule  we calculate that
            and              By the Rescale
    and thus
rule 
                            and         
                    The total contribution of    to
the output   becomes                            
and the total contribution of    to   is             
This calculation is misleading as it discounts the fact that
       would be   if    were     in other words  it ignores   dependency induced between    and    that comes
from    canceling out    in the nonlinear neuron     
similar failure occurs when         the Rescale rule results in            and           Note that gradients  gradient input  Guided Backpropagation and integrated gradients would also assign all importance to either
   or    because for any given input the gradient is zero for
one of    or     see Appendix   for   detailed calculation 
One way to address this is by treating the positive and
negative contributions separately  We again consider the
nonlinear neuron          
Instead of assuming that
    and     are proportional to     and     and that

 cid                    cid 
 cid                                cid 
 cid                    cid 
 cid                                cid 

 
 
 
 
 
 
 
 
      
     

     

 
     

 

        

   
              

   
   

In other words  we set     to the average impact of    
after no terms have been added and after     has been
added  and we set     to the average impact of     after
no terms have been added and after     has been added 
This can be thought of as the Shapely values of     and
    contributing to   
By considering the impact of the positive terms in the absence of negative terms  and the impact of negative terms
in the absence of positive terms  we alleviate some of the
issues that arise from positive and negative terms canceling
each other out  In the case of Fig    RevealCancel would
assign   contribution of   min       to both inputs  see
Appendix   for   detailed calculation 
While the RevealCancel rule also avoids the saturation and
thresholding pitfalls illustrated in Fig    and Fig    there
are some circumstances where we might prefer to use the
Rescale rule  Speci cally  consider   thresholded ReLU
where        iff         If        merely indicates
noise  we would want to assign contributions of   to both
    and      as done by the Rescale rule  to mitigate the
noise  RevealCancel may assign nonzero contributions by
considering     in the absence of     and vice versa 

Figure   Network computing     min       Assume   
   
      When         then dy
    and when         then
  
di 
    Using any of the backpropagation approaches described
do
di 
in Section   would result in importance assigned either exclusively to    or    With the RevealCancel rule  the net assigns
  min       importance to both inputs 

  Choice of Target Layer

In the case of softmax or sigmoid outputs  we may prefer to compute contributions to the linear layer preceding
the  nal nonlinearity rather than the  nal nonlinearity itself  This would be to avoid an attentuation caused by the

DeepLIFT  Learning Important Features Through Propagating Activation Differences

Sxidiff     We then evaluate the change in the logodds
score between classes co and ct for the original image and
the image with the pixels erased 
As shown in Fig    DeepLIFT with the RevealCancel rule
outperformed the other backpropagationbased methods 
Integrated gradients  Section   computed numerically
over either   or   intervals produced results comparable
to each other  suggesting that adding more intervals would
not change the result  Integrated gradients also performed
comparably to gradient input  suggesting that saturation
and thresholding failure modes are not common on MNIST
data  Guided Backprop discards negative gradients during
backpropagation  perhaps explaining its poor performance
at discriminating between classes  We also explored using
the Rescale rule instead of RevealCancel on various layers
and found that it degraded performance  Appendix   

      

summationto delta property described in Section   For
example  consider   sigmoid output         where   is
the logit of the sigmoid function  Assume            
where   
      When        and        the
output   saturates at very close to   and the contributions
of    and    are   and   respectively  However  when
       and        the output   is still very close
to   but the contributions of    and    are now both  
This can be misleading when comparing scores across different inputs because   stronger contribution to the logit
would not always translate into   higher DeepLIFT score 
To avoid this  we compute contributions to   rather than   
Adjustments for Softmax Layers
If we compute contributions to the linear layer preceding
the softmax rather than the softmax output  an issue that
could arise is that the  nal softmax output involves   normalization over all classes  but the linear layer before the
softmax does not  To address this  we can normalize the
contributions to the linear layer by subtracting the mean
contribution to all classes  Formally  if   is the number of
classes      ci represents the unnormalized contribution
to class ci in the linear layer and   cid 
represents the
normalized contribution  we have 

   ci

  cid 

  

  cid 

   ci

      ci    
 

    cj

 

As   justi cation for this normalization  we note that subtracting    xed value from all the inputs to the softmax
leaves the output of the softmax unchanged 

  Results
  Digit Classi cation  MNIST 

We train   convolutional neural network on MNIST  LeCun et al    using Keras  Chollet    to perform
digit classi cation and obtain   testset accuracy  The
architecture consists of two convolutional layers  followed
by   fully connected layer  followed by the softmax output
layer  see Appendix   for full details on model architecture and training  We used convolutions with stride    
instead of pooling layers  which did not result in   drop in
performance as is consistent with previous work  Springenberg et al    For DeepLIFT and integrated gradients 
we used   reference input of all zeros 
To evaluate importance scores obtained by different methods  we design the following task  given an image that originally belongs to class co  we identify which pixels to erase
to convert the image to some target class ct  We do this by
 nding Sxidiff   Sxico   Sxict  where Sxic is the score for
pixel xi and class    and erasing up to   pixels   of
the image  ranked in descending order of Sxidiff for which

Figure   DeepLIFT with the RevealCancel rule better identi 
 es pixels to convert one digit to another  Top  result of masking pixels ranked as most important for the original class   relative to the target class   or   Importance scores for class     and
  are also shown  The selected image had the highest change in
logodds scores for the   conversion using gradient input or
integrated gradients to rank pixels  Bottom  boxplots of increase
in logodds scores of target vs  original class after the mask is applied  for    images belonging to the original class in the testing
set   Integrated gradientsn  refers to numerically integrating the
gradients over   evenlyspaced intervals using the midpoint rule 

DeepLIFT  Learning Important Features Through Propagating Activation Differences

Figure   DeepLIFT with RevealCancel gives qualitatively desirable behavior on TALGATA simulation      Scatter plots of importance score vs  strength of TAL  motif match for different tasks and methods  see Appendix   for GATA  For each region  top  
motif matches are plotted  Xaxes  logodds of TAL  motif match vs  background  Yaxes  total importance assigned to the match for
speci ed task  Red dots are from regions where both TAL  and GATA  motifs were inserted during simulation  blue have GATA  only 
green have TAL  only  black have no motifs inserted   DeepLIFTfc RCconv RS  refers to using RevealCancel on the fullyconnected
layer and Rescale on the convolutional layers  which appears to reduce noise relative to using RevealCancel on all layers      proportion
of strong matches  logodds     to TAL  motif in regions containing both TAL  and GATA  that had total score     for task   Guided
Backprop inp and DeepLIFT with RevealCancel have no false negatives  but Guided Backprop has false positives for Task    Panel    

  Classifying Regulatory DNA  Genomics 

Next  we compared the importance scoring methods when
applied to classi cation tasks on DNA sequence inputs
 strings over the alphabet           The human genome
has millions of DNA sequence elements     in
length  containing speci   combinations of short functional words to which regulatory proteins  RPs  bind to
regulate gene activity  Each RP       GATA  has binding
af nity to speci   collections of short DNA words  motifs        GATAA and GATTA    key problem in computational genomics is the discovery of motifs in regulatory
DNA elements that give rise to distinct molecular signatures  labels  which can be measured experimentally  Here 
in order to benchmark DeepLIFT and competing methods
to uncover predictive patterns in DNA sequences  we design   simple simulation that captures the essence of the
motif discovery problem described above 
Background DNA sequences of length   were generated by sampling the letters ACGT at each position with

probabilities       and   respectively  Motif instances were randomly sampled from previously known
probabilistic motif models  See Appendix    of two RPs
named GATA  and TAL   Fig     Kheradpour   Kellis    and   instances of   given motif were inserted at random nonoverlapping positions in the DNA sequences  We trained   multitask neural network with two
convolutional layers  global average pooling and one fullyconnected layer on   binary classi cation tasks  Positive
labeled sequences in task   represented  both GATA  and
TAL  present  task   represented  GATA  present  and
  of sequences had
in task   represented  TAL  present   
both GATA  and TAL  motifs  labeled    
  had only
  had only TAL   labeled   and
GATA   labeled    
  had no motifs  labeled   Details of the simulation 
 
network architecture and predictive performance are given
in Appendix    For DeepLIFT and integrated gradients 
we used   reference input that had the expected frequencies
of ACGT at each position       we set the ACGT channel
axis to         see Appendix   for results using

DeepLIFT  Learning Important Features Through Propagating Activation Differences

shuf ed sequences as   reference  For fair comparison 
this reference was also used for gradient input and Guided
Backprop input  input  is more accurately called  input
where   measured       the reference  For DNA sequence
inputs  we found Guided Backprop input performed better
than vanilla Guided Backprop  thus  we used the former 
Given   particular subsequence  it is possible to compute
the logodds score that the subsequence was sampled from
  particular motif vs  originating from the background
distribution of ACGT  To evaluate different importancescoring methods  we found the top   matches  as ranked
by their logodds score  to each motif for each sequence
from the test set  as well as the total importance allocated
to the match by different importancescoring methods for
each task  The results are shown in Fig     for TAL  and
Appendix    for GATA  Ideally  we expect an importance scoring method to show the following properties   
high scores for TAL  motifs on task   and   low scores
for TAL  on task   with   higher scores corresponding to
stronger logodds matches  analogous pattern for GATA 
motifs  high for task   low for task     high scores for
both TAL  and GATA  motifs for task   with   higher
scores on sequences containing both kinds of motifs vs  sequences containing only one kind  revealing cooperativity 
corresponds to red dots lying above green dots in Fig   
We observe Guided Backprop input fails   by assigning
positive importance to TAL  on task    see Appendix  
for an example sequence  It fails property   by failing
to identify cooperativity in task    red dots overlay green
dots  Both Guided Backprop input and gradient input
show suboptimal behavior regarding property   in that
there is   sudden increase in importance when the logodds
score is around   but little differentiation at higher logodds scores  by contrast  the other methods show   more
gradual increase  As   result  Guided Backprop input and
gradient input can assign unduly high importance to weak
motif matches  Fig    This is   practical consequence of
the thresholding problem from Fig    The large discontinuous jumps in gradient also result in in ated scores  note
the scale on the yaxes  relative to other methods 
We explored three versions of DeepLIFT  Rescale at all
nonlinearities  DeepLIFTRescale  RevealCancel at all
nonlinearities  DeepLIFTRevealCancel  and Rescale at
convolutional layers with RevealCancel at the fully connected layer  DeepLIFTfc RCconv RS  In contrast to the
results on MNIST  we found that DeepLIFTfc RCconv 
RS reduced noise relative to pure RevealCancel  We think
this is because of the noisesuppression property discussed
in Section   if the convolutional layers act like motif detectors  the input to convolutional neurons that do not
 re may just represent noise and importance should not be
propagated to them  see Fig    for an example sequence 

Gradient inp  integrated gradients and DeepLIFTRescale
occasionally miss relevance of TAL  for Task    Fig     
which is corrected by using RevealCancel on the fully connected layer  see example sequence in Fig    Note that
the RevealCancel scores seem to be tiered  As illustrated
in Appendix    this is related to having multiple instances
of   given motif in   sequence  eg  when there are multiple
TAL  motifs  the importance assigned to the presence of
TAL  is distributed across all the motifs 

Figure   RevealCancel highlights both TAL  and GATA  motifs for Task       PWM representations of the GATA  motif
and TAL  motif used in the simulation     Scores for example sequence containing both TAL  and GATA  motifs  Letter height
re ects the score  Blue box is location of embedded GATA  motif  green box is location of embedded TAL  motif  Red underline
is chance occurrence of weak match to TAL   CAGTTG instead
of CAGATG  Both TAL  and GATA  motifs should be highlighted for Task   RevealCancel on only the fullyconnected
layer reduces noise compared to RevealCancel on all layers 

  Conclusion
We have presented DeepLIFT    novel approach for computing importance scores based on explaining the difference of the output from some  reference  output in terms
of differences of the inputs from their  reference  inputs 
Using the differencefrom reference allows information to
propagate even when the gradient is zero  Fig    which
could prove especially useful in Recurrent Neural Networks where saturating activations like sigmoid or tanh are
popular  DeepLIFT avoids placing potentially misleading
importance on bias terms  in contrast to gradient input  
see Fig    By allowing separate treatment of positive and
negative contributions  the DeepLIFTRevealCancel rule
can identify dependencies missed by other methods  Fig 
  Open questions include how to apply DeepLIFT to
RNNs  how to compute   good reference empirically from
the data  and how best to propagate importance through
 max  operations  as in Maxout or Maxpooling neurons 
beyond simply using the gradients 

DeepLIFT  Learning Important Features Through Propagating Activation Differences

Zeiler  Matthew    and Fergus  Rob 

Visualizing
CoRR 
and understanding convolutional networks 
abs    URL http arxiv org 
abs 

Zhou  Jian and Troyanskaya  Olga    Predicting effects of
noncoding variants with deep learningbased sequence
model  Nat Methods      Oct   ISSN
  doi   nmeth 

Zintgraf  Luisa    Cohen  Taco    Adel  Tameem 
Visualizing deep neural netICLR 
URL https openreview net pdf 

and Welling  Max 
work decisions  Prediction difference analysis 
 
id BJ UeU xx 

  Acknowledgements
We thank Anna Shcherbina for early experiments applying
DeepLIFT to image data and betatesting 

  Funding
AS is supported by   Howard Hughes Medical Institute
International Student Research Fellowship and   BioX
Bowes Fellowship  PG is supported by   BioX Stanford
Interdisciplinary Graduate Fellowship  AK was supported
by NIH grants DP GM  and    ES 

  Author Contributions
AS   PG conceptualized DeepLIFT  AS implemented
DeepLIFT  AS ran experiments on MNIST  AS   PG ran
experiments on genomic data  AK provided guidance and
feedback  AS  PG and AK wrote the manuscript 

References
Bach  Sebastian  Binder  Alexander  Montavon  Gr egoire 
Klauschen  Frederick    uller  KlausRobert 
and
Samek  Wojciech  On PixelWise explanations for
NonLinear classi er decisions by LayerWise relevance
propagation  PLoS One        July  

Chollet  Franois 

keras 

fchollet keras   

https github com 

Kheradpour  Pouya and Kellis  Manolis  Systematic discovery and characterization of regulatory motifs in encode tf binding experiments  Nucleic acids research   
   

Kindermans  PieterJan  Schtt  Kristof  Mller  KlausRobert  and Dhne  Sven  Investigating the in uence of
noise and distractors on the interpretation of neural networks  CoRR  abs    URL https 
 arxiv org abs 

LeCun  Yann  Cortes  Corinna  and Burges  ChristoThe mnist database of handwritten dighttp yann lecun com exdb mnist 

pher     
its 
 

Lundberg  Scott and Lee  SuIn  An unexpected unity
among methods for
interpreting model predictions 
CoRR  abs    URL http arxiv 
org abs 

Selvaraju  Ramprasaath    Das  Abhishek  Vedantam  Ramakrishna  Cogswell  Michael  Parikh  Devi  and Batra  Dhruv  Gradcam  Why did you say that  visual
explanations from deep networks via gradientbased localization  CoRR  abs    URL http 
 arxiv org abs 

Shrikumar  Avanti  Greenside  Peyton  Shcherbina  Anna 
and Kundaje  Anshul  Not just   black box  Learning
important features through propagating activation differences  arXiv preprint arXiv   

Simonyan  Karen  Vedaldi  Andrea  and Zisserman  Andrew  Deep inside convolutional networks  Visualising
image classi cation models and saliency maps  arXiv
preprint arXiv   

Springenberg  Jost Tobias  Dosovitskiy  Alexey  Brox 
Thomas  and Riedmiller  Martin    Striving for simplicity  The all convolutional net  CoRR  abs 
 
URL http arxiv org abs 
 

Sundararajan  Mukund  Taly  Ankur  and Yan  Qiqi  Gradients of counterfactuals  CoRR  abs   
URL http arxiv org abs 

