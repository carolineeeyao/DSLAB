Stochastic Modi ed Equations

and Adaptive Stochastic Gradient Algorithms

Qianxiao Li   Cheng Tai     Weinan        

Abstract

We develop the method of stochastic modi ed
equations  SME  in which stochastic gradient
algorithms are approximated in the weak sense
by continuoustime stochastic differential equations  We exploit the continuous formulation
together with optimal control theory to derive
novel adaptive hyperparameter adjustment policies  Our algorithms have competitive performance with the added bene   of being robust to
varying models and datasets  This provides  
general methodology for the analysis and design
of stochastic gradient algorithms 

nX

  

 
 

 

  Introduction
Stochastic gradient algorithms are often used to solve optimization problems of the form

       

min
  Rd
  Rd     for                 

fi   

In machine
where    fi
learning applications    is typically the total loss function
whereas each fi represents the loss due to the ith training
sample    is   vector of trainable parameters and   is the
training sample size  which is typically very large 
Solving   using the standard gradient descent  GD  requires   gradient evaluations per step and is prohibitively
expensive when    cid    An alternative  the stochastic gradient descent  SGD  is to replace the full gradient rf by
  sampled version  serving as an unbiased estimator  In its
simplest form  the SGD iteration is written as

where    cid    and   cid kg are       uniform variates taking values in     cid cid cid    ng  The stepsize  cid  is the learning rate 
Unlike GD  SGD samples the full gradient and its computational complexity per iterate is independent of    For
this reason  stochastic gradient algorithms have become increasingly popular in large scale problems 
Many convergence results are available for SGD and its
variants  However  most are upperbound type results for
 strongly  convex objectives  often lacking the precision
and generality to characterize the behavior of algorithms
in practical settings  This makes it harder to translate theoretical understanding into algorithm analysis and design 
In this work  we address this by pursuing   different analytical direction  We derive continuoustime stochastic differential equations  SDE  that can be understood as weak
approximations      
approximations in distribution  of
stochastic gradient algorithms  These SDEs contain higher
order terms that vanish as  cid      but at  nite and small
 cid  they offer much needed insight of the algorithms under consideration 
In this sense  our framework can be
viewed as   stochastic parallel of the method of modi ed
equations in the analysis of classical  nite difference methods  Noh   Protter    Daly    Hirt    Warming   Hyett    For this reason  we refer to these SDEs
as stochastic modi ed equations  SME  Using the SMEs 
we can quantify  in   precise and general way  the leadingorder dynamics of the SGD and its variants  Moreover  the
continuoustime treatment allows the application of optimal control theory to study the problems of adaptive hyperparameter adjustments  This gives rise to novel adaptive algorithms and perhaps more importantly    general methodology for understanding and improving stochastic gradient
algorithms 

xk    xk  cid   cid rf cid    xk 

 

 Institute of High Performance Computing  Singapore  Peking
University  Beijing  China  Beijing Institute of Big Data Research  Beijing  China  Princeton University  Princeton  NJ  USA 
Correspondence to  Qianxiao Li  liqix ihpc astar edu sg 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Notation  We distinguish sequential and dimensional indices by writing   bracket around the latter       xk    is
the ith coordinate of the vector xk  the kth SGD iterate 

  Stochastic Modi ed Equations
We now introduce the SME approximation  Background
materials on SDEs are found in Supplementary Materials

SME and Adaptive Stochastic Gradient Algorithms

 

 SM    and references therein  First  rewrite the SGD iteration rule   as

 cid Vk 

xk   cid  xk    cid cid rf  xk   
 
 
 cid rf  xk   cid  rf cid    xk  is   ddimensional
where Vk  
random vector  Conditioned on xk  Vk has mean   and
covariance matrix  cid cid xk  with
nX

 rf      cid  rfi   rf      cid  rfi      

 cid     

 

 
 

  

Now  consider the Stochastic differential equation

dXt     Xt dt    cid Xt dWt         

 

 
whose Euler discretization Xk    Xk    cid tb Xk   
 cid   cid Xk Zk  Zk  cid         resembles
  if we set
 cid      cid     cid   cid rf and  cid   cid   cid cid  Then  we would
expect   to be an approximation of   with the identi 
cation       cid  It is now important to discuss the precise
meaning of  an approximation  The noises that drive the
paths of SGD and SDE are independent processes  hence
we must understand approximations in the weak sense 
De nition   Let      cid            and set     bT  cid   
Let   denote the set of functions of polynomial growth 
           if there exists constants     cid      such that
jg            jxj cid  We say that the SDE   is an
order  cid  weak approximation to the SGD   if for every
       there exists       independent of  cid  such that for
all                   

jEg Xk cid   cid  Eg xk       cid cid 

The de nition above is standard in numerical analysis of
SDEs  Milstein    Kloeden   Platen   
Intuitively  weak approximations are close to the original process not in terms of individual sample paths  but their distributions  We now state informally the approximation theorem 
Informal Statement of Theorem   Let       and de ne
 cid    Rd   Rd cid   by   Assume    fi are Lipschitz continuous  have at most linear asymptotic growth and have
suf ciently high derivatives belonging to    Then 
    The stochastic process Xt            satisfying

dXt    cid rf  Xt dt    cid cid Xt 

 
  dWt 

 

The full statement  proof and numerical veri cation of
Thm    is given in SM     We hereafter call equations  
and   stochastic modi ed equations  SME  for the SGD
iterations   We refer to the second order approximation   for exact calculations in Sec    whereas for simplicity  we use the  rst order approximation   when discussing acceleration schemes in Sec    where the order of
accuracy is less important 
Thm    allows us to use the SME to deduce distributional
properties of the SGD  This result differs from usual convergence studies in that it describes dynamical behavior
and is derived without convexity assumptions on   or fi 
In the next section  we use the SME to deduce some dynamical properties of the SGD 

  The Dynamics of SGD
    Solvable SME

We start with   case where the SME is exactly solvable  Let
            and set            with           cid     cid   
and                cid    Then  the SME   for the SGD
iterations on this objective is  see SM    

dXt    cid     cid Xtdt    

 cid dWt 

 

with         This is the wellknown OrnsteinUhlenbeck
process  Uhlenbeck   Ornstein    which is exactly
solvable  see SM     yielding the Gaussian distribution

Xt  cid         cid cid     cid 

 cid     cid    cid cid   

VarXt    cid cid   cid    cid cid   cid       cid  increases from   to

We observe that EXt       cid cid   converges exponentially to the optimum       with rate  cid     cid  but
an asymptotic value of  cid     cid  The separation   cid  between the descent phase and the  uctuations phase is given
by EXt cid   

 

VarXt cid  whose solution is
  cid     

 cid  log     cid 

 cid    
 

For       cid  descent dominates and when       cid   uctuation dominates  This twophase behavior is known for convex cases via error bounds  Moulines    Needell et al 
  Using the SME  we obtained   precise characterization of this behavior  including an exact expression for
  cid  In Fig    we verify the SME predictions regarding the
mean  variance and the twophase behavior 

is an order   weak approximation of the SGD 
 ii  The stochastic process Xt            satisfying
 jrf  Xt   dt    cid cid Xt 

dXt    cid      Xt     cid 

is an order   weak approximation of the SGD 

  Stochastic Asymptotic Expansion

 
  dWt
 

In general  we cannot expect to solve the SME exactly  especially for       However  observe that the noise terms
in the SMEs   and   are   cid  Hence  we can write
Xt as an asymptotic series Xt        
 cid            

 

SME and Adaptive Stochastic Gradient Algorithms

   

   

   

   

Figure   Comparison of the SME predictions vs SGD for the simple quadratic objective  We set         cid          The predicted mean and standard deviations agree well with the empirical moments of the SGD  obtained by averaging     runs     
  sample SGD paths the predicted transition time   cid      cid cid 
We observe that   cid  corresponds to the separation of descent and
 uctuating regimes for typical sample paths 

Figure   Comparison of the moments of SGD iterates with the
SME and its asymptotic approximation  Asymp  Eq    for the
nonconvex objective with  cid      and  cid      The landscape
is shown in     In     we plot the magnitude of the mean and the
covariance matrix for the SGD  SME and Asymp  We take  cid     
  and          All moments are obtained by sampling over
    runs  the SME and Asymp are integrated numerically  We
observe   good agreement 

where each Xj   is   stochastic process with initial condition         and Xj      for    cid    We substitute
this into the SME and expand in orders of  cid  and equate
the terms of the same order to get equations for Xj   for
   cid    This procedure is justi ed rigorously in Freidlin
et al    We obtain to leading order  see SM    

Xt  cid           cid St 
 
        cid rf               and
where     solves
 St    cid StHt  cid  HtSt    cid    where Ht   Hf       with
Hf denoting the Hessian of    and  cid      cid            
It is then possible to deduce the dynamics of the SGD  For
example  there is generally   transition between descent
and  uctuating regimes  St has   steady state  assuming
it is asymptotically stable  with jS    cid    cid   jH    This
means that one should expect    uctuating regime where
the covariance of the SGD is of order   cid   cid   jH   
Preceding this  uctuating regime is   descent regime governed by the gradient  ow 
We validate our approximations on   nonconvex objective 
Set             with the sample objectives          
 
  and         cid  cos   cid  cos   cid  In
         
Fig      we plot   for  cid       cid      showing the
complex landscape  In Fig      we compare the SGD moments jE xk   and jCov xk   with predictions of the SME
and its asymptotic approximation   We observe that our
approximations indeed hold for this objective 

  Adaptive Hyperparameter Adjustment
We showed in the previous section that the SME formulation help us better understand the precise dynamics of the
SGD  The natural question is how this can translate to designing practical algorithms  In this section  we exploit the
continuoustime nature of our framework to derive adaptive

learning rate and momentum parameter adjustment policies  These are particular illustrations of   general methodology to analyze and improve upon SGD variants  We will
focus on the one dimensional case       and subsequently
apply the results to high dimensional problems by local diagonal approximations 

  Learning Rate

  OPTIMAL CONTROL FORMULATION

   SGD iterations with learning rate adjustment can be
written as

  cid cid Xt dWt 

xk    xk  cid   cid ukf xk 

 
where uk       is the adjustment factor and  cid  is the
maximum allowed learning rate  The corresponding SME
for   is given by  SM    

dXt    cid utf Xt dt   ut

 
where ut       is now the continuous time analogue of
the adjustment factor uk with the usual identi cation    
  cid  The effect of learning rate adjustment on the dynamics
of SGD is clear  Larger uk results in   larger drift term
in the SME and hence faster initial descent  However  the
same factor is also multiplied to the noise term  causing
greater asymptotic  uctuations  The optimal learning rate
schedule must balance of these two effects  The problem
can therefore be posed as follows  given    fi  how can we
best choose   schedule or policy for adjusting the learning
rate in order to minimize Ef at the end of the run  More
precisely  this can be cast as an optimal control problem 

Ef  XT   subject to  

min

 

 See SM    for   brief overview of optimal control theory 

    MomentsMean  StdSGDSMESGDSME    xkk          Moments Mean    Cov SGDSMEAsympSGDSMEAsympSME and Adaptive Stochastic Gradient Algorithms

where the timedependent function   is minimized over an
admissible control set to be speci ed  To make headway
analytically  we now turn to   simple quadratic objective 

  OPTIMAL CONTROL OF THE LEARNING RATE

       cid     with          
Consider the objective          
Moreover  we assume the fi   are such that  cid       cid     
is   positive constant  The SME is then
dXt    cid aut Xt  cid    dt   ut

  cid cid dWt 

 

Now  assume   take values in the nonrandom control set
containing all Borelmeasurable functions from       to
    De ning mt   Ef  Xt  and applying It   formula
to   we have

 mt    cid autmt    

    cid cid   
   

 

Hence  we may now recast the control problem as

min

     

mT subject to  

This problem can solved by dynamic programming  using
the HamiltonJacobi Bellman equation  Bellman   
We obtain the optimal control policy  SM    
   cid   
     

 
min   mt
 cid cid   

  cid 
   

 

 

This policy is of feedback form since it depends on the
current value of the controlled variable mt  Let us interpret
the solution  First  if       we always set the maximum
learning rate ut     This makes sense because we have
  concave objective where symmetrical  uctuations about
any point   results in   lower average value of       Hence 
not only do high learning rates improve descent  the high
 uctuations that accompany it also lowers Ef  Next  For
the convex case       the solution tells us that when the
objective value is large compared to variations in the gradient  we should use the maximum learning rate  When the
objective decreases suf ciently   uctuations will dominate
and hence we should lower the learning rate according to
the feedback policy ut    mt cid cid 
With the policy   we can solve   and plug the solution for mt back into   to obtain the annealing schedule

 

  cid 
   

 
     cid   cid 

 

   cid    or    cid    cid 
      and       cid 

where   cid        log   cid cid   cid    Note that by
putting              cid      for small  cid  this expression agrees with the transition time   between descent
and  uctuating phases for the SGD dynamics considered in
Sec    Thus  this annealing schedule says that maximum

learning rate should be used for descent phases  whereas
 cid     decay on learning rate should be applied after onset
of  uctuations  Our annealing result agree asymptotically
with the commonly studied annealing schedules  Moulines 
  Shamir   Zhang    but the difference is that we
suggest maximum learning rate before the onset of  uctuations  Of course  the key limitation is that our result is only
valid for this particular objective  This naturally brings us
to the next question  how does one apply the optimal control results to general objectives 

  APPLICATION TO GENERAL OBJECTIVES

 

Now  we turn to the setting where       and    fi are
not necessarily quadratic  The most important result in
Sec    is the feedback control law   To apply it  we
Pd
make   local diagonalquadratic assumption  we assume
that for each     Rd  there exists               so that
             cid       holds locally in    We
       cid   
also assume  cid     cid  diagf cid           cid     where each  cid   
is locally constant  By considering   separate learning rate
scale      for each trainable dimension  the control problem
decouples to   separate problems of the form considered in
Sec    And hence  we may set   cid 
    elementwise according to the policy  
Since we only assume that
the diagonalquadratic assumption holds locally 
the terms            cid    and
      cid   
            cid       must be updated on the
    There are potentially many methods for doing so 
The approach we take exploits the linear relationship
rf     cid            cid       Consequently  we may estimate           via linear regression on the    
for
each dimension  we maintain exponential moving averages  EMA  fgk      
     xgk     where
gk      rf cid    xk   
For example  gk     
 cid     gk         cid   cid     gk    The EMA decay parameter  cid      controls the effective averaging window size  We
adaptively adjust it so that it is small when gradient variations are large  and vice versa  We employ the heurisk    This is similar to
tic  cid           
the approach in Schaul et al    We also clip each
 cid      to  cid min   cid max  to improve stability  Here  we use
    for all experiments  but we checked that performance is insensitive to these values  We can now compute ak    bk    by the ordinaryleast squares formula and
 cid      as the variance of the gradients 

      cid    

     xk      

      

gxk     cid  gk   xk   

  

ak     

      cid    
bk      xk     cid  gk   
ak   
      cid    
    

 cid          

    

 

 

 

SME and Adaptive Stochastic Gradient Algorithms

Algorithm   controlled SGD  cSGD 

Hyperparameters   cid    
Initialize     cid          
for       to  iterations  cid    do

Compute sample gradient rf cid    xk 
for       to   do

     xgk    

     xk      

Update EMA fgk      
with decay parameter  cid     
Compute ak    bk     cid      using  
Compute   cid 
 cid           
uk       cid     uk         cid   cid       cid 
xk      xk     cid   cid uk   rf cid    xk   

     using  
      cid    

      

     and clip

    

end for

end for

 

This allows us to estimate the policy   as

 

 cid cid     

  cid 
      

min  ak   xk   cid bk   

ak     cid   
ak       
 
for                    Since quantities are computed from
exponentially averaged sources  we should also update our
learning rate policy in the same way  The algorithm is summarized in Alg    Due to its optimal control origin  we
hereafter call this algorithm the controlled SGD  cSGD 
Remark   Alg    can similarly be applied to minibatch
SGD  Let the batchsize be    which reduces the covariance by   times and so  cid  in the SME is replaced by  cid   
However  at the same time estimating  cid   from minibatch
gradient sample variances will underestimate  cid xk  by  
factor of    Thus the product  cid cid   remains unchanged and
Alg    can be applied with no changes 
Remark   The additional overheads in cSGD are
from maintaining exponential averages and estimating
ak  bk   cid   on the    with the relevant formulas  These are
     operations and hence scalable  Our current rough
implementation runs  cid     cid    slower per epoch than
the plain SGD  This is expected to be improved by optimization  parallelization or updating quantities less frequently 

  PERFORMANCE ON BENCHMARKS

Let us test cSGD on common deep learning benchmarks 
We consider three different models       fully connected neural network with one hidden layer and ReLU
activations  trained on the MNIST dataset  LeCun et al 
       fully connected neural network with two hidden layers and Tanh activations  trained on the CIFAR 
dataset  Krizhevsky   Hinton         convolution
network with four convolution layers and two fully connected layers also trained on CIFAR  Model details

are found in SM     In Fig    we compare the performance of cSGD with Adagrad  Duchi et al    and
Adam  Kingma   Ba    optimizers  We illustrate in
particular their sensitivity to different learning rate choices
by performing   loguniform random search over three orders of magnitude  We observe that cSGD is robust to
different initial and maximum learning rates  provided the
latter is big enough       we can take  cid      for all experiments  and changing network structures  while obtaining similar performance to welltuned versions of the other
methods  see also Tab    In particular  notice that the best
learning rates found for Adagrad and Adam generally differ
for different neural networks  On the other hand  many values can be used for cSGD with little performance loss  For
brevity we only show the test accuracies  but the training
accuracies have similar behavior  see SM    

  Momentum Parameter

Another practical way of speeding up the plain SGD is to
employ momentum updates   an idea dating back to deterministic optimization  Polyak    Nesterov    Qian 
  However  the stochastic version has important differences  especially in regimes where sampling noise dominates  Nevertheless  provided that the momentum parameter is welltuned  the momentum SGD  MSGD  is very
effective in speeding up convergence  particularly in early
stages of training  Sutskever et al   
Selecting an appropriate momentum parameter is important
in practice  Typically  generic values           are
suggested without fully elucidating their effect on the SGD
dynamics  In this section  we use the SME framework to
analyze the precise dynamics of MSGD and derive effective adaptive momentum parameter adjustment policies 

  SME FOR MSGD

The SGD with momentum can be written as the following
coupled updates

vk     cid vk  cid   cid   
 cid  
xk    xk   vk 

 xk 

 

The parameter  cid  is the momentum parameter taking values
in the range    cid   cid   cid    Intuitively  the momentum term
vk remembers past update directions and pushes along xk 
which may otherwise slow down at      narrow parts of the
landscape  The corresponding SME is now   coupled SDE
dVt    cid cid cid   cid   cid Vt  cid    Xt dt    cid cid Xt 
dXt    cid cid Vtdt 
This can be derived by comparing   with the Euler discretization scheme of   and matching moments  Details
can be found in SM    

  dWt 
 

 

SME and Adaptive Stochastic Gradient Algorithms

        fully connected NN  MNIST 

        fully connected NN  CIFAR 

   

   

Figure       Comparison of the SME prediction   with SGD
for the same quadratic example in Sec    which has      
      and  cid      We set  cid      so that  cid opt     We
plot the mean of   averaged over     SGD runs against the SME
predictions for  cid          We observe that in all cases
the approximation is accurate  In particular  the SME correctly
predicts the effect of momentum   cid     cid opt gives the best average initial descent rate   cid     cid opt causes oscillatory behavior  and
increasing  cid  generally increases asymptotic  uctuations      The
dynamics of averaged equation   which serves as an approximation of the solution of the full SME moment equation  

        CNN  CIFAR 

Figure   cSGD vs Adagrad and Adam for different models and
datasets  with different hyperparameters 
For    we perform loguniform random search with   samples over intervals 
cSGD          cid      Adagrad   cid      Adam 
 cid        For    we perform same search over intervals 
cSGD          cid      Adagrad   cid      Adam 
 cid        We average the resulting learning curves for
each choice over   runs  For    due to long training times we
choose   representative learning rates for each method  cSGD 
 cid                       Adagrad   cid         
          Adam   cid                  One
sample learning curve is generated for each choice  In all cases 
we use minibatches of size   We evaluate the resulting learning curves by the areaunder curve  The worst  median and best
learning curves are shown as dotted  solid  and dotdashed lines
respectively  The shaded areas represent the distribution of learning curves for all searched values  We observe that cSGD is
relatively robust with respect to initial maximum learning rates
and the network structures  and requires little tuning while having
comparable performance to welltuned versions of the other methods  see Tab    This holds across different models and datasets 

  THE EFFECT OF MOMENTUM

As in Sec    we take the prototypical example
       cid     with  cid  constant and study the eff        
fect of incorporating momentum updates  De ne Mt  
    EVtf Xt       By applying It   for 
 Ef  Xt  EV  
mula to   we obtain the ODE system
 cid   

 Mt     cid Mt   
 

 cid 

 cid   

 cid 

  cid   

   cid cid cid cid 
 cid 

 cid 

  cid 
 cid 

 cid cid cid cid 

     

 cid cid 
 

 

 

If         cid  has   positive eigenvalue and hence Mt
diverges exponentially  Since   is negative  its value must
then decrease exponentially for all  cid  and the descent rate
is maximized at  cid      The more interesting case is
when      
Instead of solving   we observe that
all eigenvalues of   cid  have negative real parts as long as
 cid      Therefore  Mt has an exponential decay dominated by jR cid cid    where   denotes real part and  cid cid   
 cid   
the least negative real part  Observe that the descent rate
jR cid cid   is maximized at

 cid     cid   cid   cid     cid   cid   cid     cid  is the eigenvalue with

 
 cid opt   max   cid   

 

  cid   

 cid cid 

 cid cid 

 cid   cid 

we have Mt         cid   cid cid    cid 

and when  cid     cid opt   cid  becomes complex  Also  from  

 cid cid   cid 

provided the steady state is stable  The role of momentum in this problem is now clear  To leading order in  cid 
we have  cid cid   cid   cid     cid   cid  for  cid   cid   cid opt  Hence  any
nonzero momentum will improve the initial convergence
rate  In fact  the choice  cid opt is optimal and above it  oscillations set in because of   complex  cid  At the same time 
increasing momentum also causes increment in eventual
 uctuations  since jM         cid   cid cid  In Fig     
we demonstrate the accuracy of the SME prediction  
by comparing MSGD iterations  Armed with an intuitive
understanding of the effect of momentum  we can now use
optimal control to design policies to adapt the momentum
parameter 

  OPTIMAL CONTROL OF THE MOMENTUM

PARAMETER

For       we have discussed previously that  cid      maximizes the descent rate and  uctuations generally help de 

 Epoch Test acccSGD         EpochAdagrad       EpochAdam       Epoch Test acccSGD         EpochAdagrad       EpochAdam       Epoch Test acccSGD         EpochAdagrad       EpochAdam                  fMSGD  SME opt opt opt opt opt opt            mk Avg eqn opt opt optSME and Adaptive Stochastic Gradient Algorithms

crease concave functions  Thus  the optimal control is always  cid      The nontrivial case is when       Due
to its bilinearity  directly controlling   leads to bangbang type solutions  that are rarely feedback laws  Pardalos   Yatsenko    and thus dif cult to apply in practice  Instead  we notice that the descent rate is dominated
by   cid cid  and the leading order asymptotic  uctuations is
 cid cid   cid   cid  hence we may consider

 mt     cid cid mt  cid    cid 

 
where mt     and   cid     cid cid   cid   cid  is the leading order estimate of jM    Equation   can be understood as the approximate evolution  in an averaged sense  of
the magnitude of Mt  Fig      shows that   is   reasonable approximation of the dynamics of MSGD  This allows
us to pose the optimal control problem on the momentum
parameter as

min

 cid    

mT subject to  

with  cid     cid    Solving this control problem yields the  approximate  feedback policy  SM    

 

 cid cid 
   

 
min cid opt  max     cid   cid cid 

 mt

 

   cid   
     

 

with  cid opt given in   This says that when far from optimum  mt large  we set  cid     cid opt which maximizes average
descent rate  When mt cid cid   cid   
  cid   uctuations set in and

we lower  cid 
As in Sec    we turn the control policy above into
  generally applicable algorithm by performing local
diagonalquadratic approximations and estimating the relevant quantities on the     The resulting algorithm is mostly
identical to Alg    except we now use   to update  cid     
and SGD updates are replaced with MSGD updates  see
        for the full algorithm  We refer to this algorithm
as the controlled momentum SGD  cMSGD 

  PERFORMANCE ON BENCHMARKS

We apply cMSGD to the same three setups in Sec   
and compare its performance to the plain Momentum SGD
with  xed momentum parameters  MSGD  and the annealing schedule suggested in  Sutskever et al    with
 cid     min   cid   cid cid log bk     cid max   MSGDA  In
Fig    we perform   loguniform search over the hyperparameters  cid   cid  and  cid max  We see that cMSGD achieves
superior performance to MSGD and MSGDA  see Tab   

 Bangbang solutions are control solutions lying on the boundary of the control set and abruptly jumps among the boundary values  For example  in this case it jumps between  cid      and  cid     
repeatedly 

        fully connected NN  MNIST 

        fully connected NN  CIFAR 

        CNN  CIFAR 

Figure   cMSGD vs MSGD and MSGDA on the same three
models  We set  cid      for    and  cid      for      
For    and    we perform   loguniform random search
for    cid   cid  and    cid   cid  in       For    we sample
 cid   cid   cid max       The remaining setup
is identical to that in Fig    Again  we observe that cMSGD is an
adaptive scheme that is robust to varying hyperparameters and
network structures  and outperforms MSGD and MSGDA 

Table   Best average test accuracy found by random grid search 

CSGD ADAGRAD ADAM

CMSGD MSGD MSGDA

  
  
  

 
 
 

 
 
 

 
 
 

 
 
 

 
 
 

 
 
 

especially when the latter has badly tuned  cid   cid max  Moreover  it is insensitive to the choice of initial  cid  Just like
cSGD  this holds across changing network structures  Further  cMSGD also adapts to other hyperparameter variations  In Fig    we take tuned  cid   cid max  and any  cid  and
vary the learning rate  cid  We observe that cMSGD adapts to
the new learning rates whereas the performance of MSGD
and MSGDA deteriorates and  cid   cid max must be retuned
to obtain reasonable accuracy  In fact  it is often the case
that MSGD and MSGDA diverge when  cid  is large  whereas
cMSGD remains stable 

  Related Work
Classical boundtype convergence results for SGD and
variants include Moulines   Shamir   Zhang  

 Epoch Test acccMSGD EpochMSGD EpochMSGDA max Epoch Test acccMSGD EpochMSGD EpochMSGDA max Epoch Test acccMSGD EpochMSGD EpochMSGDA max SME and Adaptive Stochastic Gradient Algorithms

        fully connected NN  MNIST 

        fully connected NN  CIFAR 

        CNN  CIFAR 

Figure   Comparing the sensitivity of cMSGD  MSGD and
MSGDA to different learning rates  The setup is same as that in
Fig    except that for MSGD and MSGDA  we now     cid   cid max
to be the best values found in Fig    for each experiment  but we
vary the learning rate in the ranges     and     cid        
 cid                  For cMSGD  we saw from Fig   
that the value of  cid  is mostly inconsequential  so we simply set
 cid      and vary  cid  in the same ranges  We observe that the unlike
MSGD and MSGDA  cMSGD is generally robust to changing
learning rates and this further con rms its adaptive properties 

Bach   Moulines   Needell et al    Xiao  
Zhang   ShalevShwartz   Zhang   Our approach differs in that we obtain precise  albeit only distributional  descriptions of the SGD dynamics that hold in
nonconvex situations 
In the vein of continuous approximation to stochastic algorithms    related body of work is stochastic approximation theory  Kushner   Yin    Ljung et al   
which establish ODEs as almost sure limits of trajectories of stochastic algorithms  In contrast  we obtain SDEs
that are weak limits that approximate not individual sample
paths  but their distributions  Other deterministic continuous time approximation methods include Su et al   
Krichene et al    Wibisono et al   
Related work in SDE approximations of
the SGD
are Mandt et al      where the authors derived
the  rst order SME heuristically 
In contrast  we establish   rigorous statement for this type of approximations
 Thm    Moreover  we use asymptotic analysis and control theory to translate understanding into practical algo 

rithms  Outside of the machine learning literature  similar
modi ed equation methods also appear in numerical analysis of SDEs  Zygalakis    and quantifying uncertainties in ODEs  Conrad et al   
The second half of our work deals with practical problems of adaptive selection of the learning rate and momentum parameter  There is abundant literature on learning rate adjustments  including annealing schedules  Robbins   Monro    Moulines    Xu    Shamir
  Zhang    adaptive perelement adjustments  Duchi
et al    Zeiler    Tieleman   Hinton   
Kingma   Ba    and metalearning  Andrychowicz
et al    Our approach differs in that optimal control
theory provides   natural  nonblack box framework for developing dynamic feedback adjustments  allowing us to
obtain adaptive algorithms that are truly robust to changing model settings  Our learning rate adjustment policy is
similar to Schaul et al    Schaul   LeCun  
based on onestep optimization  although we arrive at it
from control theory  Our method may also be easier to
implement because it does not require estimating diagonal Hessians via backpropagation  There is less literature on momentum parameter selection    heuristic annealing schedule  referred to as MSGDA earlier  is suggested in Sutskever et al    based on the original work
of Nesterov   The choice of momentum parameter in
deterministic problems is discussed in Qian   Nesterov   To the best of our knowledge    systematic
stochastic treatment of adaptive momentum parameter selection for MSGD has not be considered before 

  Conclusion and Outlook
Our main contribution is twofold  First  we propose the
SME as   uni ed framework for quantifying the dynamics of SGD and its variants  beyond the classical convex
regime  Tools from stochastic calculus and asymptotic
analysis provide precise dynamical description of these algorithms  which help us understand important phenomena 
such as descent uctuation transitions and the nature of acceleration schemes  Second  we use control theory as  
natural framework to derive adaptive adjustment policies
for the learning rate and momentum parameter  This translates to robust algorithms that requires little tuning across
multiple datasets and model choices 
An interesting direction of future work is extending the
SME framework to develop adaptive adjustment schemes
for other hyperparameters in SGD variants  such as
PolyakRuppert Averaging  Polyak   Juditsky   
SVRG  Johnson   Zhang    and elastic averaging
SGD  Zhang et al    More generally  the SME framework may be   promising methodology for the analysis and
design of stochastic gradient algorithms and beyond 

 Epoch Test acccMSGD       EpochMSGD       EpochMSGDA       Epoch Test acccMSGD       EpochMSGD     EpochMSGDA       Epoch Test acccMSGD       EpochMSGD       EpochMSGDA       SME and Adaptive Stochastic Gradient Algorithms

Acknowledgements
We would like to thank the anonymous reviewers for their
constructive comments  We are also grateful for the many
discussions with Dr Sixin Zhang  This work is supported in
part by Major Program of NNSFC under grant  
DOE DESC  and ONR   

References
Andrychowicz  Marcin  Denil  Misha  Gomez  Sergio 
Hoffman  Matthew    Pfau  David  Schaul  Tom  and
de Freitas  Nando  Learning to learn by gradient descent
by gradient descent  In Advances in Neural Information
Processing Systems  pp     

Bach  Francis and Moulines  Eric  Nonstrongly convex
smooth stochastic approximation with convergence rate
     In Advances in Neural Information Processing
Systems  pp     

Bellman  Richard  Dynamic programming and Lagrange
multipliers  Proceedings of the National Academy of Sciences     

Conrad  Patrick    Girolami  Mark    arkk    Simo  Stuart 
Andrew  and Zygalakis  Konstantinos  Probability measures for numerical solutions of differential equations 
arXiv preprint arXiv   

Daly  Bart    The stability properties of   coupled pair of
nonlinear partial difference equations  Mathematics of
Computation     

Duchi  John  Hazan  Elad  and Singer  Yoram  Adaptive
subgradient methods for online learning and stochastic
optimization  Journal of Machine Learning Research 
 Jul   

Freidlin  Mark    Sz ucs  Joseph  and Wentzell  Alexander    Random perturbations of dynamical systems  volume   Springer Science   Business Media   

Hirt  CW  Heuristic stability theory for  nitedifference
equations  Journal of Computational Physics   
   

Johnson  Rie and Zhang  Tong  Accelerating stochastic
gradient descent using predictive variance reduction  In
Advances in Neural Information Processing Systems  pp 
   

Kingma  Diederik and Ba  Jimmy  Adam    method for

stochastic optimization  ICLR   

Kloeden        and Platen     Numerical Solution of
Stochastic Differential Equations  Springer  New York 
corrected edition  June  

Krichene  Walid  Bayen  Alexandre  and Bartlett  Peter   
Accelerated mirror descent in continuous and discrete
time  In Advances in neural information processing systems  pp     

Krizhevsky  Alex and Hinton  Geoffrey  Learning multiple

layers of features from tiny images   

Kushner  Harold and Yin    George  Stochastic approximation and recursive algorithms and applications  volume   Springer Science   Business Media   

LeCun  Yann  Cortes  Corinna  and Burges  Christopher JC  The mnist dataset of handwritten digits  URL
http yann  lecun  com exdb mnist   

Ljung  Lennart    ug  Georg Ch  and Walk  Harro 
Stochastic approximation and optimization of random
systems  volume   Birkh auser   

Mandt  Stephan  Hoffman  Matthew    and Blei  David   
Continuoustime limit of stochastic gradient descent revisited  In NIPS   

Mandt  Stephan  Hoffman  Matthew    and Blei  David   
  variational analysis of stochastic gradient algorithms 
arXiv preprint arXiv   

Milstein  GN  Numerical integration of stochastic differential equations  volume   Springer Science   Business
Media   

Moulines  Eric and  Francis    Nonasymptotic analysis of
stochastic approximation algorithms for machine learning  In Advances in Neural Information Processing Systems  pp     

Needell  Deanna  Ward  Rachel  and Srebro  Nati  Stochastic gradient descent  weighted sampling  and the randomized algorithm  In Advances in Neural Information
Processing Systems  pp     

Nesterov  Yurii    method of solving   convex programming problem with convergence rate      In Soviet
Mathematics Doklady  volume   pp     

Nesterov  Yurii  Introductory lectures on convex optimization    basic course  volume   Springer Science  
Business Media   

Noh  WF and Protter  MH  Difference methods and the
equations of hydrodynamics  Technical report  California  Univ  Livermore  Lawrence Radiation Lab   

Pardalos  Panos   and Yatsenko  Vitaliy    Optimization
and Control of Bilinear Systems  Theory  Algorithms 
and Applications  volume   Springer Science   Business Media   

SME and Adaptive Stochastic Gradient Algorithms

Wibisono  Andre  Wilson  Ashia    and Jordan  Michael   
  variational perspective on accelerated methods in optimization  Proceedings of the National Academy of Sciences          doi   pnas 
 

Xiao  Lin and Zhang  Tong    proximal stochastic gradient method with progressive variance reduction  SIAM
Journal on Optimization     

Xu  Wei  Towards optimal one pass large scale learning
with averaged stochastic gradient descent  arXiv preprint
arXiv   

Zeiler  Matthew    ADADELTA  an adaptive learning rate

method  arXiv preprint arXiv   

Zhang  Sixin  Choromanska  Anna    and LeCun  Yann 
Deep learning with elastic averaging SGD  In Advances
in Neural Information Processing Systems  pp   
 

Zygalakis  KC  On the existence and the applications of
modi ed equations for stochastic differential equations 
SIAM Journal on Scienti   Computing   
 

Polyak  Boris    Some methods of speeding up the convergence of iteration methods  USSR Computational Mathematics and Mathematical Physics     

Polyak  Boris   and Juditsky  Anatoli    Acceleration of
stochastic approximation by averaging  SIAM Journal
on Control and Optimization     

Qian  Ning  On the momentum term in gradient descent
learning algorithms  Neural networks   
 

Robbins  Herbert and Monro  Sutton    stochastic approximation method  The annals of mathematical statistics 
pp     

Schaul  Tom and LeCun  Yann  Adaptive learning rates and
parallelization for stochastic  sparse  nonsmooth gradients  arXiv preprint arXiv   

Schaul  Tom  Zhang  Sixin  and LeCun  Yann  No more
pesky learning rates  In ICML   volume   pp   
   

ShalevShwartz  Shai and Zhang  Tong  Accelerated proximal stochastic dual coordinate ascent for regularized loss
minimization  Mathematical Programming  pp   
 

Shamir  Ohad and Zhang  Tong  Stochastic gradient descent for nonsmooth optimization  Convergence results
and optimal averaging schemes  In ICML   pp   
 

Su  Weijie  Boyd  Stephen  and Candes  Emmanuel   
differential equation for modeling Nesterovs accelerated
In Advances in
gradient method  theory and insights 
Neural Information Processing Systems  pp   
 

Sutskever  Ilya  Martens  James  Dahl  George  and Hinton 
Geoffrey  On the importance of initialization and momentum in deep learning  In Proceedings of the  th international conference on machine learning  ICML 
pp     

Tieleman     and Hinton     Lecture     RMSProp  Tech 

nical report   

Uhlenbeck  George   and Ornstein  Leonard    On the
theory of the Brownian motion  Physical review   
   

Warming  RF and Hyett  BJ  The modi ed equation approach to the stability and accuracy analysis of  nitedifference methods  Journal of computational physics 
   

