World of Bits  An OpenDomain Platform for WebBased Agents

Tianlin  Tim  Shi     Andrej Karpathy   Linxi  Jim  Fan   Jonathan Hernandez   Percy Liang  

Abstract

While simulated game environments have greatly
accelerated research in reinforcement learning 
existing environments lack the opendomain realism of tasks in computer vision or natural language processing  which operate on artifacts created by humans in natural  organic settings  To
foster reinforcement learning research in such
settings  we introduce the World of Bits  WoB 
  platform in which agents complete tasks on
the Internet by performing lowlevel keyboard
and mouse actions  The two main challenges
are      to curate   diverse set of natural webbased tasks  and  ii  to ensure that these tasks
have   wellde ned reward structure and are reproducible despite the transience of the web  To
tackle this  we develop   methodology in which
crowdworkers create tasks de ned by natural language questions and provide demonstrations of
how to answer the question on real websites using keyboard and mouse  HTTP traf   is cached
to create   reproducible of ine approximation of
the website  Finally  we show that agents trained
via behavioral cloning and reinforcement learning can complete   range of webbased tasks 

  Introduction
Over the last few years  we have witnessed signi cant
progress in developing agents that can interact with increasingly complex environments  Mnih et al    Silver
et al    Levine et al    Critical to this progress
are not only the core learning algorithms  Sutton et al 
  Mnih et al    Schulman et al      and the
associated techniques for learning at scale  Mnih et al 
  but simulated environments that feature complex
dynamics and help benchmark our progress       Bellemare et al    Mikolov et al    Todorov et al 

 Stanford University  Stanford  USA  OpenAI  San Francisco  USA  Correspondence to  Tianlin  Tim  Shi  tianlin cs stanford edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Figure   Agents in the World of Bits perceive the screen pixels 
the DOM  with element coordinates grounded in the image  and
  reward  and output keyboard and mouse commands 

  Johansson et al    However  simulated environments are intrinsically limited  agents in such environments never experience the sheer breadth of experience of
the real world  and thus they miss out on important semantic knowledge crucial for developing intelligence  For control tasks  it is possible to work with realistic environments
in robotics  but the complexity of physical hardware constraints ef cient data gathering and rapid iteration  Even
for narrow domains such as grasping  Levine et al   
Pinto   Gupta    the cost and effort of largescale data
collection is daunting 
To address this  we introduce World of Bits  WoB    learning platform that uses the web as   rich source of opendomain environments  In WoB  an agent receives its observations in the form of the Document Object Model  DOM 
of   webpage and its rendered pixels  and accomplishes
web tasks by sending mouse and keyboard actions  The
use of web as   learning platform offers three bene ts 
Opendomain  By allowing agents to interact with the
web  we open up the world   supply of websites as   rich
source of learning environments and application domains 
Since agents directly work with the UI  we can use existing
web infrastructure without designing specialized APIs 
Opensource  Unlike robotics  WoB is digital  which enables fast iteration and massive scaling  Webpages are
opensource and consist entirely of HTML CSS Javascript 
which is easy to inspect and change dynamically 
Easy to collect data  Because agents use same interface
as humans do  it is possible to crowdsource human demonstrations of   web task from anyone with an access to   web
browser  keyboard and mouse at   low cost  This unlocks

 in contrast to the world of atoms https goo gl JdLQGT

World of Bits  An OpenDomain Platform for WebBased Agents

you
from
to

Question  What is the
top rated place to eat
Korean food in SF 

Question  What is the
monthly
for
  with   term of
  years at today   rates 

payment

Question  How much
is an iPhone   Plus in
Indiana 

Question  What
is  
word that can be made
using scypotnha that is  
letters long 

Question  What
is  
recipe   can make that
contains Avacado but not
Chicken 

Can

 ight

Question 
book
 
San Francisco
New York 

  Constructing Web Tasks
In this section  we describe   progression of three techniques for creating web tasks  MiniWoB  Section  
FormWoB  Section   and QAWoB  Section  

and mouse actions  We train these models using both supervised learning and reinforcement learning  and show that
in some cases we can generalize across different queries
of the same template  However  our overall error rates remain relatively high  suggesting that the proposed benchmark leaves   lot of room for improvement 

Figure   Examples of opendomain web tasks  Each web task is speci ed by   natural language query template and slot values
 underlined  and the agent receives positive reward for clicking on the correct answer  We crowdsource the creation of these tasks 
the potential for largescale data collection 
While WoB speci es   platform  the main conceptual challenge is to de ne meaningful web tasks in   scalable way 
In Section   we start by constructing the Mini World of
Bits  MiniWoB    web tasks  see Figure   for examples  of varying dif culty  in which the reward function is
manually constructed 
Next  in Section   we describe FormWoB  which consists of four web tasks based on real  ight booking websites  The main dif culty here is that websites are constantly changing  and yet we would like to package them
into reproducible research environments for our agents  To
this end  we use   manin themiddle proxy to capture and
replay live HTTP traf    building up an approximation of
the live website 
Finally  inspired by large datasets such as ImageNet in
computer vision  Deng et al    and SQuAD in NLP
 Rajpurkar et al    we would like to scale up to  
diverse set of web tasks without manual effort on each
web task  To tackle this  we develop   methodology based
on crowdsourcing that effectively casts web tasks as question answering  Section   First  we ask crowdworkers
to write queries that can be answered by interacting with
  given website  Each query is de ned by   query template and slot values        New York  that  ll the template slots  See Figure   for examples  Positive reward is
given if an agent clicks on the correct answer  We create  
dataset  QAWoB  which has   queries  from   templates  We collected initial demonstrations for four of the
templates  with one demonstration per query  Collecting
demonstration for the full dataset is ongoing work 
To benchmark   standard approach  we evaluate the performance of convolutional neural networks that take as input
the image and text from the DOM and outputs keyboard

To interact with   web browser  we developed our platform
on top of OpenAI Universe  http universe openai com 
which allows one to package nearly arbitrary programs into
Gym  Brockman et al    environments suitable for reinforcement learning  Speci cally  we package   Chrome
browser inside   Docker container  which exposes   Gym
interface for the agent to interact with  At each time step
   the agent receives an observation  which consists of
the raw screen pixels     RW          of resolution
  the text DOM    and   scalar reward signal
   Each element of   is localized in the image by    tuple
             denoting its bounding box  The agent communicates back   list of actions  which can be     KeyEvent
      hold down the   button  or     PointerEvent      
move the mouse to location     while holding down
the left mouse button  Then the agent obtains reward rt
which is de ned by the speci   web task 

  Web as an Environment

  Minimalistic Web Tasks  MiniWoB

Inspired by the ATARI Learning Environment  Bellemare
et al    we designed   benchmark of   reinforce 

World of Bits  An OpenDomain Platform for WebBased Agents

Figure     of the   MiniWoB web tasks  ranging from simple  left  to more complex  right 

ment learning environments called Mini World of Bits
 MiniWoB  that share many of the characteristics of live
web tasks  interacting with buttons  text  elds  sliders  date
pickers  etc  and allows us to study these challenges in  
controlled context  Since the web offers powerful visual
design tools  the average MiniWoB environment is only
  lines of HTML CSS JavaScript  Each MiniWoB environment is an HTML page that is   pixels high    pixels wide       identical to the ATARI environment dimensions    the top   pixels  in yellow background  contain
the natural language task description  randomly generated 
and the       area below is for interactions  The rewards range from    failure  to    success  and are
weighted linearly with time to encourage fast completion
time  See Figure   for examples 

  Live Web Tasks  FormWoB

While it is possible to create web tasks from scratch      
MiniWoB  the Internet already offers   massive repository
of websites  In this section we describe an approach that
allows us to convert these websites into web tasks 
Since websites change over time and since we do not wish
to spam websites with requests while the agent is training  we need to create an of ine approximation that the
agent can interact with  To do this  when we collect human demonstrations  we use   proxy to record all HTTP
requests and responses between the agent and the website 
To train and evaluate agents on   web task  we use the proxy
to handle all requests with the recorded responses 
We also use requests to de ne reward functions  Form 
 lling tasks involve making    nal request to the website
with   set of keyvalue pairs        from  DEN  to  JFK 
We de ne the reward function as the fraction of keyvalue
pairs that match those in human demonstrations 
When an agent performs an action that generates   request
never seen during human demonstrations         cache
miss  we immediately end the episode with zero reward 
This provides   lower bound on the true reward if the agent

 Ideally  we would require exact match  but this resulted in too

sparse of   reward signal to train and evaluate with 

Figure   Our crowdsourcing interface for collecting human
demonstrations on the web  The left side streams visual observations using VNC and the right side displays queries  All observations and actions are recorded  At the end of episode  the
worker marks   DOM element as the answer  green box 

were to interact with the real website  assuming all rewards
are nonnegative  since all action sequences that result in
  cache miss receive the minimum possible reward 
FormWoB benchmark  We applied this approach to four
 ight booking websites  United  Alaska  AA  and JetBlue 
On each website  an agent must  ll out   form and click
on the submit button  The form  lling process requires  
diverse set of interaction skills  such as typing cities in  
text box using autocomplete  using   date picker  etc  For
each website  there is   query template parameterized by
the following  elds  an origin airport    destination airport 
  departure date  and   return date  Airport names are sampled from   major US cities  and dates are sampled from
March   We created   different instantiations for
each query template  and collected on average   episode of
human demonstration for every query 

  Crowdsourcing Web Tasks at Scale  QAWoB

To take full advantage of the scale and diversity of the web 
we now present   more scalable approach to generating
web tasks that does not involve specifying the reward functions manually for each web task  The key is cast web tasks
as question answering  and solicit questions from crowd 

World of Bits  An OpenDomain Platform for WebBased Agents

    Website categories 

    GUI operations 

Figure   QAWoB contains queries from   diverse set of categories and require many types of operations 

workers  The approach has two stages 
Stage     worker provides   website       yelp com 
and   query template        What is the cheapest restaurant that serves  type of food  near  geographic location  We also ask workers to generate multiple slot
values for each template        brunch     San Francisco 
 hamburger     JFK international airport  etc 
Stage   Next    worker takes   query from stage   and
uses our demonstration interface to answer it  see Figure   The interface has    Select  button  which allows
the worker to mark the DOM element of the webpage corresponding to the answer  We de ne the  very sparse  reward for the task to be   only if an agent clicks on the annotated DOM element 
We encouraged workers to be creative when they pick the
website and the queries so that we can capture   wide
distribution of online activities  However  we do impose
some constraints  For instance  in the instruction we discourge queries that require too much reading comprehension      
 How many royal families are mentioned in
Game of Thrones  on wikipedia org  We also
require that the website be mobilefriendly  because the
learning environment operates in mobile view 
QAWoB benchmark  Our crowdsourced QAWoB dataset
has   query templates  The majority of the templates
have   slots  while the average is   We gather      
slot values per template  resulting in   total queries 
  of the queries have corresponding answers  In most
cases  one needs to navigate through multiple screens or
menus  and perform   search before locating the answer 
This makes the problem particularly hard for pure RL approaches  as random exploration has little chance to stumble upon the goal state 
We label   of the templates with the sequence of GUI
operations required to  nd the answer  Note that there are
multiple ways to accomplish the task and some of the operations can be reordered  so we only provide one of the
shortest paths  There are   GUI operations  search  text

Figure   CNN architecture  GlobalCNN  The CNN representation is concatenated with DOM features into   global feature vector  which is used to predict mouse and keyboard events  LocalCNN  depicted  The mouse position de nes an attention mechanism that pools the CNN features 

 any textbox that is not   search box  date  dropdown 
scroll  click  any click that is not part of the other operations  and other  less common GUI widgets like sliders 
We also organize the templates into   categories  dining 
entertainment  housing  transportation  shopping  calculator  and other  Figure   shows the distribution of categories
and GUI operations 

  Training Web Agents
To build an agent for the WoB setting requires modeling
  novel state space  images and DOM  and action space
 keyboard and mouse 

  Model
State space  The state consists of   color image    the
DOM    and the query    The color image   has size
          The DOM is   list of text elements  with
bounding boxes              to represent their spatial relations  For MiniWoB  the query is natural language  For
FormWoB and QAWoB  we assume   semantic frame is
extracted for    in the format of  template  slots 
Action space  We model
the cursor position    
 mx  my                 with   multinomial distribution over the positions in   regular grid over the image  We model the mouse actions with   multinomial distribution over four possibilities  noop  click  drag 
scrollup  scrolldown  Finally  the key actions
also follow the multinomial distribution  We found that
giving the agent unrestricted access to the keyboard is impractical  as the agent may press key combinations such

  The interface runs VNC connected to   WoB docker con 

tainer running   browser 

 We also experimented with   Gaussian distribution but found

it inadequate due to its unimodal shape 

imageDOM  InputCNN  State Featuresfeature  Action Representation  Action mousemouse buttonskeyboardquerysampleFCsampleFCsamplesampleLocalCNNGlobalCNNWorld of Bits  An OpenDomain Platform for WebBased Agents

as  CTRL    which closes the window  Therefore  in
addition to keys we create atomic actions out of common and safe key combinations  such as  CTRL     copy 
 CTRL     paste  and  CTRL     select all 
Architecture  Our model  see Figure    rst processes
the image using   Convolutional Neural Network  CNN 
For DOM  we compute   text feature map based on the
matching between query and DOM  Then the two maps
are concatenated into   join representation  On top of this
we develop two variants   rst we  atten the features and
feed them directly through   fullyconnected layer  GlobalCNN  Since we had the intuition that local features alone
should suf ce to characterize the action  we also examine
  LocalCNN architecture to capture the intuition that agent
should attend to where cursor is  So the mouse distribution
is used as soft attention  Bahdanau et al    to average the CNN features into   global representation to predict
mouse buttons and keyboard events 

  Optimization

We train models on web tasks by sequencing behavior
cloning and reinforcement learning 
Behavior cloning  Since our web tasks can have very long
time horizons and sparse rewards    naive application of reinforcement learning will likely fail  Therefore  we pretrain
our networks by optimizing   supervised learning objective
 Pomerleau    on demonstrations  which were used to
de ne the reward in the  rst place  Since   typical recording might have thousands of frames  we  lter out frames
where there was no action to obtain   dataset of stateaction
tuples 
Reinforcement learning  Policies trained with supervised
learning suffer from compounding errors  so we  ne tune
the policies by optimizing the expected reward using  
policy gradient method  Sutton et al   
In particular  we use the Asynchronous Advantageous ActorCritic
       Mnih et al    and estimate the advantage using
the Generalized Advantage Estimation  Schulman et al 
    with the standard settings            

  Experiments
Our goal in this section is to establish baselines that current
techniques provide on web environments  and highlight the
challenges for future work in this area 

  Results on Synthetic Web Tasks  MiniWoB 
Demonstration data  We collected   minutes of human
demonstrations on each of the   MiniWoB environments
 about   hours total  Unlike the FormWoB and QAWoB
settings  the MiniWoB dataset contains interactions that re 

quire dragging and hovering       to trigger   menu expansion  Therefore  we process the demonstrations at regular   millisecond intervals   frames per second  to extract approximately   stateaction pairs  With gridpoints spaced   pixels across the   pixel area  we obtain
        grid and   possible actions  move  drag  click 
leading to   total of               possible actions 
Model  In these experiments we use    layer feedforward
network that takes the           image  and applies  
convolutional layers with        lters of stride   and sizes
          We then average pool the representation and pass it through one fullyconnected layer of  
units and another to compute the logits for the mouse and
key actions  Surprisingly  we found that feeding in the previously taken actions hurts performance because the agent
learns to use continuous paths similar to humans and develops   tendency to meander  which negatively impacts
exploration in many environments 
Evaluation  For the purposes of evaluation    robust statistic to use is the success rate  SR  for each environment 
The MiniWoB tasks are designed so that rewards in the interval     indicate partial credit towards the task  while
negative rewards indicate   failure  Given   list of re 

wards    we thus compute the success rate as cid      
 cid      cid    We can immediately evaluate two meth 

ods on all environments    the random baseline  and  
humans  refer to Figure  
Supervised Learning  We obtain   behavior cloning policy by training on the demonstrations using Adam  Kingma
  Ba    with   learning rate of   and batch size
of   We achieved better results by weighing click and
keyboard event losses  which are rare compared to move
events    times higher in the objective  We then run the
 xed policy on each environment for   steps  about
  hours at  FPS  and evaluate the success rate  see Figure
  yellow bars 
Reinforcement Learning  We run   environments in parallel at   FPS for up to   million steps and perform an
update every   time steps       training batches have size
          steps  with Adam and   learning rate of
  To mitigate the effects of our asynchronous setting 
we train   times and use the best one  The results are shown
in Figure    green bars 
Interpretation  We summarize the quantitative results
across all environments in Table   We refer to an environment as  Solved  if its success rate is at least half  
that of   human  From these numbers  it is evident that
supervised learning slightly improves the policy   to
  but   much larger improvement can be obtained by
 netuning the policy with reinforcement learning  
to   We also see that most of our performance comes

World of Bits  An OpenDomain Platform for WebBased Agents

Figure   The success rate on all MiniWoB environments  normalized by human performance   The performance on the cropped ChaseCircle is   The tasks are arranged in an approximate subjective level of dif culty from easy  left  to hard  right 

Success Rate  SR 
  Solved
SR  Click
SR  Drag
SR  Mouse Keyboard
SR  Compound

 
 
 
 
 
 

Random SL SL RL  envs
 
 
 
 
 
 

 
 
 
 
 
 

 
 
 
 
 
 

Table   Summary of MiniWoB humannormalized success rate
across all environments  and across   environment categories
based on the required interactions   envs denotes the number of
environments in each category  SL is supervised learning and RL
is reinforcement learning 

from environments that require mouse interaction  Click  
Drag  We also see   sharp drop in tasks that require keyboard input   SR  Finally   Compound  environments
are our most dif cult environments         synthetic email 
 ight booking  search engine  calendar  text editor  etc 
They combine multiple interactions over longer sequences
      search for an email and reply with some text  and
clearly pose   signi cant challenge   SR  Note that
Random policy can do well in some environments because
the action frequency is high   FPS  and our rewards for
correct actions are scaled linearly based on time 

  Results on Live Web Tasks  FormWoB 
Environment setup  Next  we evaluate our model on
the four FormWoB tasks  The resolution of these environments is           The FormWoB dataset contains four  ight booking website  United  united com 
Alaska  alaskaair com  JetBlue  jetblue com  and American  aa com  We run the environments at   frame per
second to accommodate the load time of webpages 
Demonstration Data  For each website  we collected  
 query  demonstration  pairs using AMT  Unlike MiniWoB 
most of the interactions here involve clicking and typing  After preprocessing  each episode consists of approxi 

mately   keyboard or mouse events  Similar to MiniWoB  we divide the screen into   grid points  and use
the key encoding scheme introduced in Section  
Model  Our model is the same  layer architecture in
MiniWoB  except we remove the dragging actions  We
also evaluate the LocalCNN model that directly outputs  
          dense feature map  which is used to drive attention and mouse clicks We use   simple heuristic to combine the DOM together with the query to compute   queryspeci   feature map  which indicates salient locations in
the input  In particular  we intersect the words in the query
and the DOM using   similarity score based on edit distance  and  put  that score into the middle of the bounding
box that contains that DOM element  For instance  if  
query contains the word  From  then any element in the
webpage that contains the word  From  would have higher
activation in the feature map 
We found that treating the keyboard simply as another
categorical distribution was very challenging because the
model would have to learn to type out entire phrases such
as  San Francisco  one character at   time  Therefore  we
augment the state with   pointer into each slot in the query
and de ne actions for typing the next character of some
slot  As an example  consider the following query with
four slots 

In this example  we would have   multinomial distribution
over the   slots  If the agent outputs the action sequence
               it will  rst type              the pre 
   of  San Francisco  reset the pointer for the  rst slot 
and then type        
Supervised Learning  We use similar supervised learning

Departure CityDestination CityDeparture MonthS                                 ok   Departure DayN                     World of Bits  An OpenDomain Platform for WebBased Agents

Figure   Learning curves and rewards on FormWoB task Book    ight from  origin  to  destination  leaving  departure date  and
returning  return date  on united com  GlobalCNN outperforms LocalCNN across the board 

Figure   Rewards for the   FormWoB tasks and   QAWoB tasks  Random achieves   human is  

setting as in MiniWoB  except the learning rate is   and
the keyboard event losses are weighted   times higher 
Reinforcement Learning  We  netune the models using RL on each of the environments separately  For every
episode  we sample randomly from the set of queries and
run the model at   FPS 
Evaluation  We are interested in measuring the model  
generalization ability across queries  We split the tasks on
each website into   for training  and   for testing 
First  we report the test likelihood as   metric to show how
well the agent models human trajectories  We then evaluate
the rewards the agent is able to achieve on both training and
test sets  We report the average rewards over the  nal three
checkpoints 
Results on FormWoB  Figure   shows the learning curves
on the United website  The performance of random agents
is identically zero on these tasks  Our model shows some
learning and generalization  In particular  for  ight booking  the model achieves   of human level performance on training queries  and   on test queries  Figure   summarizes the model   performance on   web tasks
in our experiment 
We visualize the model   attention output at some key
frames in Figure   As we can see  the model generalizes
by correctly selecting the city in dropdown and picking the
correct date  aided by text matching  The CNN identi es

the  Submit  button even after some random scrolling has
occurred  The most common failure mode is if the agent
falls off the demonstrators  state distributions      
triggering an error message  it is dif cult to take actions to
recover 

  Results on Crowdsourced Web Tasks  QAWoB 

Using same setup as in FormWoB  we perform experiments
on the following websites from the QAWoB dataset  Xe
 xe com  Allrecipes  allrecipes com  Scrabbleword nder
 scrabbleword nder org  and Mapquest  mapquest org 
The results of SL and SL RL of both LocalCNN and
GlobalCNN models on QAWoB are reported in Figure  
We  nd the performance of LocalCNN to be inadequate
on these web tasks  while GlobalCNN performs much better  This is consistent with GlobalCNN achieving   lower
training loss     compared to LocalCNN     It
is likely that the inductive bias introduced in LocalCNN
makes it incapable of  tting noisy human demonstrations 
Figure     shows some example failure cases 

  Related Work
Reinforcement learning environments  Our work enjoys the company of many recent projects that aim to provide challenging environments for reinforcement learning
agents  including the ATARI Learning Environment  Belle 

RewardPerformance on Real Web Tasks LocalCNN  SL   RL  on TrainLocalCNN  SL  on TrainLocalCNN  SL   RL  on TestLocalCNN  SL  on TestGlobalCNN  SL   RL  on TrainGlobalCNN  SL  on TrainGlobalCNN  SL   RL  on TestGlobalCNN  SL  on TestUnitedAlaskaAAJetblueAllrecipesXeScrabblewordfinderMapquest Highcharts comWorld of Bits  An OpenDomain Platform for WebBased Agents

Figure   Visualization of agent   distribution over mouse locations on   test task from FormWoB  united com 

 

the  rst to tackle the problem of interacting with websites
using both vision and raw mouse and keyboard actions on
opendomain tasks at scale 
Natural language to actions  There is   large body of
work on connecting language to actions  Closely related
to our work is Branavan et al    who used reinforcement learning to map instructions         Windows troubleshooting article  to actions over   user interface in  
virtual machine  however  they used preprocessed actions 
Other work operates in the context of navigation  Vogel  
Jurafsky    Tellex et al    Artzi   Zettlemoyer 
  and building tasks  Long et al    Wang et al 
  The focus of these efforts is on modeling natural
language semantics  Our work provides   bridge between
this semanticoriented work and the more controloriented
tasks found in most reinforcement learning environments 

  Conclusion
In this paper  we introduced World of Bits  WoB    platform that allows agents to complete web tasks with keyboard and mouse actions  Unlike most existing reinforcement learning platforms  WoB offers the opportunity to
tackle realistic tasks at scale  We described   progression
of three techniques to create web tasks suitable for reinforcement learning    Minimalistic tasks such as MiniWoB  handcrafted tasks    Proxy environments such
as FormWoB  live websites  handcrafted tasks  and  
Crowdsourced environments such as QAWoB  live websites  crowdsourced tasks  Finally  we showed that while
standard supervised and reinforcement learning techniques
can be applied to achieve adequate results across these environments  the gap between agents and humans remains
large  and welcomes additional modeling advances 

Acknowledgements
This work was done in collaboration between OpenAI and
Stanford  Tim Shi is partly funded by Tencent  We would
like to thank John Schulman for insightful discussions 

   

   

   

Figure   Common error cases      Deviating from the human
demonstration state distribution 
    HTTP request not in our
cache      Picking the wrong answer to the query 

mare et al    MuJoCo  Todorov et al    CommAI  Baroni et al    Project Malmo  Johansson et al 
  SNES  Bhonker et al    TorchCraft  Synnaeve
et al    DeepMind Lab  Beattie et al    and ViZDoom  Kempka et al    World of Bits differs primarily by its focus on the opendomain realism of the web 
Performing tasks on the web  The web is   rich environment with   long tail of different phenomena and the
emergence of highlevel semantics  The information retrieval and natural language processing communities have
long used the web as   source of textual data  Hearst   
Brill et al    Etzioni et al    Nogueira   Cho
  introduced WebNav    software tool that transforms
  website into   synthetic goaldriven web navigation task 
Some work has also focused on mapping natural language
queries to programs that operate on the DOM structure of
web pages  Pasupat   Liang    These previous works
focus on higherlevel actions that abstract away the visual
layout and the keyboard and mouse movements  which limits their scope  especially given the increasing prevalence of
highly interactive websites  To our knowledge  our work is

World of Bits  An OpenDomain Platform for WebBased Agents

References
Artzi     and Zettlemoyer     Weakly supervised learning
of semantic parsers for mapping instructions to actions 
Transactions of the Association for Computational Linguistics  TACL     

experimental study  Arti cial Intelligence   
   

Hearst        Automatic acquisition of hyponyms from
large text corpora  In Interational Conference on Computational linguistics  pp     

Bahdanau     Cho     and Bengio     Neural machine
translation by jointly learning to align and translate 
arXiv preprint arXiv   

Johansson     Shalit     and Sontag     Learning representations for counterfactual inference  In International
Conference on Machine Learning  ICML   

Baroni  Marco  Joulin  Armand  Jabri  Allan  Kruszewski 
Germ an  Lazaridou  Angeliki  Simonic  Klemen  and
Commai  Evaluating the  rst
Mikolov  Tomas 
arXiv preprint
steps towards   useful general ai 
arXiv   

Beattie  Charles  Leibo  Joel    Teplyashin  Denis  Ward 
Tom  Wainwright  Marcus    uttler  Heinrich  Lefrancq 
Andrew  Green  Simon  Vald es    ctor  Sadik  Amir 
et al  Deepmind lab  arXiv preprint arXiv 
 

Bellemare  Marc    Naddaf  Yavar  Veness  Joel  and
Bowling  Michael  The arcade learning environment 
An evaluation platform for general agents     Artif  Intell  Res JAIR     

Bhonker  Nadav  Rozenberg  Shai  and Hubara  Itay  Playing snes in the retro learning environment  arXiv preprint
arXiv   

Branavan  Satchuthananthavale RK  Chen  Harr  Zettlemoyer  Luke    and Barzilay  Regina  Reinforcement
learning for mapping instructions to actions  In Proceedings of the Joint Conference of the  th Annual Meeting
of the ACL and the  th International Joint Conference
on Natural Language Processing of the AFNLP  Volume
 Volume   pp    Association for Computational
Linguistics   

Brill     Dumais     and Banko     An analysis of the
AskMSR questionanswering system  In Association for
Computational Linguistics  ACL  pp     

Brockman  Greg  Cheung  Vicki  Pettersson  Ludwig 
Schneider  Jonas  Schulman  John  Tang  Jie  and
arXiv preprint
Zaremba  Wojciech  Openai gym 
arXiv   

Deng     Dong     Socher     Li     Li     and FeiFei 
   ImageNet    largescale hierarchical image database 
In Computer Vision and Pattern Recognition  CVPR 
pp     

Etzioni     Cafarella     Downey     Popescu    
Shaked     Soderland     Weld        and Yates    
Unsupervised namedentity extraction from the web  An

Kempka  Micha  Wydmuch  Marek  Runc  Grzegorz 
Toczek  Jakub  and Ja skowski  Wojciech  Vizdoom   
doombased ai research platform for visual reinforcement learning  arXiv preprint arXiv   

Kingma  Diederik and Ba 

Jimmy 
method for stochastic optimization 
arXiv   

Adam 

 
arXiv preprint

Levine  Sergey  Pastor  Peter  Krizhevsky  Alex  and
Quillen  Deirdre  Learning handeye coordination for
robotic grasping with deep learning and largescale data
collection  arXiv preprint arXiv   

Long     Pasupat     and Liang     Simpler contextIn As 

dependent logical forms via model projections 
sociation for Computational Linguistics  ACL   

Mikolov  Tomas  Joulin  Armand  and Baroni  Marco   
roadmap towards machine intelligence  arXiv preprint
arXiv   

Mnih     Kavukcuoglu     Silver     Rusu        Veness     Bellemare        Graves     Riedmiller    
Fidjeland        Ostrovski     et al  Humanlevel control through deep reinforcement learning  Nature   
   

Mnih  Volodymyr  Badia  Adria Puigdomenech  Mirza 
Mehdi  Graves  Alex  Lillicrap  Timothy    Harley  Tim 
Silver  David  and Kavukcuoglu  Koray  Asynchronous
In Internamethods for deep reinforcement learning 
tional Conference on Machine Learning   

Nogueira  Rodrigo and Cho  Kyunghyun  Endto end goaldriven web navigation  In Advances in Neural Information Processing Systems  pp     

Pasupat     and Liang     Zeroshot entity extraction from
web pages  In Association for Computational Linguistics
 ACL   

Pinto  Lerrel and Gupta  Abhinav 

Supersizing selfsupervision  Learning to grasp from    tries and  
In Robotics and Automation  ICRA 
robot hours 
  IEEE International Conference on  pp   
IEEE   

World of Bits  An OpenDomain Platform for WebBased Agents

Pomerleau  Dean    Alvinn  an autonomous land vehicle
in   neural network  Technical report  Carnegie Mellon
University  Computer Science Department   

Rajpurkar     Zhang     Lopyrev     and Liang     Squad 
  questions for machine comprehension of text 
In Empirical Methods in Natural Language Processing
 EMNLP   

Schulman  John  Levine  Sergey  Abbeel  Pieter  Jordan 
Michael    and Moritz  Philipp  Trust region policy optimization  In ICML  pp       

Schulman  John  Moritz  Philipp  Levine  Sergey  Jordan 
Michael  and Abbeel  Pieter  Highdimensional continuous control using generalized advantage estimation 
arXiv preprint arXiv     

Silver  David  Huang  Aja  Maddison  Chris    Guez 
Arthur  Sifre  Laurent  Van Den Driessche  George 
Schrittwieser  Julian  Antonoglou  Ioannis  Panneershelvam  Veda  Lanctot  Marc  et al  Mastering the game of
go with deep neural networks and tree search  Nature 
   

Sutton     McAllester     Singh     and Mansour    
Policy gradient methods for reinforcement learning with
function approximation  In Advances in Neural Information Processing Systems  NIPS   

Synnaeve  Gabriel  Nardelli  Nantas  Auvolat  Alex  Chintala  Soumith  Lacroix  Timoth ee  Lin  Zeming  Richoux  Florian  and Usunier  Nicolas  Torchcraft    library for machine learning research on realtime strategy
games  arXiv preprint arXiv   

Tellex     Kollar     Dickerson     Walter        Banerjee        Teller        and Roy     Understanding natural language commands for robotic navigation and mobile manipulation  In Association for the Advancement
of Arti cial Intelligence  AAAI   

Todorov  Emanuel  Erez  Tom  and Tassa  Yuval  Mujoco 
In IntelliA physics engine for modelbased control 
gent Robots and Systems  IROS    IEEE RSJ International Conference on  pp    IEEE   

Vogel     and Jurafsky     Learning to follow navigational
directions  In Association for Computational Linguistics
 ACL  pp     

Wang        Liang     and Manning     Learning language
games through interaction  In Association for Computational Linguistics  ACL   

