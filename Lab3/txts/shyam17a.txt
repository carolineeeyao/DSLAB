Attentive Recurrent Comparators

Pranav Shyam     Shubham Gupta   Ambedkar Dukkipati  

Abstract

Rapid learning requires  exible representations
to quickly adopt to new evidence  We develop  
novel class of models called Attentive Recurrent
Comparators  ARCs  that form representations
of objects by cycling through them and making
observations  Using the representations extracted
by ARCs  we develop   way of approximating  
dynamic representation space and use it for oneshot learning 
In the task of oneshot classi 
cation on the Omniglot dataset  we achieve the
state of the art performance with an error rate of
  This represents the  rst superhuman result achieved for this task with   generic model
that uses only pixel information 

  Introduction
Utilizing the success and the potential of Deep Neural Networks to solve hard Arti cial Intelligence tasks requires
neural models that are capable of performing rapid learning
 Lake et al    For models to embody such rich learning capabilities  we believe that   crucial characteristic will
be the employment of dynamic representations   representations that are formed by observing   growing and continually evolving set of features  We call the space that is
formed by such evolving representations the dynamic representation space 
In this paper  we present   novel model for oneshot learning that utilizes   crude approximation of such   dynamic
representation space  This is done by constructing the representation space lazily and relative to   particular  test 
sample every time  For the purpose of producing such relative representations  we develop   novel class of models
called Attentive Recurrent Comparators  ARCs 

 Department of Computer Science

and Engineering 
Rashtreeya Vidyalaya College of Engineering  Bengaluru  India
 Department of Computer Science and Automation  Indian Institute of Science  Bengaluru  India  Correspondence to  Pranav
Shyam  pranavshyam gmail com 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

We  rst test ARCs across many tasks that require assessment of visual similarity  We  nd that ARCs that do not use
any convolutions show comparable performance to Deep
Convolutional Neural Networks on challenging datasets
like CASIA WebFace and Omniglot  Though dense ARCs
are as capable as ConvNets    combination of both ARCs
and convolutions  ConvARCs  produces much more superior models  In the task of estimating the similarity of
two characters from the Omniglot dataset  ARCs and Deep
ConvNets both achieve about   accuracy  whereas
ConvARCs achieve   accuracy  In the task of face
veri cation on the CASIA Webface dataset  ConvARCs
achieved   accuracy surpassing the   accuracy
achieved by   CNN baseline considered 
We then use ARCs as   means for developing   lazy  relative representation space and use it for oneshot learning 
On the challenging Omniglot oneshot classi cation task 
our model achieved an accuracy of   signi cantly
surpassing the current stateof theart set by all other methods  This is also the  rst superhuman result achieved for
this task with   generic model that uses only pixel information 

  Comparing Objects

ARCs are inspired by our interpretation of how humans
generally compare   set of objects  When   person is asked
to compare two objects and estimate their similarity  the
person does so by repeatedly looking back and forth between the two objects  With each glimpse of the object   
speci   observation is made  These observations which are
made in both objects are then cumulatively used to come to
  conclusion about their similarity    crucial characteristic
of this process is that new observations are made conditioned on the previous context that has been investigated
so far by the observer  The observation and it   contextual
location are all based on intermediate deductions   deductions that are themselves based on the observations made
so far in the two objects    series of such guided observations and their entailing inferences are accumulated to form
   nal the judgement on their similarity  We will refer to
how humans compare objects as the human way 
In stark contrast to this  current similarity estimating systems in Deep Learning are analogues of the Siamese sim 

Attentive Recurrent Comparators

ilarity learning system  Bromley et al    In this system     xed set of features is detected in both the objects 
The two objects are compared based on mutual agreement
of the detected features  More concretely  comparison between two objects in this system consists of measuring the
distance between their vector embeddings or representations    neural network that is speci cally trained to detect
the most salient features in an object for   task de nes the
object to embedding mapping  Detection of features in one
object is independent of the features present in the other
object 
There is   major underlying difference between the human approach discussed above and the siamese approach
to the problem  In the human way  the information from
the two objects is fused from the very beginning and this
combined information primes the subsequent steps in comparison  There are multiple lookups on each of the objects
and each of these lookups are conditioned on the observations of both the objects so far  In the siamese way  when
the embeddings are compared the information fuses mostly
at an abstract level and only in the last stage 
Inspired by the human way  we develop an endto end differentiable model that can learn to compare objects called
Attentive Recurrent Comparators  ARCs 
Fundamentally  the excellent performance of ARCs shows
the value of  early fusion  of information across the context and the value of dynamic representations  Further  it
also gives merit to the view that attention and recurrence
together can be as good as convolutions in   few special
cases 
Finally  the superior similarity learning capability of ARCs
can be of independent interest as an alternative to siamese
neural networks for tasks such as face recognition and
voice veri cation 

  Attentive Recurrent Comparators
Our ARC model is essentially an algorithmic imitation of
the human way discussed in Section   and built with
Deep Neural Networks  Using attention and recurrence 
an ARC makes an observation in one object conditioned
on the observations made so far in both objects  The exposition of an ARC model that can compare two images and
judge their similarity is given below  But it can be trivially
generalised to more images or other modalities 
The model consists of   recurrent neural network controller
and an attention mechanism that takes in   specially constructed presentation sequence as the input  Given two images  xa  xb  we alternate between the two images for  
 nite number of presentations of each image to form the
presentation sequence xa  xb  xa  xb    xa  xb  The model

Figure   The abstract graph of an ARC comparing two images 
The controller which is an RNN primes the whole process  The
two images are alternatively and repeatedly attended to  At each
timestep the glimpse taken from the image is based on the attention parameters    which is calculated using the previous state of
RNN ht  by projecting it with Wg  The glimpse obtained Gt
and the previous state ht  together used to update the state of
controller to ht 

repeatedly cycles through both the images  attending to one
image at one timestep 
For timestep   the image presented is given by 

It   xa if       is   else xb

The attention mechanism focuses on   speci   region of
the image current image It to get the glimpse Gt 

Gt   attend It     

where      Wght 

attend  is the attention mechanism that acts on image It
 described in the Section      are the attention glimpse
parameters which specify the location and size of the attention window  At each step  we use the previous hidden
state of the RNN controller ht  to compute     Wg is the
projection matrix that maps the hidden state to the required
number of attention parameters 
Next  both the glimpse and previous hidden state are utilized to form the next hidden state 

ht   RN    Gt  ht 

RN     is the update function for the recurrent controller
being used  This state update function could either be simple RNN or an LSTM 

Attentive Recurrent Comparators

Over the course of many time steps  model observes many
aspects of both the images  The observations are made by
the model at each time step by directing its attention to  
region of interest in each input  Since the controller of the
model is   Recurrent Neural Network  this round robin like
cyclic presentation of images allows for early fusion of information from both images  This makes the model aware
of the context in which it is operating under  Consequently 
this provides feedback to the attention mechanism to attend
on the relevant and crucial parts of each image considering
the observations made so far in both the images 
If we make   glimpses  or observations  of each image  the
hidden state of the RNN controller at the  nal timestep
hT       can then be used as the relative representation
of xa with respect to xb or vice versa  Note that It for
some   alternates between xa and xb  while the rest of the
equations are exactly the same for all time steps 
We arrived at the iterative attention paradigm after trying
out many approaches to attend to multiple images at once
on   few toy datasets  Other approaches for early fusion
like attending to both images in the same timestep or having   controllers with shared weights failed or had poor
empirical performance  Iteratively attending to the inputs
is more computationally ef cient  scalable and more consistent statistically than the other approaches 

  Attention Mechanism

The attention mechanism we used is incrementally derived from zoomable and differentiable image observation
mechanism of DRAW Gregor et al    The attention
window is de ned by an         grid of Cauchy kernels 
We found that the heavy tail of the Cauchy curve alleviates
some of the vanishing gradient issues and it also increases
the speed of training 
The grid   location and size is de ned based on the glimpse
parameters  The       grid of kernels is placed at       
on the       image  with the central Cauchy kernel being
located at        The elemental square in the grid has  
side of length   The glimpse parameter set    is unpacked

to get       cid   cid   cid       and   are computed from cid   cid  
and cid  using the following transforms 

            cid   
       cid 

     

 

            cid   
      cid 

 

The location of   ith row  jth column   Cauchy kernel in
terms of the pixel coordinates of the image is given by 
                    
                    
  
  
The horizontal and vertical  lterbank matrices are then cal 

culated as 

FX           
ZX

FY           
ZY

 cid 
 cid 

 

 cid 
 cid 

   

 

   

 cid     
 cid     

 

 

 

 

 cid cid cid 
 cid cid cid 

ZX and ZY are normalization constants such that they
make  aFX            and  bFX           
Final result of attention on an image is given by 

attend It        FY ItF  
 

attend thus gets an       patch of the image  which is
 attened and used in the model 

  Use of Convolutions

As seen in the experimental sections that follow  use of convolutional feature extractors gave   signi cant boost in performance  Given an image  the application of several layers of convolution produces      solid of activations  or  
stack of    feature maps  Attention over this corresponds
to applying the same    attention  described in Section  
above  over the entire depth of the    feature map  The attended subsolid is then  attened and used as the glimpse 

  Dynamic Representations and Oneshot

Classi cation

Oneshot learning requires learning models to be at the
apotheosis of data ef ciency  In the case of oneshot classi cation  only   single example of each individual class is
given and the model is expected to generalise to new samples of the same class 

  Dynamic Representations

Deep Neural Networks learn useful representations of objects from data  Representation of   sample is computed by
identifying    xed set of features in it  and these features
are learnt from scratch and are purely based on data provided during training  In the end    trained neural network
can be interpreted as being composed of two components  
  function that maps the input sample to   point in representation space and   classi er that learns   decision boundary
in this representation space 
Rapid learning expects that this representation space to be
dynamic   representations should change with newly found
data  All features that form   good representation aren  
known during initial learning and entirely new concepts
with neverbefore seen features should be expected  Ideally  the entire representation space should change when
the new concept is introduced  This would enable the assimilation of new concepts in conjunction with the old con 

Attentive Recurrent Comparators

cepts  One way of training such systems is to have   metalearning system where the model is trained to represent entities in space  rather than being trained to represent an entity 
 Schaul   Schmidhuber    Deep Learning research in this direction recently  Santoro et al    has
explored developing complex models that are trained in an
endto end manner  But empirically  we found that such
topdown hierarchical models are dif cult to train  suffer
from reduced supervision and require specially constructed
datasets 
However  there is another alternative strategy that could be
employed as crude approximation of this ideal scenario 
This involves lazily developing   representation space that
is conditioned on the test sample only at inference time 
Until then  all samples presented to the model are just
stored asis in   repository  When the test sample is given 
we compare this sample with every other sample in our
repository using ARCs to form   relative representation
of each sample  the representation being the  nal hidden
state of the recurrent controller  In this relative representation space  which is relative to   test sample  we use  
trained classi er that can identify the most similar sample pair  given the entire context of relative representation
space  This relative representation space is dynamic as it
changes relative to the test sample 

  Oneshot Learning Models

The standard oneshot classi cation setup consists of   support set and   test sample  In an oneshot learning episode 
the support set containing   single example of each class is
 rst provided to the model  Next    test sample is given and
the model is expected to make its classi cation prediction 
Finally  the classi cation accuracy is calculated based on
all the predictions  We developed the following two models with ARCs for this task 

  NAIVE ARC MODEL

This is   trivial extension of ARCs for used for the veri cation task    test sample is compared against all the images
in the support set  It is matched to the sample with maximum similarity and the corresponding class is the prediction of the model  Here  we are reducing the relative representations to similarity scores directly  The entire context
of the relative representation space is not incorporated 

  FULL CONTEXT ARC

This model incorporates the full knowledge of the relative
representation space generated before making   prediction 
While Naive ARC model is simple and ef cient  it does not
incorporate the whole context in which our model is expected to make the decision of similarity  When the test
sample is being compared with all support samples  the

comparisons are all independently done 
It is highly desirable to have    way ARC  where each
observation is conditioned on the all images in the background set  Unfortunately  such   model is not practical 
This would require maintaining   lot of context in the controller state  But  scaling up the controller memory incurs  
huge  quadratic  parameter burden  So instead  we use   hierarchical setup  which decomposes the comparisons to be
at two levels    rst local pairwise comparison and   second
global comparison  We found that this model reduces the
information that has to be crammed in the controller state 
while still providing suf cient context 
As with the Naive method  we compare test sample from
evaluation set with each image from support set in pairs 
But instead of emitting   similarity score immediately  we
process the relative representations of each comparison 
Relative representations are the  nal hidden state of the
controller when the test image   is being compared to imT Sj   These emage Sj from the support set  ej   hL
beddings are further processed by   BiDirectional LSTM
layer  This merges the information from all comparisons 
thus providing the necessary context before prediction  The
approach taken here is very similar to Matching Networks
 Vinyals et al    but it is slightly more intuitive and
provides superior results 

 
LST    ej 

 
LST    ej   

cj    

        

Each embedding is mapped to   single score sj      cj 
where     is an af ne transform followed by   nonlinearity  The  nal output is the normalized similarity with
respect to all similarity scores 

pj   sof tmax sj 

        

This whole process is to make sure that we adhere to the
fundamental principle of Deep Learning  which is to optimise objectives that directly re ect the task  The softmax
normalisation allows for the expression of relative similarity rather than absolute similarity 

  Experiments
In this section  we  rst detail the analysis done to better
understand the empirical functioning of ARCs  both qualitatively and quantitatively  We then benchmark ARCs
on standard similarity learning tasks on two datasets and
present the results 

  Model Analysis

For the analysis presented below  we use the simple ARC
model described in Section   trained for the veri cation  or
similarity learning  task on the Omniglot dataset  The ver 

Attentive Recurrent Comparators

    It can be seen that the two characters look very similar in
their stroke pattern and differ only in their looping structure 
ARC has learnt to focus on these crucial aspects 

    ARC parses over the characters in   left to right  top to bottom fashion  Finally  it ends up focussing in the region where
the  rst character has   prolonged downward stroke  whereas
the second one does not 

Figure   Attention windows over time when comparing the two
Omniglot characters  The top row has the  rst image and the bottom row has the second  Each column represents   glimpse step 
    Comparing two dissimilar characters and     Comparing two
similar characters 

  cation task is   binary classi cation problem wherein the
model is trained to predict whether the   drawings provided
are of the same character or not 
The  nal hidden state of the RNN controller hT is used to
output at   single logistic neuron that estimates the probabilty of similarity  The particular model under consideration has an LSTM controller  Hochreiter   Schmidhuber 
  with forget gates  Gers et al    The number
of glimpses per image was  xed to   thus making the total
number of recurrent steps         greyscale images
of characters were used and the attention glimpse resolution of     was used  Similar dissimilar pairs of character
drawings were randomly chosen from within the same language to make the task more challenging 

  QUALITATIVE ANALYSIS

ARCs tend to adopt   left to right parsing strategy for most
pairs  during which the attention window gradually reduces
in size  As seen in Figures     and     the observations
made by ARC in one image are de nitely being conditioned on the observations in the other image  We also frequently encountered cases wherein the attention window 
would end up focusing on   blank region 

  QUANTITATIVE ANALYSIS

We performed simple yet insightful ablation studies to understand ARC   dynamics  The ARC accumulates information about both the input images by   series of attentive
observations  To see how the information content varied
with observations  we trained   separate binary classi ers
to classify images as being similar or not based on hidden
states of the LSTM controller at every even timestep  The
performance of these classi ers is summarized in Table  
Since the ARC has an attention window of only   pixels 
it can barely see anything in the  rst time step  where its attention is spread throughout the whole image  With more
glimpses   ner observations bring in more precise information and the recurrent transitions make use of this knowledge  leading to higher accuracies  We also used the   binary classi ers to study how models con dence grows with
more glimpses and such examples are provided in Figure  

Table   Glimpses per image versus classi cation accuracy of
ARC  Out of the   alphabets provided in the Omniglot dataset 
  were used for training and validation and the last   for testing

GLIMPSES ACCURACY  TEST SET 

 
 
 
 
 

 
 
 
 
 

  OMNIGLOT DATASET

  Similarity Learning

Omniglot is   dataset by  Lake et al    that is specially
designed to compare and contrast the learning abilities of
humans and machines  The dataset contains handwritten
characters of   languages  alphabets  with   total characters  The dataset is divided into   background set and an
evaluation set  Background set contains   alphabets  
characters  and only this set should be used to perform all
learning       hyperparameter inference or feature learning  The remaining   alphabets are for pure evaluation
purposes only  Each character is       greyscale image  There are only   samples for each character  each
drawn by   distinct individual 

In this section we compare ARCs with other Deep Learning
methods in the task of similarity learning on two datasets 
Omniglot and CASIA WebFace Dataset  We consider
strong convolutional baselines  which have been shown
time and again to excel at such visual tasks  Particularly 
we use Wide Resnets  WRNs   Zagoruyko   Komodakis 
  which are the current state of the art models in image
classi cation  Wide ResNets used contain   blocks of convolutional feature extractors  ConvARC models also used
Wide Resnets for feature extraction but with one less block
of convolutions  We used moderate data augmentation consisting of translation   ipping  rotation and shearing  which

Attentive Recurrent Comparators

    ARC is very unsure of similarity at the beginning  But at  th
glimpse  th column  the attention goes over the region where
there are strokes in the  rst image and no strokes in the second
one resulting in dropping of the score 

    Initially ARC is unsure or thinks that the characters are similar  But towards the end  at  th glimpse  th column  the model
focusses on the region where the connecting strokes are different  The similarity score drops and with more  ponder  it falls
down signi cantly 

Figure   Attention windows over time and instantaneous predictions from independent binary classi ers  The  rst glimpse is
omitted as it covers the whole image 
In the graph  xaxis 
glimpse number  yaxis  similarity score  The red line is the decision threshold  above which the images are considered to be
similar  Both of the cases above are examples of   dissimilar pair 

we found to be critical for training ARC models  WRNs
also were trained with the same augmentation  Hyper parameters were set for reasonable values for all our ARC
models and no hyperparameter tuning of any kind was employed 

  OMNIGLOT

The same exact model used in the previous section was
used for this comparison as well  The data split up of
the Omniglot dataset used for this comparison is different
from the above    alphabets were used for training   
for validation and   for testing  this was in order to be
comparable to the ConvNets in  Koch et al The results
are aggregated in Table   Our simple ARC model without
using any convolutional layers obtains   performance that
matches   AlexNet style   layer Deep Convnet  Using convolutional feature extractors  ARCs outperform the Wide
ResNet based Siamese ConvNet baselines  even the ones
containing an order of magnitude more parameters 

  CASIA WEBFACE

CASIA Webface is the largest public repository of faces
consisting of   distinct images of over   thousand
people  We split the data as follows  Training set   
  people  validation set      people  and Test
set      people  The images were downscaled to
    pixels and an attention window of     pixels was
used  The rest of the architecture is same as the Omniglot

Table   Performance of ARC vs conventional methods on the
veri cation task on Omniglot dataset  Wide ResNets suf xes
specify the depth and width  Example         means that it
is   ResNet that   is layers deep with each residual block having
  width multiplier of   Out of the   alphabets provided in the
Omniglot dataset    were used for training    for validation and
the last   for testing

MODEL

ACCURACY  TEST SET 

DEEP SIAMESE NET  KOCH ET AL 

SIAMESE RESNET       
SIAMESE RESNET       
SIAMESE RESNET       

SIAMESE NETWORK

ARC

CONVARC

 
 
 
 
 
 
 

Table   Performance of ARC vs conventional methods on the
veri cation task on CASIA Webface dataset  Wide ResNets suf 
 xes notation is same as used in Table  

MODEL

ACCURACY  TEST SET 

SIAMESE RESNET       

ARC

CONVARC

 

 

 

model  Results are tabluated in Table  

  One Shot Classi cation
Oneshot classi cation on the Omniglot dataset is   very
challenging task as most Deep Learning systems do not
work well on this dataset 
 Lake et al    developed   dedicated system for such rapid knowledge acquisition called Bayesian Programming Learning  which surpasses human performance and is the current state of the
art method 
The details of the Omniglot dataset are given in Section
    Oneshot classi cation task on this dataset is setup
as follows  from   randomly chosen alphabet    characters are chosen which becomes the support set classes  One
character among these   becomes the test character   
drawers are chosen  one each for the support set drawings
and the test character drawing  The task is to match the test
drawing to the correct character   class in the support set 
Assigning an image to one of the   characters results in  
 way   shot classi cation task 

Attentive Recurrent Comparators

  Baselines and Other Methods

 Vinyals et al    and MANNs

We compare the two models discussed in Section   with
other methods in literature  starting from the simplest baseline of kNearest Neighbours to the latest metalearning
methods  The training and evaluation practices are nonconsistent and the two main threads of variation are detailed below 
Across Alphabets  Many papers recently  like Matching
Networks
 Santoro
et al    have used   chars for the background set
 instead of   speci ed by  Lake et al    The remaining   characters are used for testing  Most importantly  the characters sampled for both training and evaluation are across all the alphabets in the training set 
Within Alphabets  This corresponds to standard Omniglot
setting where characters are sampled within an alphabet
and only the   background characters are used for training
and validation 
The across alphabet task is much simpler as it is easy to distinguish characters belonging to different languages  compared to distinguishing characters belonging to the same
language 
There are large variations in the resolution of the images
used as well  The Deep Siamese Network of Koch et al 
uses     images and thus not directly comparable to
out model  but we include it as it is the current best result
using deep neural nets  The performance of MANNs in this
standard setup is interpreted from the graph in the paper
as the authors did not report it 
It should also be noted
that Bayesian Program Learning  BPL   Lake et al   
incorporates human stroke data into the model  Lake et al
estimate the human performance to be at  
Results are presented in Table   and   Our ARC models
outperform all previous methods according to both of the
testing protocols and establish the corresponding state of
the art results 

Table   Oneshot classi cation accuracies of various methods
and our ARC models on Omniglot dataset   Across Alphabets

MODEL

ACCURACY

KNN
CONV SIAMESE NETWORK
MANN
MATCHING NETWORKS
NAIVE ARC
NAIVE CONVARC
FULL CONTEXT CONVARC

 
 
   
 
 
 
 

Table   Oneshot classi cation accuracies of various methods
and our ARC models on Omniglot dataset   Within Alphabets

MODEL

ACCURACY

KNN
SIAMESE NETWORK
DEEP SIAMESE NETWORK  KOCH ET AL 
HUMANS
BPL
NAIVE ARC
NAIVE CONVARC
FULL CONTEXT CONVARC

 
 
 
 
 
 
 
 

  miniImageNet

Recently  Vinyals et al    introduced   oneshot learning benchmark based off of the popular ImageNet dataset 
It uses   testing protocol that is very similar to Omniglot 
The dataset consists of   colour images of size  
with   classes of   examples each  As with the original paper  we used   classes for training and tested on the
remaining   classes  We report results on  way oneshot
task in Table   which is   oneshot learning with   classes
at   time 

Table     way oneshot Classi cation accuracies of various methods and our ARC models   miniImageNet

MODEL

ACCURACY

RAW PIXELS    COSINE SIMILARITY
BASELINE CLASSIFIER
MATCHING NETWORKS
NAIVE CONVARC

 
 
 
 

  Related Work
Deep Neural Networks  Schmidhuber     LeCun et al 
  are very complex parametrised functions which can
be adapted to have the required behaviour by specifying  
suitable objective function  Our overall model is   simple
combination of the attention mechanism and recurrent neural networks  RNNs 
It is known that attention brings in selectivity in processing
information while reducing the processing load  Desimone
  Duncan    Attention and  Recurrent  Neural Networks were combined in Schmidhuber   Huber   to
learn fovea trajectories  Later attention was used in conjunction with RBMs to learn what and where to attend
in Larochelle   Hinton   and in Denil et al   

Attentive Recurrent Comparators

Hard Attention mechanism based on Reinforcement Learning was used in Mnih et al    and further extended to
multiple objects in Ba et al    both of these models
showed that the computation required at inference is signi cantly less compared to highly parallel Convolutional
Networks  while still achieving good performance    soft
or differentiable attention mechanisms have been used in
Graves     specialised form of location based soft
attention mechanism  well suited for    images was developed for the DRAW architecture  Gregor et al    and
this forms the basis of our attention mechanism in ARC 
  survey of the methods and importance of measuring similarity of samples in Machine Learning is presented in Bellet et al    With respect to Deep Learning methods 
the most popular architecture family is that of Siamese Networks  Bromley et al    The energy based derivation
of the same is presented in Chopra et al   
  bayesian framework for oneshot visual recognition was
presented in FeFei et al   
Lake et al   
extensively study oneshot Learning and present   novel
probabilistic framework called Bayesian Program Learning  BPL  for rapid learning  They have also released
the Omniglot dataset  which has become   testing ground
for oneshot learning techniques  Recently  many Deep
Learning methods have been developed to do oneshot
learning  Koch et al  use Deep Convolutional Siamese
Networks for performing oneshot classi cation  Matching Networks  Vinyals et al    and Memory Augmented Neural Networks  Santoro et al    are other
approaches to perform continual or meta learning in the low
data regime 

  Conclusion and Future Work
We presented   model that uses attention and recurrence to
cycle through   set of images repeatedly and estimate their
similarity  We showed that this model is not only viable
but is also much better than the popular siamese neural networks in wide use today in terms of performance and generalization  We showed the value of having dynamic representations and presented   novel way of approximating
it  Our main result is in the task of oneshot classi cation
on the Omniglot dataset  where we achieved state of the
art performance surpassing human performance using only
raw pixel data 
Though presented in the context of images  ARCs can be
used for any modality  There are innumerable ways to extend ARCs  Better attention mechanisms  higher resolution
images  careful hyperparameter tuning  more complicated
controllers etc   can be employed to achieve better performance  However  one potential downside of this model is
that due to sequential execution of the recurrent core and

by the very design of the model  it might be more computationally expensive than distance metric methods 
More interesting directions would involve developing more
complex architectures using this bottomup  lazy approach
to solve even more challenging AI tasks 

Acknowledgements
We would like to thank Akshay Mehrotra  Gaurav Pandey
and Siddharth Agrawal for their extensive support and
feedback while developing the ideas in this work  We
would like to thank Soumith Chintala for his feedback
on this manuscript and the idea and Ankur Handa for
helping us with the CASIA dataset  We would also like
to thank Sanyam Agarwal  Wolfgang Richter  Shreyas
Karanth and Aadesh Bagmar for their valuable feedback
on the manuscript  Finally  we would like to thank the
anonymous reviewers for helping us signi cantly improve
the quality of this paper 
Authors acknowledge  nancial support for the  CyberGut 
expedition project by the Robert Bosch Centre for Cyber
Physical Systems at the Indian Institute of Science  Bengaluru 

References
Ba  Jimmy  Mnih  Volodymyr  and Kavukcuoglu  Koray 
Multiple object recognition with visual attention  arXiv
preprint arXiv   

Bellet  Aur elien  Habrard  Amaury  and Sebban  Marc   
survey on metric learning for feature vectors and structured data  arXiv preprint arXiv   

Bromley  Jane  Bentz  James    Bottou    eon  Guyon 
Isabelle  LeCun  Yann  Moore  Cliff    ackinger  Eduard  and Shah  Roopak  Signature veri cation using  
siamese time delay neural network  International Journal of Pattern Recognition and Arti cial Intelligence   
   

Chopra  Sumit  Hadsell  Raia  and LeCun  Yann  Learning   similarity metric discriminatively  with application
In   IEEE Computer Society
to face veri cation 
Conference on Computer Vision and Pattern Recognition
 CVPR  volume   pp    IEEE   

Denil  Misha  Bazzani  Loris  Larochelle  Hugo  and
de Freitas  Nando  Learning where to attend with deep
architectures for image tracking  Neural computation 
   

Desimone  Robert and Duncan  John  Neural mechanisms
of selective visual attention  Annual review of neuroscience     

Attentive Recurrent Comparators

Schmidhuber  Juergen and Huber  Rudolf  Learning to generate arti cial fovea trajectories for target detection  International Journal of Neural Systems     
   

Schmidhuber    urgen  Deep learning in neural networks 

An overview  Neural Networks     

Vinyals  Oriol  Blundell  Charles  Lillicrap  Timothy 
Kavukcuoglu  Koray  and Wierstra  Daan  MatcharXiv preprint
ing networks for one shot learning 
arXiv   

Zagoruyko  Sergey and Komodakis  Nikos  Wide residual
networks  CoRR  abs    URL http 
 arxiv org abs 

FeFei  Li  Fergus  Robert  and Perona  Pietro    bayesian
approach to unsupervised oneshot learning of object
In Computer Vision    Proceedings 
categories 
Ninth IEEE International Conference on  pp   
  IEEE   

Gers  Felix    Schmidhuber    urgen  and Cummins  Fred 
Learning to forget  Continual prediction with lstm  Neural computation     

Graves  Alex  Generating sequences with recurrent neural

networks  arXiv preprint arXiv   

Gregor  Karol  Danihelka  Ivo  Graves  Alex  Rezende 
Danilo Jimenez  and Wierstra  Daan  Draw    recurrent neural network for image generation  arXiv preprint
arXiv   

Hochreiter  Sepp and Schmidhuber    urgen  Long shortterm memory  Neural computation   
 

Koch  Gregory  Zemel  Richard  and Salakhutdinov  Ruslan  Siamese neural networks for oneshot image recognition 

Lake  Brenden    Salakhutdinov  Ruslan  and Tenenbaum 
Joshua    Humanlevel concept learning through probabilistic program induction  Science   
   

Lake  Brenden    Ullman  Tomer    Tenenbaum 
Joshua    and Gershman  Samuel    Building maCoRR 
chines that
abs    URL http arxiv org 
abs 

learn and think like people 

Larochelle  Hugo and Hinton  Geoffrey    Learning to
combine foveal glimpses with   thirdorder boltzmann
machine  In Advances in neural information processing
systems  pp     

LeCun  Yann  Bengio  Yoshua  and Hinton  Geoffrey  Deep

learning  Nature     

Mnih  Volodymyr  Heess  Nicolas  Graves  Alex  et al  Recurrent models of visual attention  In Advances in Neural
Information Processing Systems  pp     

Santoro  Adam  Bartunov  Sergey  Botvinick  Matthew 
Wierstra  Daan  and Lillicrap  Timothy  Oneshot learning with memoryaugmented neural networks  arXiv
preprint arXiv   

Schaul  Tom and Schmidhuber    urgen  Metalearning 

Scholarpedia     

