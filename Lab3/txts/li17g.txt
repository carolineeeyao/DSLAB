Convergence Analysis of Proximal Gradient with Momentum for Nonconvex

Optimization

Qunwei Li   Yi Zhou   Yingbin Liang   Pramod    Varshney  

Abstract

Algorithm   APG

In this work  we investigate the accelerated proximal gradient method for nonconvex programming  APGnc  The method compares between
  usual proximal gradient step and   linear extrapolation step  and accepts the one that has  
lower function value to achieve   monotonic decrease  In speci    under   general nonsmooth
and nonconvex setting  we provide   rigorous argument to show that the limit points of the sequence generated by APGnc are critical points
of the objective function  Then  by exploiting the Kurdyka ojasiewicz     property for
  broad class of functions  we establish the linear
and sublinear convergence rates of the function
value sequence generated by APGnc  We further
propose   stochastic variance reduced APGnc
 SVRGAPGnc  and establish its linear convergence under   special case of the    property 
We also extend the analysis to the inexact version of these methods and develop an adaptive
momentum strategy that improves the numerical
performance 

  Introduction
Many problems in machine learning  data mining  and signal processing can be formulated as the following composite minimization problem

 cid  

min
  Rd

                    

   

Typically      Rd     captures the loss of data  tting and
can be written as      
   fl with each fl corresponding to the loss of one sample  The second term     Rd    
 
is the regularizer that promotes desired structures on the solution based on prior knowledge of the problem 

 Syracuse University  NY  USA  Correspondence to  Qunwei

Li  qli syr edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Input                                  
  
for         do
yk   xk   tk 
 xk   xk 
xk    prox   yk       yk 
tk   

   
  
 

 

tk

 

end for

In practice  many problems of     are formulated  either
naturally or intensionally  into   convex model to guarantee the tractability of algorithms  In particular  such convex problems can be ef ciently minimized by many  rstorder algorithms  among which the accelerated proximal
gradient  APG  method  also referred to as FISTA  Beck
  Teboulle      is proven to be the best for minimizing such class of convex functions  We present one of its
basic forms in Algorithm   Compared to the usual proximal gradient step  the APG algorithm takes an extra linear extrapolation step for acceleration  It has been shown
 Beck   Teboulle      that the APG method reduces the
function value gap at   rate of      where   denotes
the number of iterations  This convergence rate meets the
theoretical lower bound of  rstorder gradient methods for
minimizing smooth convex functions  The reader can refer
to  Tseng    for other variants of APG 

Algorithm   Monotone APG  mAPG 

 xk   xk 

 zk   xk    tk 

Input                                  
  
for         do
yk   xk   tk 
zk    prox   yk       yk 
tk
vk    prox   xk       xk 
tk   
if    zk       vk  then
else if    vk       zk  then

xk    zk 

   
  
 

 

tk

 

xk    vk 

end if
end for

Although convex problems are tractable and can be glob 

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Algorithm   APG nonconvex problem  APGnc 

  Main Contributions

Input                
for         do

  
          
xk   prox   yk       yk 
vk   xk      xk   xk 
if    xk       vk  then
else if    vk       xk  then

end if
end for

yk    xk 

yk    vk 

ally minimized  many applications naturally require to
solve nonconvex optimization problems of     Recently 
several variants of the APG method have been proposed
for nonconvex problems  and two major ones are presented
in Algorithm   and Algorithm   respectively  The major
difference to the original APG is that the modi ed methods
only accept the new iterate when the corresponding function value is suf ciently decreased  which leads to   more
stable convergence behavior  In particular   Li   Lin   
analyzed mAPG  Algorithm   by exploiting the Kurdyka 
 ojasiewicz     property  which is   local geometrical
structure very generally held by   large class of nonconvex
objective functions  and has been successfully exploited to
characterize the asymptotic convergence behavior of many
 rst order methods  It was shown in  Li   Lin    that
mAPG achieves the      convergence rate for convex
problems of     and converges to   critical point at sublinear and linear rates under different cases of the KL property for nonconvex problems  Despite the desirable convergence rate  mAPG requires two proximal steps  which
doubles the computational complexity of the original APG 
In comparison  the APGnc  Algorithm   requires only one
proximal step  and hence computes faster than mAPG in
each iteration  However  the analysis of APGnc in  Yao  
Kwok    does not exploit the KL property and no convergence rate of the function value is established  Hence 
there is still no formal theoretical comparison of the overall
performance  which depends on both computation per iteration and convergence rate  between mAPG and APGnc  It
is unclear whether the computational saving per iteration in
APGnc is at the cost of lower convergence rate 
The goal of this paper is to provide   comprehensive analysis of the APGnc algorithm under the KL framework 
thus establishing   rigorous comparison between mAPG
and APGnc and formally justifying the overall advantage
of APGnc 

This paper provides the convergence analysis of APGnc
type algorithms for nonconvex problems of     under the
KL framework as well as the inexact situation  We also
study the stochastic variance reduced APGnc algorithm and
its inexact situation  Our analysis requires novel technical treatments to exploit the    property due to the joint
appearance of the following ingredients in the algorithms
including momentum terms  inexact errors  and stochastic
variance reduced gradients  Our contributions are summarized as follows 
For APGnc applied to nonconvex problems of     we
show that the limit points of the sequences generated by
APGnc are critical points of the objective function  Then 
by exploiting different cases of the Kurdyka ojasiewicz
property of the objective function  we establish the linear
and sublinear convergence rates of the function value sequence generated by APGnc  Our results formally show
that APGnc  with one proximal map per iteration  achieves
the same convergence properties as well as the convergence
rates as mAPG  with two proximal maps per iteration  for
nonconvex problems  thus establishing its overall computational advantage 
We further propose an APGnc  algorithm  which is an improved version of APGnc by adapting the momentum stepsize  see Algorithm   and shares the same theoretical convergence rate as APGnc but numerically performs better
than APGnc 
Furthermore  we study the inexact APGnc in which the
computation of the gradient and the proximal mapping may
have errors  We show that the algorithm still achieves the
convergence rate at the same order as the exact case as long
as the inexactness is properly controlled  We also explicitly characterize the impact of errors on the constant factors
that affect the convergence rate 
To facilitate the solution to largescale optimization problems  we study the stochastic variance reduced APGnc
 SVRGAPGnc  and show that such an algorithm achieves
linear convergence rate under   certain case of the    property  We further analyze the inexact SVRGAPGnc and
show that it also achieves the linear convergence under the
same    property as long as the error in the proximal mapping is bounded properly  This is the  rst analysis of the
SVRG proximal algorithm with momentum that exploits
the    structure to establish linear convergence rate for
nonconvex programming 
Our numerical results further corroborate the theoretic
analysis  We demonstrate that APGnc APGnc  outperforms APG and mAPG for nonconvex problems in
both exact and inexact cases  and in both deterministic
and stochastic variants of the algorithms  Furthermore 

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

APGnc  outperforms APGnc due to properly chosen momentum stepsize 

  Comparison to Related Work
APG algorithms  The original accelerated gradient
method for minimizing   single smooth convex function
dates back to  Nesterov    and is further extended as
APG in the composite minimization framework in  Beck  
Teboulle      Tseng    While these APG variants
generate   sequence of function values that may oscillate 
 Beck   Teboulle      proposed another variant of APG
that generates   nonincreasing sequence of function values  Then   Li   Lin    further proposed an mAPG that
generates   suf ciently decreasing sequence of function
values  and established the asymptotic convergence rates
under the    property  Recently   Yao   Kwok   
proposed APGnc  which is   more ef cient version of APG
for nonconvex problems  but the analysis only characterizes  xed points and did not exploit the    property to
characterize the convegence rate    uni ed treatment of
accelerated gradient method for nonconvex stochastic optimization is presented in  Ghadimi   Lan    But the
discussion does not exploit the    property  and requires
function   to be convex  Our study establishes the convergence rate analysis of APGnc under the    property 
Nonconvex optimization under    The    property
 Bolte et al    is an extension of the  ojasiewicz gradient inequality  ojasiewicz    to the nonsmooth case 
Many  rstorder descent methods  under the    property 
can be shown to converge to   critical point  Attouch  
Bolte    Attouch et al    Bolte et al    with
different types of asymptotic convergence rates 
 Li  
Lin    and our paper focuses on the  rstorder algorithms with momentum  and respectively analyze mAPG
and APGnc by exploiting the    property 
Inexact algorithms under   
 Attouch et al   
Frankel et al    studied the inexact proximal algorithm
under the    property  This paper studies the inexact proximal algorithm with momentum       APGnc  under the   
property  While  Yao   Kwok    also studied the inexact APGnc  the analysis did not exploit the    property
to characterize the convergence rate 
Nonconvex SVRG  SVRG was  rst proposed in  Johnson   Zhang    to accelerate the stochastic gradient
method for strongly convex objective functions  and was
studied for the convex case in  Zhu   Yuan    Recently  SVRG was further studied for smooth nonconvex
optimization in Reddi et al      Then in  Reddi et al 
    the proximal SVRG was proposed and studied for
nonsmooth and nonconvex optimization  Our paper further
incorporates SVRG for the proximal gradient with momentum in the nonconvex case  Furthermore  we exploit   cer 

tain    property in our analysis that is very different from
the PL property exploited in  Reddi et al      and requires special technical treatment in convergence analysis 

  Preliminaries and Assumptions
In this section  we  rst introduce some technical de nitions
that are useful later on  and then describe the assumptions
on the problem     that we take in this paper 
Throughout this section      Rd       is an extended realvalued function that is proper       its domain
dom          Rd            is nonempty  and is
closed       its sublevel sets      Rd            are
closed for all        Note that   proper and closed function
  can be nonsmooth and nonconvex  hence we consider the
following generalized notion of derivative 
De nition    Subdifferential   Rockafellar   Wets   
The Frech et subdifferential    of   at     dom   is the set
of     Rd such that

lim inf
  cid      

          cid     

 cid     cid 

   

while the  limiting  subdifferential    at     dom   is the
graphical closure of    

      xk    xk                xk   cid  uk     

In particular  this generalized derivative reduceds to   
when   is continuously differentiable  and reduces to the
usual subdifferential when   is convex 
De nition    Critical point    point     Rd is   critical
point of   iff          
De nition    Distance  The distance of   point     Rd to
  closed set     Rd is de ned as 

dist      miny   cid       cid 

 

De nition    Proximal map      
 Rockafellar   Wets 
  The proximal map of   point     Rd under  
proper and closed function   with parameter       is de 
 ned as 

prox        argminz         

 cid       cid 

 

where  cid     cid  is the Euclidean    norm 
We note that when   is convex  the corresponding proximal
map is the minimizer of   strongly convex function        
singleton  But for nonconvex    the proximal map can be
setvalued  in which case prox      stands for an arbitrary
element from that set  The proximal map is   popular tool
to handle the nonsmooth part of the objective function  and
is the key component of proximallike algorithms  Beck  
Teboulle      Bolte et al   

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

De nition    Uniformized    property   Bolte et al 
  Function   is said to satisfy the uniformized   
property if for every compact set     domh on which   is
constant  there exist         such that for all        and
all          Rd   dist                            
         one has

 

 cid                 dist         

 
where the function              takes the form      
     for some constants              
The above de nition is   modi ed version of the original
   property  Bolte et al    Kurdyka    and is
more convenient for our analysis later  The    property is
  generalization of the  ojasiewicz gradient inequality to
nonsmooth functions  Bolte et al    and it is   powerful tool to analyze   class of  rstorder descent algorithms
 Attouch   Bolte    Attouch et al    Bolte et al 
  In particular  the class of semialgebraic functions
satisfy the above    property  This function class covers
most objective functions in real applications  for instance 
all lp where       and is rational  real polynomials  rank 
etc  For   more detailed discussion and   list of examples
of    functions  see  Bolte et al    and  Attouch et al 
 
We adopt the following assumptions on the problem     in
this paper 
Assumption   Regarding the functions       and        
   in    
  They

semicontinous 
set
sublevel
inf   Rd      
     Rd             is bounded for all       

lower
the

and
 

proper
 

are

  They satisfy the uniformized    property 
  Function   is continuously differentiable and the gradi 

ent    is LLipschitz continuous 

Note that the sublevel set of   is bounded when either   or
  has bounded sublevel set             or          as
 cid   cid      Of course  we do not assume convexity on
either   or    and the    property serves as an alternative
in this general setting 

  Main Results
In this section  we provide our main results on the convergence analysis of APGnc and SVRGAPGnc as well as
inexact variants of these algorithms  All proofs of the theorems are provided in supplemental materials 

  Convergence Analysis

In this subsection  we characterize the convergence of
APGnc  Our  rst result characterizes the behavior of the
limit points of the sequence generated by APGnc 

Theorem   Let Assumption   hold for the problem
    the sequence  xk  gener 
    Then with stepsize      
ated by APGnc satis es
   xk  is   bounded seuqence 
  The set of limit points   of  xk  forms   compact set 

on which the objective function   is constant 

  All elements of   are critical points of    

Theorem   states that the sequence  xk  generated by
APGnc eventually approaches   compact set         closed
and bounded set in Rd  of critical points  and the objective
function remains constant on it  Here  approaching critical points establishes the  rst step for solving general nonconvex problems  Moreover  the compact set   meets the
requirements of the uniform    property  and hence provides   seed to exploit the    property around it  Next 
we further utilize the    property to establish the asymptotic convergence rate for APGnc  In the following theorem    is the parameter in the uniformized    property via
     for some
the function   that takes the form        
             

    the sequence  rk  satis es for    large enough

Theorem   Let Assumption   hold for the problem     Let             for all        the set of limit
points  and denote rk      xk        Then with stepsize
     
  If       then rk reduces to zero in  nite steps 
  If        
  If        

     rk 
     
         
     
where         
        
 
min   
       
 

      then rk         

    then rk    

    and     

   

 

 

 

 

   

 cd 

  

Theorem   characterizes three types of convergence behaviors of APGnc  depending on   that parameterizes the   
property that the objective function satis es  An illustrative
example for the  rst kind       can take   form similar to
            for       around the critical points  The function is  sharp  around its critical point       and thus the
iterates slide down quickly onto it within  nite steps  For
the second kind        
      example functions can take
  form similar to            around the critical points 
That is  the function is strongly convexlike and hence the
convergence rate is typically linear  Lastly  functions of
the third kind are  at  around its critical points and thus
the convergence is slowed down to sublinear rate  We
note that characterizing the value of   for   given function
is   highly nontrivial problem that takes much independent effort  Kurdyka   Spodzieja    Li   Kei   
Nevertheless     property provides   general picture of the
asymptotic convergence behaviors of APGnc 

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Algorithm   APGnc with adaptive momentum  APGnc 

Input                         
  
for         do

xk   prox   yk       yk 
vk   xk    xk   xk 
if    xk       vk  then
yk    xk        
else if    vk       xk  then
yk    vk      min   

     

end if
end for

  APGnc with Adaptive Momentum

The original APGnc sets the momentum parameter     
   which can be theoretically justi ed only for convex
 
problems  We here propose an alternative choice of the
momentum stepsize that is more intuitive for nonconvex
problems  and refer to the resulting algorithm as APGnc 
 See Algorithm   The idea is to enlarge the momentum
  to further exploit the opportunity of acceleration when
the extrapolation step vk achieves   lower function value 
Since the proofs of Theorem   and Theorem   do not depend on the exact value of the momentum stepsize  APGnc
and APGnc  have the same orderlevel convergence rate 
However  we show in Section   that APGnc  improves
upon APGnc numerically 

  Inexact APGnc

We further consider inexact APGnc  in which computation
of the proximal gradient step may be inexact      
   yk       yk    ek 

xk   prox  

where ek captures the inexactness of computation of
    yk  and    captures the inexactness of evaluation of
the proximal map as given by

    is convex 
    is nonconvex  and      
In the  rst case        reduces to the usual subdifferential
of convex functions  and the inexactness   naturally induces
the following  subdifferential
                            cid          cid         Rd 

Moreover  since the    property utilizes the information of
     we then need to characterize the perturbation of    under the inexactness   This leads to the following de nition 

De nition   For any     Rd  let   cid          such that
           cid  has the minimal norm  Then the perturbation
between    and    is de ned as     dist       cid 

The following theorem states that for nonconvex functions 
as long as the inexactness parameters ek     and    are
properly controlled  then the inexact APGnc converges at
the same orderlevel rate as the corresponding exact algorithm 
Theorem   Consider the above two cases for inexact
APGnc under Assumption   If for all      

 cid ek cid     cid xk   yk cid 
      cid xk   yk cid 
      cid xk   yk cid 

 
 
 

then all the statements in Theorem   remain true and the
convergence rates in Theorem   remain at the same or 
   
der with the constants         
   where       depends on     and   and     
min   
  Correspondingly   
smaller stepsize      

       
 

            

     should be used 

     

 

 

   

 cd 

  

It can be seen that  due to the inexactness  the constant factor    in Theorem   is enlarged  which further leads to  
smaller    in Theorem   Hence  the corresponding convergence rates are slower compared to the exact case  but
remain at the same order 

    prox 

     

               

 cid       cid 

              

 cid       cid 

     Rd 

 

  Stochastic Variance Reduced APGnc

The inexact proximal algorithm has been studied in  Attouch et al    for nonconvex functions under the   
property  Our study here is the  rst treatment of inexact
proximal algorithms with momentum       APGlike algorithms  Furthermore  previous studies addressed only the
inexactness of gradient computation for nonconvex problems  but our study here also includes the inexactness of
the proximal map for nonconvex problems requiring only  
to be convex as the second case we specify below 
We study the following two cases 

In this subsection  we study the stochastic variance reduced
APGnc algorithm  referred to as SVRGAPGnc  The main
steps are presented in Algorithm   The major difference
from APGnc is that the single proximal gradient step is replaced by   loop of stochastic proximal gradient steps using
variance reduced gradients 
Due to the stochastic nature of the algorithm  the iterate
sequence may not stably stay in the local    region  and
hence the standard    approach fails  We then focus on the
analysis of the special but important case of the global   

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

             

 mL 

Input         
for           do

Algorithm   SVRGAPGnc
        
    yk  gk       yk 
  
for                 do
sample   from         
       xt
vt
xt 
    prox   xt
end for
    xm
       xm
zk   xm
         zk  then
if    xm
else if    zk       xm

     vt
  

yk    xm
   

  

    then

        yk    gk 

yk    zk 

end if
end for

property with      
  In fact  if       the    property in
such   case reduces to the well known Polyak ojasiewicz
 PL  inequality studied in  Karimi et al    Various
nonconvex problems have been shown to satisfy this property such as quadratic phase retrieval loss function  Zhou
et al    and neural network loss function  Hardt  
Ma    The following theorem characterizes the convergence rate of SVRGAPGnc under the    property with
 
     
Theorem   Let         where       and satis es
          If the problem     satis es the    property
globally with       then the sequence  yk  generated
by Algorithm   satis es

      yk         cid   

  

 cid  

              

 

where    
value 

      
 

   
    

    

  and     is the optimal function

Hence  SVRGAPGnc also achieves the linear convergence
rate under the    property with      
  We note that Theorem   differs from the linear convergence result established
in  Reddi et al      for the SVRG proximal gradient in
two folds    we analyze proximal gradient with momentum but  Reddi et al      studied proximal gradient al 
  here is different
gorithm    the    property with      
from the generalized PL inequality for composite functions
adopted by  Karimi et al    In order to exploit the
   property  our analysis of the convergence rate requires
novel treatments of bounds  which can be seen in the proof
of Theorem   in  

  Inexact SVRGAPGnc

We further study the inexact SVRGAPGnc algorithm  and
the setting of inexactness is the same as that in Section  

Here  we focus on the case where   is convex and ek    
The following theorem characterizes the convergence rate
under such an inexact case 
Theorem   Let   be convex and consider only the inexactness   in the proximal map  Assume the    property is globally satis ed with       Set       
where       and satis es             Assume that

     

  cid 

  cid 

      
  
and de ne  xt 
quence  yk  satis es

  cid cid xt 
      yk         cid   

    prox   xt

  

  

    xt
        xt
 cid  

  cid cid  for some      

   Then the se 

              

 

where    
function value 

      

       
 

   
     

 

  and     is the optimal

The convergence analysis for stochastic methods in inexact case has never been addressed before  To incorporate
the    property in deriving the convergence rate  we use  
reference sequence generated by exact proximal mapping 
Even though this sequence is not actually generated by the
algorithm  we can reach to the convergence rate by analyzing the relation between the reference sequence and the
actual sequence generated by the algorithm 
Compared to the exact case  the convergence rate remains
at the same order       the linear convergence  but the convergence is slower due to the larger parameter   caused by
the error parameter  

  Experiments
In this section  we compare the ef ciency of APGnc and
SVRGAPGnc with other competitive methods via numerical experiments 
In particular  we focus on the nonnegative principle component analysis  NNPCA  problem 
which can be formulated as

 cid 

zizT
 

     cid   cid 

 

 cid    cid 
 cid 

  

min
  

   
 

xT

 cid    cid 

  

It can be equivalently written as

min

 

   
 

xT

zizT
 

     cid   cid       

 

Here    corresponds to the  rst two terms  and   is the indicator of the nonnegative orthant           This problem
is nonconvex due to the negative sign and satis es Assumption   In particular  it satis es the    property since it is
quadratic 
For the experiment  we set             and randomly generate the samples zi from normal distribution 

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

All samples are then normalized to have unit norm  The
initialization is randomly generated  and is applied to all
the methods  We then compare the function values versus
the number of effective passes through   samples 

   

   

Figure   Performance comparison of APGnc  APGnc  mAPG 
and the traditional proximal method 
    There
exists the proximal error 

    Error free 

       
We further study the inexact case in Figure       where we
introduce the proximal error       
    at the kth iteration 
One can see that inexact APGnc  and inexact APGnc also
outperform other two inexact algorithms  Furthermore  in
Figure       and     we compare exact and inexact algorithms respectively for APGnc  and APGnc  It can been
that even with   reasonable amount of inexactness  both
methods converge comparably to their corresponding exact
methods  Although initially the function value drops faster
in exact algorithms  both exact and inexact algorithms converge to the optimal point almost at the same time  Such
  fact demonstrates the robustness of the algorithms  We
note that the relative comparison of the performance among
the algorithms does not change under other choices like
            

   

   

Figure   Performance comparison of the same algorithm with
and without the proximal error      Performance comparison of
APGnc      Performance comparison of APGnc 

   

   

Figure   Performance comparison of SVRGAPGnc  SVRGAPGnc  and the traditional proximal SVRG      Error free     
There exists the proximal error 

  Comparison among APG variants

zizT

  

  cid 

We  rst compare among the deterministic APGlike methods in Algorithms       and the standard proximal gradient
method  The original APG in Algorithm   is not considered since it is not   descent method and does not have
convergence guarantee in nonconvex cases  We tuned  
 xed step size         where   is the spectral norm of
the sample matrix
    We set       for APGnc 
The results are shown in Figures   and   In Figure      
we show the performance comparison of the methods when
there is no error in gradient or proximal calculation  One
can see that APGnc and APGnc  outperform all other APG
variants 
In particular  APGnc  performs the best with
our adaptive momentum strategy  justifying its empirical
advantage  We note that the mAPG requires two passes
over all samples at each iteration  and is  therefore  less
data ef cient compared to other APG variants  We further
note that other choices of stepsize less than the standard
choice    does not change the relative comparison of
the performance among the algorithms  and we observed
that the adaptive momentum performs practically well for

   

   

Figure   Performance comparison of the same algorithm with
and without the proximal error      Performance comparison of
SVRGAPGnc      Performance comparison of SVRGAPGnc 

  Comparison among SVRGAPG variants

We then compare the performance among SVRGAPGnc 
SVRGAPGnc  and the original proximal SVRG methods 
and pick the stepsize      mL with        The results
are presented in Figures   and   In the error free case in
Figure       one can see that SVRGAGPnc  method outperforms the others due to the adaptive momentum  and the
SVRGAPGnc method also performs better than the original proximal SVRG method 
For the inexact case  we set the proximal error as     

 Number of effective passesFunction value  APGnc APGncmAPGProximal method Number of effective passesFunction value  APGnc APGncmAPGProximal method Number of effective passesFunction value  APGnc Inexact APGnc Number of effective passesFunction value  APGncInexact APGnc Number of effective passesFunction value  SVRG APGnc SVRG APGncProximal SVRG Number of effective passesFunction value  SVRG APGnc SVRG APGncProximal SVRG Number of effective passesFunction value  SVRG APGnc Inexact SVRG APGnc Number of effective passesFunction value  SVRG APGncInexact SVRG APGncConvergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

 

        where   is chosen to suppress the
min 
large inexactness during the initial few iterations  One can
see from Figure       that the performance is degraded
compared to the exact case  and converges to   different local minimum  In this result  all the methods are no longer
monotone due to the inexactness and the stochastic nature
of SVRG  Nevertheless  the SVRGAPGnc  still yields the
best performance 
We also compare the results corresponding to SVRGAPGnc  and SVRGAPGnc  with and without the proximal error  in Figure       and     respectively  It is clear
that the SVRGbased algorithms are much more sensitive
to the error comparing with APGbased ones  Even though
the error is set to be smaller than in the inexact case with
APGbased methods  one can observe more signi cant performance gaps than those in Figure  

  Conclusion
In this paper  we provided comprehensive analysis of the
convergence properties of APGnc as well as its inexact and stochastic variance reduced forms by exploiting
the    property  We also proposed an improved algorithm APGnc  by adapting the momentum parameter  We
showed that APGnc shares the same convergence guarantee and the same order of convergence rate as the mAPG 
but is computationally more ef cient and more amenable
to adaptive momentum  In order to exploit the    property
for accelerated algorithms in the situations with inexact errors and or with stochastic variance reduced gradients  we
developed novel convergence analysis techniques  which
can be useful for exploring other algorithms for nonconvex
problems 

Acknowledgements
This work was supported in part by the NSF grant ECCS
 

References
Attouch     and Bolte     On the convergence of the proximal algorithm for nonsmooth functions involving analytic features  Mathematical Programming   
    ISSN  

Attouch     Bolte     Redont     and Soubeyran     Proximal alternating minimization and projection methods
for nonconvex problems  An approach based on the
Kurdyka ojasiewicz inequality  Mathematics of Operations Research     

Attouch     Bolte     and Svaiter     Convergence of descent methods for semialgebraic and tame problems 

proximal algorithms  forwardbackward splitting  and
regularized GaussSeidel methods  Mathematical Programming     

Beck     and Teboulle     Fast gradientbased algorithms
for constrained total variation image denoising and deblurring problems  Transactions on Image Processing 
  November    

Beck     and Teboulle       fast iterative shrinkagethresholding algorithm for
inverse problems 
SIAM Journal of Image Science       

linear

Bolte     Daniilidis     and Lewis     The  ojasiewicz inequality for nonsmooth subanalytic functions with applications to subgradient dynamical systems  SIAM Journal
on Optimization     

Bolte     Danilidis     Ley     and Mazet     Characterizations of  ojasiewicz inequalities and applications 
Subgradient  ows  talweg  convexity  Transactions of
the American Mathematical Society   
 

Bolte     Sabach     and Teboulle     Proximal alternating
linearized minimization for nonconvex and nonsmooth
problems  Mathematical Programming   
   

Frankel     Garrigos     and Peypouquet     Splitting
methods with variable metric for kurdyka ojasiewicz
Journal of
functions and general convergence rates 
Optimization Theory and Applications   
 

Ghadimi     and Lan     Accelerated gradient methods
for nonconvex nonlinear and stochastic programming 
Mathematical Programming     

Gong     Zhang     Lu     Huang        and Ye       general iterative shrinkage and thresholding algorithm for
nonconvex regularized optimization problems  In International Conference on Machine Learning   

Hardt     and Ma    

Identity matters in deep learning 
Arxiv preprint    URL http arxiv org 
abs 

Johnson     and Zhang     Accelerating stochastic gradient
descent using predictive variance reduction  In Advances
in Neural Information Processing Systems  pp   
 

Karimi     Nutini     and Schmidt     Linear convergence of gradient and proximalgradient methods under the Polyak ojasiewicz condition  Machine Learning and Knowledge Discovery in Databases  European
Conference  pp     

Convergence Analysis of Proximal Gradient with Momentum for Nonconvex Optimization

Kurdyka     On gradients of functions de nable in ominimal structures  Annales de   institut Fourier   
   

Zhu     and Yuan     Improved SVRG for nonstrongly 
In Interna 

convex or sumof nonconvex objectives 
tional Conference on Machine Learning   

Kurdyka    

and Spodzieja    

Separation of
real algebraic sets and the  ojasiewicz exponent 
Wydzia  Matematyki Informatyki  Uniwersytet  odzki 
 
URL https books google com 
books id CL PMwEACAAJ 

Li     and Kei     Calculus of the exponent of Kurdyka 
 ojasiewicz inequality and its applications to linear convergence of  rstorder methods  ArXiv preprint  February   URL https arxiv org abs 
 

Li     and Lin     Accelerated proximal gradient methods for nonconvex programming  In Advances in Neural
Information Processing Systems  pp     

 ojasiewicz     Ensembles semianalytiques  Institut des

Hautes Etudes Scienti ques   

Nesterov       method of solving   convex programming
problem with convergence rate      Soviet Mathematics Doklady     

Reddi     Hefny     Sra     Poczos     and Smola    
Stochastic variance reduction for nonconvex optimization  ArXiv preprint      URL https arxiv 
org abs 

Reddi     Sra     Poczos     and Smola     Proximal
stochastic methods for nonsmooth nonconvex  nitesum
In Advances in Neural Information Prooptimization 
cessing Systems   pp       

Rockafellar       and Wets         Variational Analysis 

Springer   

Schmidt     Roux       and Bach       Convergence
rates of inexact proximalgradient methods for convex
In Advances in Neural Information Prooptimization 
cessing Systems   pp     

Tseng     Approximation accuracy  gradient methods  and
error bound for structured convex optimization  Mathematical Programming     

Yao     and Kwok       More ef cient accelerated proximal algorithm for nonconvex problems  ArXiv preprint 
December   URL https arxiv org abs 
 

Zhou     Zhang     and Liang     Geometrical properties
and accelerated gradient solvers of nonconvex phase retrieval  The  th Annual Allerton Conference   

