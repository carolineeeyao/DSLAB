Learning Algorithms for Active Learning

Philip Bachman     Alessandro Sordoni     Adam Trischler  

Abstract

We introduce   model that learns active learning
algorithms via metalearning  For   distribution
of related tasks  our model jointly learns    data
representation  an item selection heuristic  and
  prediction function  Our model uses the item
selection heuristic to construct   labeled support
set for training the prediction function  Using the
Omniglot and MovieLens datasets  we test our
model in synthetic and practical settings 

  Introduction
For many realworld tasks  labeled data is scarce while
unlabeled data is abundant  It is often possible  at some cost 
to obtain labels for the unlabeled data  In active learning 
  model selects which instances to label so as to maximize
some combination of task performance and data ef ciency 
Active learning is motivated by the observation that   model
may perform better while training on less labeled data if it
can choose the data on which it trains  Cohn et al   
     in SVMs  Sch lkopf   Smola    only the support
vectors affect the decision boundary  If one could identify
the support vectors in advance  the classi er trained on the
resulting set of examples would obtain the same decision
boundary with less data and computation 
Active learning can bene     variety of practical scenarios 
For example  preference information for   new user in  
movie recommender system may be scarce  and recommendations for the new user could be improved by carefully
selecting several movies for her to rate  Sun et al     
Houlsby et al    Aggarwal    Likewise  collecting
labels for   medical imaging task may be costly because it
requires   specialist  Hoi et al    and the cost could be
reduced by carefully selecting which images to label 
Various heuristics for selecting instances to label have been
proposed in the active learning literature  such as choos 

 Equal contribution  Microsoft Maluuba  Montreal  Canada 
Correspondence to     Bachman  phbachma microsoft com 
   Sordoni  alsordon microsoft com 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright   by
the author   

ing the instance whose label the model is most uncertain
about  or the instance whose label is expected to maximally
reduce the model   uncertainty about labels for other instances  GiladBachrach et al    Settles    Houlsby
et al    We propose moving away from engineered
selection heuristics towards learning active learning algorithms endto end via metalearning  Our model interacts
with labeled items for many related tasks in order to learn
an active learning strategy for the task at hand  In recommendation systems  for example  ratings data for existing
users can inform   strategy that ef ciently elicits preferences for new users who lack prior rating data  thus bootstrapping the system quickly out of the coldstart setting
 Golbandi et al      Sun et al      Kawale et al 
    learned active learning strategy could outperform
taskagnostic heuristics by sharing experience across related tasks  In particular  the model       data representation 
 ii  strategy for selecting items to label  and  iii  prediction function could all coadapt  Moving from pipelines of
independentlyengineered components to endto end learning has lead to rapid improvements in       computer vision 
speech recognition  and machine translation  Krizhevsky
et al    Hannun et al    He et al    Wu et al 
 
We base our model on the Matching Networks  MN  introduced by Vinyals et al    We extend the MN  
oneshot learning ability to settings where labels are not
available   priori  We cast active learning as   sequential
decision problem  at each step the model requests the label
for   particular item in   pool of unlabeled items  then adds
this item to   labeled support set  which is used for MNstyle
prediction  We train our model endto end with backprop
and reinforcement learning  We expedite the training process by allowing our model to observe and mimic   strong
selection policy with oracle knowledge of the labels 
We demonstrate empirically that our proposed model learns
effective active learning algorithms in an endto end fashion 
We evaluate the model on  active  variants of existing oneshot learning tasks for Omniglot  Lake et al    Vinyals
et al    Santoro et al    and show that it can
learn ef cient label querying strategies  We also test the
model   ability to learn an algorithm for bootstrapping  
recommender system using the MovieLens dataset  showing
it holds promise for application in more practical settings 

Learning Algorithms for Active Learning

  Related Work
Various heuristics have been proposed to guide the selection
of which examples to label during active learning  Settles 
  For instance  Lewis   Gale   and Tong  
Chang   developed policies based on the con dence
of the classi er  while GiladBachrach et al    used
the disagreement of   committee of classi ers  Houlsby
et al    presented an approach based on Bayesian information theory  in which examples are selected in order to
maximally reduce the entropy of the posterior distribution
over classi er parameters 
The idea of learning an active learning algorithm endto end 
via meta active learning  was recently investigated by Woodward   Finn   Building on the memoryaugmented
neural network  MANN   Santoro et al    the authors
developed   streambased active learner  In streambased
active learning the model decides  while observing items
presented in an exogenouslydetermined order  whether to
predict each item   label or to pay   cost to observe its label 
Our proposed model instead falls into the class of poolbased active learners       it has access to   static collection
of unlabeled data and selects both the items for which to
observe labels  and the order in which to observe them 
Active learning can be useful when the cost incurred for
labeling an item may be traded for lower prediction error 
and where the model must be data ef cient       in medical
imaging  Hoi et al    We explicitly train our model
to balance between task performance and labeling cost  In
this sense  we build an anytime active learner  Zilberstein 
  with the model trained at each step to output the best
possible prediction on the evaluation set 
Our model builds on the matchingnetworks  MN  architecture presented by Vinyals et al    which enables
 oneshot  learning       learning the appearance of   class
from just   single example of that class  Santoro et al   
Koch    Vinyals et al    assume that at least one
example per class exists in the labeled support set available
to the model  Confronted with the harder task of composing
  labeled support set from   larger pool of unlabeled examples  we show that the active learning policy learnt by our
model obtains  in some cases  an equally effective support
set  As in the recent oneshot learning work of Santoro et al 
  and Vinyals et al    and the active learning
work of Woodward   Finn   we evaluate our model
on the Omniglot dataset  This dataset was developed for the
foundational oneshot learning work of Lake et al   
which focused on probabilistic program induction 
The coldstart problem is ubiquitous in recommendation systems  Aggarwal    Lika et al    Harpale   Yang 
  Sun et al      Elahi et al    Instead of bootstrapping from   coldstart by randomly selecting items for

  user to rate  an active learner asks for particular items to
help learn   strong user model more quickly  In modelfree
strategies  Rashid et al    items are selected according
to general empirical statistics such as popularity or informativeness  These approaches are computationally cheap 
but lack the bene ts of adaptation and personalization  Proposals for learning an adaptive selection strategy have been
made in the form of Bayesian methods that learn the parameters of   user model  Houlsby et al    Harpale   Yang 
  and in the form of decisiontrees learned from existing ratings  Sun et al      An extensive review can be
found in Elahi et al    Intuitively  our model learns  
compact  parametric representation of   decision tree endto 
end  by directly maximizing task performance  We evaluate
our active learner on MovieLens      standard dataset
for recommendation tasks 
We provide hints to our model during training using samples from an oracle policy that knows all the labels  Related
approaches have been explored in previous work on imitation learning and learning to search  Ross   Bagnell   
Chang et al    These methods  which focus the cost
of sampling from the oracle policy on states visited by the
model policy  have recently been adopted by researchers
working with deep networks for representation learning
 Zhang   Cho    Sun et al   

  Model Description
We now present our model  which metalearns algorithms
for active learning  Our model metalearns by attempting
to actively learn on tasks sampled from   distribution over
tasks  using supervised feedback to improve its expected
performance on new tasks drawn from   similar distribution 
Succinctly  our model solves each task by adaptively selecting items for the labeled support set used by   Matching
Network  Vinyals et al    to classify test items  The full
support set from which our model selects these examples
contains both labeled and unlabeled data 
For   summary of our model  see the architecture diagram in
Figure   the optimization objectives in Equations     and
  and the pseudocode in Algorithm   We present   formal
description of our meta active learning task in Section  
We describe the details of our model in Section   and our
approach to parameter optimization in Section  

  Task Description

Our model re nes its behaviour over many training episodes 
in order to maximize performance during test episodes not
encountered in training  In each episode  our model interacts with   support set            comprising items  
for which the model can request labels    and   similarlyde ned evaluation set             Let Su
       

Learning Algorithms for Active Learning

denote the set of items in the support set whose labels are
          
still unknown after   label queries  and let Sk
denote the complementary set of items whose labels are
known  Let St denote the joint set of labeled and unlabeled
items after   label queries  Let the realvalued vector st
denote the control state of our model after viewing   labels 
and let      St  st  denote the reward won by our model
when predicting labels for the evaluation set based on the
information it has received after   label queries  We assume
all functions depend on the model parameters   and omit
this dependence from our notation for brevity 
We de ne the prediction reward as follows 

     St  st     cid 

      

log        st  St 

 

which gives loglikelihood of the predictions        st  St 
on the evaluation set  The prediction    conditions on  the
test item     the current control state st  and the current
labeled unlabeled support set St  For tests on Omniglot  see
Section   we use negative crossentropy on the class
labels  and for MovieLens  see Section   we use the
negative Root Mean Squared Error  RMSE 
At each step   of active learning  the model requests the
label for an item   from the set Su
   and updates its control
state from st  to st based on the response  Together  st
and St determine the model   predictions for test items
and the model   decision about which label to request next 
Algorithm   describes this process in detail  and Section  
formally describes the functions used in Algorithm  
The idealized objective for training our model is 

 cid 

 cid    cid 

  

 cid cid 

maximize

 

 

      

 

      

     St  st 

 

 

in which   is the max number of label queries to perform 
       indicates an episode sampled from some distribution    and         indicates unrolling the model   active
learning policy   for   steps on support set    Unrolling  
produces the intermediate states           ST   sT  
To optimize this objective  our model repeatedly samples an
episode        then unrolls   for   steps of active learning  and maximizes the prediction reward      St  st  at
each step  Alternately  our model could maximize only the
reward at the  nal step  We maximize reward at each step in
order to promote anytime behaviour        the model should
perform as well as possible after each label query  Anytime
behaviour is desirable in many practical settings       for
movie recommendations the model should be robust to early
termination while eliciting the preferences of   new user 
During training  for computational ef ciency  our model

 cid 

 cid    cid 

  

 cid cid 

maximizes the following approximation of Equation  

 

      

 

      

   Su

    St  st         ST   sT  

 

 

in which    Su
    St  st  is   prediction reward for unlabeled
items in the support set  We assume labels for the full
support set are available during training  We compute
   Su
    St  st  using   fast prediction module  and compute
     St  st  using   slow prediction module  The fast and
slow prediction rewards can be obtained by substituting the
appropriate predictions into Equation   Sections   and
  describe these modules in detail 

  Model Architecture Details

Our model comprises multiple modules  contextfree and
contextsensitive encoding  controller  selection  reading 
fast prediction  and slow prediction  We present an overview
of our model in Fig    and Alg    which describe how our
model   modules perform active learning  The rest of this
subsection describes the individual modules in more detail 

   st 

        Sk

Algorithm   Endto end active learning loop  for Eq   
    encode items in   with contextsensitive encoder
    and encode items in   with contextfree encoder
             Su
                 
  for               do
  select next instance
 
    SELECT Su
   Sk
 
  read labeled instance and update controller
 
 xi  yi    READ      
 
st   UPDATE st  xi  yi 
 
  update known   unknown set
 
      xi  yi 
    Sk
Sk
 
      xi 
    Su
Su
 
  perform fast prediction
 
    FASTPRED    Su
LS
 
  end for
    perform slow prediction
    SLOWPRED    Su
  LE

    Sk

    st 

    Sk

    sT  

  CONTEXT FREE SENSITIVE  ENCODING

The contextfree encoder associates each item with an embedding independent of the context in which the item was
presented  For our Omniglot tests  this encoder is   convnet with two convolutional layers that downsample via
strided convolution  followed by another convolutional layer
and   fullyconnected linear layer which produces the  
nal contextfree embedding  For our MovieLens tests  this
encoder is   simple lookup table mapping movie ids to

Learning Algorithms for Active Learning

   and similarly de ne    cid 

  for  xi     

Figure     summary of the modules in our model  Items in the support and evaluation set are embedded using   contextfree encoder 
Final embeddings for support set items are computed by processing their contextfree embeddings with   contextsensitive encoder  The
selection module places   distribution over unlabelled items in Su
  using   gated combination of controlleritem similarity features and
itemitem similarity features  The read module copies the selected item and its label  and transforms them for input to the controller 
which then updates its state from st  to st  Fast predictions are made within the support set   based on sharpened itemitem similarity
features  Slow predictions are made for items in the heldout set   using   Matching Networkstyle function which incorporates masking
to account for known unknown labels  and conditions on the state st  We train this system endto end with Reinforcement Learning 
embeddings  We denote the contextfree encoding of item
xi     as   cid 
The contextsensitive encoder produces an embedding   cid cid 
for each item xi     based on the contextfree embeddings
     xj      The contextsensitive encoder is not applied
  cid 
to items in the evaluation set  Our model uses   modi ed
form of the encoder from Matching Networks  Vinyals et al 
  Speci cally  we run   bidirectional LSTM  Hochreiter   Schmidhuber    Schuster   Paliwal    over
all contextfree embeddings for the support set  and then
add   linear function of the concatenated forwards and backwards states to the contextfree embedding   cid 
We can write this as follows 

At each step    the controller receives an input rt from
the reading module which encodes the most recently read
item label pair  Additional inputs could take advantage of
taskspeci   information  The control module performs an
LSTM update 

We initialize    for each episode        using the  nal state
of the backwards LSTM in the contextsensitive encoder
which processed the support set    In principal  this allows
the controller to condition its behaviour on the full unlabeled
contents of the support set  Alg    line  

st   LSTM st  rt 

  CONTROLLER

 

  to get   cid cid 
   

 cid cid hi   cid hi

 cid 

  cid cid 
      cid 

    We

 

 

in which  cid hi gives the forward encoder state for item xi 
 cid hi gives the backward encoder state  and We is   trainable
matrix  We compute the forward states  cid hi as in   standard
LSTM  processing the support set items xi sequentially
following   random order  We compute the backward states
 cid hi by processing the sequence of concatenated   cid 
  and  cid hi
vectors in reverse 

  SELECTION

At each step    the selection module places   distribution
    Su
    It then samples the
  over all unlabeled items xu
   
index of an item to label from    
    and feeds it to the reading
module  Alg    line  
Our model computes    
  using   gated  linear combination of features which measure controlleritem similarity
and itemitem similarity  For each item  we compute the
controlleritem similarity features 

      cid cid 
bi

   cid  Wbst 

  READING
This module concatenates the embedding   cid cid 
  and label yi
for the item indicated by the selection module  and linearly transforms them before passing them to the controller
 Alg    line  

where Wb is   trainable matrix and  cid  indicates elementwise
multiplication  We also compute the following six itemitem similarity features   max mean min  cosine similarity
to any labeled item  and  max mean min  cosine similarity
to any unlabeled item  We concatenate the controlleritem

selectreadvisibleitem labelshiddencontextualencodingsupport setheldoutitemcontroller LSTMattendmatching networksstyle slowpredictorpredictfast predictorRewardRewardLearning Algorithms for Active Learning

similarity features and itemitem similarity features to get  
   We also compute   gating vector  gt    Wgst 
vector di
in which Wg is   trainable matrix and   indicates the
standard sigmoid 
    Su
For each xu

    we compute the selection logit 

     gt  cid  di
pi

  cid wp 

     xu

where wp indicates   trainable vector  Finally  we compute
  via softt by normalizing over the logits pi
   
max  This module performs worse when the controlleritem
or itemitem features are removed  Our model intelligently
adapts these heuristics to the task at hand  We provide
pseudocode for how these modules interact during active
learning in Algorithm  

    Su

  FAST PREDICTION

The fast prediction module makes an attentionbased prei   Su
  using its cosine
diction for each unlabeled item xu
    Sk
    which are sharpsimilarities to the labeled items xk
  between xu
ened by   nonnegative matching score   
  and
the control state st  The cosine similarities are taken between the contextsensitive embeddings   cid cid 
  and   cid cid 
  of the
respective items  These do not change with   and may be
precomputed before unrolling the active learning policy 
Predictions from this module are thus fast to compute while
unrolling the policy  Alg    line   The precomputed cosine similarities may be reused in the selection module for
computing itemitem similarity features  further amortizing
their cost 
    we compute   set of attention
For each unlabeled xu
  by applying   softmax to
weights over the labeled xk
the relevant cosine similarities  using   
  as   temperature for
the softmax  We compute the sharpening term as follows 

    Sk

    exp   cid cid 
  

   cid   st 

where    indicates   trainable matrix  This module performs signi cantly worse without the sharpening term  The
 nal fast prediction is formed by taking   convex combination of the labels yj for the labeled xk
  using the
computed attention weights 

    Sk

  SLOW PREDICTION

The slow prediction module implements   modi ed Matching Network prediction  which accounts for the distinction
between labeled and unlabeled items in St  and conditions
on the active learning control state st  Alg    line  
Given the contextfree embedding    cid  for some heldout
example         the state st  and required initial values  this
module predicts   label by iterating the steps 
  mk   LSTM mk   xk     cid  st 

     cid cid       cid    Wmmk
   ak   attend   cid cid  Sk
   
   xk   yk   attRead ak  Sk
   

Here  LSTM is an LSTM update  mk is the matching state
at step       cid cid  is the matchsensitive embedding of    at step
   Wm is   trainable matrix   ak are the matching attention
weights at step     xk is the  item attention  result from step
   and  yk is the  label attention  result from step    For
details of the attend and attRead functions  refer to Vinyals
et al    As    nal prediction  this module returns
the label attention result  yK from the Kth  nal  step of
iterative matching  In our tests we         
Note  our model contains many linear transforms      Our
model adds bias and gain terms to all of these transforms 
as described for weight normalization  Salimans   Kingma 
  We omit these terms for brevity  Similarly  we use
layer normalization in our active learning and matching
controller LSTMs  Ba et al   

  Training the Model

We optimize the parameters of our model using   combination of backpropagation and policy gradients  For   clear
review of optimization techniques for general stochastic
computation graphs  see Schulman et al     
Using the notation from Section   and following the approach of  Schulman et al      we can write the gradient
of our training objective as follows 

            

 cid 

 cid 

 cid 

 cid 

 

 

 

    cid       

  log   cid        

  cid   

     cid   

in which           denotes the expected reward won by
the active learning model while working on episode       
 cid   denotes the set of intermediate states  St  st  generated
by the model while working with          cid    denotes the
sum of rewards  as described in Equation   received by
the model while working on episode        In the term
   cid    all decisions made by the model to produce  cid   are
treated as constant  Taking the expectation of Equation  
with respect to episodes            gives us an unbiased
gradient estimator for the objective in Equation  
Rather than using the gradients in Equation   directly  we
optimize the model parameters using Generalized Advantage Estimation  Schulman et al      which provides
an actorcritic approach for approximately optimizing the
policy gradients in Equation   For more details on how
Generalized Advantage Estimation helps reach   favourable
biasvariance tradeoff in policy gradient estimation  see the
source paper  Schulman et al      We apply the GAE
updates using ADAM  Kingma   Ba   

Learning Algorithms for Active Learning

 lters and no downsampling  These layers produce      
      feature map that we  atten and pass through   fully
connected layer  All convolutional layers use the leaky
ReLU nonlinearity  Maas et al   
We setup Nway  Kshot Omniglot classi cation as follows 
We randomly pick   character classes from the available
train test classes  Then  we build   support set by randomly
sampling   items for each character class       in the  way
setting  there are  items in the support set  The heldout
set is always obtained by randomly sampling   item per
class  In our active learning setting  Kshot is proportional
to how many labels the model can acquire  In the Nway 
Kshot setting  the model asks for     labels before performing heldout prediction  For example  in  way   shot
classi cation  the model asks for   labels  Following each
label query  we also measure anytime performance of the
fast prediction module on the items remaining in Su
    Note
that the  shot setting is particularly challenging for our
model  as it needs to ask for different classes at each step 
and the ability to identify missing classes is limited by the
accuracy of the underlying oneshot classi er 
We compare our active learner to four baselines  To compute   pessimistic estimate of potential performance  we use
  matching network where we label     items chosen at
random from the full support set  Matching Net  random 
As the labels are randomly sampled  it is possible that  
given class is never represented among the labeled items
and the model cannot classify perfectly  even in principle 
To compute an optimistic estimate of potential performance 
we measure the  ideal  matching network accuracy by labeling   classbalanced subset of items from the full support
set  Matching Net  balanced  This baseline represents
  highlyperformant policy that the active learner can  in
principle  learn  For the last baseline  MinMax Cos  we
formulate   heuristic policy  At each active learning step 
we select the item which has minimum maximum cosine
similarity to unlabeled items in the support set  This heuristic selects item that are different from each other    strategy
wellsuited to the Omniglot classi cation task where items
are drawn from   consistent set of underlying classes 
We report the results in Table   Matching Networks operating on   randomly sampled set of labels suffer the most
in  shot scenarios  where the probability of all classes
being represented is particularly low  especially in the  
way case  Overall  the active policy nearly matches the
performance of the optimistic balanced Matching Network
baseline  Degradation of performance by   is observed
for the  shot   way case  This is not surprising since
augmenting the number of classes in the support set  while
keeping the number of shots  xed  considerably increases
the dif culty of the problem for the active learner  Figure  
shows   rollout of the model policy in the  way setting 

Figure     rollout of our active learning policy for Omniglot  using   support set of   items from   different classes with   items
per class  Each row represents the support set at different active
iterations  For visualization purposes  each column represents  
class  Unlabeled items have white background while selected items
have black background  In this case  the model behaves optimally
by selecting at each step an item with   yetunseen label 

  Experiments
  Omniglot

We run our  rst experiments on the Omniglot dataset  Lake
et al    consisting of   characters from   different alphabets each handwritten by   different persons 
Following Vinyals et al    we divide the dataset into
  characters for training and keep the rest for testing 
When measuring test performance  our model interacts with
characters it did not encounter during training 
For the contextfree embedding function we use   threelayer convolutional network  The  rst two layers use      
convolutions with    lters and downsample with   double
stride  The third layer uses         convolution with  

Support Set       Support Set       ClassesTimeSupport Set       Support Set       Support Set       Support Set       Support Set       Support Set       Support Set       Support Set       Learning Algorithms for Active Learning

Table   Results for our active learner and baselines for the Nway  Kshot classi cation settings 

Model

Matching Net  random 
Matching Net  balanced 
Active MN
MinMax Cos

 shot
 
 
 
 

 way

 shot
 
 
 
 

 shot
 
 
 
 

 shot
 
 
 
 

 way
 shot
 
 
 
 

 shot
 
 
 
 

Figure   provides results for the more challenging setting
of  way classi cation  We tested two properties of our
model  its anytime performance beyond the  shot setting 
and its ability to generalize to problems with more classes
than were seen during training  The model performed well
on  way classi cation  and quickly approached the optimistic estimate after acquiring more labels  We also found
that policies trained for as little as  way classi cation
could generalize to the  way setting 
Our model relies on   number of moving parts  When designing the architecture  we followed the simple approach of
minimizing changes to the original Matching Network from
Vinyals et al    We now provide ablation test results
for several parts of our model  In the  way   shot setting
accuracy dropped from   to   when we removed attention temperature from the fast prediction module  Reducing
the number of matching steps from   to   or   had no significant effect in this setting  Removing the contextsensitive
encoder also had no signi cant effect  Streamlining our
architecture is clearly   useful topic for future work aimed
at scaling our approach to more realistic settings 

  MovieLens

  SETUP

We test our model in the  coldstart  collaborative  ltering scenario using the publicly available MovieLens  
dataset  The dataset contains approximately    ratings
on    movies by    users  The ratings are on an ordinal
 point scale  from   to   with intervals of   We subsample the dataset by selecting   movies and   users
with the most ratings  After  ltering  the dataset contains
approximately    ratings  We partition the data randomly
into   training users and   test users  The training
set represents the users already in the system who are used
to    the model parameters  We use the test users to evaluate
our active learning approach  For each user  we randomly
pick   ratings to include in the support set  movies that the
user can be queried about  and   movies and ratings for the
heldout set  We ensure that movies in the heldout set and
at http grouplens org datasets 

 Available
movielens 

in the support set do not overlap  We train our active learner
to minimize the meansquared error  MSE  with respect
to the true rating  We adapt the prediction modules of our
model to output the rating for   heldout item as follows 
we compute   convex combination of the ratings of  visible 
movies in the support set  the movies the active learner has
already queried about  where the weights are given by the
 nal attention step of the slow predictor  Although more
complex strategies are possible  we empirically found this
simple strategy to work well in our experiments  For evaluation  we sample   episodes         support ratings
and   heldout ratings from the same user  from the test
set and we compute the average peruser root meansquared
error  RMSE       we average the ratings in the heldout set
of each test episode and then average across test episodes 
We report the average performance obtained by   runs with
different random seeds 

  MOVIE EMBEDDINGS

For each movie  we pretrain an embedding vector by decomposing the full user movie rating matrix using   latent factor
model  Koren    This process only uses the training set 
For each user   and movie    we estimate the true rating
ru   with   linear model  ru       cid 
  xm   bu   bm    
where xu  xm are the user and movie embedding respectively and bu  bm    are the user  movie  and global bias 
respectively  We train the latent factor model by minimizing
the mean squared error between true rating   and predicted
rating     We use the trained xm as input representations for
the movies throughout our experiments 

  RESULTS

In Figure   we report the results of our active model against
various baselines  The Regression baseline performs regularized linear regression on movies from the support set
whose ratings have been observed incrementally in random
order  Because of the small amount of training data  for
each additional label we tune the regularization parameter
by monitoring performance on   separate set of validation
episodes  The Gaussian Process baseline selects the next
movie to label in proportion to the variance of the predictive posterior distribution over its rating  This gives an

Learning Algorithms for Active Learning

Figure   Experiment results for our model and baselines on Omniglot  The left plot shows how prediction accuracy improves with the
number of labels requested in   challenging  way setting  After   label requests  corresponding to    way   shot problem  the
active policy outperforms random policy and random MN baselines  but is inferior to the balanced MN  After   labels  the active policy
nearly matches the performance of the balanced MN using   labels  way   shot  The right plot shows the number of unique labels
with respect to the number of requested labels for models trained on problems with   classes  and tested on  way classi cation  This
gives an idea of how models search for labels from unseen groups and generalize to problems with different numbers of classes 

selects the unrated movie which differs most from the rated
movies  Entropy Sampling selects movies in proportion to
rating prediction entropy 
The active policy learned endto end outperforms the baselines in terms of RMSE  particularly after requesting only
the  rst few labels  After   ratings  our model achieves an
improvement of   in RMSE against the best baseline 
Unsurprisingly  the gap diminishes with   higher number
of labels requested  After observing   labels  the PopularEntropy baseline and our architecture equipped with the
MinMax Cos heuristic converge toward the active policy
but never quite match it  For MovieLens  where labels are
userdependent and not tied to an underlying class    datadriven selection policy may adapt better to the task  This
contrasts with the Omniglot setting  where there is no aspect of personalization and Active MN and MinMax Cos
perform similarly  The heuristic is designed not to select
items similar to those it has already seen  but doing so can
be bene cial in personalized settings  Elahi et al   

  Conclusion
We introduced   model that learns active learning algorithms
endto end  Our goal was to move away from engineered
selection heuristics towards strategies learned directly from
data  Our model leverages labeled instances from different
but related tasks to learn   selection strategy for the task at
hand  while simultaneously adapting its representation of
the data and its prediction function  We evaluated the model
on  active  variants of oneshot learning tasks for Omniglot 
demonstrating that its policy approaches an optimistic performance estimate  On   coldstart collaborative  ltering
task derived from MovieLens  the model outperforms several baselines and shows promise for application in more
realistic settings 

Figure   Performance of the model and baselines measured with
RMSE on the Movielens dataset 

idea of the impact of using MN oneshot capabilities rather
than standard regression techniques  The PopularEntropy 
MinMax Cos  Entropy Sampling baselines train our model
endto end  but using    xed selection policy  Speci cally 
we train our architecture endto end  but instead of training an active learning policy through the select module we
choose items from the support set incrementally according
to   heuristic policy  This gives an idea of the importance of
learning the selection policy  The PopularEntropy policy 
adapted from the coldstart work of Rashid et al     
priori scores each item in the support set according to the
logarithm of its popularity multiplied by the entropy of the
item   ratings measured across users  This strategy aims
to collect  rst the ratings for those movies that are both
popular and have been rated differently by different users 
Although it is simplistic  the policy achieves competitive
performance for bootstrapping   system from   coldstart
setting  Elahi et al    The MinMax Cos policy is
identical to the synonymous baseline used for Omniglot      
it selects the unrated movie which has minimum maximum
cosine similarity to any of the rated movies  Roughly  this

 Labelsrequested AccuracySupportset items classes items classMNbalanced shot MNbalanced shot MNrandomRandompolicyActivepolicy Labelsrequested UniquelabelsSupportset items classes items classOraclePolicyRandomPolicyActivePolicy   ActivePolicy   ActivePolicy   ActivePolicy   Numberoflabelsrequested RMSESupportset moviesRegressionGaussianProcessPopularEntropyMin MaxCosEntropySamplingActiveMNLearning Algorithms for Active Learning

References
Aggarwal  Charu    Recommender Systems  Springer   

Ba  Jimmy Lei  Kiros  Jamie Ryan  and Hinton  Geoffrey    Layer

normalization  arXiv preprint arXiv   

Chang  KaiWei  Krishnamurthy  Akshay  Agarwal  Alekh  III 
Hal Daum  and Langford  John  Learning to search better than
your teacher  International Conference on Machine Learning
 ICML   

Cohn  David    Ghahramani  Zoubin  and Jordan  Michael    Active learning with statistical models  Journal of arti cial intelligence research     

Elahi  Mehdi  Ricci  Francesco  and Rubens  Neil    survey of
active learning in collaborative  ltering recommender systems 
Computer Science Review     

GiladBachrach  Ran  Navot  Amir  and Tishby  Naftali  Query by
committee made real  In Proceedings of the  th International
Conference on Neural Information Processing Systems  pp   
  MIT Press   

Golbandi  Nadav  Koren  Yehuda  and Lempel  Ronny  On bootstrapping recommender systems  In Proceedings of the  th
ACM International Conference on Information and Knowledge
Management  CIKM    

Golbandi  Nadav  Koren  Yehuda  and Lempel  Ronny  Adaptive
bootstrapping of recommender systems using decision trees  In
Proceedings of the Fourth ACM International Conference on
Web Search and Data Mining  WSDM    

Hannun  Awni  Case  Carl  Casper  Jared  Catanzaro  Bryan 
Diamos  Greg  Elsen  Erich  Prenger  Ryan  Satheesh  Sanjeev  Sengupta  Shubho  Coates  Adam  and Ng  Andrew   
Deep speech  Scaling up endto end speech recognition  arXiv
preprint arXiv     

Harpale  Abhay   and Yang  Yiming  Personalized active learning
for collaborative  ltering  In Proceedings of the  st annual
international ACM SIGIR conference on Research and development in information retrieval  pp    ACM   

He  Kaiming  Zhang  Xiangyu  Ren  Shaoqing  and Sun  Jian 
Deep residual learning for image recognition  In Conference on
Computer Vision and Pattern Recognition  CVPR   

Hochreiter  Sepp and Schmidhuber    rgen  Long shortterm mem 

ory  Neural Computation     

Kawale  Jaya  Bui  Hung    Kveton  Branislav  TranThanh  Long 
and Chawla  Sanjay  Ef cient thompson sampling for online
matrixfactorization recommendation  In Advances in Neural
Information Processing Systems  NIPS   

Kingma  Diederik   and Ba  Jimmy  Adam    method for stochas 

tic optimization  arXiv     cs LG   

Koch  Gregory  Siamese neural networks for oneshot image

recognition  PhD thesis  University of Toronto   

Koren  Yehuda  Factor in the neighbors  Scalable and accurate collaborative  ltering  ACM Transactions on Knowledge Discovery
from Data  TKDD     

Krizhevsky  Alex  Sutskever  Ilya  and Hinton  Geoffrey    Imagenet classi cation with deep neural networks  In Advances in
Neural Information Processing Systems  NIPS   

Lake  Brenden    Salakhutdinov  Ruslan  and Tenenbaum 
Joshua    Humanlevel concept learning through probabilistic
program induction  Science     

Lewis  David   and Gale  William      sequential algorithm for
training text classi ers  In Proceedings of the  th annual international ACM SIGIR conference on Research and development
in information retrieval  pp    SpringerVerlag New York 
Inc   

Lika  Blerina  Kolomvatsos  Kostas  and Hadjiefthymiades 
Stathes  Facing the cold start problem in recommender systems 
Expert Systems with Applications     

Maas  Andrew    Hannun  Awni    and Ng  Andrew    Recti er nonlinearities improve neural network acoustic models 
International Conference on Machine Learning  ICML   

Rashid  Al Mamunur  Albert  Istvan  Cosley  Dan  Lam  Shyong   
McNee  Sean    Konstan  Joseph    and Riedl  John  Getting
to know you  learning new user preferences in recommender
systems  In Proceedings of the  th international conference on
Intelligent user interfaces  pp    ACM   

Rashid  Al Mamunur  Karypis  George  and Riedl  John  Learning
preferences of new users in recommender systems  an information theoretic approach  ACM SIGKDD Explorations Newsletter 
   

Ross  St phane and Bagnell     Andrew 

and imitation learning via interactive noregret
arXiv     cs LG   

Reinforcement
learning 

Hoi  Steven CH  Jin  Rong  Zhu  Jianke  and Lyu  Michael   
Batch mode active learning and its application to medical imIn Proceedings of the  rd international
age classi cation 
conference on Machine learning  pp    ACM   

Salimans  Tim and Kingma  Diederik    Weight normalization   
simple reparameterization to accelerate training of deep neural networks  In Advances in Neural Information Processing
Systems  NIPS   

Houlsby  Neil  Husz    Ferenc  Ghahramani  Zoubin  and Lengyel 
     Bayesian active learning for classi cation and preference
learning  arXiv preprint arXiv   

Houlsby  Neil  Hernandez  Jose  and Ghahramani  Zoubin  Coldstart active learning with robust ordinal matrix factorization  In
Proceedings of The  st International Conference on Machine
Learning  pp     

Santoro  Adam  Bartunov  Sergey  Botvinick  Matthew  Wierstra 
Daan  and Lillicrap  Timothy  Oneshot learning with memoryaugmented neural networks  arXiv preprint arXiv 
 

Sch lkopf  Bernhard and Smola  Alexander    Learning with
kernels  support vector machines  regularization  optimization 
and beyond   

Learning Algorithms for Active Learning

Schulman  John  Heess  Nicolas  Weber  Theophane  and Abbeel 
Pieter  Gradient estimation using stochastic computation graphs 
In Advances in Neural Information Processing Systems  NIPS 
   

Schulman  John  Moritz  Philipp  Levine  Sergey  Jordan 
Michael    and Abbeel  Pieter  Highdimensional continuous
control using generalized advantage estimation  In International
Conference on Learning Representations  ICLR     

Schuster     and Paliwal       Bidirectional recurrent neural

networks  Transactions on Signal Processing     

Settles  Burr  Active learning literature survey  University of

Wisconsin  Madison     

Sun  Mingxuan  Li  Fuxin  Lee  Joonseok  Zhou  Ke  Lebanon 
Guy  and Zha  Hongyuan  Learning multiplequestion decision
trees for coldstart recommendation  In Proceedings of the Sixth
ACM International Conference on Web Search and Data Mining 
WSDM      

Sun  Mingxuan  Li  Fuxin  Lee  Joonseok  Zhou  Ke  Lebanon 
Guy  and Zha  Hongyuan  Learning multiplequestion decision
trees for coldstart recommendation  In Proceedings of the sixth
ACM international conference on Web search and data mining 
pp    ACM     

Sun  Wen  Venkatraman  Arun  Gordon  Geoffrey    Boots  Byron 
and Bagnell    Andrew  Deeply aggrevated  Differentiable imitation learning for sequential prediction  International Conference
on Machine Learning  ICML   

Tong  Simon and Chang  Edward  Support vector machine active
learning for image retrieval  In Proceedings of the ninth ACM
international conference on Multimedia  pp    ACM 
 

Vinyals  Oriol  Blundell  Charles  Lillicrap  Tim  Wierstra  Daan 
et al  Matching networks for one shot learning  In Advances in
Neural Information Processing Systems  NIPS  pp   
 

Woodward  Mark and Finn  Chelsea  Active oneshot learning  In

NIPS Workshop   

Wu  Yonghui  Schuster  Mike  Chen  Zhifeng  Le  Quoc   
Norouzi  Mohammad  Macherey  Wolfgang  Krikun  Maxim 
Cao  Yuan  Gao  Qin  Macherey  Klaus  Klingner  Jeff  Shah 
Apurva  Johnson  Melvin  Liu  Xiaobing  Kaiser  Lukasz 
Gouws  Stephan  Kato  Yoshikiyo  Kudo  Taku  Kazawa  Hideto 
Stevens  Keith  Kurian  George  Patil  Nishant  Wang  Wei 
Young  Cliff  Smith  Jason  Riesa  Jason  Rudnick  Alex 
Vinyals  Oriol  Corrado  Greg  Hughes  Macduff  and Dean 
Jeffrey  Google   neural machine translation system  Bridging
the gap between human and machine translation  arXiv preprint
arXiv   

Zhang  Jiakai and Cho  Kyunghyun  Queryef cient imitation
learning for endto end autonomous driving  American Association for Arti cial Intelligence  AAAI   

Zilberstein  Shlomo  Using anytime algorithms in intelligent sys 

tems  AI magazine     

