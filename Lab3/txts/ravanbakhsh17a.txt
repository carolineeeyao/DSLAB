Equivariance Through ParameterSharing

Siamak Ravanbakhsh   Jeff Schneider   Barnab as   oczos  

Abstract

We propose to study equivariance in deep neural networks through parameter symmetries  In
particular  given   group  cid  that acts discretely
on the input and output of   standard neural net 

work layer      cid      cid     we show that   

is equivariant with respect to  cid action iff  cid  explains the symmetries of the network parameters
   Inspired by this observation  we then propose two parametersharing schemes to induce
the desirable symmetry on    Our procedure
for tying the parameters achieves  cid equivariance
and  under some conditions on the action of  cid 
it guarantees sensitivity to all other permutation
groups outside  cid 

Given enough training data    multilayer perceptron would
eventually learn the domain invariances in   classi cation
task  Nevertheless  success of convolutional and recurrent
networks suggests that encoding the domain symmetries
through shared parameters can signi cantly boost the generalization of deep neural networks  The same observation
can be made in deep learning for semisupervised and unsupervised learning in structured domains  This raises an
important question that is addressed in this paper  What
kind of priors on input output structure can be encoded
through parametersharing 
This work is an attempt at answering this question  when
our priors are in the form discrete domain symmetries  To
formalize this type of prior    family of transformations of
input and output to   neural layer are expressed as group
 action  on the input and output  The resulting neural network is invariant to this action  if transformations of the input within that particular family  does not change the output
      rotationinvariance  However  if the output is transformed  in   predictable way  as we transform the input 
the neural layer is equivariant to the action of the group 

 School of Computer Science  Carnegie Mellon University 
  Forbes Ave  Pittsburgh  PA  USA   Correspondence
to  Siamak Ravanbakhsh  mravanba cs cmu edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Our goal is to show that parametersharing can be used to
achieve equivariance to any discrete group action 
Application of group theory in machine learning has been
the topic of various works in the past       Kondor   
Bart ok et al    In particular  many probabilistic inference techniques have been extended to graphical models
with known symmetry groups  Raedt et al    Kersting et al    Bui et al    Niepert    Deep and
hierarchical models have used   variety of techniques to
study or obtain representations that isolate transformations
from the  content        Hinton et al    Jayaraman
  Grauman    Lenc   Vedaldi    Agrawal et al 
  The simplest method of achieving equivariance is
through dataaugmentation  Krizhevsky et al    Dieleman et al    Going beyond augmentation  several
methods directly apply the groupaction  in one way or another  by transforming the data or its encodings using group
members  Jaderberg et al    Anselmi et al   
Dieleman et al    An alternative path to invariance via
harmonic analysis  In particular cascade of wavelet transforms is investigated in  Bruna   Mallat    Oyallon  
Mallat    Sifre   Mallat    More recently  Cohen
  Welling      study steerable  lters       Freeman
et al    HelOr   Teo    as   general mean for
achieving equivariance in deep networks  Invariance and
equivariance through parametersharing is also discussed
in several prior works  Cohen   Welling      Gens  
Domingos   
The desirability of using parametersharing for this purpose
is mainly due to its simplicity and computational ef ciency 
However  it also suggests possible directions for discovering domain symmetries through regularization schemes 
Following the previous work on the study of symmetry in
deep networks  we rely on group theory and groupactions
to formulate invariances and equivariances of   function 
Due to discrete nature of parametersharing  our treatment
here is limited to permutation groups  Action of   permutation group  cid  can model discrete transformations of   set

of variables  such as translation and   rotation of pixels

around any center in an image  If the output of   function
transforms with    cid action as we transform its input with  
different  cid action  the function is equivariant with respect
to action of  cid  For example  in   convolution layer  as we
translate the input  the featuremaps are also translated  If

Equivariance Through ParameterSharing

and output variables respectively  Here  cid  is represented using its Cayley diagram 

Figure   Summary  given   group action on input and output of   neural network layer  de ne   parametersharing for this layer that is
equivariant to these actions 

 left   cid   cid  is   Dihedral group  acting on       input image and an output vector of size    cid  and  cid  denote the index set of input 
 middleleft   cid action for  cid   cid  is shown for an example input   cid action on the input is   combination of circular shifts  blue arrows 
 middleright  The structure   designed using our procedure  such that its symmetries  cid cid cid  subsumes the permutation group  cid cid cid 

and vertical  ips  red arrows  of the    image   cid  acts on the output indices  cid  only through circular shift    permutation group  cid cid cid 
encodes the simultaneous  action  of  cid  on input and output indices 

 right  the same structure   unfolded to   bipartite form to better show the resulting parametersharing in the neural layer  The layer is
equivariant to  cid action  shifting the input will shift the output of the resulting neural network function  while  ipping the input does not
change the output 

the output does not transform at all  the function is invariant
to the action of  cid  Therefore  invariance is   special equivariance  In this example  different translations correspond
to the action of different members of  cid 
The novelty of this work is its focus on the  model symmetry  as   gateway to equivariance  This gives us new
theoretical guarantees for    strict  notion of equivariance
in neural networks  The core idea is simple  consider   colored bipartite graph   representing   neural network layer 
Edges of the same color represent tied parameters  This
neural network layer as   function is equivariant to the actions of   given group  cid   and nothing more  iff the action
of  cid  is the symmetry group of          there is   simple
bijection between parameter symmetries and equivariences
of the corresponding neural network 
The problem then boils down to designing colored bipartite
graphs with given symmetries  which constitutes   major
part of this paper  Fig    demonstrates this idea 
For the necessary background on group theory see the Appendix  In the following  Section   formalizes equivariance
wrt discrete group action  Section   relates the model symmetries   neural layer to its equivariance  Section   then
builds on this observation to introduce two procedures for
parametersharing that achieves   desirable equivariance 

 Throughout this paper  since we deal with  nite sets  we use
circular shift and circular convolution instead of shift and convolution  The two can be made identical with zeropadding of the
input 

Here  we also see how group and graph convolution as well
as deepsets become special instances in our parametersharing procedure  which provides new insight and improved design in the case of group convolution  Where input and output of the layer have   oneto one mapping  we
see that the design problem reduces   wellknown problem
in combinatorics 

  Group Action and Equivariance

This group is   subgroup of the symmetric group  cid cid  the

Let              xN   cid   denote   set of variables and
 cid cid  be    nite group  The discrete action of  cid  on  
is in the form of permutation of indices in  cid            
group of all     permutations of   objects  We use cid   
             to denote the ordered counterpart to  cid  and the
 cid action on this vector  cid cid     cid           cid    is   simple
permutation  Using   
 cid   cid  on     cid   is given by  cid   
 cid     
ily isomorphic to  cid  itself   cid cid     cid  captures the structure
 cid   cid  in  cid cid   cid action is faithful iff two groups are isomorphic  cid   cid cid    that is  cid action preserves its structure 
In this case  each  cid     cid  maps to   distinct permutation
 cid cid     cid 
     cid  Given any  cid action on  cid  we can

of  cid  when it acts on  cid  We use  cid cid  to denote the image of

 cid action on  cid  is   permutation group that is not necessar 

to denote    the discrete action of

 cid cid   cid 

ef ciently obtain  cid cid  see Appendix 

 cid 

 

 cid 

 

 cid 

Equivariance Through ParameterSharing

the

For

cyclic

Example    Cyclic Group  Consider

same permutations of variables in         singlestep
of circular shift to the right  With the above action 
the resulting permutation group  cid cid  is isomorphic to

group  cid     cid  and de ne its action on      cid  by
de ning it on the index set  cid      as  cid     cid   
mod  cid     cid  This action is not faithful 
example  the action of  cid      and  cid      result in the
 cid   cid 
Now consider the same group  cid   cid  with   different
action on  cid   cid      cid    mod  cid     cid  where we
replaced  with  Let  cid cid  be the resulting permutation group  Here again  cid cid   cid  Although isomorphic 
 cid cid   cid cid  as they are different permutation groups of  cid 
Consider the function    cid      cid    and let  cid cid  and  cid cid 

We are now ready to de ne equivariance and invariance 

 cid cid  and  cid cid  can also be represented using permutation ma 

be the action of  cid  on input output index sets  cid  and  cid 
De nition   The joint permutation group  cid cid cid  is   subdirect product  or pairing  of  cid cid  and  cid cid 

 cid cid cid   cid cid   cid cid cid cid   cid cid   cid   cid 
  is  cid cid cid equivariant iff
 cid cid     cid cid         cid    cid cid   cid cid   cid cid cid 
Moreover  if  cid cid cid  is trivial  we have
 cid cid             cid      cid cid   cid cid 
and   is  cid cid invariant 
trices   cid         and   cid         EquivariG cid       cid       cid      cid    cid   cid cid cid   
Observation   If the function    cid      cid    is  cid cid cid 
mutation group  cid cid cid   cid 
cyclic group  cid     cid  and for  cid     cid  de ne the action
on  cid      to be  cid     cid    mod   Also let its
action on  cid                be  cid      cid    mod   In

The following observation shows that the subgroup relationship affects equivariance and invariance 

equivariant  then it is also  cid cid cid equivariant for any per 

Example    Reverse Convolution  Consider

ance relation of   then becomes

other words   cid action on  cid  performs circular shift to
the right and its action on  cid  shifts variables to the left 
Examples of the permutation matrix representation for

the

 

     

           
           
           
           
           

two members of  cid cid  and  cid cid  are

 cid       
     

corresponding to right and left shift on vectors of differ 

Using permutation matrices one could check the equivariance condition   for this function  We can show that

 cid             
 
ent lengths  Now consider the function    cid     cid  
      Wx WT             
                     cid 
  is equivariant to  cid cid cid  Consider    cid  and its images
 cid   cid cid  and  cid   cid cid         of   is
          
   
 cid                 
 
       
   
       
   cid         
              
for any    One could verify this equality for all  cid   cid 
Now consider the group  cid cid cid   cid cid cid  where  cid cid   cid cid 
and members of  cid cid          perform left circular
shift of length     and   It is easy to see that  cid cid cid 
 cid  Moreover since  cid cid cid   cid cid cid    above is  cid cid cid 

which is equal to its       

           
           
           
           
           

     
     
     
     
     

     
     
     
     
     

     
     
     
     
     

     
     
     
     
     

equivariant as well  However  one prefers to characterize
the equivariance properties of   using  cid cid cid  rather than
 cid cid cid 

           

     

The observation above suggests that  cid cid cid equivariance is
not restrictive enough  As an extreme case    constant func 

tion         is equivariant to any permutation group
 cid cid cid     cid cid   cid cid  In this case equivariance of   with reDe nition   we say   function      cid      cid    is
 not   cid equivariant for any  cid   cid 

spect to   particular  cid cid cid  is not very informative to us  To
remedy this  we de ne   more strict notion of equivariance 

uniquely  cid equivariant iff it is  cid equivariant and it is

  Symmetry Groups of   Network
Given   group  cid  and its discrete action through  cid cid cid  we
are interested in de ning parametersharing schemes for  
parametric class of functions that guarantees their unique
 cid cid cid equivariance  We start by looking at   single neural
layer and relate its unique  cid cid cid equivariance to the symmetries of   colored multiedged bipartite graph that de 

Equivariance Through ParameterSharing

to each edge  Nonexisting edges receive no color 

We are interested in the symmetries of this structure  The

each part of the bipartite graph  that preserve all edge 

 nes parametersharing  We then show that the idea extends to multiplelayers 

De nition     colored multiedged bipartite graph  
 cid   cid    is   triple  where  cid  and  cid  are its two sets of
nodes  and      cid   cid        is the edge function
that assigns multiple edgecolors from the set            
set of permutations cid   cid   cid cid   cid cid  of nodes  within
colors de ne the Automorphism Group  cid cid cid   cid cid 
 cid cid    that is        cid   cid 
 cid   cid   cid cid cid            cid     cid     
of binary relations between  cid  and  cid    that is    
 cid   cid        where each relation is associated with
one color                          cid   cid 
for  cid cid cid 
 cid   cid   cid cid cid   
             cid     cid                

Alternatively  to facilitate the notation  we de ne the same
structure  colored multiedged bipartite graph  as   set

This de nition of structure  gives an alternative expression

 

 

             

The signi cance of this structure is in that  it de nes  
parametersharing scheme in   neural layer  where the same
edgecolors correspond to the same parameters  Consider

the function                cid     cid  
       wcxn      
 
where    cid   cid  is   strictly monotonic nonlinearity and
            wc          wC  is the parametervector for this
       to the symmetries of  
Theorem   For any     cid        wc  wc       the
function        is uniquely  cid cid cid equivariant 
Corollary   For any  cid cid cid     cid cid cid 
       is  cid cid cid equivariant 

layer 
The following key theorem relates the equivariances of

the function

Example    Reverse Convolution  Revisiting
Example   we can show that
Theorem   holds 
parametersharing of the matrix   is visualized below 

In this case         and the
where we used two different line styles for        cid 

the condition of

In this  gure  the circular shift of variables at the output
and input level to the left and right respectively  does not
change the edgecolors  For example in both cases node
     connection to nodes       using dashedlines is
preserved 
Six repetitions of this action produces different permutations corresponding to six members of  cid cid cid  Therefore

 cid cid cid   cid cid cid  and according to Corollary     is

 cid cid cid  equivariant  Moreover  using Theorem   of the
next section  we can prove that these six permutations
are the  only  edgecolor preserving ones for this structure  resulting in unique equivariance 

multiple edges to   single edge 

Matrix Form  To write   in   matrix form  if there are
multiple edges between two nodes       we need to merge
them  In general  by assigning on distinct color to any set in

the range of    cid   cid      we can          reduce
rewrite   using     cid    
          Wx  Wm     
       wc
nonlinearity   Theorem   simply states that for all
 cid cid   cid cid   cid cid cid      cid   and   given by  

Using this notation  and due to strict monotonicity of the

In other words we can

 

  cid Wx  WG cid   

 

Example    PermutationEquivariant Layer 

Consider all permutations of indices  cid  and  cid   cid 

The implication is that to achieve unique equivariance for
  given groupaction  we need to de ne the parametersharing using the structure   with symmetry group  cid cid cid 

We want to de ne   neural layer such that all permu 

tations of the input  cid cid     cid cid     cid cid  result in the same

Equivariance Through ParameterSharing

lowing colored bipartite graph  for   special case where

permutation of the output  cid cid     cid cid  Consider the folN         It is easy to show that colorpreserving
permutations of this structure are  cid cid cid   cid cid   cid cid 
 cid   cid   cid   cid cid   cid cid  On one hand  for cid   cid 
 cid cid   cid cid  having  cid     cid  clearly preserves the colors 
On the other hand  if  cid   cid  there exists     cid   also in
 cid  such that  cid     cid    Therefore cid   cid  does not
preserve the relation            cid  corresponding to dashed edges  and therefore cid   cid   cid cid cid 
This proves  cid cid cid   cid cid   cid cid  The function   for
                 Ix    Tx 

this   is

Ravanbakhsh et al    Zaheer et al    derive
the same permutation equivariant layer  by proving the
commutativity in   while here it follows from Corollary  

Multiple Layers  For deep networks  the equivariance of

the composition     to  cid action follows from that of
individual layer    cid      cid    and    cid       cid    Asfollows that     is  cid cid cid equivariant  where  cid cid cid   
 cid cid   cid cid  This is because cid   cid  and     cid  
 cid cid     cid cid     cid cid   

suming   is  cid cid cid equivariant and   is  cid cid cid equivariant 
where  cid action on  cid  is shared between the two layers  it

 

  Structure Design
Consider the de nition of neural layer   that employs
parametersharing according to   Given  cid action on  cid 
and  cid  we are interested in designing structures   such

that  cid cid cid     cid cid cid  According to the Theorem   it

then follows that   is uniquely  cid cid cid equivariant  Here 
we give the suf cient conditions and the design recipe to
achieve this 
For this we brie   review some group properties that are
used in later developments 

regularity The group action is free or semiregular iff

transitivity We say that  cid action on  cid  is transitive iff

          cid  there exists at least one action  cid     cid 
 or  cid cid   cid cid  such that  cid      
          cid  there is at most one  cid     cid  such at
 cid       and the action is regular iff it is both transitive and free        for any pair        cid  there is
uniquely one  cid   cid  such that  cid       Any free ac 
 cid cid  That is we call  cid cid  semiregular iff        cid  at

tion is also faithful  We use   similar terminology for

this number is exactly one 

fore  for   semiregular  cid action  the action of  cid  on

where np is an arbitrary representative of the parti 

most one  cid cid   cid cid  moves    to    and  cid cid  is regular if
orbit The orbit of      cid  is all the members to which it
can be moved   cid      cid      cid     cid  The orbits of
    cid  form an equivalence relation  This equivalence
relation partitions  cid  into orbits  cid          cid np 
tion  cid np   cid  Note that the  cid action on  cid  is always
transitive on its orbits   that is for any          cid np 
there is at least one  cid   cid  such that     cid    Therethe orbits  cid np       is regular 
Example    Mirror Symmetry  Consider  cid   cid 
 cid                  acting on  cid  where the
 cid                             
sitive          cannot be moved to      If   is even 
the element in the middle     
  is moved to itself by
two different actions  cid     cid  Furthermore  if   is even 
larly  If   is odd   cid action has   
  orbits  However  its
  is not
action on the orbit of the middle element  cid   

 cid  is faithful in its action on  cid  however  cid cid  is not tran 

then  cid action is semiregular  This is because otherwise

only nontrivial action is de ned as  ipping the input 

  orbits and  cid  acts on these orbits regu 

 cid action has  

regular 

In the following  Section   proposes   procedure for
parametersharing in   fully connected layer  Although
simple 
this design is dense and does not guarantee
 unique  of equivariance  Section   proposes an alternative design with sparse connections that in some settings ensures unique equivariance  Section   investigates
the effect of having multiple input and output channels in
the neural layer and Section   studies   special case of

 cid cid     cid cid  where input and output indices have   oneto 

one mapping 

  Dense Design

each orbit with   different color gives

Consider   complete bipartite graph with  cid  and  cid  as its two

parts and edges        cid   cid  The action of  cid cid cid  partitions the edges into orbits cid cid cid np  mq np mq  where
 np  mq  is   representative edge from an orbit  Painting
Therefore two edges       and       have the same
     

 cid   cid       cid cid cid np  mq 
   cid   
   
 cid           cid  

color iff an action in  cid cid cid  moves one edge to the other 

      cid  

 

Equivariance Through ParameterSharing

Proposition    cid cid cid    for   of  
Corollary          for structure   is equivariant

to  cid cid cid 

smaller groups it could be very inef cient in practice  as
sometimes we can achieve equivariance through   sparse
structure   As an example  consider the    circular convolution layer  It is easy to show that according to this design  the convolution  lter will be the same size as the input
image  While this achieves the desirable equivariance  it is
inef cient and does not generalize as well as   convolution
layer with small  lters  Moreover  the dense design does
not guarantee  unique  equivariance  We next show under
some conditions on  cid cid cid  the sparse design can produce this
stronger guarantee 

  Sparse Design

Our sparse construction uses orbits and symmetric generating sets 

  Let us denote the orbits of  cid action on  cid  and  cid  by

 cid np          and cid mq           respec 

tively  where   and   are the total number of orbits
and np mq are  arbitrary  representative members of
orbits  cid np   cid mq respectively  Note that in contrast to
previous section  here we are considering the orbit of
variables rather than the edges 

  The set  cid     cid  is called the generating set of  cid   
 cid   cid  iff every member of  cid  can be expressed as
   cid  we call it  
is closed under inverse  cid   cid   cid 

  combination of members of  cid  If the generating set

symmetric generating set 

layer

indexing for the input

Example    Nested Subsets and Wreath Product 
The permutationequivariant
that we saw in
Example   is useful for de ning neural layers for set
structure  If our datastructure is in the form of nested
subsets  then we require equivariance to permutation
of variables within each set as well as permutation of
subsets  Here  we show how to use our dense design for
this purpose 
We use   special
to better
identify the exchangeability of variables  We as 

sume   subsets  each of which has   variables    
                            xD   
The group of our interest is the wreath product  cid   
We use       to index input variables and       for
sharing for an example with          

 cid    This type of group product can be used to build
hierarchical and nested structures with different type of
symmetries at each level  Nesting subsets corresponds to
the most basic form of such hierarchical constructions 

output variables 
The following  gure shows the resulting parameter 

How did we arrive at this structure   Recall Our

objective is to de ne parametersharing so that     
 cid dD    cid dD is equivariant to the action of  cid   
 cid      cid          permutations within sets at two levI                  
ange  II                      connects each
                is the set of edges from one

els  This groupaction identi es three partitions of
edges  seen in the  gure 
connects each variable to its counterpart  dashed or 

variable to other variables within the same subset  III 

subset to another  According to the Corollary   this
parametersharing guarantees equivariance 

This fullyconnected design is useful when the group  cid cid cid 
is large  for example when dealing with  cid cid  However  for

 

De ne the structure   as

In words  we have one color per each combination of or 

 cid   cid     cid           cid cid 
     cid cid cid cid np   cid cid mq cid cid   cid cid   cid cid cid 
bits        and members of the generating set  cid   cid  The
Theorem    cid cid cid     cid cid cid  for   of   Moreover if  cid cid  and  cid cid  are both semiregular  then  cid cid cid   
 cid cid cid 

following theorem relates the symmetry group of this structure to  cid 

Note that this result holds for any choice of   symmetric
generating set  cid  in de ning   Therefore  in designing
sparse layers  one seeks   minimal  cid 

Corollary   The function        using the structure

  is  cid cid cid equivariant  If  cid cid  and  cid cid  are semiregular 
this function is  uniquely   cid cid cid equivariant 

Equivariance Through ParameterSharing

wq   cid   cid cid cid np 

pression   of the structured neural layer for the structure

Now  assuming  cid action is semiregular on both  cid  and  cid 

using  arbitrarily chosen  representatives  np     and
 mq     for orbits in  cid  and  cid  we can rewrite the exabove  Here  components of                   are enumerated for          cid cid   cid cid 
 cid cid mq          
 
    
 cid cid 

where      cid     cid  is the set of unique parameters 
ters  wq   cid   cid  identi ed by   and   subset of inputs
   cid cid cid np   cid  identi ed by  cid cid 
      and for  cid  this is      The symmetric gener 

Example    Dihedral Group of Fig    In the example of Fig    the number of orbits of  cid action on  cid  is

and each element  cid cid mq depends on subset of parame 

 

ating set is the generating set that is used in the Cayley
diagram  with the addition of inverse shift  inverse of the
blue arrow  We then used   to build the structure of
Fig     right 

The important implication is that  orbits and multiple
channels are treated identically by both dense and
sparse designs 

Example    Group Convolution  The idea of groupconvolution is studied by Cohen   Welling     see
also  Olah    The following claim relates the function of this type of layer to our sparse design 

Claim   Under the following conditions the neural
layer   using our sparse design   performs group
convolution     there is   bijection between the output

and  cid         cid   cid  and  II   cid cid  is transitive 
even in the setting where  cid     cid  When  cid cid  is semiregular and not transitive        group convolution

This also identi es the limitations of groupconvolution

is not guaranteed to be uniquely equivariant while the
sparse parametersharing of   provides this guarantee 
For demonstration consider the following example in
equivariance to mirror symmetry 

This  gure shows the bipartite structure for  cid     cid   
    and  cid     cid action is horizontal  ip of the
input and the output  On the right   cid   cid  while on the

left  cid cid action has two orbits  Orbits are identi ed by
linestyle and color of the circles  In   neural layer with
this parametersharing  when we  ip the input variables
 around the mirror line  the output is also  ipped 
The representatives in each orbit on  cid  and  cid  is identi ed with   star  Note that each combination of orbits
  and   has   parameter of its own  identi ed with different edgestyles  While this construction guarantees
 unique   cid equivariance  if instead we use the same
parameters across orbits  as suggested by the original
group convolution  we get the parametersharing of the
 gure below middle 

Example    Reverse Convolution  The parametersharing structure of reverse convolution in Examples  
and   is produced using our sparse design  In these
examples  both  cid cid  and  cid cid  are regular  Therefore
unique
the
proposed
equivariance 

parametersharing

provides

  Multiple Channels

 

nels 

network layer    cid      cid     Here  we want to see how
In this section  we extend our results to multiple input and
to achieve  cid cid cid equivariance for      cid        cid    
output channels  Up to this point  we considered   neural
 
where   and    are the number of input and output chanFirst  we extend the action of  cid  on  cid  and  cid  to  cid    
 cid           cid 
 
subdirect product  cid cid         cid cid 
 

nels  For this  simply repeat the  cid action on each component   cid action on multiple input channels is equivalent to

   cid cid  The same applies

  as well as  cid  

  to accommodate multiple chan 

Ktimes

 

Ktimes

to  cid cid 
This repetition  multiplies the orbits of  cid cid  one for each
channel  so that instead of having   and   orbits on the

input  cid  and output  cid  sets  we have      and     
number of parameters by   factor of      

orbits on the input  cid   and output  cid  

  This increases the

 

Equivariance Through ParameterSharing

cyclic group  cid  on eight input output variables   that is

Multiples of  rotation is produced as the action of
 cid   cid             cid action is semiregular with two
consists of  cid    rotation by   and its inverse 
rotation by   Each edge in each of these  gures  has

orbits  these orbits the two inner and outer set of four
nodes  The representatives of each orbit in our sparse design is indicated using  lled circles  The generating set

  corresponding edge in the opposite direction  within  
different relation  To avoid overcrowding the  gure  we
have dropped this edge from the drawing above  unless
both edges belong to the same relation 

In this case  the resulting neural layer has the desired
equivariance  right  However  it is equivariant to the

  in the second  cid  group exchanges variables across the
orbits on  cid   left in  gure above 

action of   larger group  cid cid cid   cid   cid   cid  in which
   cid cid   cid cid 
xn      cid    that is  cid     cid  We can ensure this by having   relation                     cid  in   that guarantees any cid   cid   cid cid cid  applies the same permutation
to  cid  and  cid   cid          cid     cid  The resulting structure
 cid   cid          can be also interpreted as
cause we can collapse the two parts by identifying     cid 
with     cid 

In semisupervised and unsupervised applications  we often need to produce   single output yn for each input

  colored multiedged directed graph  digraph  This is be 

Therefore  the symmetrygroup of the original bipartite
structure 
is isomorphic to symmetry group of   colored multiedged digraph on  cid  Achieving unique  cid 
equivariance then reduces to answering the following ques 

tion  when could we express   permutation group  cid   cid cid 
as the symmetry group  cid cid cid  of   colored multiedged

digraph with   nodes 
This problem is wellstudied under the class of concrete
representation problems  Babai   
Permutation
groups  cid  that can be expressed in this way are called  
closed groups  Wielandt    The recipe for achieving

 cid cid   cid cid cid  is similar to our dense construction of Secest permutation group  cid cid   cid cid  with the same orbit on  cid cid 
tion groups are  closed  cid cid   cid cid  This result also follows
Example    Equivariance to  Rotations 

tion   The  closure  cid cid  of   group  cid cid  is then  the great 

as  cid cid  It is known that for example semiregular permuta 

  corollary of our Theorem   for sparse design of  

Figure below compares the digraph representation of  
produced using  left  our sparse design  and  right  our
dense design 

same orbit by  cid action on  cid   cid  receive the same color 

 In   fully connected digraph  the edges that belong to the

Example    Graph Convolution  Consider the setting where we use the  normalized  adjacency matrix

         or Laplacian  of   graph   to identify
where     cid   and             has different param 

parametersharing in   neural network layer  For   single input output channel  this is often in the form of Ax 

eters for diagonal and offdiagonal values       Kipf  
Welling    Bruna et al    Henaff et al   
for multiple channels see Section   The following
corollary of Theorem   identi es the equivariance of
Ax 

Corollary   Given the digraph   and its binary ad 

jacency matrix           then            is

uniquely equivariant to the symmetrygroup of  

Since two graphs on   nodes can have identical symmetries  one implication of this corollary is that graphconvolution has identical equivariances for graphs with
the same symmetry groups 

  Conclusion
This work is   step towards designing neural network layers
with   given equivariance and invariance properties  Our
approach was to relate the equivariance properties of the
neural layer to the symmetries of the parametermatrix 
We then proposed two parametersharing scheme that
achieves equivariance wrt any discrete groupaction  Moreover under some conditions  we guarantee sensitivity wrt
other group actions  This is important because even   trivial constant function is invariant to all transformations  It
is therefore essential to be able to draw the line between
equivariance invariance and sensitivity in   function  To
our knowledge  our work presents the  rst results of its
kind on guarantees regarding both variance and equivariance with respect to group actions 

Equivariance Through ParameterSharing

Acknowledgment
This
DESC  and NSF grant IIS 

research is

supported in part by DOE grant

References
Agrawal  Pulkit  Carreira  Joao  and Malik  Jitendra 
Learning to see by moving  In Proceedings of the IEEE
International Conference on Computer Vision  pp   
   

Anselmi  Fabio  Leibo  Joel    Rosasco  Lorenzo  Mutch 
Jim  Tacchetti  Andrea  and Poggio  Tomaso  Unsupervised learning of invariant representations in hierarchical
architectures  arXiv preprint arXiv   

Babai  Laszlo  Automorphism groups  isomorphism  reconstruction  chapter   of the handbook of combinatorics  University of Chicago   

Bart ok    abor  Szepesv ari  Csaba  and Zilles  Sandra 
Models of active learning in groupstructured state
spaces  Information and Computation   
 

Bruna  Joan and Mallat  St ephane  Invariant scattering convolution networks  IEEE transactions on pattern analysis and machine intelligence     

Bruna  Joan  Zaremba  Wojciech  Szlam  Arthur  and LeCun  Yann  Spectral networks and locally connected networks on graphs  arXiv preprint arXiv   

Bui  Hung Hai  Huynh  Tuyen    and Riedel  Sebastian 
Automorphism groups of graphical models and lifted
variational inference  arXiv preprint arXiv 
 

Cohen  Taco   and Welling  Max  Group equivariant convolutional networks  arXiv preprint arXiv 
   

Cohen  Taco   and Welling  Max  Steerable cnns  arXiv

preprint arXiv     

Dieleman  Sander  Willett  Kyle    and Dambre  Joni 
Rotationinvariant convolutional neural networks for
galaxy morphology prediction  Monthly notices of the
royal astronomical society     

Dieleman  Sander  De Fauw  Jeffrey  and Kavukcuoglu 
Koray  Exploiting cyclic symmetry in convolutional neural networks  arXiv preprint arXiv   

Freeman  William    Adelson  Edward    et al  The design
and use of steerable  lters  IEEE Transactions on Pattern analysis and machine intelligence   
 

Gens  Robert and Domingos  Pedro    Deep symmetry
networks  In Advances in neural information processing
systems  pp     

HelOr  Yacov and Teo  Patrick      common framework
for steerability  motion estimation  and invariant feature
detection  In Circuits and Systems    ISCAS  Proceedings of the   IEEE International Symposium on 
volume   pp    IEEE   

Henaff  Mikael  Bruna  Joan  and LeCun  Yann  Deep
convolutional networks on graphstructured data  arXiv
preprint arXiv   

Hinton  Geoffrey    Krizhevsky  Alex  and Wang  Sida   
In International ConferTransforming autoencoders 
ence on Arti cial Neural Networks  pp    Springer 
 

Jaderberg  Max  Simonyan  Karen  Zisserman  Andrew 
In Advances in
et al  Spatial transformer networks 
Neural Information Processing Systems  pp   
 

Jayaraman  Dinesh and Grauman  Kristen  Learning image representations equivariant to egomotion  In Proc 
ICCV   

Kersting  Kristian  Ahmadi  Babak  and Natarajan  Sriraam  Counting belief propagation  In Proceedings of
the TwentyFifth Conference on Uncertainty in Arti cial
Intelligence  pp    AUAI Press   

Kipf  Thomas   and Welling  Max  Semisupervised clasarXiv

si cation with graph convolutional networks 
preprint arXiv   

Kondor  Risi  Group theoretical methods in machine learn 

ing  Columbia University   

Krizhevsky  Alex  Sutskever  Ilya  and Hinton  Geoffrey   
Imagenet classi cation with deep convolutional neural
networks  In Advances in neural information processing
systems  pp     

Lenc  Karel and Vedaldi  Andrea  Understanding image representations by measuring their equivariance and
equivalence  In Proceedings of the IEEE conference on
computer vision and pattern recognition  pp   
 

Niepert  Mathias  Markov chains on orbits of permutation

groups  arXiv preprint arXiv   

Olah  Christopher 

Groups

and group convoluhttp colah github io posts 

tions 
 GroupsConvolution   

Equivariance Through ParameterSharing

Oyallon  Edouard and Mallat  St ephane  Deep rotoIn Protranslation scattering for object classi cation 
ceedings of the IEEE Conference on Computer Vision
and Pattern Recognition  pp     

Raedt  Luc De  Kersting  Kristian  Natarajan  Sriraam  and
Poole  David  Statistical relational arti cial intelligence 
Logic  probability  and computation  Synthesis Lectures
on Arti cial Intelligence and Machine Learning   
   

Ravanbakhsh  Siamak  Schneider  Jeff  and Poczos  Barnabas  Deep learning with sets and point clouds  arXiv
preprint arXiv   

Sifre  Laurent and Mallat  St ephane  Rotation  scaling and
deformation invariant scattering for texture discrimination  In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pp   
 

Wielandt     Permutation groups through invariant relations and invariant functions  Dept  of Mathematics 
Ohio State University   

Zaheer  Manzil  Kottur  Satwik  Ravanbakhsh  Siamak 
Poczos  Barnabas  Salakhutdinov  Ruslan  and Smola 
Alexander    Deep sets  CoRR  abs   
URL http arxiv org abs 

