Improving Viterbi is Hard 

Better Runtimes Imply Faster Clique Algorithms

Arturs Backurs   Christos Tzamos  

Abstract

The classic algorithm of Viterbi computes the
most likely path in   Hidden Markov Model
 HMM  that results in   given sequence of observations  It runs in time        given   sequence of   observations from   HMM with  
states  Despite signi cant interest in the problem and prolonged effort by different communities  no known algorithm achieves more than  
polylogarithmic speedup  In this paper  we explain this dif culty by providing matching conditional lower bounds  Our lower bounds are based
on assumptions that the best known algorithms
for the AllPairs Shortest Paths problem  APSP 
and for the MaxWeight kClique problem in
edgeweighted graphs are essentially tight  Finally  using   recent algorithm by Green Larsen
and Williams for online Boolean matrixvector
log    speedup for
multiplication  we get    
the Viterbi algorithm when there are few distinct
transition probabilities in the HMM 

 

  Introduction
  Hidden Markov Model  HMM  is   simple model that
describes   random process for generating   sequence of
observations    random walk is performed on an underlying graph  Markov Chain  and  at each step  an observation
is drawn from   probability distribution that depends only
on the current state  the node in the graph 
HMMs are   fundamental statistical tool and one of the
most important questions in the applications of HMMs is
computing the most likely sequence of states visited by the
random walk in the HMM given the sequence of observations  Andrew Viterbi proposed an algorithm  Viterbi 
  for this problem that computes the solution in

Authors ordered alphabetically 

 MIT  US  Correspondence to  Arturs Backurs  backurs mit edu  Christos Tzamos
 tzamos mit edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

       time for any HMM with   states and an observation sequence of length     This algorithm is known as the
Viterbi algorithm and the problem of computing the most
likely sequence of states is also known as the Viterbi Path
problem 
The Viterbi algorithm has found wide applicability in machine learning  It is an important tool for structured prediction  used      for structured perceptrons  Collins   
Other applications include speech recognition  Rabiner 
  Ne an et al    Bengio    partof speech
tagging  Collins    action planning  Attias   
emotion recognition  Cohen et al    human activity
classi cation  Mannini   Sabatini    and waveform
classi cation  Kim   Smyth    Furthermore  it is often combined with other methods  For example    combination of the Viterbi algorithm and neural networks is
used for speech recognition  Mohamed et al    AbdelHamid et al    Bourlard   Morgan    handwriting recognition and protein secondary structure prediction  Lin et al    Peng et al    It also can be combined with Support Vector Machines  Altun et al   
Finally  the Viterbi algorithm is used as   module in Graph
Transformer Networks  with applications to speech recognition  LeCun et al    Collobert   
The quadratic dependence of the algorithm   runtime on
the number of states is   longstanding bottleneck that limits its applicability to problems with large state spaces 
particularly when the number of observations is large   
lot of effort has been put into improving the Viterbi algorithm to lower either the time or space complexity  Many
works achieve speedups by requiring structure in the input  either explicitly by considering restricted classes of
HMMs  Felzenszwalb et al    Siddiqi   Moore   
or implicitly by using heuristics that improve runtime in
certain cases  Esposito   Radicioni    Kaji et al 
  For the general case  in  Lifshits et al    Mahmud   Schliep    it is shown how to speed up the
Viterbi algorithm by   log    when the number of distinct
observations is constant using the Four Russians method
or similar ideas  More recently  in  Cairo et al   
the same logarithmic speedup was shown to be possible
for the general case  Despite signi cant effort  only log 

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

Alphabet size
 
    for any constant      

    
    
     when          unary 

Lower Bound Complexity
Theorem  
Theorem  
Theorem  
Upper Bound Complexity
 
Theorem  

    

log   

Alphabet size
Any

Assumption
APSP Conjecture
kClique Conjecture
APSP Conjecture
Assumption
 
probabilities in HMM

log   distinct

 

transition

Table   Summary of our upper and lower bounds for the Viterbi Path problem    is the number of states in the underlying
HMM and   is the number of observations  For   sparse HMM with   nonzero transition probabilities  we show   tight
lower bound of      see Theorems     and   in Section  

arithmic improvements are known other than in very special cases  In contrast  the memory complexity can be reduced to almost linear in the number of states without signi cant overhead in the runtime  Grice et al    Tarnas
  Hughey    Churbanov   WintersHilt   
In this work  we attempt to explain this apparent barrier for
faster runtimes by giving evidence of the inherent hardness
of the Viterbi Path problem  In particular  we show that getting   polynomial speedup  would imply   breakthrough
for fundamental graph problems  Our lower bounds are
based on standard hardness assumptions for the AllPairs
Shortest Paths and the MinWeight kClique problems and
apply even in cases where the number of distinct observations is small 
Before formally stating our results  let us give some background on the MinWeight kClique problem  This fundamental graph problem asks to  nd the minimum weight
kclique in the given undirected weighted graph on   nodes
and      weighted edges  This is the parameterized version of the NPhard MinWeight Clique problem  Karp 
  The MinWeight kClique is amongst the most wellstudied problems in theoretical computer science  and it is
the canonical intractable problem in parameterized complexity 
  naive algorithm solves the MinWeight kClique in
  nk  time and the best known algorithm still runs in
  nk    for any constant    Obtaining   signi cantly
faster algorithm for this problem is   longstanding open
question 
  conjecture in graph algorithms and parameterized complexity is that it there is no   nk  algorithm for any
constant       The special case of the conjecture with
      says that  nding the minimum weight triangle
in   weighted graph cannot be solved in      time
for any constant       There are many negative results that intuitively support this conjecture    truly sub 

cubic algorithm for MinWeight  Clique implies such algorithm for the AllPairs Shortest Paths as well  Williams
  Williams    The latter is   well studied problem
and no truly subcubic algorithm is known for it despite
signi cant effort  Williams    Unconditional lower
bounds for kClique are known for various computational
models  such as  nk  for monotone circuits  Alon   Boppana    The planted Clique problem has also proven
to be very challenging        Alon et al      Hazan
  Krauthgamer    Jerrum    MaxClique is also
known to be hard to ef ciently approximate within nontrivial factors    stad   
We complement our lower bounds with an algorithm for
Viterbi Path that achieves speedup  
log    when there
are few distinct transition probabilities in the underlying
HMM  We summarize our results in Table  

 

Our results and techniques Our  rst lower bound shows
that the Viterbi Path problem cannot be computed in time
       for   constant       unless the APSP conjecture is false  The APSP conjecture states that there is
no algorithm for the AllPairs Shortest Paths problem that
runs in truly subcubic  time in the number of vertices of the
graph  We obtain the following theorem 
Theorem   The VITERBI PATH problem requires
        time assuming the APSP Conjecture 

The proof of the theorem gives   reduction from AllPairs
Shortest Paths to the Viterbi Path problem  This is done
by encoding the weights of the graph of the APSP instance
as transition probabilities of the HMM or as probabilities
of seeing observations from different states  The proof requires   large alphabet size         large number of distinct
observations  which can be as large as the number of total
steps    
  natural question question to ask is whether there is  
faster algorithm that solves the Viterbi Path problem when

 Getting an algorithm running in time  say       

 Truly subcubic means      for constant      

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

the alphabet size is much smaller than     say when       
and the alphabet size is    We observe that in such   case 
the input size to the Viterbi Path problem is only     
we only need to specify the transition probabilities of the
HMM  the probabilities of each observation in each state
and the sequence of observations  The Viterbi algorithm
in this setting runs in             time  Showing
  matching APSP based lower bound seems dif cult because the runtime in this setting is quadratic in the input
size while the APSP conjecture gives only     hardness
for input size    To our best knowledge  all existing reduction techniques based on the APSP conjecture do not
achieve such an ampli cation of hardness  In order to get
  lower bound for smaller alphabet sizes  we need to use  
different hardness assumption 
For this purpose  we consider the kClique conjecture  It
is   popular hardness assumption which states that it is
not possible to compute   minimum weight kclique on an
edgeweighted graph with   vertices in time   nk  for
constant   and       With this assumption  we are able
to extend Theorem   and get the following lower bound for
the Viterbi Path problem on very small alphabets 
Theorem   For any          the VITERBI PATH problem on      nC  observations from an alphabet of size
    requires         time assuming the kClique
Conjecture for      cid   

   cid     

To show the theorem  we perform   reduction from the
MinWeight kClique problem  Given   MinWeight kClique instance  we create an HMM with two special
nodes    start node and an end node  and enforce the following behavior of the optimal Viterbi path  Most of the
time it stays in the start or end node  except for   small
number of steps  during which it traverses the rest of the
graph to move from the start to the end node  The time at
which the traversal happens corresponds to   clique in the
original graph of the MinWeight kClique instance  We
penalize the traversal according to the weight of the corresponding kclique and thus the optimal path will  nd the
minimum weight kclique  Transition probabilities of the
HMM and probabilities of seeing observations from different states encode edgeweights of the MinWeight kClique
instance  Further  we encode the weights of smaller cliques
into the sequence of observations according to the binary
expansion of the weights 
Our results of Theorems   and   imply that the Viterbi algorithm is essentially optimal even for small alphabets  We
also study the extreme case of the Viterbi Path problem
with unary alphabet where the only information available
is the total number of steps     We show   surprising behavior  when       the Viterbi algorithm is essentially optimal  while there is   simple much faster algorithm when
       See Section   for more details 

 

We complement our lower bounds with an algorithm for
Viterbi Path that achieves speedup  
log    when there
are few distinct transition probabilities in the underlying
HMM  Such   restriction is mild in applications where one
can round the transition probabilities to   small number of
distinct values 

 

log   distransition probabilities for   constant      
log    randomized algorithm for the

Theorem   When there are fewer than  
tinct
there is       
VITERBI PATH problem that succeeds whp 

 

We achieve this result by developing an algorithm for
online  min    matrixvector multiplication for the case
when the matrix has few distinct values  Our algorithm is
presented in Section   and is based on   recent result for online Boolean matrixvector multiplication by Green Larsen
and Williams  Larsen   Williams   
The results we presented above hold for dense HMMs  For
sparse HMMs that have at most   edges out of the    possible ones      
the transition matrix has at most   nonzero probabilities  the VITERBI PATH problem can be easily solved in        time  The lower bounds that we presented above can be adapted directly for this case to show
that no faster algorithm exists that runs in time       
See the corresponding discussion in Section  

  Preliminaries
Notation For
               by    

an integer    we denote

the

set

De nition    Hidden Markov Model    Hidden Markov
Model  HMM  consists of   directed graph with   distinct
hidden states     with transition probabilities          of
going from state   to state    In any given state  there is
  probability distribution of symbols that can be observed
and          gives the probability of seeing symbol   on
state    The symbols come from an alphabet   of size
  An HMM can thus be represented by   tuple          

  The Viterbi Path Problem

Given an HMM and   sequence of   observations  the
Viterbi algorithm  Viterbi    outputs   sequence of  
states that is most likely given the   observations  More
precisely  let                 sT   be the given sequence of
  observations where symbol st     is observed at time
                  Let ut       be the state of the HMM at time
                  The Viterbi algorithm  nds   state sequence
                   uT   starting at        that maximizes
Pr      The problem of  nding the sequence   is known
as the Viterbi Path problem  In particular  the Viterbi Path

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

problem solves the optimization problem

 cid     ut  ut       ut  st 
 cid 

 

  cid 

  

arg max

    uT

The Viterbi algorithm solves this problem in        by
computing for               the best sequence of length
  that ends in   given state in   dynamic programming
fashion  When run in   word RAM model with   log   
bit words  this algorithm is numerically unstable because
even representing the probability of reaching   state requires linear number of bits  Therefore  log probabilities
are used for numerical stability since that allows to avoid
under ows  Young et al    Amengual   Vidal   
Li   Tang    Lee et al    Huang et al   
To maintain numerical stability and understand the underlying combinatorial structure of the problem  we assume
that the input is given in the form of logprobabilities      
the input to the problem is             log          and
            log          and focus our attention on the
Viterbi Path problem de ned by matrices   and   
De nition    Viterbi Path Problem  The VITERBI PATH
problem is speci ed by   tuple           where   and  
are       and       matrices  respectively  and    
            sT   is   sequence of        observations
           sT     over an alphabet of size   Given an instance           of the VITERBI PATH problem  our goal
is to output   sequence of vertices               uT      
with        that solves

  cid 

  

arg min

    uT

   ut  ut      ut  st   

We can assume that log probabilities in matrices   and  
are arbitrary positive numbers without the restriction that
the corresponding probabilities must sum to   See Appendix   for   discussion 
  simpler special case of the VITERBI PATH problem asks
to compute the most likely path of length   without any
observations 
De nition    Shortest Walk Problem  Given an integer
  and   weighted directed graph  with possible selfloops 
on   vertices with edge weights speci ed by   matrix    the
SHORTEST WALK problem asks to compute   sequence of
vertices                   uT       that solves

  cid 

  

arg min

    uT

  ut  ut 

It is easy to see that the SHORTEST WALK problem corresponds to the VITERBI PATH problem when       and
           for all        

  Hardness assumptions

We use the hardness assumptions of the following problems 
De nition    ALLPAIRS SHORTEST PATHS
 APSP 
problem  Given an undirected graph            with  
vertices and positive integer weights on the edges   nd the
shortest path between   and   for every           

that

APSP

states
problem

conjecture
The
ALLPAIRS SHORTEST PATHS
      time in expectation 
Conjecture
The
 APSP
ALLPAIRS SHORTEST PATHS problem on   graph
with   vertices and positive integer edgeweights bounded
by nO  requires       time in expectation 

the
requires

conjecture 

 

There is   long list of works showing conditional hardness
for various problems based on the AllPairs Shortest Paths
conjecture  Roditty   Zwick    Williams   Williams 
  Abboud   Williams    Abboud et al       
De nition    MINWEIGHT kCLIQUE problem  Given  
complete graph            with   vertices and positive integer edgeweights  output the minimum total edgeweight
of   kclique in the graph 

This is   very well studied computational problem and despite serious efforts  the best known algorithm for this problem still runs in time   nk    which matches the runtime of the trivial algorithm up to subpolynomial factors 
The kClique conjecture states that this problem requires
 nk    time and it has served as   basis for showing conditional hardness results for several problems on
sequences  Abboud et al        Bringmann et al 
  and computational geometry  Backurs et al   
Conjecture
The
MINWEIGHT kCLIQUE problem on   graph with  
vertices and positive integer edgeweights bounded by
nO    requires  nk    time in expectation 

conjecture 

 kClique

 

For       the MINWEIGHT  CLIQUE problem asks to
 nd the minimum weight triangle in   graph  This problem is also known as the MINIMUM TRIANGLE problem
and under the  Clique conjecture it requires      
time  The latter conjecture is equivalent to the APSP conjecture  Williams   Williams   
We
following
MINWEIGHT kCLIQUE problem 
De nition    MINWEIGHT kCLIQUE problem for
kpartite graphs  Given   complete kpartite graph    
              Vk     with  Vi    ni and positive integer weights on the edges  output the minimum total edgeweight of   kclique in the graph 

variant

often

use

the

the

of

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

 cid cid  

 cid   

If for all      we have that ni     
  it can be shown that
the MINWEIGHT kCLIQUE problem for kpartite graphs
requires  
time assuming the kClique
conjecture  We provide   simple proof of this statement in
the appendix 

 

   ni

  Hardness of VITERBI PATH
We begin by presenting our main hardness result for the
VITERBI PATH problem 
Theorem   The VITERBI PATH problem requires
        time assuming the APSP Conjecture 

To show APSP hardness  we will perform   reduction
from the MINIMUM TRIANGLE problem  described in Section   to the VITERBI PATH problem 
In the instance
of the MINIMUM TRIANGLE problem  we are given    
partite graph                      such that      
                  We want to  nd   triangle of minimum
weight in the graph    To perform the reduction  we de ne
  weighted directed graph   cid                    cid 
  cid  contains all the edges of   between    and    directed
from    towards    edges from   towards all nodes of   
of weight   and edges from all nodes of    towards   of
weight   We also add   selfloops at nodes   and   of
weight  
We create an instance of the VITERBI PATH problem
          as described below  Figure   illustrates the construction of the instance 

  Matrix   is the weighted adjacency matrix of   cid  that
takes value    or   suf ciently large integer  for
nonexistent edges and nonexistent selfloops 

  The alphabet of the HMM is         and thus
matrix   has        rows and           columns 
For all             and                is equal to the
weight of the edge        in graph    Moreover  for all
                      or   suf ciently large
number  and for all                          
  Finally  all remaining entries corresponding to
nodes   and   are  

  Sequence   of length            is generated by
appending the observations      and   for all      
and adding      observation at the end 

Given the above construction  the theorem statement follows directly from the following claim 
Claim   The weight of the solution to the VITERBI PATH
instance is equal to the weight of the minimum triangle in
the graph   

Proof  The optimal path for the VITERBI PATH instance
begins at node   It must end in node   since otherwise
when observation    arrives we collect cost   Similarly  whenever an observation   arrives the path must be
either on node   or   Thus  the path  rst loops in node  
and then goes from node   to node   during three consecutive observations      and   for some       and stays in
node   until the end  Let         and         be the two
nodes visited when moving from node   to node   The
only two steps of nonzero cost are 

  Moving from node   to node    at the  rst observation

   This costs                          

  Moving from node    to node    at the second obser 

vation    This costs                  

Thus  the overall cost of the path is equal to          
                  which is equal to the weight of the
triangle           in    Minimizing the cost of the path in
this instance is therefore the same as  nding the minimum
weight triangle in   

  Hardness of VITERBI PATH with small

alphabet

The proof of Theorem   requires   large alphabet size 
which can be as large as the number of total steps     In
the appendix  we show how to get   lower bound for the
VITERBI PATH problem on alphabets of small size by using   different hardness assumption 
Theorem   For any          the VITERBI PATH problem on      nC  observations from an alphabet of size
    requires         time assuming the kClique
Conjecture for      cid   

   cid     

  Complexity of VITERBI PATH for unary

alphabet

In this section  we focus on the extreme case of
VITERBI PATH with unary alphabet 
Theorem   The VITERBI PATH problem requires
        time when       even if the size of the
alphabet is       assuming the APSP Conjecture 

The above theorem follows from APSPhardness of the
SHORTEST WALK problem that we present next 
Theorem   The SHORTEST WALK problem requires
        time when        assuming the APSP Conjecture 

Proof  We will
from the
MINIMUM TRIANGLE problem to the VITERBI PATH

perform  

reduction

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

wv   

 
 

 

 
 
 

 
 
 
 

 

 

Node

 

           

 

          
   
 
wv      
 
 

 

    The graph speci ed by transition matrix    Every edge        in         has
the original edgeweight as in graph   

    The cost of seeing   symbol at every
node given by matrix   

  

  

Figure   The construction of matrices   and   for the reduction in the proof of Theorem   The notation wv   denotes
the weight of the edge        in the original graph   

problem 
In the instance of the MINIMUM TRIANGLE
problem  we are given    partite undirected graph
                     with positive edge weights such
that                         We want to  nd  
triangle of minimum weight in the graph    To perform
the reduction  we de ne   weighted directed and acyclic
graph   cid                          cid    cid  Nodes
in   cid  are in oneto one correspondence with nodes in
  and    cid         cid  is de ned as follows  We add all
edges of   between nodes in   and    directed from  
towards    and similarly  we add all edges of   between
nodes in    and    directed from    towards    Instead
of having edges between nodes in    and    we add the
corresponding edges of   between nodes in    and   cid 
directed from    towards   cid  Moreover  we add additional
edges of weight   to create   path   of       nodes 
starting from node   and going through all nodes in   in
some order  Finally  we create another path    cid  of      
nodes going through all nodes in   cid  in the same order as
their counterparts on path   and ending at node   These
edges have weight   apart from the last one  entering node
  which has weight       suf ciently large negative
constant 
We create an instance of the SHORTEST WALK problem
by setting           and   to be the weighted adjacency
matrix of   cid  that takes value    or   suf ciently large
integer  for nonexistent edges and selfloops 
The optimal walk of the SHORTEST WALK instance must
include the edge of weight    entering node   since otherwise the cost will be nonnegative  Moreover  the walk

 Since the de nition of SHORTEST WALK doesn   allow negative weights  we can equivalently set its weight to be   and add
  to all the other edge weights 

must reach node   exactly at the last step since otherwise
the cost will be   as there are no outgoing edges from
node   By the choice of     the walk leaves path   at some
node        then visits nodes    and    in    and    respectively  and subsequently moves to node   cid      cid  where
  cid  is the counterpart of   on path    cid  The total cost of the
walk is thus the weight of the triangle           in    minus    Therefore  the optimal walk has cost equal to the
weight of the minimum triangle up to the additive constant
  

 

log   

Notice that when        the runtime of the Viterbi algorithm is no longer optimal  We now present   faster algorithm with   total running time log       
As we show in Section  
the general VITERBI PATH
problem reduces  according to Equation   to computing
 min    matrixvector products 
In the case of unary
alphabet  it corresponds to computing  min    matrixvector product   times as follows                    
This can be equivalently performed by  rst computing all
 min    matrixmatrix products                    
using exponentiation with repeated squaring and then multiplying the resulting matrix with the vector    This requires only   log     matrix  min   multiplications  Using the currently best algorithm for  min    matrix product  Williams    we get an algorithm with total run 
 
ning time log       

log   

  Hardness for sparse HMMs
The VITERBI PATH lowerbounds we have provided apply
to the case where the HMM has all    possible edges 
For sparse HMMs that have at most   edges out of the

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

 

 

  states in   cid    

   possible ones       the transition matrix has at most  
nonzero probabilities  the VITERBI PATH problem can be
easily solved in        time  The lower bounds that we
presented in the paper can be adapted directly for this case
to show that no faster algorithm exists that runs in time
       This can be easily seen via   padding argum states and   edges  Adding   
ment  Consider   hard instance for VITERBI PATH on  
dense HMM with
 
stance with   states and          
additional states with selfloops  we obtain   sparse inm        edges 
  cid 
Thus  any algorithm that computes the optimal Viterbi Path
in        time for the resulting instance would solve
 
the original instance with
time contradicting the corresponding lower bound 
This observation directly gives the following lower bounds
for VITERBI PATH problem  parametrized by the number
  of edges in an HMM with   states 
Theorem   The VITERBI PATH problem requires
        time for an HMM with   edges and  
states  assuming the APSP Conjecture 
Theorem   For any          the VITERBI PATH problem on      mC  observations from an alphabet of size
    requires         time assuming the kClique
Conjecture for      cid   
Theorem   The VITERBI PATH problem requires
        time when      
  even if the size of the

   cid     

alphabet is       assuming the APSP Conjecture 

to the minimum entry in the vector obtained by   sequence
of    min    matrixvector products  as follows 
                                              bT  
where   is   vector with entries        and zi     for
all    cid    Vector   represents the cost of being at node   at
time   Vector             represents the minimum cost
of reaching each node at time   after seeing observation
   After   steps  every entry   of vector   represents
the minimum minimum cost of   path that starts at     
  and ends at uT     after   observations  Taking the
minimum of all entries gives the cost of the solution to the
VITERBI PATH instance 
To evaluate   we design an online  min    matrixvector multiplication algorithm  In the online matrixvector
multiplication problem  we are given   matrix and   sequence of vectors in online fashion  We are required to
output the result of every matrixvector product before receiving the next vector  Our algorithm for online  min   
matrixvector multiplication is based on   recent algorithm
for online Boolean matrixvector multiplication by Green
Larsen and Williams  Larsen   Williams   
Theorem    Green Larsen and Williams  Larsen  
Williams    For any matrix            and any
log    vectors            vT        
sequence of      
online Boolean matrixvector multiplication of   and vi
can be performed in   
log    amortized time whp  No
preprocessing is required 

 

 

    faster VITERBI PATH algorithm
In this section  we present   faster algorithm for the
VITERBI PATH problem  when there are only few distinct
transition probabilities in the underlying HMM 
Theorem   When there are fewer than  
tinct
there is       
VITERBI PATH problem that succeeds whp 

log   distransition probabilities for   constant      
log    randomized algorithm for the

 

 

The number of distinct transition probabilities is equal to
the number of distinct entries in matrix    in De nition  
The same is true for matrix   in the additive version of
VITERBI PATH  in De nition   So  from the theorem
statement we can assume that matrix   has at most  
log  
different entries for some constant      
To present our algorithm  we revisit
VITERBI PATH  We want
             uT that minimizes the quantity 

the de nition of
to compute   path     

 

  cid 

  

min

    uT

   ut  ut      ut  st   

 

De ning the vectors bt      st  we note that   is equal

 

 

We show the following theorem for online  min   
matrixvector multiplication  which gives the promised
runtime for the VITERBI PATH problem  since we are interested in the case where   and   are polynomially related 
           
Theorem   Let     Rn   be   matrix with at most
log   distinct entries for   constant       For any se 
 
log    vectors            vT   Rn  online
quence of      
 min    matrixvector multiplication of   and vi can be
 
performed in   
log    amortized time whp  No preprocessing is required 
Proof  We will show the theorem for the case where    
        The general case where matrix   has    
 
log   distinct values      ad can be handled by creat 
 
ing   matrices      Ad  where each matrix Ak has enij     if Aij   ak and   otherwise  Then  vector
tries Ak
    min    product between   matrix   and   vector  
is denoted by       and is equal to   vector   where ui  
minj Mi     vj 

 Even though computing all  min    products does not directly give   path for the VITERBI PATH problem  we can obtain
one at no additional cost by storing back pointers  This is standard
and we omit the details 

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

 

         can be computed by computing rk   Ak     for
    ak  This introduces  
every   and setting ri   mink rk
log   in amortized runtime but the  nal amorfactor of  
log    if       is suf ciently
tized runtime remains   
small  From now on we assume that            and
de ne the matrix             whose every entry is   if
the corresponding entry at matrix   is   and   otherwise 
For every query vector    we perform the following 

 

the anonymous reviewers for their careful reviews  This
work was supported in part by an IBM PhD Fellowship 
the NSF and the Simons Foundation 

  Sort indices      in such that vi        vin in

    log    time 

 

  Partition the indices into      

log   sets  where set

Sk contains indices     cid   

   cid    ik cid   

   cid 

  Set            where   indicates an unde ned

value 

  For         ll the entries of   as follows 

  Let ISk be the indicator vector of Sk that takes
value   at index   if     Sk and   otherwise 
  Compute the Boolean matrixvector product
         cid  ISk using the algorithm from Theorem  
  Set rj   mini Sk  Aj     vi  for all         such
that rj     and   

     

  Return vector   

 

 

 

Runtime of the algorithm per query The algorithm perlog   Boolean matrixvector multiplicaforms      
tions  for   total amortized cost of       
log     
log    for   small enough constant       Moren 
over  to  ll an entry rj the algorithm requires going through
all elements in some set Sk for   total runtime of   Sk   
log    Thus  for all entries pj the total time ren 
quired is   
log    The runtime of the other steps is
dominated by these two operations so the algorithm takes
  

log    amortized time per query 

 

 

 

Correctness of the algorithm To see that the algorithm
correctly computes the  min    product        observe
that the algorithm  lls in the entries of vector   from smallest to largest  Thus  when we set   value to entry rj we
never have to change it again  Moreover  if the value rj
gets  lled at step    it must be the case that    cid 
      for all
  cid       This means that for all indices              Sk 
the corresponding entry Aj   was always  

Acknowledgments
We thank Piotr Indyk for many helpful discussions  for
comments on an earlier version of the writeup and for suggestion on how to improve the presentation  We also thank

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

References
Abboud  Amir and Williams  Virginia Vassilevska  Popular conjectures imply strong lower bounds for dynamic
problems  In Foundations of Computer Science  FOCS 
  IEEE  th Annual Symposium on  pp   
IEEE   

Amengual  Juan   and Vidal  Enrique  Ef cient errorcorrecting viterbi parsing  Pattern Analysis and Machine
Intelligence  IEEE Transactions on   
 

Attias  Hagai  Planning by probabilistic inference  In AIS 

TATS   

Abboud  Amir  Williams  Virginia Vassilevska  and
Weimann  Oren  Consequences of faster alignment of
sequences  In Automata  Languages  and Programming 
pp    Springer   

Backurs  Arturs  Dikkala  Nishanth  and Tzamos  Christos 
Tight Hardness Results for Maximum Weight RectanIn International Colloquium on Automata  Langles 
guages  and Programming   

Abboud  Amir  Backurs  Arturs  and Williams  Virginia Vassilevska  If the Current Clique Algorithms are
Optimal  so is Valiant   Parser  In Foundations of Computer Science  FOCS    IEEE  th Annual Symposium on  pp    IEEE     

Abboud  Amir  Grandoni  Fabrizio  and Williams  Virginia Vassilevska  Subcubic equivalences between graph
centrality problems  APSP and diameter  In Proceedings
of the TwentySixth Annual ACMSIAM Symposium on
Discrete Algorithms  pp    SIAM     

Abboud  Amir  Williams  Virginia Vassilevska  and Yu 
Huacheng  Matching triangles and basing hardness on
an extremely popular conjecture  In Proceedings of the
FortySeventh Annual ACM on Symposium on Theory of
Computing  pp    ACM     

AbdelHamid  Ossama  Mohamed  Abdelrahman  Jiang 
Hui  and Penn  Gerald  Applying convolutional neural
networks concepts to hybrid nnhmm model for speech
recognition  In Acoustics  Speech and Signal Processing
 ICASSP    IEEE International Conference on  pp 
  IEEE   

Alon  Noga and Boppana  Ravi    The monotone circuit
complexity of boolean functions  Combinatorica   
   

Alon  Noga  Krivelevich  Michael  and Sudakov  Benny 
Finding   large hidden clique in   random graph  Random Struct  Algorithms     

Alon  Noga  Andoni  Alexandr  Kaufman  Tali  Matulef 
Kevin  Rubinfeld  Ronitt  and Xie  Ning  Testing kwise
and almost kwise independence  In Proceedings of the
 th Annual ACM Symposium on Theory of Computing 
San Diego  California  USA  June     pp   
   

Altun  Yasemin  Tsochantaridis 

Ioannis  Hofmann 
Thomas  et al  Hidden markov support vector machines 
In ICML  volume   pp     

Bengio  Samy  An asynchronous hidden markov model for
audiovisual speech recognition  Advances in Neural Information Processing Systems  pp     

Bourlard  Herve   and Morgan  Nelson  Connectionist
speech recognition    hybrid approach  volume  
Springer Science   Business Media   

Bringmann  Karl  Gr nlund  Allan 

and Larsen 
Kasper Green    dichotomy for regular expression
membership testing  arXiv preprint arXiv 
 

Cairo  Massimo  Farina  Gabriele  and Rizzi  Romeo  Decoding Hidden Markov Models Faster Than Viterbi Via
Online MatrixVector  max Multiplication  In Thirtieth AAAI Conference on Arti cial Intelligence   

Churbanov  Alexander and WintersHilt  Stephen  Implementing EM and Viterbi algorithms for Hidden Markov
Model in linear memory  BMC bioinformatics   
 

Cohen  Ira  Garg  Ashutosh  Huang  Thomas    et al  Emotion recognition from facial expressions using multilevel
In Neural information processing systems  volhmm 
ume   Citeseer   

Collins  Michael  Discriminative training methods for
hidden markov models  Theory and experiments with
In Proceedings of the ACL 
perceptron algorithms 
conference on Empirical methods in natural language
processingVolume   pp    Association for Computational Linguistics   

Collobert  Ronan  Deep learning for ef cient discriminative parsing  In AISTATS  volume   pp     

Esposito  Roberto and Radicioni  Daniele    Carpediem 
Optimizing the viterbi algorithm and applications to supervised sequential learning  Journal of Machine Learning Research   Aug   

Felzenszwalb  Pedro    Huttenlocher  Daniel    and KleinFast algorithms for largestate space

berg  Jon   

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

HMMs with applications to web usage analysis  Advances in NIPS     

Grice    Alicia  Hughey  Richard  and Speck  Don  Reduced space sequence alignment  Computer applications
in the biosciences  CABIOS     

  stad  Johan  Clique is hard to approximate within   

Acta Mathematica     

Hazan  Elad and Krauthgamer  Robert  How hard is it to
approximate the best nash equilibrium  SIAM    Comput     

Huang  Xuedong  Acero  Alex  Hon  HsiaoWuen  and
Foreword ByReddy  Raj  Spoken language processing 
  guide to theory  algorithm  and system development 
Prentice Hall PTR   

Jerrum  Mark  Large cliques elude the metropolis process 

Random Struct  Algorithms     

Kaji  Nobuhiro  Fujiwara  Yasuhiro  Yoshinaga  Naoki  and
Kitsuregawa  Masaru  Ef cient staggered decoding for
In Proceedings of the  th Annual
sequence labeling 
Meeting of the Association for Computational Linguistics  pp    Association for Computational Linguistics   

Karp  Richard    Reducibility among combinatorial problems  In Complexity of computer computations  pp   
  Springer   

Kim  Seyoung and Smyth  Padhraic  Segmental hidden
markov models with random effects for waveform modeling  Journal of Machine Learning Research   Jun 
   

Larsen  Kasper Green and Williams  Ryan  Faster online matrixvector multiplication  In Proceedings of the
TwentyEighth Annual ACMSIAM Symposium on Discrete Algorithms  pp    SIAM   

LeCun  Yann  Bottou    on  Bengio  Yoshua  and Haffner 
Patrick  Gradientbased learning applied to document
recognition  Proceedings of the IEEE   
   

Lee  Peng  Dong  Ming  Liang  Weiqian  and Liu  Runsheng  Design of Speech Recognition CoProcessor for
the Embedded Implementation  In Electron Devices and
SolidState Circuits    EDSSC   IEEE Conference on  pp    IEEE   

Lifshits  Yury  Mozes  Shay  Weimann  Oren  and ZivUkelson  Michal  Speeding up HMM decoding and
training by exploiting sequence repetitions  Algorithmica     

Lin  Kuang  Simossis  Victor    Taylor  Willam    and
Heringa  Jaap    simple and fast secondary structure
prediction method using hidden neural networks  Bioinformatics     

Mahmud  Md Pavel and Schliep  Alexander  Speeding up
Bayesian HMM by the four Russians method  In International Workshop on Algorithms in Bioinformatics  pp 
  Springer   

Mannini  Andrea and Sabatini  Angelo Maria  Machine
learning methods for classifying human physical activity from onbody accelerometers  Sensors   
   

Mohamed  Abdelrahman  Dahl  George    and Hinton 
Geoffrey  Acoustic modeling using deep belief networks  IEEE Transactions on Audio  Speech  and Language Processing     

Ne an  Ara    Liang  Luhong  Pi  Xiaobo  Xiaoxiang  Liu 
Mao  Crusoe  and Murphy  Kevin    coupled hmm for
audiovisual speech recognition  In Acoustics  Speech 
and Signal Processing  ICASSP    IEEE International Conference on  volume   pp  II  IEEE 
 

Peng  Jian  Bo  Liefeng  and Xu  Jinbo  Conditional neural  elds  In Advances in neural information processing
systems  pp     

Rabiner  Lawrence      tutorial on hidden markov models and selected applications in speech recognition  Proceedings of the IEEE     

Roditty  Liam and Zwick  Uri  On dynamic shortest
paths problems  In Algorithms ESA   pp   
Springer   

Siddiqi  Sajid   and Moore  Andrew    Fast inference and
In Proceedings of
learning in largestate space hmms 
the  nd international conference on Machine learning 
pp    ACM   

Tarnas  Christopher and Hughey  Richard  Reduced space
hidden Markov model training  Bioinformatics   
   

Li  Peng and Tang  Hua  Design   coprocessor for Output Probability Calculation in speech recognition 
In
Circuits and Systems    ISCAS   IEEE International Symposium on  pp    IEEE   

Viterbi  Andrew    Error bounds for convolutional codes
and an asymptotically optimum decoding algorithm  Information Theory  IEEE Transactions on   
   

Improving Viterbi is Hard  Better Runtimes Imply Faster Clique Algorithms

Williams  Ryan  Faster allpairs shortest paths via cirIn Proceedings of the  th Annual
cuit complexity 
ACM Symposium on Theory of Computing  pp   
ACM   

Williams  Virginia Vassilevska and Williams  Ryan  Subcubic equivalences between path  matrix and triangle
problems  In Foundations of Computer Science  FOCS 
   st Annual IEEE Symposium on  pp   
IEEE   

Young  Steve  Evermann  Gunnar  Gales  Mark  Hain 
Thomas  Kershaw  Dan  Liu  Xunying  Moore  Gareth 
Odell  Julian  Ollason  Dave  Povey  Dan  et al  The HTK
book  volume   Entropic Cambridge Research Laboratory Cambridge   

