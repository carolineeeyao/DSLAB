Provably Optimal Algorithms for Generalized Linear Contextual Bandits

Lihong Li   Yu Lu   Dengyong Zhou  

Abstract

Contextual bandits are widely used in Internet
services from news recommendation to advertising  and to Web search  Generalized linear
models  logistical regression in particular  have
demonstrated stronger performance than linear
models in many applications where rewards are
binary  However  most theoretical analyses on
contextual bandits so far are on linear bandits  In
this work  we propose an upper con dence bound
 
based algorithm for generalized linear contextual bandits  which achieves an    
dT   regret
over   rounds with   dimensional feature vectors  This regret matches the minimax lower
bound  up to logarithmic terms  and improves on
the best previous result by  
  factor  assuming the number of arms is  xed    key component in our analysis is to establish   new  sharp
 nitesample con dence bound for maximumlikelihood estimates in generalized linear models  which may be of independent interest  We
also analyze   simpler upper con dence bound
algorithm  which is useful in practice  and prove
it to have optimal regret for certain cases 

 

  Introduction
Contextual bandit problems are originally motivated by applications in clinical trials  Woodroofe    When  
standard treatment and   new treatment are available for
  certain disease  the doctor needs to decide  in   sequetial
manner  which of them to use based on the patient   pro les
such as age  general physical status or medicine history 
With the development of modern technologies  contextual
bandit problems have more applications  especially in webbased recommendation  advertising and search  Agarwal

 Microsoft Research  Redmond  WA    Department
of Statistics  Yale University  New Haven  CT  USA  CorLihong Li  lihongli microsoft com 
respondence
Yu
Zhou  denzho microsoft com 

Lu  yu lu yale edu 

to 

Dengyong

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

et al    Li et al      In the problem of personalized news recommendation  the website must recommend news articles that are most interesting to users that
visit the website  The problem is especially challenging
for breaking news  as little data are available to make good
prediction about user interest    tradeoff naturally occurs
in this kind of sequential decision making problems  One
needs to balance exploitation choosing actions that performed well in the past and exploration choosing actions that may potentially give better outcomes 
In this paper  we study the following stochastic  Karmed
contextual bandit problem  Suppose at each of the  
rounds  an agent is presented with   set of   actions  each
of which is associated with   context    ddimensional feature vector  By choosing an action based on the rewards
obtained from previous rounds and on the contexts  the
agent will receive   stochastic reward generated from some
unknown distribution conditioned on the context and the
chosen action  The goal of the agent is to maximize the
expected cumulative rewards over   rounds  The most
studied model in contextual bandits literature is the linear
model  Auer    Dani et al    Rusmevichientong
  Tsitsiklis    Chu et al    AbbasiYadkori et al 
  in which the expected rewards at each round is   linear combination of features in the context vector  The linear model is theoretically convenient to work with  However  in practice  we usually have binary rewards  click or
not  treatment working or not  Logistic regression model
based algorithms have been shown to have substantial improvements over linear models  Li et al    We therefore consider generalized linear models  GLM  in the contextual bandit setting  in which linear  logistic and probit
regression serve as three important special cases 
The celebrated work of Lai   Robbins    rst introduces the upper con dence bound  UCB  approach to ef 
cient exploration  Later  the idea of con dence bound has
been successfully applied to many stochastic bandits problems  from Karm bandits problems  Auer et al     
Bubeck   CesaBianchi    to linear bandits  Auer 
  AbbasiYadkori et al    UCBtype algorithms
are both ef cient and provable optimal in Karm bandits
and Karmed linear bandits  However  most study are limited to the linear case  While some UCBtype algorithms
using GLMs perform well empirically  Li et al   

Generalized Linear Contextual Bandits

Organization Section   introduces the generalized linear
bandit problem  Section   gives   brief review of the statistical properties of generalized linear model  and gives  
sharp nonasymptotic normalitytype result for GLM parameter estimation which can be of independent value 
With this tool  Section   presents our algorithms and the
main theoretical results  Section   concludes the paper with
further discussions  including several open problems  All
proofs are given in the supplementary materials 
Notations For   vector     Rd  we use  cid   cid  to denote its
 cid  norm and   cid  its transpose  Bd        Rd    cid   cid     
is the unit ball centered at the origin  The weighted  cid norm
associated with   positivede nite matrix   is de ned by
 cid   cid    
  cid Ax  The minimum and maximum singular
values of   matrix   are written as  min    and  cid   cid  respectively  The trace of   matrix   is tr     For two symmetric matrices   and   of the same dimensions     cid   
means that       is positive semide nite  For   realvalued function    we use    and    to denote its  rst and
second derivatives  Finally                      

 

there is little theoretical study of them    natural question
arises  can we  nd an ef cient algorithm to achieve the optimal convergence rate for generalized linear bandits 

 

 

Our Contributions
In this paper  we propose   GLM
version of the UCB algorithm called SupCBGLM that
achieves   regret over   rounds of order    
dT   This rate
improves the stateof theart results of Filippi et al   
  factor  assuming the number of actions is  xed 
by  
Moreover  it matches the GLM bandits problem   minimax lower bound indicated by the linear bandits problem
and thus is optimal  SupCBGLM is inspired by the seminal work of Auer   which introduced   technique to
construct independence samples in linear contextual bandits    key observation in proving this result is that the
 cid  con dence ball of the unknown parameter is insuf cient
to calculate   sharp upper con dence bound  yet what we
need is the con dence interval in all directions  Thus  we
prove    nite sample normality type con dence bound for
the maximum likelihood estimator of GLM  To the best of
our knowledge  this is the  rst nonasymptotic normality
type result for the GLM and might be of its own theoretical
value  We also analyze   simple version of UCB algorithm
called UCBGLM that is widely used in practice  We prove
it also achieves the optimal regret bound under   reasonable assumption  These results shed light on explaining the
good empirical performance of GLM bandits in practice 

 

Related Work The study of GLM bandits problem goes
back at least to Sarkar   who considered discounted
regrets rather than cumulative regerts  They prove that  
myopic rule without exploration is asymptotically optimal 
Recently  Filippi et al    study the same stochastic
GLM bandit problem considered here  They propose the
 
GLMUCB algorithm  similar to our Algorithm   which
achieves   regret of     
    after   rounds  However  as
we believe the optimal regret for stochastic GLM bandits
should be the same as linear case when the number of acd term than the optimal
tions is small  their rates misses  
rates 
Another line of research focuses on using EXPtype algorithms  which can be applied to almost any model
classes  Auer et al      These algorithms  which
choose actions using   carefully randomized policy  use
importance sampling to reduce   bandit problem to its fullinformation analogue  Later variants of the EXP  algo 
 
rithm  Beygelzimer et al    Agarwal et al    give
an    
dKT   regret that is nearoptimal with respect to
    However  these regret bounds have  
  dependence 
Moreover  these algorithms can be expensive to run  they
either have   computational complexity exponential in   for
our GLM case  or need to make   large number of calls to
  nontrivial optimization oracle 

 

 

 cid 

  for all   

        

  Problem Setting
We consider the stochastic Karmed contextual bandit
problem  Let   be the number of total rounds  At round
   the agent observes   context consisting of   set of  
feature vectors   xt               Rd  which is drawn
IID from an unknown distribution   with  cid xt   cid     
Each feature vector xt   is associated with an unknown
stochastic reward yt         The agent selects one action  denoted at  and observes the corresponding reward
yt at  Finally  we make   regularity assumption about the
there exists   constant       such that
distribution  
     xt ax cid 
 min     
In this paper  we are concerned with the generalized linear
model  or GLM  in which there is an unknown     Rd and
   xed  strictly increasing link function           such
that               cid  where   is the chosen action  
feature and   the corresponding reward  One can verify
that linear and logistic models are special cases of GLM
with         and                respectively 
The agent   goal is to maximize the cumulative expected
rewards over   rounds  Suppose the agent takes action at
at round    Then the agent   strategy can be evaluated by
comparing its expected reward to the best expected reward 
To do so  de ne the optimal action at round   by   
   
     Then  the agent   total regret of
argmaxa       cid 
following strategy   can be expressed as follows
 

       cid 

  cid 

RT    

 cid 

 

 cid 

   cid 

    

 

  

Note that RT   is in general   random variable due to the

  at

Generalized Linear Contextual Bandits

Yt      cid 

possible randomness in   Denote by Xt   xt at  Yt  
yt at  and our model can be written as
         

 
where              are independent zeromean noise 
Here  Xt is   random variable because the agent chooses
current action based on previous rewards  Formally  we assume there is an increasing sequence of sigma  elds  Fn 
such that    is Ftmeasurable with          Ft       
An example of Fn will be the sigma eld generated by
               Xn  Yn  Also  we assume the noise    is
subGaussian with parameter   where   is some positive 
universal constant  that is  for all   

  cid        Ft 

 cid      

 
In practice  when we have bounded reward Yt       the
noise    is also bounded and hence satis es   with some
appropriate   value 
In addition to the boundedness assumption on the rewards and feature vectors  we also need
the following assumption on the link function  
Assumption       inf cid   cid   cid cid     cid     

As we shall see in Section   the asymptotic normality of
maximumlikelihood estimates implies the necessity of this
assumption  Note that this assumption is weaker than Assumption   in Filippi et al    as it only requires to
control the local behavior of    cid  near  
Assumption     is twice differentiable  Its  rst and second order derivatives are upperbounded by    and   
respectively 

It can be veri ed that Assumption   holds for the logistic
link function  where we may choose            

  Generalized Linear Models
To motivate the algorithms proposed in this paper  we  rst
brie   review the classical likelihood theory of generalized
linear models  In the canonical generalized linear model
 McCullagh   Nelder    the conditional distribution
of   given   is from the exponential family  and its density  parameterized by       can be written as

 cid      cid        cid 

  

 cid 

           exp

        

   

Here         is   known scale parameter       and  
are three normalization functions mapping from   to   
The exponential family   is   very broad family of distributions including the Gaussian  binomial  Poisson  gamma
and inverseGaussian distributions  It follows from standard properties of exponential families  Brown    that
  is in nitely differentiable satisfying      cid          

         cid  and      cid            
It can be
checked that the data generated from   automatically satis es the subGaussian condition  
Suppose we have independent samples of               Yn
condition on               Xn  The loglikelihood function
of   under model   is

 cid 

    Yt   

  cid 

  

 

 cid  YtX cid 
  cid 

  

  

         cid 
  
  
         cid 

 YtX cid 

     constant  

log  cid   

 

Consequently  the maximum likelihood estimate  MLE 
may be de ned by

  cid 

  

     argmax
 

 YtX cid 

         cid 

    

    where     cid  

From classical likelihood theory  Lehmann   Casella 
  we know that when the sample size   goes to in nity  the MLE    is asymptotically normal  that is       
     
      cid 
  XtX cid 
  is the Fisher
       the asympInformation Matrix  Note that if    cid 
totic variance of   cid    can go to in nity for some    This
suggests the necessity of Assumption  
As we will see later  the normality result is crucial in our
regret analysis of GLM bandits  However  to the best of
our knowledge  there is no nonasymptotic normality results of the MLE for GLM  In the following  we present  
 nitesample version of the classical asymptotic normality
results  which can be of independent interest 

Theorem   De ne Vn    cid  

   and let       be

given  Furthermore  assume that

   XtX cid 
 cid 

 cid 

 

 min Vn        
 

     log
Then  with probability at least      
likelihood estimator satis es  for any     Rd  that

 
 

 

the maximum 

 

 cid log cid   cid  

 
 

 

 

   cid          
 

This theorem characterizes the behavior of MLE on every
direction  It implies that   cid       has   subGaussian
tail bound for any     Rd  It also provides   rigorous justi 
 cation of the asymptotic upper con dence bound derived
heuristically by Filippi et al    Section  
The proof of the theorem is given in the appendix  It consists of two main steps  as is typical for proving normalitytype results of MLEs  Van der Vaart    We  rst show
the   consistency of   to   Then  by using   secondorder Taylor expansion or Newtonstep  we can prove the
desired normality of  

Generalized Linear Contextual Bandits

The condition   on  min Vn  is necessary for the consistency of estimating linear models  Lai   Wei    Bickel
et al    and generalized linear models  Fahrmeir  
Kaufmann    Chen et al    It can be satis ed under mild conditions such as the proposition below  which
will be useful for our analysis 

Proposition   De ne Vn    cid  

   XtX cid 
   where Xt is
drawn iid from some distribution   with support in the unit
ball  Bd  Furthermore  let       XtX cid 
   be the second
moment matrix  and   and       be two positive constants  Then  there exist positive  universal constants   
and    such that  min Vn      with probability at least
      as long as

 cid 

 cid log 

 cid 

 

  

      

   

 min 

 

  

 min 

 

Proof Sketch  We give   proof sketch here  and the full
proof is found in the appendix  In the following  for simplicity  we will drop the subscript   when there is no ambiguity  Therefore  Vn is denoted   and so on  We will need  
technical lemma  which is an existing result in random matrix theory  The version we presented here is adapted from
Equation   of Theorem   from Vershynin  
Lemma   Let     Rn   be   matrix whose rows Ai
are independent subGaussian isotropic random vectors in
Rd with parameter   namely    exp   cid Ai   EAi   
exp   cid   cid    for any     Rd  Then  there exist positive  universal constants    and    such that  for every       the following holds with probability at least
      exp      where        
  
    cid     Id

 cid         

 cid cid   
 cid cid    max     
  ZZ cid    Id  De ne    cid  
is upperbounded by cid cid cid cid     
 cid 

Let   be   random vector drawn from the distribution
  De ne         Then   is isotropic  namely 
        
From Lemma   we have that  for any    with probability
at least       exp       min             
nd  
   where   is the subGaussian parameter of    which
  
 
min    see       Vershynin   We thus can rewrite the above inequality
 which holds with probability       as
 

   ZtZ cid 

 

 

 

 min            

min 

  

nd    

 

 

 cid 
 cid   log   

 

This implies the following lower bound 
nd     

 min        min       

 

Finally  simple calculations show that the last expression is
no less than   as long as   is no smaller than the expression
stated in the proposition   nishing the proof 

  Algorithms and Main Results
In this section  we are going to present two algorithms 
While the  rst algorithm is computationally more ef cient 
the second algorithm has   provable optimal regret bound 

  Algorithm UCBGLM

The idea of upper con dence bounds  UCB  is highly
effective in dealing with the exploration and exploitation tradeoff in many parametric bandit problems  including Karm bandits  Auer et al      and linear bandits  AbbasiYadkori et al    Auer    Chu et al 
  Dani et al    For the generalized linear model
considered here  since   is   strictly increasing function 
our goal is equivalent to choosing         to maximize
  cid 
     at round    Suppose    is our current estimator of  
after round    An exploitation action is to take the action
that maximizes the estimated mean value  while an exploration action is to choose the one that has the largest variance  Thus  to balance exploitation and exploration  we
can simply choose the action that maximizes the sum of estimated mean and variance  which can be interpreted as an
upper con dence bound of   cid 
    This leads to the algot  
rithm UCBGLM  Algorithm  

Algorithm   UCBGLM
Input  the total rounds     tuning parameter   and  
Initialization  randomly choose at       for         set

      cid 

For                           do
  Calculate the maximumlikelihood estimator    by

solving the equation

 Yi      cid 

  Xi    

 cid 

      cid Xt   cid  
  Choose at   argmaxa   
  Observe Yt  let Xt   Xt at  Vt    Vt   XtX cid 
End For

  cid 

   

 

 

 cid 

 
 

 

   XtX cid 
  cid 

  

UCBGLM take two parameters  At the initialization stage 
we randomly choose actions to ensure   unique solution
of   The choice of   in the theorem statement follows
from Proposition   with       It should be noted that the
IID assumption about contextual       the distribution  
is only needed to ensure      is invertable  similar to the
 rst phase in the algorithm of Filippi et al    the rest
of our analysis does not depend on this stochastic assumption  The same may be achieved by using regularization
 see       AbbasiYadkori et al    Another tuning
parameter   is used to control the amount of exploration 
The larger the   is  the more exploration will be used 
As mentioned earlier  the feature vectors Xt depend on the

Generalized Linear Contextual Bandits

previous rewards  Consequently  the rewards  Yi         
may not be independent given  Xi          We instead use results on selfnormalized martingales  AbbasiYadkori et al    together with    nitetime normality
result like Theorem   to prove the next theorem 
Theorem   Fix any       There exists   universal
constant       such that if we run UCBGLM with
     
      
 
log  then  with probability at least       the regret
of the algorithm is upper bounded by

  log             log  and       

 cid   

 cid   

 cid 

RT      

    

 

log

  

   

 
The theorem shows an     
    regret bound that is independent of   
Indeed  this rate matches the minimax
lower bound up to logarithm factor for the in nite actions
contextual bandit problems  Dani et al    By choosing        and using the fact that RT       this high 
 
probability result implies   bound on the expected regret 
  RT         
    Our result improves the previous
regret bound of Filippi et al    by  
log   factor 
Moreover  the algorithm proposed in Filippi et al   
involves   projection step  which is computationally more
expensive comparing to UCBGLM  Finally  this algorithm
works well in practice  We give   heuristic argument for its
strong performance in Section   under   speci   condition
that sometimes are satis ed 

 

Proof of Theorem   We  rst bound the onestep regret  To
  and             where
do so       and let   
    arg maxa       cid 
     is an optimal action at round
  
   The selection of at in UCBGLM implies

    xt   

RT  

 cid   

       cid     cid   

   cid  

   cid Xt     cid     cid Xt cid  

 
 

 
 

 

 

Then  we have
 cid   

 
 

 
 

 
 

 
 
 
 

   cid   

    Xt        cid 

    Xt     cid 
    Xt cid  

    Xt     cid     cid   
     cid     cid Xt   cid     cid   
   cid   
   cid  
   cid Xt cid  
   cid  
   cid   

   cid cid Xt cid  

 cid     cid   

and  cid Xt cid  

 cid   cid Vt
where the last inequality is due to CauchySchwartz inequality  We have the following two lemmas to bound
 cid   cid Vt
  respectively  Their proofs are de 
 
 
ferred to the appendix 
Lemma   Let  Xt 
   be   sequence in Rd satisfying
   Suppose there is an integer   such that  min Vm      then
for all      

 cid Xt cid      De ne        and Vt  cid   
 cid       

   XsX cid 
 cid 

 cid 

    cid 

 cid Xt cid  

 
 

 

    

 nd log

 

 

 cid 

Lemma   Suppose  min          For any    
      de ne event

    

 cid   cid Vt

   
 

 
 

log            log 

 

Then  event    holds for all       with probability at least
     

 cid 

 cid 

 cid   

We now choose      
 
event    holds for all       then 

  log             log  If

 cid 

   cid   

    Xt cid  

 
 

   cid  

   cid   
 

 
 

 cid   

 cid cid Xt cid  

     cid     cid Xt   cid 
   
   cid Xt cid  
  cid 

 
 
 
 

 cid 

Combining the above with Lemma   yields

 cid cid   
     cid     cid Xt   cid cid     

    

     
 

log

     log

 cid   

  

 cid   
 cid 

 

 cid 

     

Note that   is an increasing Lipschitz function with Lipschitz constant    and the   function is bounded between
  and   The regret of algorithm UCBGLM can be upper
bounded as

 cid 
 cid 
  cid 

  

 

 cid 
  cid 

   cid   

     cid       cid Xt   cid 

   cid   

     cid       cid Xt   cid 

 cid cid   
     cid     cid Xt   cid cid 

 

    

        

 cid 

 cid 

    

The proof can be  nished by applying   and the speci ed
value of   to the bound above 

 

  Algorithm SupCBGLM

While the algorithm UCBGLM performs suf ciently well
 
in practice  Li et al    it is unclear whether it can
achieve the optimal rates of   
dT log    when   is
 xed and small  As mentioned in Section   the key
technical dif culty in analyzing UCBGLM is the dependence between samples  Inspired by   technique developed
by Auer   to create independent samples for linear
contextual bandits  we propose another algorithm SupCBGLM  Algorithm   which uses algorithm CBGLM  Algorithm   as   subroutine 

Generalized Linear Contextual Bandits

Algorithm   CBGLM
Input  parameter   index set     and candidate set   

  Let    be the solution of cid 
  Vt  cid 

     XiX cid 

    

 

 Yi      cid 

   Xi    

  For        do

wt      cid xt   cid  

 
 

  mt      cid xt       cid 

End For

     up to the  

This algorithm also relies on the idea of con dence bound
to do exploration  At round    the algorithm screens the
candidate actions based on the value of     
    through  
stages until an action is chosen  At stage    we set the
con dence level at stage   to be     If     
         for
some    we need to do more exploration on xt   and thus
we choose this action  Otherwise  the actions are  ltered
in step    such that the actions passed to the next stage are
close enough to the optimal action  Since all the widths
             for some
are smaller than     if     
          
    As  the action   can not be the optimal action  The    
 
ter process terminates when we have already got accurate
estimate of all   cid 
  level and we do not
need to do exploration  Thus in step    we just choose the
action that maximizes the estimated mean value 
Our algorithm is different from the algorithm SupLinRel
in Auer   that we directly maximize the mean  rather
than the upper con dence bound  in steps   and    This
modi cation leads to   simpler algorithm and   cleaner regret analysis  Also  we would like to point out that  unlike
SpectralEliminator  Valko et al    the algorithm can
easily handle   changing action set 
The following result  adapted from Auer   lemma  
shows how the algorithm SupCBGLM will give us independent samples  For the sake of completeness  we also
present its proof here 
Lemma   For all         and          given  xi ai     
      the rewards  yi ai            are independent
random variables 

Algorithm   SupCBGLM
Input  tuning parameter     the number of trials    
Initialization 

for         randomly choose at      
Set      cid log    cid               and        

          
For                     do
  Initialize          and      

  While at  Null

   Run CBGLM with   and        to calculate

    

    for all     As 

    and     
         for some     As 

   If     

   Else if     

set at      update              
 
       

  for all     As 
     update            
    

set at   argmax

  As
         for all     As 

   Else if     

As         As      

      max
  As

             
    

           

End For

 cid 

 cid   

With Lemma   we are able to apply the nonasymptotic
normality result   and thus to prove our regret bound of
Algorithm SupCBGLM 
 
Theorem   For any           if we run the SupCBGLM
algorithm with    
       rounds  where

 cid  log      for

dT and      
 

the regret of the algorithm is bounded as

 cid cid 
RT      cid log   log      log      
 cid 
 log    cid dT log  

dT  
with probability at least       With          we obtain

  RT      

  max

log     

      

 cid 

  

 

 

 

 

 

Proof of Lemma   Since   trial   can only be added to
      in step    of algorithm SupCBGLM  the event     
    only depends on the results of trials          
and on     
     we know it only
depends on the feature vectors xi ai            and on xt   
This implies the lemma 

     From the de nition of     

 
The theorem demonstrates an    
dT log    regret bound
 
for the algorithm SupCBGLM  It has been proved in Chu
et al    Theorem   that
dT is the minimax lower
bound of the expected regret for Karmed linear bandits 
  special of the GLM bandits considered here  Therefore 

Generalized Linear Contextual Bandits

the regret of our SupCBGLM algorithm is optimal up to
logarithm terms of   and    To the best of our knowledge 
this is the  rst algorithm which achieves the  near optimal
rate of GLM bandits 
It is worthwhile to compare Theorem   with the result in
 
Theorem   When          is small  the rate of SupCBGLM is faster  and we improve the previous rates by  
 
factor  Here  we give   brie   illustration of how we get rid
of the extra
  factor  Both in Theorem   and in Filippi
et al       cid       is upper bounded by using the
CauchySchwartz inequality 
   cid          cid   cid  

 

 

 

 
 

Lemma   in the supplementary material establishes that

 cid cid cid      cid cid cid Vn
 cid   log    

 cid cid cid      cid cid cid Vn

    
 

This will lead to an extra
  factor compared to   By
using the CauchySchwartz inequality   we only make
use of the fact that    is close to   in the  cid  sense  However    tells us that actually    is close to   in every
direction  This is the reason why we are able to remove
the extra
  factor to achieve   nearoptimal regret  It also
explains why the bound in Theorem   is tight when   is
large  As   goes large  it is likely there is   direction   for
which   is tight 

 

Proof of Theorem   To facilitate our proof  we  rst
present two technical lemmas  Lemma   follows from
Lemma   Theorem   Theorem   of Vershynin  
and   union bound  The proof of Lemma   is deferred to
the appendix 
Lemma   Fix       Choose in SupCBGLM    
and      
 
  De ne the following event 
        cid 

 cid  log      Suppose   satis es condition

EX        

           
     

 

 

dT

                              
Then  event EX holds with probability at least      

Proof of Lemma   By Lemma   we have independent
samples now  Then to apply Theorem   the key is to
lower bound the minimum eigenvalue of Vt  Note that we
randomly select the feature vectors at the  rst    
dT
rounds  that is  they are independent  Moreover  the feature vectors are bounded  Thus                   are independent subGaussian with parameter  
It follows from
Proposition   that
 
 min Vt     min         

 

dT

for some constant   with probability at

least    
dT   By Theorem   and union bound  we have

exp 

the desired result under condition  
Lemma   Suppose that event EX holds  and that in round
    As for all
   the action at is chosen at stage st  Then    
    st  Furthermore  we have
 
if at is selected in step   
  if at is selected in step     

 
   

       cid 

    

  at

 

   cid 
 

 cid     st
De ne Vs    cid 
 cid 

    

  at  

       

 cid 
        XtX cid 

   then by Lemma  

 cid xt at cid  

   cid   log            

       

 
   

 cid 

       

On the other hand  by the step    of SupCBGLM 

  at           
    

 

Let   be the collection of trials such that at is chosen in
step     Since we have chose     log      each        
      must be in one of    and hence                      

 

Combining the above two inequalities gives us

            cid   log            
   cid  
       cid  If we set    
 cid 
 cid 
 cid 
  cid 
 cid 
 cid 
  cid 
 cid 

       cid 

       cid 

       cid 

 cid 
 cid 

     

   cid 

   cid 

   cid 

RT  

  

 

 

 

 cid 

 cid 

    

    

    

    

  at

  at

  at

  

 

 

 

 

dT   we have

 cid 

   cid 

       cid 

 

  at

 

  

       

 

 

dT          
 
 

 

 

 

    

  cid 

                

 

  

 

dT      

 cid 
  cid 
       cid   log      
     cid log   log      log      

   
 

      

dT      

   log

 
 

 

 

  

 
 

ST

dT  

with probability at least       Here  the  rst inequality is
due to the assumption that           The second inequality is Lemma   The third inequality is the inequality  

Generalized Linear Contextual Bandits

follows that 

  cid 

    

 cid min Vt 

  cid 

    

 

 
        

   

It should be cautioned that  since we do not know the distribution of our feature vectors  we cannot assume the above
gap exists  It is therefore challenging to make the above
arguments rigorous 
In fact  when studying the ARIMA
model in time series  Lai   Wei   Example   provide an example such that  min Vt      log   

  Open Questions
Computational ef cient algorithms  While UCBGLM
and SupCBGLM enjoy good theoretical properties  they
can be expensive in some applications  First  they require
inverting         matrix in every step    costly operation
when   is large  Second  at step    the MLE is computed
using     samples  meaning that the perstep complexity
grows at least linearly with   for   straightforward implementation of the algorithms  It is therefore interesting to
investigate more scalable alternatives  It is possible to use  
 rstorder  iterative optimization procedure to amortize the
cost  analogous to the approach of Agarwal et al   

Kdependent lower bound  Currently  all
the lower
bound results on  generalized  linear bandits have no dependence on    the number of arms  The minimax lower
bound will be of particularly interest because all current
lower bound results assume that        Although it will
at most be   logarithm dependence on    it is still   theoretically interesting question 

Randomized algorithms with optimal regret rate  As
opposed to the deterministic  UCBstyle algorithms studied in this paper  randomized algorithms like EXP   Auer
et al      and Thompson Sampling  Thompson   
have advantages in certain situations  for example  when reward observations are delayed  Chapelle   Li    Recently developed techniques for analyzing Bayes regret in
BLM bandits  Russo   Van Roy    may be useful to
analyze the cumulative regret considered here 

 

 

and the fourth inequality is implied by CauchySchwartz 
This completes the proof of the highprobability result 

  Discussions
In this paper  we propose two algorithms for Karmed bandits with generalized linear models  While the  rst algorithm  UCBGLM  achieves the optimal rate for the case
of in nite number of arms  the second algorithm SupCBGLM is provable optimal for the case of  nite number actions at each round  However  it remains open whether
UCBGLM can achieve the optimal rate for small   

    better regret bound for UCBGLM

  key quantity in determining the regret of UCBGLM is
the minimum eigenvalue of Vt 
If we make an addition
 
assumption on the minimum eigenvalue of Vt  we will be
able to prove an   
Theorem   We run algorithm UCBGLM with    
    log   and        For any           sup 
 
pose there is an universal constant   such that

dT   regret bound for UCBGLM 

holds with probability at least       and

  cid 

    

     

 
 
min  Vt     

 

   

 cid 

  log   

 cid    
 cid dT log    

   

 

Then  the regret of the algorithm is bounded by

RT   CL 

 

with probability at least       where   is   positive  universal constant 

This theorem provides some insights of why UCBGLM
performs well in practice  Although the condition in   is
hard to check and may be violated in some cases  for example  in Karmed bandits  we provide   heuristic argument
to justify this assumption in   range of problems  When
  is large enough  our estimator    is very close to   If
we assume there is   positive gap between  cid xt   
   cid  and
 cid xt     cid  for all    cid    
    we will have at     
  after  for
  steps  Since  xt            are independent
example 
for           xt   
  are also independent samples  Then
Vt   will be wellapproximated by the covariance matrix of
    which we denote by   In many problem in pracxt   
tice  especially when features are dense  it is unlikely the
feature vector xt   
  lies in   lowdimensional subspace of
Rd  It implies that   has full rank  and that we will have
 min Vt          min  when   is large enough  It

 

 

 

Generalized Linear Contextual Bandits

References
AbbasiYadkori  Yasin    al    avid  and Szepesv ari  Csaba 
Improved algorithms for linear stochastic bandits  In Advances in Neural Information Processing Systems   pp 
   

Agarwal  Alekh  Hsu  Daniel  Kale  Satyen  Langford 
John  Li  Lihong  and Schapire  Robert    Taming the
monster    fast and simple algorithm for contextual bandits  In Proceedings of the  th International Conference
on Machine Learning  ICML  pp     

Agarwal  Deepak  Chen  BeeChung  Elango  Pradheep 
Motgi  Nitin  Park  SeungTaek  Ramakrishnan  Raghu 
Roy  Scott  and Zachariah  Joe  Online models for conIn Advances in Neural Information
tent optimization 
Processing Systems   pp     

Auer  Peter  Using con dence bounds for exploitationexploration tradeoffs  The Journal of Machine Learning
Research     

Auer  Peter  CesaBianchi  Nicolo  and Fischer  Paul 
Finitetime analysis of the multiarmed bandit problem 
Machine learning       

Chu  Wei  Li  Lihong  Reyzin  Lev  and Schapire  Robert   
Contextual bandits with linear payoff functions  In Proceedings of the  th International Conference on Arti 
cial Intelligence and Statistics  AISTATS  pp   
 

Dani  Varsha  Hayes  Thomas    and Kakade  Sham   
Stochastic linear optimization under bandit feedback  In
Proceedings of the  st Annual Conference on Learning
Theory  COLT  pp     

Fahrmeir  Ludwig and Kaufmann  Heinz  Consistency and
asymptotic normality of the maximum likelihood estimator in generalized linear models  The Annals of Statistics     

Filippi  Sarah  Cappe  Olivier  Garivier  Aur elien  and
Szepesv ari  Csaba  Parametric bandits  The generalized
linear case  In Advances in Neural Information Processing Systems   pp     

Lai  Tze Leung and Robbins  Herbert  Asymptotically ef 
 cient adaptive allocation rules  Advances in Applied
Mathematics     

Auer  Peter  CesaBianchi  Nicolo  Freund  Yoav  and
Schapire  Robert    The nonstochastic multiarmed bandit problem  SIAM Journal on Computing   
   

Lai  Tze Leung and Wei  Ching Zong  Least squares estimates in stochastic regression models with applications
to identi cation and control of dynamic systems  The
Annals of Statistics     

Beygelzimer  Alina  Langford  John  Li  Lihong  Reyzin 
Lev  and Schapire  Robert    Contextual bandit algorithms with supervised learning guarantees  In Proceedings of the  th International Conference on Arti cial
Intelligence and Statistics  AISTATS  pp     

Bickel  Peter    Ritov  Ya acov  and Tsybakov  Alexandre    Simultaneous analysis of Lasso and Dantzig selector  The Annals of Statistics     

Brown  Lawrence    Fundamentals of Statistical Exponential Families with Applications in Statistical Decision
Theory  volume   of Lecture NotesMonograph Series 
Institute of Mathematical Statistics   

Bubeck    ebastien and CesaBianchi  Nicolo  Regret analysis of stochastic and nonstochastic multiarmed bandit
problems  Foundations and Trends in Machine Learning     

Chapelle  Olivier and Li  Lihong  An empirical evaluation
of Thompson sampling  In Advances in Neural Information Processing Systems   pp     

Chen  Kani  Hu  Inchi  and Ying  Zhiliang  Strong consistency of maximum quasilikelihood estimators in generalized linear models with  xed and adaptive designs  The
Annals of Statistics     

Lehmann  Erich Leo and Casella  George  Theory of Point
Estimation  volume   of Springer Texts in Statistics 
Springer Science   Business Media   

Li  Lihong  Chu  Wei  Langford  John  and Schapire 
Robert      contextualbandit approach to personalized
news article recommendation  In Proceedings of the  th
International Conference on World Wide Web  WWW 
pp    ACM   

Li  Lihong  Chu  Wei  Langford  John  Moon  Taesup  and
Wang  Xuanhui  An unbiased of ine evaluation of contextual bandit algorithms with generalized linear models  JMLR Workshop and Conference Proceedings   
   

McCullagh  Peter and Nelder  John    Generalized Linear

Models  volume   CRC press   

Pollard  David  Empirical processes  Theory and applications  In NSFCBMS regional conference series in probability and statistics  pp     JSTOR   

Rusmevichientong  Paat and Tsitsiklis  John    Linearly
parameterized bandits  Mathematics of Operations Research     

Generalized Linear Contextual Bandits

Russo  Daniel and Van Roy  Benjamin  Learning to optimize via posterior sampling  Mathematics of Operations
Research     

Sarkar  Jyotirmoy  Onearmed bandit problems with covariates  The Annals of Statistics   
 

Thompson  William    On the likelihood that one unknown
probability exceeds another in view of the evidence of
two samples  Biometrika     

Valko  Michal  Munos    emi  Kveton  Branislav  and
Koc ak  Tom      Spectral bandits for smooth graph functions  In Proceedings of the  th International Conference on Machine Learning  ICML  pp     

Van der Vaart  Aad    Asymptotic Statistics  volume  

Cambridge university press   

Vershynin  Roman 

Introduction to the nonasymptotic
analysis of random matrices 
In Eldar  Yonina    and
Kutyniok  Gitta  eds  Compressed Sensing  Theory and
Applications  pp    Cambridge University Press 
 

Woodroofe  Michael    onearmed bandit problem with  
concomitant variable  Journal of the American Statistical Association     

