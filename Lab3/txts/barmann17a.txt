Emulating the Expert  Inverse Optimization through Online Learning

Andreas   rmann     Sebastian Pokutta     Oskar Schneider    

Abstract

In this paper  we demonstrate how to learn the
objective function of   decision maker while only
observing the problem input data and the decision maker   corresponding decisions over multiple rounds  Our approach is based on online
learning techniques and works for linear objectives over arbitrary sets for which we have   linear optimization oracle and as such generalizes
previous work based on KKTsystem decomposition and dualization approaches  The applicability of our framework for learning linear constraints is also discussed brie    Our algorithm
  and we demonconverges at   rate of     pT
strate its effectiveness and applications in preliminary computational results 

  Introduction
Human decision makers are very good at making decisions
under rather imprecise speci cation of the decisionmaking
problem both in terms of constraints as well as objective 
One might argue that the human decision maker can pretty
reliably learn from observed previous decisions     traditional learningby example setup  At the same time  when
we try to turn these decisionmaking problems into actual
optimization problems  we often run into all types of issues
in terms of specifying the model  In an optimal world  we
would be able to infer or learn the optimization problem
from previously observed decisions taken by an expert 
This problem naturally occurs in many settings where we
do not have direct access to the decision maker   preference
or objective function but we can observe her behaviour and
the learner as well as the decision maker have access to
the same information  Natural examples are as diverse as

 Equal

contribution

 FriedrichAlexander Universit  
ErlangenN rnberg  Erlangen  Germany  Georgia Institute of
Technology  Atlanta  USA  Correspondence to  Andreas   rmann  Andreas Baermann math unierlangen de  Sebastian
Pokutta  Sebastian Pokutta isye gatech edu  Oskar Schneider
 Oskar Schneider fau de 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

making recommendations based on user history and strategic planning problems  where the agent   preferences are
unknown but the system is observable  Other examples
include knowledge transfer from   human planner into  
decisionsupport system  often human operators have arrived at  nelytuned  objective functions  through many
years of experience  and in many cases it is desirable to
replicate the decisionmaking process both for scaling up
and also for potentially including it in largescale scenario
analysis and simulation to explore responses under varying
conditions 
Here we consider the learning of preferences or objectives
from an expert by means of observing her actions  More
precisely  we observe   set of input parameters and corresponding decisions of the form                 pT   xT  
They are such that pt     with                 is   certain
realization of problem parameters from   given set      
and xt is an optimal solution to the optimization problem

truex

max cT
           pt 

where ctrue     is the expert   true but unknown objective
and   pt      for some  xed     We assume that we
have full information on the feasible set   pt  and that we
can compute argmax cT           pt  for any candidate
objective       and                   We present an online
learning algorithm based on the multiplicative weights update method that allows us to learn   strategy             cT  
of subsequent objective function choices with the following guarantee  if we optimize according to the surrogate
objective function ct instead of the actual unknown objective function ctrue in response to parameter realization pt 
we obtain   sequence of optimal decisions         to each ct 
given by

 xt   argmax cT

            pt 

that are essentially as good as the decisions xt taken by the
expert on average  To this end  we interpret the observations of parameters and expert solutions as revealed over
multiple rounds such that in each round   we are shown the
parameters pt  rst  then take our optimal decision  xt according to our objective function ct  then we are shown the
solution xt chosen by the expert and  nally we are allowed

Emulating the Expert  Inverse Optimization through Online Learning

to update ct for the next round  For this setup  we will be
able to show that our algorithm attains an error bound of

 
 

   

TXt 

 ct   ctrue    xt   xt     Kr ln  

 

 

where       is an upper bound on the  diameter of the
feasible regions   pt  with                   This implies that
both the deviations in true cost cT
true xt    xt      as well
as the deviations in surrogate cost cT
   xt   xt      can be
made arbitrarily small on average  In other words  the average regret for having decided optimally according to the
surrogate objectives ct vs  having decided optimally for the
true objective ctrue vanishes at   rate of     pT
  This result shows that linear objective functions over general feasible sets can be learned from relatively few observations of
historical optimal parametersolutions pairs  We will also
brie   discuss the case where the objective ctrue is known 
but some linear constraints are unknown in this paper 

Literature Overview
The idea of learning or inferring parts of an optimization
model from data is   reasonably wellstudied problem under many different assumptions and applications and has
gained signi cant attention in the optimization community over the last few years  as discussed for example in
 den Hertog   Postek     Lodi     SimchiLevi 
  These papers argue that there would be signi cant
bene ts in combining traditional optimization models with
dataderived components  Most approaches in the literature focus on deriving the objective function of an expert decision maker based on past observations of input
data and the decisions she took in each instance 
In almost all cases  the objective functions are learned by considering the KKTconditions or the dual of the  parameterized  optimization problem  and as such convexity for
both the feasible region and the objective function is inherently assumed  Examples of this approach include  Keshavarz et al     Li    and  Thai   Bayen   
where the latter also consider the derivation of variational
inequalities from data  Sometimes also distributional assumptions regarding the observations are made  Applications of such approaches have been heavily studied in the
context of energy systems  Ratliff et al    Konstantakopoulos et al    robot motion  Papadopoulos et al 
   Yang et al    medicine  Sayre   Ruan   
and revenue management  Kallus   Udell    Qiang
  Bayati    Chen et al    Kallus   Udell   
Bertsimas   Kallus    also in the situation where the
observed decisions were not necessarily optimal  Nielsen
  Jensen    Very closely related to our learning approach in terms of the problem formulation is  Troutt et al 
  which was later extended in  Troutt et al   
where an optimization model is de ned that searches for

  linear optimization problem that minimizes the total difference between the observed solutions and solutions found
by optimizing according to that optimization problem  In
the latter case  the models are solved using LP duality and
cutting planes respectively  In their followup work  Troutt
et al      genetic algorithm is used to solve the problem heuristically under rather general assumptions  but inherently without any quality guarantees  and  Troutt et al 
  study experimental setups for learning objectives under various stochastic assumptions  focussing on maximal
likelihood estimation  which is generally the case for their
line of work  we make no such assumptions 
Closely related to learning optimization models from observed data is the subject of inverse optimization  Here
the goal is to  nd an objective function that renders the
observed solutions optimal with respect to the concurrently observed parameter realizations  Here approaches
mostly from convex optimization are used for inverse optimal control  Iyengar   Kang    Panchea   Ramdani    Molloy et al    inverse combinatorial optimization     Burton    Burton   Toint     
Sokkalingam et al    Ahuja   Orlin    integer inverse optimization  Schaefer    and inverse optimization in the presence of noisy data  such as observed decisions that were suboptimal  Aswani et al    Chan
et al   
All these approaches heavily rely on duality and thus require convexity assumptions both for the feasible region as
well as the objectives  As such  they cannot deal with more
complex  possibly nonconvex decision domains  This in
particular includes the important case of integervalued decisions  such as  yes no decisions  and also many other
nonconvex setups  several of which admit ef cient linear
optimization algorithms  Previously  this was only possible when the structure of the feasible set could be benefically exploited  In contrast  our approach does not make
any such assumptions and only requires access to   linear
optimization oracle  in short  LP oracle  for the feasible
region 
Also related to our work is inverse reinforcement learning
and apprenticeship learning  where the reward function is
the target to be learned  However  in this case the underlying problem is modeled as   Markov decision process
 MDP  see       Syed   Schapire    and  Ratia et al 
  Typically  the guarantees are of   different form
though  Similarly  our work is not to be confused with that
of  Taskar et al    and  III et al    who develop
online algorithms for learning aggregation vectors for edge
features in graphs that use inverse optimization as   subroutine to de ne the update rule  In contrast  we do inverse
optimization by means of an online learning algorithm  basically the reverse setup 

Emulating the Expert  Inverse Optimization through Online Learning

Our approach is based on online learning  and we use the
simple EXP algorithm here to attain the stated regret bound 
The EXP algorithm is commonly also called Multiplicative
Weights Update  MWU  algorithm and was developed in
the works of  Littlestone   Warmuth     Vovk   
and  Freund   Schapire     see  Arora et al   
Hazan    for   comprehensive introduction  see also
 Audibert et al      similar algorithm was used by
 Plotkin et al    for solving fractional packing and
covering problems  We also note that our feedback is
stronger than bandit feedback  This requirement is not unexpected as the costs chosen by the  adversary  depend on
our decision  as such the bandit model  see       Dani et al 
   AbbasiYadkori et al    does not readily apply 

Contribution
To the best of the authors  knowledge  this paper makes the
 rst attempt to learn the objective function of an optimization model from data using an online learning approach 
Online learning of optimization problems  Based on samples for the inputoutput relationship of an optimization
problem solved by   decision maker  our aim is to learn
an objective function which is consistent with the observed
inputoutput relationship  this is the best one can hope for 
In our setup  the expert solves the decisionmaking problem repeatedly for different input parameter realizations 
From these observations  we are able to learn   strategy of
objective functions that emulate the expert   unknown objective function such that the difference in solution quality
between the solutions converges to zero on average 
While previous methods based on dualization or KKTsystem based approaches can lead to similar or even
stronger results in the continuous convex case  online
learning allows us to relax this convexity requirement and
to work with arbitrary decision domains as long as we are
able to optimize   linear function over them  Thus  we do
not explicitly analyze the KKTsystem or the dual program
 in the case of LPs  see Remark  
In particular  one
might consider our algorithm as an algorithmic analogue
of the KKTsystem  or dual program  in the convex case 
To summarize  we stress that
    we do not make any
assumptions regarding distribution of the observations 
    the observations can be chosen by   fullyadaptive adversary  and     we do not require any convexity assumptions regarding the feasible regions and only rely on access to an LP oracle  We would also like to mention that
our approach can be extended to work with slowly changing objectives using appropriate online learning algorithms
such as  for example   Jadbabaie et al    or  Zinkevich 
  the regret bounds will depend on the rate of change 

Preliminary Computational Tests  While   full computational study is beyond the scope of this paper and left for
future work  we implemented    rst preliminary version of
our algorithm  and we report computational results for  
few select problems 

  Problem Setting
We consider the following family of optimization problems  OPT      which depend on   parameter        
  for some      

truex

max cT
             
  is the objective function and       
where ctrue  
  is the feasible region  where the latter depends on the
parameter    Of particular interest to us will be feasible
regions that arise as polyhedra de ned by linear constraints
and their intersections with integer lattices 

                                  

with            and           However  our approach can also readily by applied in the case of more complex feasible regions  such as mixedinteger sets bounded
by convex functions 

                                 

with                   convex   or even more
general settings  In fact  for any possible choice of model
for the set of feasible decisions  we only require the availability of   linear optimization oracle capable of optimizing
linear functions over      for any         We call   decision       optimal for   if it is an optimal solution to
OPT   
We assume that Problem OPT    models   parameterized
optimization problem which has to be solved repeatedly for
various input parameters    Our task is to learn the  xed objective function ctrue from given observations of the parameter   and   corresponding optimal solution   to OPT   
To this end  we further assume that we are given   series of
observations  pt  xt   of parameter realizations pt    
together with an optimal solution xt to OPT pt  computed
by the expert for                   these observations are revealed over time in an online fashion  in round    we obtain   parameter setting pt and compute an optimal solution  xt     pt  with respect to an objective function ct
based on what we have learned about ctrue so far  Then
we are shown the solution xt the expert with knowledge of
ctrue would have taken and can use this information to update our inferred objective function for the next round  In
the end  we would like to be able to use our inferred objective function to take decisions that are essentially as good

Emulating the Expert  Inverse Optimization through Online Learning

as those chosen by the expert in an appropriate aggregation
measure such as  for example   on average  or  with high
probability  The quality of the inferred objective is measured in terms of cost deviation between our solutions  xt
and the solutions xt obtained by the expert  Details will
be given in the next section  where we will derive an algorithm based on multiplicative weights updates  MWU  to
solve the above task 
To    some useful notations  let      denote the ith component of   vector   throughout and let                   
for any natural number    Further  let                
denote the allones vector in
As   technical assumption  we further demand kctruek   
  and ctrue     Both requirements are without loss of
generality and are motivated by our choice of MWU as the
online learning algorithm to simplify the exposition  We
can drop these assumptions by employing  for example  the
Online Gradient Descent algorithm of  Zinkevich   
which requires an explicit projection step 

  

  Learning Objectives
Ideally  we would like to  nd the true objective function ctrue as   solution to the following optimization problem 

kck  Xt     max

min
    
   

    pt 

cT      cT xt   

 

where xt        is the optimal decision taken by the
expert in round    The  normalized  true objective function ctrue     is an optimal solution to Problem   with
objective value   This is because any solution    with
  ck      is feasible and produces nonnegative summands

  max

    pt 

 cT       cT xt 

        

as we assume xt     pt  to be optimal for pt with respect
to ctrue  Thus  the optimal value of   is bounded from
below by  
When solving Problem   we are interested in an objective
function vector       that delivers   consistent explanation for why the expert chose xt as his response to the parameters pt in round                   To be more precise  we
want to minimize the deviation between the optimal value
obtained when optimizing over   pt  with our guess for
the objective function   and the value of the expert   decision evaluated according to our guess    averaged over all
observations  Our algorithm presented here will provide
even stronger guarantees in some cases  such as the one described in Section   showing that we can replicate the
decisionmaking behavior of the expert 

Problem   contains   instances of the following maximization subproblem 

max cT  
           pt 

   
   

For each                   the corresponding Subproblem  
asks for an optimal solution  xt when optimizing over the
feasible set   pt  with our guess   as the objective function 
Remark   Note that in the case of polyhedral feasible
regions       pt    At  bt            and   pt   
    Atx   bt  for                   Problem  
    
can be reformulated as   linear program by dualizing the
  instances of Subproblem   This yields

 

min

  yt   cT xt 
 bT

     AT

TXt 

nXi 

  yt    
yt    
ci    

     

                  
                  

where the yt are the corresponding dual variables and the
xt are the observed decisions from the expert       the latter
are part of the input data  This problem asks for   primal
objective function vector   that minimizes the total duality gap summed over all primaldual pairs  xt  yt  while
all yt   shall be dual feasible  which makes the xt   the respective primal optimal solutions  Thus  Problem   can
be seen as   direct generalization of the linear primaldual
optimization problem 
In fact  our approach also covers
nonconvex cases       mixedinteger linear programs 

Problem   can be interpreted as   game over   rounds
between   player who chooses an objective function ct in
round          and   player who knows the true objective
function ctrue and chooses the observations  pt  xt  in   potentially adversarial way  The payoff of the latter player in
each round   is equal to cT
   xt   xt           the difference in cost between our solution and the expert   solution
as given by our guessed objective function ct 
As Problem   is hard to solve in general  we will
design an algorithm that 
rather than  nding an optimal objective     nds   strategy of objective functions                cT   to play in each round whose error in
solution quality as compared to the true objective function
is as small as possible  Our aim will then be to give   quality guarantee for this strategy in terms of the number of
observations 

Emulating the Expert  Inverse Optimization through Online Learning

To allow for approximation guarantees  it is necessary that
the observed feasible sets have   common upper bound on
their  diameter 
De nition   The  diameter of   set        denoted by diam    is the largest distance between any
two points            measured in the in nitynorm      
diam      maxx   Skx        
In the following  we assume that there exists         with
diam   pt      for all                   With these
prerequisites  our application of multiplicative weights updates  MWU  to learn the objective function of an optimization problem proceeds as outlined in Algorithm  

comparison between the objective function ct chosen in
each round   with the unknown true objective function ctrue 

cT
  yt  

cT
true yt    yt   

ln  

 

 

TXt 

TXt 

where the  yt  is to be understood componentwise  Using
that each each entry of  yt  is at most   and dividing by    
we can conclude

 
 

TXt 

cT
  yt  

 
 

and further

TXt 

cT
trueyt    

ctrue     

ln  
  

nXi 

Algorithm   Online Objective Function Learning
input observations  pt  xt  for                
output sequence of objectives               cT

       ln  
   set learning rate 
          initialize weights 
  for                 do
ct   wt
 
kwtk 
 xt   argmax cT
 
lem  
if  xt   xt then

 normalize weights 

        pt   solve Subprob 

else

yt    
yt    xt xt
  xt xtk 

 
 
 
 
 
 
  end for
  return                cT  

end if
wt      wt       yt     update weights 

For the series of objectives functions  ct   that our algorithm produces over rounds                   we can establish
the following guarantee 
Theorem   Let       with diam    pt      for all
                  Then we have

 
 

   

TXt 

 ct   ctrue    xt   xt     Kr ln  

 

 

and in particular it also holds 

       
       

  PT
  PT

   cT

   cT

   

   xt   xt     Kq ln  
true xt    xt     Kq ln  

   

Proof  According to the standard performance guarantee
of MWU  see        Arora et al    Corollary  
Algorithm   attains the following solution quality for the

 
 

TXt 

cT
  yt  

 
 

cT
trueyt      

ln  
  

 

TXt 

The righthand side attains its minimum for       ln  

which yields the bound

   

 
 

TXt 

cT
  yt  

 
 

TXt 

trueyt      ln  

 

cT

 

Substituting back for the yt   and using

  Tk xt   xtk    max
max

   

diam   pt      

we obtain

 

cT

 
 

TXt 

cT
   xt   xt   

true xt    xt     Kr ln  
TXt 
 
 
Observe that for each summand          we have cT
   xt  
xt      as  xt  xt     pt  and  xt is the maximum over this
set with respect to ct  With   similar argument  we see that
true xt    xt      for all          Thus  we have
cT
 ct   ctrue    xt   xt     Kr ln  

   

 
 

 

 

 

 

and similarly for the separate terms with analogue argumentation  This establishes the claim 

TXt 

Note that by using exponential updates of the form

wt      wt     yt   

in line   of the algorithm  we could attain the same bound 
cf   Arora et al    Theorem   Secondly  we remark
that our choice of the learning rate   requires the number
of rounds   to be known beforehand 
From the above theorem  we can conclude that the average
error over all observations  pt  xt  for                 when
choosing objective function ct in iteration   of Algorithm  
instead of ctrue converges to   with an increasing number of
observations   at   rate of roughly     pT

 

Emulating the Expert  Inverse Optimization through Online Learning

Corollary   Let       with diam    pt      for all
                  Then we have

argmin cT           pt  so that for xt      we have

and

cT
true xt    xt     

     either the two optimal solutions coincide or they differ
by at least   with respect to ctrue  In particular  optimizing
ctrue over   pt  leads to   unique optimal solution for all
pt with          While this condition sounds unnatural at
 rst  for example it is trivially satis ed for the important
case where   pt  with          is   polytope with vertices in     and ctrue is   rational vector  In this case 
write ctrue    
  and observe that the minwith      
kdk 
imum change in objective value between any two vertices
     of the  polytope with cT
truey is bounded by
  so that  stability with      
true         
 cT
kdk 
kdk 
holds in this case  The same argument works for more general polytopes via bounding the minimum nonzero change
in objective function value via the encoding length 
We obtain the following simple corollary of Theorem  
Corollary   Let       with diam    pt      for all
                  let    pt   be  stable for some      
and let NT                xt   xt  Then
 NT   Kr   ln  

truex   cT

 

 

   cT

  PT

true xt    xt     Kq ln  

Proof  We start with the guarantee from the proof of Theorem        
    Now let
  Pt NT
NT be as above so that      
cT
true xt    xt   
 Kq ln  
true xt    xt  as xt was
    Observe that     cT
optimal for ctrue together with  stability  We thus obT  NT     Kq ln  
    which is equivalent to  NT 
tain  
 Kq   ln  

   

   NT   Kq ln  

From the above corollary  we obtain in particular that in
the  stable case we have  
           the
average number of times that  xt deviates from xt tends to
  in the long run  We hasten to stress  however  that the
convergence implied by this bound can potentially be slow
as it is exponential in the actual encoding length of ctrue 
this is to be expected given the convergence rates of our
algorithm and online learning algorithms in general 

  Learning Constraints
We will only very brie   address the case of learning constraints due to space limitations  We consider the family of
optimization problems  OPT                 given

  limT 
  limT 

 

  PT
  PT

 

   cT

   cT

   xt   xt     
true xt    xt     

In other words  both the average error incurred from replacing the actual objective function ctrue by the estimation ct
as well as the average error in solution quality with respect
to ctrue tend to   as   grows 
Moreover  using Markov   inequality we also obtain the
following quantitative bound on the deviation by more than
    from the average cost 
Corollary   Let     Then the fraction of observations xt with cT
      is at most
  In particular  for any           after
   

true xt    xt     Kq ln  

 Kp ln  

   

    ln        

vations xt with cost cT
is at most   

 
observations the fraction of obsertrue xt    xt     

      Kq ln  

     

  

 

Proof  The  rst part is an obvious application of Markov  
inequality  The second part follows from solving    
 Kp ln  

        for   and plugging in values 

 

  The Stable Case
Note that limT ct   ctrue    xt   xt      as derived from Equation   does not necessarily imply that we
can approximate ctrue itself    counterexample is the case
where   pt                   which means that
any two objective functions           with             
for                 and         are equivalent if
      are chosen such that kc      kc       
Using this construction  we can easily  nd examples for
which kc                 but where the two objective
functions are equivalent in terms of optimal solutions 
While in most applications it is suf cient to be able to produce solutions via the surrogate objectives that are essentially equivalent to those for the true objective  we will
show now that under slightly strengthened assumptions we
can obtain signi cantly stronger guarantees for the convergence of the solutions  we will show that in the long run
we learn to emulate the true optimal solutions provided that
the problems have unique solutions as we will make precise
now 
We say that the sequence of feasible regions    pt  
is  stable for ctrue for some       if for any    
        
 

  with kck          ctrue and  xt

Emulating the Expert  Inverse Optimization through Online Learning

by

max        
     Ax   btrue
     

where          is the objective function          is
the constraint matrix and btrue     is the righthand side 
We assume that the ct   are known to both the learner and
the expert  The same can be assumed for   without loss of
generality by standard arguments  The righthand side btrue
is only known to the expert and to be learned from observing pt as well as an optimal solution xt for OPT pt  in
round   
The most natural approach for solving this learning problem is to apply Algorithm   to the dual of OPT pt 

truey

min bT
     AT       pt 

     

where   are the dual variables for the linear constraints  In
the dual problem  btrue is the unknown objective function
 btrue     without loss of generality  while the constraints
to be optimized over in each round are known   the same
setting as before 
It is important to note though that the
learner has to observe the dual optimal solutions yt and
the guarantee will be that the dual regret is tending to  
It remains open whether this can be also achieved when
receiving only the primal optimal solutions xt as feedback 
we suspect the answer to be in the negative in general 

  Applications
We will now sketch two select applications of our framework for learning objective functions  These are the learning of customer preferences from observed purchases and
the learning of travel times in   road network 
Our preliminary computational experiments have been obtained on   Mac Book Pro   with an Intel Core    CPU
with two   GHz cores  We have implemented our framework using python and Gurobi    Gurobi Optimization 
Inc   

  Learning Customer Preferences
We consider   market  where different goods   can be
bought by its customers  The prices for the goods can vary
over different days          We assume that the goods are
chosen by the customer to maximize utility given their budget constraints  Each sample  pt  xt  corresponds to   day
         where pt    pt  ptG  with pt  is the budget of
the buyer and pG
  contains the prices ptg for each good  

at time    The customer solves the following optimization
problem OPT pt  on day   

max Xg  
     Xg  

ugxg

ptgxg   pt 

   

     

where the utility ug of good   of the customer is unknown
 and kept constant over time 
We consider two different setups  in the  rst setup  we assume that the goods are divisible  which means that the
condition           is relaxed to           this
is the Linear Knapsack Problem  In the second setup  the
goods are not divisible  so that we solve the problem with
the original constraint           as an integer program 
this is the Integer Knapsack Problem 
We generated random instances for our computational results  considering       observations for   varying
number of goods           The customer  
unknown utility vector is chosen at random as  arbitrary 
integer numbers from the interval     from   uniform
distribution and then normalized to have  norm   The
prices on day   are chosen to be ptg   ug       rtg 
where rtg is an integer uniformly chosen at random from
the interval     Choosing utilities and weights similar to each other typically leads to harder  integer  knapsack problems  cf   Pisinger    The righthand side
pt  is then again an integer drawn uniformly from the in 

terval  Pg   ptg    

Table   Errors for Integer Knapsack with       items
 
 
 
 

Error    
Average objective error
Average solution error
Average cumulative error

 
 
 
 

 
 
 
 

In Table   we show the computational results for the Integer Knapsack Problem with       items  We report
errors for     and   iterations of our algorithm 
The objective error for each round          is de ned by
     xt   xt  and describes the deviation between the solucT
tion  xt found by the oracle in that round and the solution
xt observed from the expert as evaluated with our guess for
the objective function ct  Accordingly  the solution error
in each round   is de ned as cT
true   xt   xt  and evaluates
the deviation between the two solutions in the true objective function  Together they yield the total error  given by
 ct   ctrue    xt   xt  which is the total deviation between
choosing ct and ctrue in Problem   in round    Each of
these error types is shown in our plots over time  depicting both the error in   given round   and the average error

Emulating the Expert  Inverse Optimization through Online Learning

Figure   Linear Knapsack problem with       items over
      iterations  We plot  
  ct   ctrue    xt   xt  over
  on the xaxis in blue  In red we plot the cost  ct   ctrue    xt  
xT   of round    As can be seen  after few iterations most solutions
reside on the xaxis and only few deviate beyond the average 

  PT

Figure   Resourceconstrained shortest path problem on   grid
graph with       rows and       columns as described above
for       iterations  Total error as in Figure   Convergence
is slower here  although with an error that is several orders of
magnitude smaller  as the problem is much more complex  Still 
in most rounds we have an error close to  

over rounds          We depict   representative knapsack
instance in Figure  

  Learning Travel Times
While the  rst example explored learning over   temporal
horizon  in this example the various observations         
arise from different drivers in   road network  More precisely  we consider   resourceconstrained shortest path
problem  where we are given   graph            where
drivers have to  nd costminimal st paths subject to   resource or budget constraint  For each arc        we denote
the arc length with ae  The observations          represent drivers in the network and each observation  pt  xt 
  is the starting point
consists of pt      
and   
It
is assumed that driver   takes the path with the shortest
travel time with respect to the unknown travel times ce with
      while at the same time being subject to   limit   
  of
total distance that can be traveled  The values of xt indicate the traversed edges of the graph that driver   takes  The
optimization problem OPT pt  solved by driver   is then 

  is the ending point of the journey of driver   

    where   

      

      

if       
 
if       
 
otherwise

        

cexe

min Xe  
     Xe   

xe  Xe   
Xe  

xe    

 
 
 

aexe     

 

   

     

and we want to learn the values ce for       corresponding
to the travel time to traverse arc   
We created instances of the problem based on grid graphs
with   rows and   columns  The unknown driving times
vector of the network and the resource value for each arc
 in our case the length of the arc  were chosen at random
in the same fashion as for the knapsack problems  For each
sample  we chose   random pair of an origin and   destination node  The resource limit for the sample is calculated as
the length of the shortest path between the selected nodes
multiplied by   In other words   nd the fastest path
while driving at most   more than length of the shortest
path  See Figure   for our result over       samples 
Additional computations are included in the Appendix 

  Final Remarks
In its current form  we explicitly use the optimality of the
observed actions to learn the objective function  While beyond the scope of this paper  it would be interesting to analyse to what extent this optimality requirement can be relaxed to approximate solutions  Clearly  one can simply rede ne the underlying feasible regions   pt  to correspond
to the approximate feasible regions  however this can lead
to unwanted effects of the summands in our regret bound
not being nonnegative anymore if the solutions obtained
for the surrogate objective is better than the approximately
optimal observed solution  Another important question is
to what extent our framework can be extended to the learning of constraints  and objective functions simultaneously 

Emulating the Expert  Inverse Optimization through Online Learning

Acknowledgements
We would like to thank the reviewers for the helpful comments  Research reported in this paper was partially supported by NSF CAREER award CMMI 

References
AbbasiYadkori  Yasin         vid  and Szepev ri  Csaba 
In
Improved algorithms for linear stochastic bandits 
Conference on Neural Information Processing System
 NIPS   

Ahuja  Ravindra    and Orlin  James      faster algorithm
for the inverse spanning tree problem  Journal of Algorithms  pp     

Arora  Sanjeev  Hazan  Elad  and Kale  Satyen  The multiplicative weights update method    metaalgorithm and
applications  Theory of Computing     

Aswani  Anil  Shen  ZuoJun Max  and Siddiq  Auyon  Inverse optimization with noisy data  Technical report 
University of California  Berkeley    available at 
https arxiv org abs 

Audibert  JeanYves  Bubeck    bastien  and Lugosi    
bor  Regret in online combinatorial optimization  Mathematics of Operations Research     

Bertsimas  Dimitris and Kallus  Nathan  Pricing from observational data  Technical report  Massachusetts Institute of Technology   
available at https 
arxiv org pdf 

Burton     and Toint  Ph     On an instance of the inverse
shortest paths problem  Mathematical Programming   
   

Burton     and Toint  Ph     On the use of an inverse
shortest paths algorithm for recovering linearly correlated costs  Mathematical Programming   
 

Chan  Timothy       Lee  Taewoo  and Terekhov  Daria 
Goodness of    in inverse optimization  Technical report  University of Toronto  Canada    available at 
https arxiv org abs 

Chen  Xi  Owen  Zachary  Pixton  Clark  and SimchiLevi 
David    statistical learning approach to personalization
in revenue management  Technical report  New York
University   

Dani  Varsha  Hayes  Thomas    and Kakade  Sham    
Stochastic linear optimization under bandit feedback  In
Conference on Learning Theory  COLT   

den Hertog  Dick and Postek  Krzysztof  Bridging the
gap between predictive and prescriptive analytics  
new optimization methodology needed  Technical report  Tilburg University  Netherlands    Available
at  http www optimizationonline org 
DB HTML html 

Freund  Yoav and Schapire  Robert    Adaptive game playing using multiplicative weights  Games and Economic
Behavior     

Gurobi Optimization  Inc  Gurobi optimizer reference
manual  http www gurobi com    URL
http www gurobi com 

Hazan  Elad  Introduction to online convex optimization 
Foundations and Trends in Optimization   
    doi    URL http 
 ocobook cs princeton edu 

III  Hal Daum  Khuller  Samir  Purohit  Manish  and
Sanders  Gregory  On correcting inputs  Inverse optimization for online structured prediction 
In Proceedings of the IARCS Annual Conference on Foundations of
Software Technology and Theoretical Computer Science
 FSTTCS   

Iyengar  Garud and Kang  Wanmo  Inverse conic programming with applications  Operations Research Letters   
   

Jadbabaie  Ali  Rakhlin  Alexander  Shahrampour  Shahin 
and Sridharan  Karthik  Online optimization  Competing
with dynamic comparators  In AISTATS   

Kallus  Nathan and Udell  Madeleine  Learning preferences from assortment choices in   heterogeneous
Technical report  Massechusetts Instipopulation 
tute of Technology   
available at  https 
 pdfs semanticscholar org     
         ea   ebbbd   
pdf 

Kallus  Nathan and Udell  Madeleine 
high

in

Dynamic
dimensions 
 

assortment
Technical
https arxiv org pdf 

personalization
report 

Cornell University 

   Burton        Pulleyblank  Ph     Toint  Network Optimization  chapter The Inverse Shortest Paths Problem
with Upper Bounds on Shortest Paths Costs  pp   
  Springer   

Keshavarz  Arezou  Wang  Yang  and Boyd  Stephen  Imputing   convex objective function 
In Proceedings of
the   IEEE International Symposium on Intelligent
Control  ISIC  pp     

Emulating the Expert  Inverse Optimization through Online Learning

Konstantakopoulos  Ionnias    Ratliff  Lillian    Jin 
Ming  Spanos  Costas  and Sastry     Shankar  Smart
building energy ef ciency via social game    robust
utility learning framework for closingthe loop 
In
   st International Workshop on Science of Smart
City Operations and Platforms Engineering  SCOPE  in
partnership with Global City Teams Challenge  GCTC 
 SCOPE   GCTC  pp     

Li  Jonathan YuMeng 

Inverse optimization of convex
risk function  Technical report  University of Ottawa 
Canada    available at  https arxiv org 
abs 

Littlestone  Nick and Warmuth  Manfred    The weighted
majority algorithm  Information and Computation   
   

Lodi  Andrea 

Big data   mixedinteger

Presentation 

ear  programming 
https atienergyworkshop files 
wordpress com andrealodi pdf 
 

 nonlinat 

available

Molloy  Timothy    Tsai  Dorian  Ford  Jason    and
Perez  Tristan  Discretetime inverse optimal control
with partialstate information    softoptimality approach with constrained state estimation  In   IEEE
 th Conference on Decision and Control  CDC  pp 
   

Nielsen  Thomas    and Jensen  Finn    Learning   decision makers   utility function from  possibly  inconsistent behavior  Arti cial Intelligence     

Panchea  Adina    and Ramdani  Nacim  Towards solving
inverse optimal control in   boundederror framework 
In   American Control Conference  ACC  pp   
   

Papadopoulos  Alessandro Vittorio  Bascetta  Luca  and
Ferretti  Gianni  Generation of human walking paths 
Autonomous Robots     

Pisinger  David  Where are the hard knapsack problems 
Computers   Operations Research   
 

Ratia    ctor  Montesano  Luis  and MartinezCantin 
On the performance of maximum likeliarXiv preprint

Ruben 
hood inverse reinforcement learning 
arXiv   

Ratliff  Lillian    Dong  Roy  Ohlsson  Henrik  and Sastry 
   Shankar  Incentive design and utility learning via energy disaggregation  In Proceedings of the  th World
Congress of the International Federation of Automatic
Control  pp     

Sayre        and Ruan     Automatic treatment planning
with convex imputing  Journal of Physics  Conference
Series     

Schaefer  Andrew  Inverse integer programming  Optimiza 

tion Letters     

SimchiLevi  David  OM research  From problemdriven
to datadriven research  Manufacturing   Service Operations Management     

Sokkalingam        Ahuja  Ravindra    and Orlin 
Solving inverse spanning tree problems
James   
through network  ow techniques  Operations Research 
   

Syed  Umar and Schapire  Robert      gametheoretic
approach to apprenticeship learning  In Conference on
Neural Information Processing System  NIPS   

Taskar  Ben  Chatalbashev  Vassil  Koller  Daphne  and
Guestrin  Carlos  Learning structured prediction models 
  large margin approach  In Proceedings of the International Conference on Machine Learning  ICML   

Thai      me and Bayen  Alexandre   

Imputing  
variational inequality function or   convex objective
Journal of Mathefunction    robust approach 
matical Analysis and Applications   
to appear 
available at  http www sciencedirect com 
science article pii     

Troutt  Marvin    Tadisina  Suresh    Sohn  Changsoo 
and Brandyberry  Alan    Linear programming system
identi cation  European Journal on Operational Research     

Plotkin  Serge    Shmoys  David    and  va Tardos 
Fast approximation algorithms for fractional packing
and covering problems  Mathematics of Operations Research     

Troutt  Marvin    Pang  WanKai  and HungHuo  Shui 
Behavioral estimation of mathematical programming objective function coef cients  Management Science   
   

Qiang 

Sheng and Bayati  Mohsen 

Dynamic
reTechnical
pricing with demand covariates 
port  Stanford University 
available at 
 
https papers ssrn com sol papers 
cfm abstract id 

Troutt  Marvin    Brandybarry  Alan    Sohn  Changsoo  and Tadisina  Suresh    Linear programming system identi cation  The general nonnegative parameters
case  European Journal on Operational Research   
   

Emulating the Expert  Inverse Optimization through Online Learning

Troutt  Marvin    Gwebu  Kholekile    Wang  Jing  and
Brandyberry  Alan    Some experiments on subjective
optimisation  International Journal of Operational Research     

Vovk  Volodimir    Aggregating strategies  In Conference

on Learning Theory  COLT   

Yang  Insoon  Zeilinger  Melanie    and Tomlin  Claire   
Utility learning model predictive control for personal
electric loads 
In  rd IEEE Conference on Decision
and Control  pp     

Zinkevich  Martin  Online convex programming and
Technical
generalized in nitesimal gradient ascent 
report  School of Computer Science  Carnegie Mellon
University    available at  http wwwcgi 
cs cmu edu afs cs cmu edu Web People 
maz publications techconvex pdf 

