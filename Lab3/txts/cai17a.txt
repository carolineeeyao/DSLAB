Priv IT  Private and Sample Ef cient Identity Testing

Bryan Cai     Constantinos Daskalakis     Gautam Kamath    

Abstract

We develop differentially private hypothesis testing methods for the small sample regime  Given
  sample   from   categorical distribution   over
some domain   an explicitly described distribution   over   some privacy parameter   accuracy parameter   and requirements    and
 II for the type   and type II errors of our test 
the goal is to distinguish between       and
dTV           We provide theoretical bounds
for the sample size     so that our method both
satis es    differential privacy  and guarantees    and  II type   and type II errors  We
show that differential privacy may come for free
in some regimes of parameters  and we always
beat the sample complexity resulting from running the  test with noisy counts  or standard
approaches such as repetition for endowing nonprivate  style statistics with differential privacy guarantees  We experimentally compare the
sample complexity of our method to that of recently proposed methods for private hypothesis
testing  Gaboardi et al    Kifer   Rogers 
 

  Introduction
Hypothesis testing is the ageold problem of deciding
whether observations from an unknown phenomenon  
conform to   model    Often   can be viewed as   distribution over some alphabet   and the goal is to determine 
using samples from    whether it is equal to some model
distribution   or not  This type of test is the lifeblood of
the scienti   method and has received tremendous study in
statistics since its very beginnings  Naturally  the focus has
been on minimizing the number of observations from the
unknown distribution   that are needed to determine  with

 Equal contribution

Institute of Technology  Cambridge  Massachusetts  USA  Correspondence
to  Bryan Cai  bcai mit edu  Constantinos Daskalakis
 costis csail mit edu  Gautam Kamath    csail mit edu 

 Massachusetts

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

con dence  whether       or    cid    
In several  elds of research and application  however  samples may contain sensitive information about individuals 
consider for example  individuals participating in some
clinical study of   disease that carries social stigma  It may
thus be crucial to guarantee that operating on the samples
needed to test   statistical hypothesis protects sensitive information about the samples  This is not at odds with the
goal of hypothesis testing itself  since the latter is about
verifying   property of the population   from which the
samples are drawn  and not of the samples themselves 
Without care  however  sensitive information about the
sample might actually be divulged by statistical processing that is improperly designed  As recently exhibited  for
example  it may be possible to determine whether individuals participated in   study from data that would typically
be published in genomewide association studies  Homer
et al    Motivated in part by this realization  there has
been increased recent interest in developing data sharing
techniques which are private  Johnson   Shmatikov   
Uhler et al    Yu et al    Simmons et al   
Protecting privacy when computing on data has been extensively studied in several  elds ranging from statistics to
diverse branches of computer science including algorithms 
cryptography  database theory  and machine learning  see 
      Dalenius    Adam   Worthmann    Agrawal
  Aggarwal    Dinur   Nissim    Dwork   
Dwork   Roth    and their references    notion of privacy proposed by theoretical computer scientists which has
found   lot of traction is that of differential privacy  Dwork
et al    Roughly speaking  it requires that the output
of an algorithm on two neighboring datasets   and   cid  that
differ in the value of one element be statistically close  For
  formal de nition see Section  
Our goal in this paper is to develop tools for privately performing statistical hypothesis testing  In particular  we are
interested in studying the tradeoffs between statistical accuracy  power  signi cance  and privacy in the sample size 
To be precise  given samples from   categorical distribution
  over some domain   an explicitly described distribution
  over   some privacy parameter   accuracy parameter  
and requirements    and  II for the type   and type II errors of our test  the goal is to distinguish between      

Priv IT

and dTV           We want that the output of our test
be    differentially private  and that the probability we
make   type   or type II error be    and  II respectively 
Treating these as hard constraints  we want to minimize the
number of samples that we draw from   
Notice that the correctness constraint on our test pertains
to whether we draw the right conclusion about how   compares to    while the privacy constraint pertains to whether
we respect the privacy of the samples that we draw from   
The pertinent question is how much the privacy constraint
increases the number of samples that are needed to guarantee correctness  Our main result is that privacy may come
for free in certain regimes of parameters  and has   mild
cost for all regimes of parameters 
To be precise  without privacy constraints  it is well known
 
    log  
that identity testing can be performed from   
   
samples  where   is the size of   and     min     II 
and that this is tight  Batu et al    Paninski   
Valiant   Valiant    Acharya et al    Our main
theoretical result is that  with privacy constraints  the number of samples that are needed is

 

 cid 

 cid 

 

  

max

 
   

 
 

 

  

 

  log 

 

 

 cid 

 cid 

 

Our statistical test is provided in Section   where the above
upper bound on the number of samples that it requires is
proven as Theorem   Notice that privacy comes for free
when the privacy requirement   is  
    for example
when       and the required statistical accuracy is  
The precise constants sitting in the    notation of Eq   
are given in the proof of Theorem   We experimentally
verify the sample ef ciency of our tests by comparing them
to recently proposed private statistical tests  Gaboardi et al 
  Kifer   Rogers    discussed in more detail
shortly  Fixing   differential privacy and type    type II error
constraints  we compare how many samples are required
by our and their methods to distinguish between hypotheses that are       apart in total variation distance  We
 nd that different algorithms are more ef cient depending
on the regime and properties desired by the analyst  Our
experiments and further discussion of the tradeoffs are presented in Section  

 
    log  

Approach    standard approach to turn an algorithm differentially private is to use repetition  As already mentioned above  absent differential privacy constraints  statistical tests have been provided that use an optimal    
    number of samples    trivial way to get
  
   differential privacy using such   nonprivate test is to
create    datasets  each comprising   samples from
   and run the nonprivate test on one of these datasets  chosen randomly  It is clear that changing the value of   single

 

 
    log  
 

element in the combined dataset may only affect the output
of the test with probability at most   Thus the output is
   differentially private  see Section   for   proof  The
issue with this approach is that the total number of samples
that it draws is        
    which is higher than
our target  See Corollary  
  different approach towards private hypothesis testing is
to look deeper into the nonprivate tests and try to  privatize  them  The most sampleef cient tests are variations
of the classical  test  They compute the number of times 
Ni  that element       appears in the sample and aggregate
those counts using   statistic that equals  or is close to  the
 divergence between the empirical distribution de ned
by these counts and the hypothesis distribution    They accept   if the statistic is low and reject   if it is high  using
some threshold 
  reasonable approach to privatize such   test is to add
noise       Laplace  noise  to each count Ni  before
running the test  It is well known that adding Laplace 
noise to   set of counts makes them differentially private 
see Theorem   However  it also increases the variance of
the statistic  This has been noticed empirically in recent
work of  Gaboardi et al    for the  test  We show
that the variance of the optimal  style test statistic signi cantly increases if we add Laplace noise to the counts 
in Section   thus increasing the sample complexity from
   to     So this route  too  seems problematic 
  
  last approach towards designing differentially private
tests is to exploit the distance beween the null and the alternative hypotheses    correct test should accept the null
with probability close to   and reject an alternative that is
 far from the null with probability close to   but there are
no requirements for correctness when the alternative is very
close to the null  We could thus try to interpolate smoothly
between datasets that we expect to see when sampling the
null and datasets that we expect to see when sampling an
alternative that is far from the null  Rather than outputting
 accept  or  reject  by merely thresholding our statistic 
we would like to tune the probability that we output  reject  based on the value of our statistic  and make it so that
the  reject  probability is  Lipschitz as   function of the
dataset  Moreover  the probability should be close to   on
datasets that we expect to see under the null and close to  
on datasets that we expect to see under an alternative that
 
is  far  As we show in Section    style statistics have
high sensitivity  requiring  
   samples to be made appropriately Lipschitz 
While both the approach of adding noise to the counts  and
that of turning the output of the test Lipschitz fail in isolation  our test actually goes through by intricately combining these two approaches  It has two steps 

 

Priv IT

     ltering step  whose goal is to  reject  when   is
blatantly far from    This step is performed by comparing the counts Ni with their expectations under   
after having added Laplace  noise to these counts 
If the noisy counts deviate from their expectation  taking into account the extra variance introduced by the
noise  then we can safely  reject  Moreover  because
noise was added  this step is differentially private 

  If the  ltering step fails to reject  we perform   statistical step  This step just computes the  style statistic
from  Acharya et al    without adding noise to
the counts  The crucial observation is that if the  ltering step does not reject  then the statistic is actually
 Lipschitz with respect to the counts  and thus the
value of the statistic is still differentially private  We
use the value of the statistic to determine the bias of  
coin that outputs  reject 

Details of our test are given in Section  

Related Work 
Identity testing is one of the most classical problems in statistics  where it is traditionally called
hypothesis or goodnessof   testing  see  Pearson   
Fisher    Rao   Scott    Agresti    for some
classical and contemporary references  In this  eld  the focus is often on asymptotic analysis  where the number of
samples goes to in nity  and we wish to get   grasp on
their asymptotic distributions and error exponents  Agresti 
  Tan et al   
In the past twenty years  this
problem has enjoyed signi cant interest in the theoretical
computer science community  see        Batu et al   
Paninski    Levi et al    Valiant   Valiant   
Acharya et al    Canonne et al    Diakonikolas  
Kane    Daskalakis et al    and  Canonne   
for   survey  where the focus has instead been on the  nite
sample regime  rather than asymptotics  Speci cally  the
goal is to minimize the number of samples required  while
still remaining computationally tractable 
  number of recent works  Wang et al    Gaboardi
et al    Kifer   Rogers     and   simultaneous
work  focused on independence testing  Kakizaki et al 
  investigate differential privacy with the former set
of goals  In particular  their algorithms focus on  xing  
desired signi cance  type   error  and privacy requirement 
and study the asymptotic distribution of the test statistics 
On the other hand  we are the  rst work to apply differential privacy to the latter line of inquiry  where our goal is
to minimize the number of samples required to ensure the
desired signi cance  power and privacy  As   point of comparison between these two worlds  we provide an empirical
evaluation of our method versus their methods 
The problem of distribution estimation  rather than testing 
has also recently been studied under the lens of differential

privacy  Diakonikolas et al    This is another classical statistics problem which has recently piqued the interest of the theoretical computer science community  We
note that the techniques required for this setting are quite
different from ours  as we must deal with issues that arise
from very sparsely sampled data 

  Preliminaries
In this paper  we will focus on discrete probability distributions over     For   distribution    we will use the notation
pi to denote the mass   places on symbol   
De nition   The total variation distance between   and  
is de ned as

dTV        

 
 

 pi   qi   

 cid 

    

De nition     randomized algorithm   with domain Nn
is    differentially private if for all     Range     and
for all pairs of inputs      cid  such that  cid       cid cid     

Pr                  Pr      

 cid 

          

If       the guarantee is called pure differential privacy 

In the context of distribution testing 
the neighboring
dataset de nition corresponds to two datasets where one
dataset is generated from the other by removing one sample  Up to   factor of   this is equivalent to the alternative
de nition where one dataset is generated from the other by
arbitrarily changing one sample 
De nition   An algorithm for the        II identity
testing problem with respect to    known  distribution  
takes   samples from an  unknown  distribution   and has
the following guarantees 

  If        then with probability at least    it outputs

       

  If dTV           then with probability at least  II

it outputs     cid    

In particular     and  II are the type   and type II errors of
the test  Parameter   is the radius of distinguishing accuracy  Notice that  when   satis es neither of cases above 
the algorithm   output may be arbitrary 

We note that if an algorithm is to satisfy both these de 
nitions  the latter condition  the correctness property  need
only be satis ed when   falls into one of the two cases 
while the former condition  the privacy property  must be
satis ed for all realizations of the samples from    and in
particular  for   which do not fall into the two cases above 

Priv IT

We recall the classical Laplace mechanism  which states
that applying independent Laplace noise to   set of counts
is differentially private 
Theorem    Theorem   of  Dwork   Roth   
Given   set of counts            Nn  the noised counts      
           Nn   Yn  are    differentially private when the
Yi   are        random variables drawn from Laplace 

Finally  we recall the de nition of zeroconcentrated differential privacy from  Bun   Steinke    and its relationship to differential privacy 
De nition     randomized algorithm   with domain Nn
is  zeroconcentrated differentially private  zCDP  if for
all pairs of inputs      cid  such that  cid       cid cid      and all
     

           

 cid 

     

where    is the    enyi divergence between the distribution of       and      cid 
Proposition    Propositions   and   of  Bun   Steinke 
  If   mechanism    satis es    differential privacy  then    satis es  
   zCDP  If   mechanism    satis es  zCDP  then    satis es      
  log   
differential privacy for any      

 cid 

    Simple Upper Bound

 cid   

 cid 

 
 

In this section  we provide an  
upper bound for the
differentially private identity testing problem  More generally  we show that if an algorithm requires   dataset of
size   for   decision problem  then it can be made    
differentially private at   multiplicative cost of   in the
sample size  This is   folklore result  but we include and
prove it here for completeness 
Theorem   Suppose there exists an algorithm for   decision problem   which succeeds with probability at least
    and requires   dataset of size    Then there exists an
   differentially private algorithm for   which succeeds
            and requires  
with probability at least  
dataset of size     

Proof  First  with probability   we  ip   coin and output yes or no with equal probability  This guarantees that
we have probability at least   of either outcome  which
will allow us to satisfy the multiplicative guarantee of differential privacy 
We then draw   datasets of size    and solve the decision problem  nonprivately  for each of them  Finally  we
select   random one of these computations and output its
outcome 
The correctness follows  since we randomly choose the
right answer with probability   or with probability  

we solve the problem correctly with probability       As
for privacy  we note that  if we remove   single element
of the dataset  we may only change the outcome of one
of these computations  Since we pick   random computation  this is selected with probability   and thus the
probability of any outcome is additively shifted by at most
  Since we know the minimum probability of any output is   this gives the desired multiplicative guarantee
required for    differential privacy 

 

   samples for identity testing 

We obtain the following corollary by noting that
the
tester of  Acharya et al     among others  requires
  
Corollary   There exists an    differentially private
testing algorithm for the        II identity testing problem for any distribution   which requires

 cid   

 
 

 cid 

     

  log 

samples  where     min      II 

  Roadblocks to Differentially Private

Testing

In this section  we describe roadblocks which prevent two
natural approaches to differentially private testing from
working 
In Section   we show that if one simply adds Laplace
noise to the empirical counts of   dataset       runs the
Laplace mechanism of Theorem   and then attempts to
run an optimal identity tester  the variance of the statistic
increases dramatically  and thus results in   much larger
sample complexity  even for the case of uniformity testing  The intuition behind this phenomenon is as follows 
When performing uniformity testing in the small sample
regime  when the number of samples   is the square root
of the domain size    we will see           elements
 
  times    
   elements   time  and    elements  
times  If we add Laplace  noise to guarantee    
differential privacy  this obliterates the signal provided by
these collision statistics  and thus many more samples are
required before the signal prevails 
In Section   we demonstrate that   statistics have high
sensitivity  and thus are not naturally differentially private 
In other words  if we consider     statistic  
on two datasets   and   cid  which differ in one record 
            cid  may be quite large  This implies that
methods such as rescaling this statistic and interpreting it
as   probability  or applying noise to the statistic  will not
be differentially private until we have taken   large number
of samples 

    Laplaced  statistic has large variance
Proposition   Applying the Laplace mechanism to  
dataset before applying the identity tester of  Acharya
et al    results in   signi cant increase in the variance  even when considering the case of uniformity  More
precisely  if we consider the statistic

 cid 

 cid 

 

     

 Ni   Yi           Ni   Yi 

    

   

where Ni is the number of occurrences of symbol   in
the dataset    which is of size   oisson    and Yi  
Laplace  then

  If   is uniform  then     cid       

   and Var   cid   

   
     

  If   is   particular distribution which is  far in total variation distance from uniform  then     cid   
         
    

The variance of the statistic can be compared to that of the
unnoised statistic  which is upper bounded by    We
can see that the noised statistic has larger variance until
       
Proof  First  we compute the mean of   cid  Note that since
        oisson    the Ni   will be independently distributed as   oisson mpi   see        Acharya et al   
for additional discussion 

 cid 

   

     

 Ni   Yi           Ni   Yi 

 cid 

   
 Ni          Ni

   

    
     Yi Ni          Yi
   

 cid 

 cid cid 
 cid cid 
 cid 

    

   

 

    

              

              

   

 cid 

    
   
  

In other words  the mean is   rescaling of the   distance
between   and    shifted by some constant amount  When
       the  distance between   and   is   and the expectation is just the second term  Focus on the case where   is
even  and consider   such that pi          if   is even 
and        otherwise  This is  far from uniform in
total variation distance  Furthermore  by direct calculation 
           and thus the expectation of   cid  in this case
is          
   

Priv IT

Next  we examine the variance of   cid  Let      mpi and
 cid 
    mqi        By   similar computation as before  we
have that

Var  

 cid 

   

 

            

 cid 
  

 

 

    
             
 

       
 cid 

 cid 

 

 
 

 cid 

 cid 

 
 cid 

Since all four summands of this expression are nonnegative  we have that

 cid 

    

Var  

 cid 

     
 

 
 cid 

 

 

   
     

If we wish to use Chebyshev   inequality to separate these
two cases  we require that Var   cid  is at most the square
of the mean separation 
In other words  we require that
         or that      
   

 cid    

 cid 

 

 

     statistic has high sensitivity
Consider the primary statistic which we use in Algorithm
 

      

 

  

    

 Ni   mqi    Ni

 

mqi

 cid 

As shown in Section            if       and         
if dTV           and the variance of   is such that these
two cases can be separated with constant probability   
natural approach is to truncate this statistic to the range
    interpret it as   probability and output the result of
Bernoulli      if        the result is likely to be   and if
dTV           the result is likely to be   One might hope
that this statistic is naturally private  More speci cally  we
would like that the statistic   has low sensitivity  and does
not change much if we remove   single individual  Unfortunately  this is not the case  We consider datasets      cid 
where   cid  is identical to    but with one fewer occurrence
of symbol    It can be shown that the difference in   is

Letting   be the uniform distribution and requiring that
this is at most    for the sake of privacy  we have   conm      or that
straint which is roughly of the form  Nin

 cid 

 
Ni
 

 

 cid 

 

     

 

In particular  if Ni   nc for any       this does not
   sample complexity  One may
achieve the desired   
observe that  if Ni is this large  looking at symbol   alone
is suf cient to conclude   is not uniform  even if the count
Ni had Laplace noise added  Indeed  our main algorithm of
Section   works in part due to our formalization and quanti cation of this intuition 

 
 

   

           

 cid 

   

 Ni   mqi    

  qi

Priv IT

  Priv IT    Differentially Private Identity

Tester

In this section  we sketch the proof of our main testing upper bound 
Theorem   There exists an    differentially private
testing algorithm for the        II identity testing problem for any distribution   which requires

 cid 

 cid 

 

 cid 

 cid 

      

max

 
   

 
 

 

  

 

  log 

samples  where     min      II 

The full details of the proof are provided in the supplementary materials 
The pseudocode for this algorithm is provided in Algorithm
  We    the constants        and        For  
highlevel overview of our algorithm   approach  we refer
the reader to the Approach paragraph in Section  

 

distribution  

Algorithm   Priv IT    differentially private identity tester
  Input    an explicit distribution    sample access to  
  De ne          qi                    
  Sample Yi   Laplace    for all      
    such that
  if
then
 
   log
return either     cid     or         with equal probability

there exists
 

 Yi   

     

 cid 

 cid 

  end if
  Draw   multiset   of   oisson    samples from  
  Let Ni be the number of occurrences of the ith domain
element in  
  for       do
 
 

if  Ni   Yi   mqi     

     

   log

 cid 

 

 

 

max cid 

return     cid    

mqi

  

the interval    

 
end if
 
  end for
       
  Let   be the closest value to   which is contained in
  Sample     Bernoulli    
  if       then
 
  else
 
  end if

return     cid    

return        

 cid 
mqi log    log   cid  then
 cid 
     Ni mqi Ni

Proof of Theorem    sketch  We focus on the case where
      the general case follows at the cost of   multiplicative log  in the sample complexity from   stan 

 cid 

 Yi     

dard ampli cation argument  We will require the following
tail bounds on Ni and Yi 
Claim  
for all       with probability exactly       
Claim  
multaneously for all       with probability at least
     

 cid 
mpi log    log   cid  si 

 Ni   mpi    max cid 

simultaneously

     

      
   

   log

 

 

Correctness  Correctness can be shown in   similar way
 
to  Acharya et al      in short  if      
  
then the expectations are separated in the two cases  and the
variance is bounded    careful combination of the previous
claims and Chebyshev   inequality guarantee correctness 

  qi

Privacy  We will prove     differential privacy 
which in our setting  will imply    differential privacy
 due to Claim  
We  rst consider the possibility of rejecting in line  
Noising our counts by the random variables Yi ensures that
this step is     differentially private 
Consider the difference in value of   for two neighboring datasets   and   cid  differing in               cid   
 Ni mqi 
  Conditioning on the event that we did not
return in line   we can show
 Ni   mqi      log     

 cid    log     
 cid cid   

  max
            cid 
Enforcing
mqi log  

 
 
that
  qi
each of these terms are at most    gives the condition
    max
 
Since both terms are at most    this step is     
differentially private  By composition of differential privacy  this gives the desired overall     differential
privacy and thus  pure differential privacy 

 cid 
 cid 
 cid   

  
that
   
 

 cid 

mqi log    log  

This
 

 cid 

implies

   log   

  log     

 cid 

 cid 

 

 

  
   

 

  

 

  

  

 

 

 

  Experiments
We performed an empirical evaluation of our algorithm 
Priv IT  on synthetic datasets  All experiments were
performed on   laptop computer with     GHz Intel Core
  HQ CPU and   GB of RAM  Signi cant discussion
is required to provide   full comparison with prior work in
this area  since performance of the algorithms varies depending on the regime 
We compared our algorithm with two recent algorithms for
differentially private hypothesis testing 

  The Monte Carlo Goodness of    test with Laplace

noise from  Gaboardi et al    MCGOF 

  The projected Goodness of Fit test from  Kifer  

Rogers    zCDPGOF 

Priv IT

We note that we implemented   modi ed version of
Priv IT  which differs from Algorithm   in lines   to
  In particular  we instead consider   statistic

 cid 

 Ni   mqi    Ni

 

   

   

mqi

 

We add Laplace noise to    with scale parameter  
where   is the sensitivity of    which guarantees    
differential privacy  Then  similar to the other algorithms 
we choose   threshold for this noised statistic such that
we have the desired type   error  This algorithm can be
analyzed to provide identical theoretical guarantees as Algorithm   but with the practical advantage that there are
fewer parameters to tune 
To begin our experimental evaluation  we started with uniformity testing  Our experimental setup was as follows 
The algorithms were provided   as the uniform distribution
over     The algorithms were also provided with samples
from some distribution    This  unknown    was   for the
case        or   distribution which we call the  Paninski
construction  for the case dTV           The Paninski
construction is   distribution where half the elements of the
support have mass    and half have mass    
We use this name for the construction as  Paninski   
showed that this example is one of the hardest to distinn  samples to
guish from uniform  one requires  
 nonprivately  distinguish   random permutation of this
construction from the uniform distribution  We  xed parameters       and      
In addition  recall that
Proposition   implies that pure differential privacy  the privacy guaranteed by Priv IT  is stronger than zCDP  the
privacy guaranteed by zCDPGOF  In particular  our guarantee of  pure differential privacy implies  zCDP  As
  result  we ran zCDPGOF with   privacy parameter of
 zCDP  which is equivalent to the amount of zCDP
our algorithm provides  Our experiments were conducted
on   number of different support sizes    ranging from  
to   For each    we ran the testing algorithms with increasing sample sizes   in order to discover the minimum
sample size when the type   and type II errors were both
empirically below   To determine these empirical error
rates  we ran all algorithms   times for each   and   
and recorded the fraction of the time each algorithm was
correct  As the other algorithms take   parameter    as  
target type   error  we input   as this parameter 
The results of our  rst test are provided in Figure   The
xaxis indicates the support size  and the yaxis indicates
the minimum number of samples required  We plot three
lines  which demonstrate the empirical number of samples

Figure   The sample complexities of Priv IT  MCGOF  and
zCDPGOF for uniformity testing

required to obtain   type   and type II error for the different algorithms  We can see that in this case  zCDPGOF
is the most statistically ef cient  followed by MCGOF and
Priv IT 
To explain this difference in statistical ef ciency  we note
that the theoretical guarantees of Priv IT imply that it
performs well even when data is sparsely sampled  More
precisely  one of the bene ts of our tester is that it can
reduce the variance induced by elements whose expected
number of occurrences is less than   Since none of these
testers reach this regime       even zCDPGOF at    
  expects to see each element   times  we do not
reap the bene ts of Priv IT  Ideally  we would run these
algorithms on the uniform distribution at suf ciently large
support sizes  However  since this is prohibitively expensive to do with thousands of repetitions  for any of these
methods  we instead demonstrate the advantages of our
tester on   different distribution 
Our second test is conducted with   being    histogram 
where all but   vanishing fraction of the probability mass is
concentrated on   small  constant fraction of the support 
This serves as our proxy for   very large support  since now
we will have elements which have   subconstant expected
number of occurrences  The algorithms are provided with
samples from   distribution    which is either   or   similar
Paninski construction as before  where the total variation
distance from   is placed on the support elements containing nonnegligible mass  We ran the test on support sizes  
ranging from   to   All other parameters are the same

   khistogram is   distribution where the domain can be partitioned into   intervals such that the distribution is uniform over
each interval 
 In particular  in Figure      support elements contained
     probability mass  but similar trends hold with modi cations of these parameters 

 SupportSize   SampleComplexity   Priv ITzCDPGOFMCGOFUniformityTestingPriv IT

Figure   The sample complexities of Priv IT and zCDPGOF
for identity testing on    histogram

Figure   The sample complexities of Priv IT and zCDPGOF
for uniformity testing  with approximate differential privacy

as in the previous test 
The results of our second test are provided in Figure   In
this case  we compare Priv IT and zCDPGOF  and note
that our test is slightly better for all support sizes    though
the difference can be pronounced or diminished depending on the construction of the distribution    We found
that MCGOF was incredibly inef cient on this construction
  even for       it required   samples  which is
  factor of   worse than zCDPGOF on   support of size
      To explain this phenomenon  we can inspect the
contribution of   single domain element   to their statistic 

 Ni   Yi   mqi 

mqi

 

 

 

In the case where mqi  cid    and        this is approximately equal to    
  The standard deviation of this term
mqi
will be of the order
mqi    which can be made arbitrarily
large as mqi     While zCDPGOF may naively seem
susceptible to this same pitfall  their projection method appears to elegantly avoid it 
As    nal test  we note that zCDPGOF guarantees zCDP 
while Priv IT guarantees  vanilla  differential privacy 
In our previous tests  our guarantee was  differential privacy  while theirs was  
   zCDP  by Proposition   our
guarantees imply theirs  In the third test  we revisit uniformity testing  but when their guarantees imply ours  More
speci cally  again with       we ran zCDPGOF with
the guarantee of  
   zCDP and Priv IT with the guarantee of    
  log    for various       We note
that   is often thought in theory to be  cryptographically
small   such as   but we compare with   wide range
of   both large and small       et for              
This test was conducted on support sizes   ranging from  
to  

 cid 

     

The results of our third test are provided in Figure   We
found that  for all   tested  Priv IT required fewer samples than zCDPGOF  This is unsurprising for   very large
and small  since the differential privacy guarantees become
very easy to satisfy  but we found it to be true for even
 moderate  values of   This implies that if an analyst is
satis ed with approximate differential privacy  she might
be better off using Priv IT  rather than an algorithm
which guarantees zCDP 
While the main focus of our evaluation was statistical in nature  we will note that Priv IT was more ef cient in runtime than our implementation of MCGOF  and more ef cient
in memory usage than our implementation of zCDPGOF 
The former point was observed by noting that  in the same
amount of time  Priv IT was able to reach   trial corresponding to   support size of   while MCGOF was
only able to reach   The latter point was observed by
noting that zCDPGOF ran out of memory at   support size
of   This is likely because zCDPGOF requires matrix computations on   matrix of size      It is plausible
that all of these implementations could be made more time
and memory ef cient  but we found our implementations
to be suf cient for the sake of our comparison 

Acknowledgments
The authors would like to thank Jon Ullman for helpful discussions in the early stages of this work  The authors were
supported by NSF CCF  CCF  CCF 
  and ONR   

 SupportSize   SampleComplexity   Priv ITzCDPGOFIdentityTestingona Histogram SupportSize   SampleComplexity   zCDPGOFPriv IT   Priv IT   Priv IT   Priv IT   Priv IT   UniformityTesting RevisitedPriv IT

References
Acharya  Jayadev  Daskalakis  Constantinos  and Kamath 
Gautam  Optimal testing for properties of distributions 
In Advances in Neural Information Processing Systems
  NIPS   pp    Curran Associates  Inc 
 

Adam  Nabil    and Worthmann  John    Securitycontrol
methods for statistical databases    comparative study 
ACM Computing Surveys  CSUR     

Agrawal  Dakshi and Aggarwal  Charu    On the design
and quanti cation of privacy preserving data mining alIn Proceedings of the  th ACM SIGMODgorithms 
SIGACTSIGART Symposium on Principles of Database
Systems  PODS   pp    New York  NY  USA 
  ACM 

Agresti  Alan  Categorical Data Analysis  Wiley   

Batu  Tugkan  Fischer  Eldar  Fortnow  Lance  Kumar 
Ravi  Rubinfeld  Ronitt  and White  Patrick  Testing
random variables for independence and identity  In Proceedings of the  nd Annual IEEE Symposium on Foundations of Computer Science  FOCS   pp   
Washington  DC  USA    IEEE Computer Society 

Bun  Mark and Steinke  Thomas  Concentrated differential
privacy  Simpli cations  extensions  and lower bounds 
In Proceedings of the  th Conference on Theory of
Cryptography  TCC     pp    Berlin  Heidelberg    Springer 

Canonne  Cl ement      survey on distribution testing 
Your data is big  but is it blue  Electronic Colloquium
on Computational Complexity  ECCC     

Canonne  Cl ement      short note on Poisson tail bounds 
http www cs columbia edu ccanonne 
files misc poissonconcentration 
pdf   

Canonne  Cl ement    Diakonikolas 

Ilias  Gouleakis 
Themis  and Rubinfeld  Ronitt  Testing shape restrictions of discrete distributions  In Proceedings of the  rd
Symposium on Theoretical Aspects of Computer Science 
STACS   pp     

Dalenius  Tore  Towards   methodology for statistical dis 

closure control  Statistisk Tidskrift     

Daskalakis  Constantinos  Dikkala  Nishanth  and Kamath  Gautam  Testing Ising models  arXiv preprint
arXiv   

Diakonikolas  Ilias and Kane  Daniel      new approach
In Profor testing properties of discrete distributions 
ceedings of the  th Annual IEEE Symposium on Foundations of Computer Science  FOCS   pp   
Washington  DC  USA    IEEE Computer Society 

Diakonikolas  Ilias  Hardt  Moritz  and Schmidt  Ludwig 
Differentially private learning of structured discrete distributions  In Advances in Neural Information Processing Systems   NIPS   pp    Curran Associates  Inc   

Dinur  Irit and Nissim  Kobbi  Revealing information while
In Proceedings of the  nd ACM
preserving privacy 
SIGMODSIGACT SIGART Symposium on Principles of
Database Systems  PODS   pp    New York 
NY  USA    ACM 

Dwork  Cynthia  Differential privacy    survey of reIn Proceedings of the  th International Confersults 
ence on Theory and Applications of Models of Computation  TAMC   pp    Berlin  Heidelberg   
Springer 

Dwork  Cynthia and Roth  Aaron  The Algorithmic Foundations of Differential Privacy  Now Publishers  Inc 
 

Dwork  Cynthia  McSherry  Frank  Nissim  Kobbi  and
Smith  Adam  Calibrating noise to sensitivity in private
data analysis  In Proceedings of the  rd Conference on
Theory of Cryptography  TCC   pp    Berlin 
Heidelberg    Springer 

Fisher  Ronald    The Design of Experiments  Macmillan 

 

Gaboardi  Marco  Lim  HyunWoo  Rogers  Ryan    and
Vadhan  Salil    Differentially private chisquared hypothesis testing  Goodness of    and independence testIn Proceedings of the  rd International Confering 
ence on Machine Learning  ICML   pp   
JMLR  Inc   

Homer  Nils  Szelinger  Szabolcs  Redman  Margot  Duggan  David  Tembe  Waibhav  Muehling  Jill  Pearson 
John    Stephan  Dietrich    Nelson  Stanley    and
Craig  David    Resolving individuals contributing trace
amounts of dna to highly complex mixtures using highdensity snp genotyping microarrays  PLoS Genetics   
   

Johnson  Aaron and Shmatikov  Vitaly  Privacypreserving
data exploration in genomewide association studies  In
Proceedings of the  th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining 
KDD   pp    New York  NY  USA   
ACM 

Priv IT

Kakizaki  Kazuya  Sakuma  Jun  and Fukuchi  Kazuto  Differentially private chisquared test by unit circle mechIn Proceedings of the  th International Conanism 
ference on Machine Learning  ICML   JMLR  Inc 
 

Valiant  Gregory and Valiant  Paul  An automatic inequality prover and instance optimal identity testing  In Proceedings of the  th Annual IEEE Symposium on Foundations of Computer Science  FOCS   pp   
Washington  DC  USA    IEEE Computer Society 

Wang  Yue  Lee  Jaewoo  and Kifer  Daniel  Differentially private hypothesis testing  revisited  arXiv preprint
arXiv   

Yu  Fei  Fienberg  Stephen    Slavkovi    Aleksandra   
and Uhler  Caroline  Scalable privacypreserving data
sharing methodology for genomewide association studJournal of Biomedical Informatics   
ies 
 

Kifer  Daniel and Rogers  Ryan      new class of private
chisquare tests  In Proceedings of the  th International
Conference on Arti cial Intelligence and Statistics  AISTATS   pp    JMLR  Inc   

Klar  Bernhard  Bounds on tail probabilities of discrete
distributions  Probability in the Engineering and Informational Sciences     

Levi  Reut  Ron  Dana  and Rubinfeld  Ronitt  Testing
properties of collections of distributions  Theory of Computing     

Paninski  Liam    coincidencebased test for uniforIEEE
mity given very sparsely sampled discrete data 
Transactions on Information Theory   
 

Pearson  Karl  On the criterion that   given system of deviations from the probable in the case of   correlated system
of variables is such that it can be reasonably supposed to
have arisen from random sampling  Philosophical Magazine Series      

Pollard  David 

  few good inequalities 

http 

 www stat yale edu pollard Books 
Mini Basic pdf   

Rao  Jon      and Scott  Alastair    The analysis of categorical data from complex sample surveys  Chisquared
tests for goodness of    and independence in twoway tables  Journal of the Americal Statistical Association   
   

Simmons  Sean  Sahinalp  Cenk  and Berger  Bonnie  Enabling privacypreserving gwass in heterogeneous human populations  Cell Systems     

Tan  Vincent      Anandkumar  Animashree  and Willsky  Alan    Error exponents for composite hypothesis
In Proceedings
testing of Markov forest distributions 
of the   IEEE International Symposium on Information Theory  ISIT   pp    Washington  DC 
USA    IEEE Computer Society 

Uhler  Caroline  Slavkovi    Aleksandra  and Fienberg 
Stephen    Privacypreserving data sharing for genomewide association studies  The Journal of Privacy and
Con dentiality     

