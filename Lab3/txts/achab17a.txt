Uncovering Causality from Multivariate Hawkes Integrated Cumulants

Massil Achab   Emmanuel Bacry   St phane Ga ffas   Iacopo Mastromatteo   JeanFran ois Muzy    

Abstract

We design   new nonparametric method that allows one to estimate the matrix of integrated kernels of   multivariate Hawkes process  This matrix not only encodes the mutual in uences of
each node of the process  but also disentangles
the causality relationships between them  Our
approach is the  rst that leads to an estimation
of this matrix without any parametric modeling
and estimation of the kernels themselves  As  
consequence  it can give an estimation of causality relationships between nodes  or users  based
on their activity timestamps  on   social network
for instance  without knowing or estimating the
shape of the activities lifetime  For that purpose 
we introduce   moment matching method that  ts
the secondorder and the thirdorder integrated
cumulants of the process    theoretical analysis
allows us to prove that this new estimation technique is consistent  Moreover  we show on numerical experiments that our approach is indeed
very robust to the shape of the kernels  and gives
appealing results on the MemeTracker database
and on  nancial order book data 

  Introduction
In many applications  one needs to deal with data containing
  very large number of irregular timestamped events that are
recorded in continuous time  These events can re ect  for
instance  the activity of users on   social network  Subrahmanian et al    highfrequency variations of signals in
 nance  Bacry   Muzy    earthquakes and aftershocks
in geophysics  Ogata    crime activity  Mohler et al 
  or position of genes in genomics  ReynaudBouret
  Schbath    In this context  multidimensional counting processes based models play   paramount role  Within
this framework  an important task is to recover the mutual

 Ecole Polytechnique  Palaiseau  France  Capital Fund Management  Paris  France  Universit  de Corse  Corte  France  Correspondence to  Massil Achab  massil achab     org 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright   by
the author   

in uence of the nodes  by leveraging on their timestamp
patterns  GomezRodriguez et al    Farajtabar et al 
  Xu et al   
Consider   set of nodes                  For each       
we observe   set     of events  where any         labels
the occurrence time of an event related to the activity of   
The events of all nodes can be represented as   vector of
counting processes           
  counts
the number of events of node   until time        namely
 Zi     The vector of stochastic intensities
   
      
   cid  associated with the multivariate counting
      
process     is de ned as

   cid 

       

   cid  where    

  
    lim
dt 

     

  dt      
dt

     Ft 

for        where the  ltration Ft encodes the information
available up to time    The coordinate   
  gives the expected instantaneous rate of event occurrence at time   for
node    The vector    characterizes the distribution of     
see  Daley   VereJones    and patterns in the events
timeseries can be captured by structuring these intensities 

  Hawkes processes

The Hawkes process framework  Hawkes    corresponds to an autoregressive structure of the intensities in order to capture selfexcitation and crossexcitation of nodes 
which is   phenomenon typically observed in social networks  Crane   Sornette    Namely      is called  
Hawkes point process if the stochastic intensities can be
written as

 cid   

  cid 

  

 

  
        

 ij       cid dN  
  cid 

where         is an exogenous intensity and  ij are positive  integrable and causal  with support in    functions
called kernels encoding the impact of an action by node  
on the activity of node    Note that when all kernels are zero 
the process is   simple homogeneous multivariate Poisson
process 

  Related works

Most papers use very simple parameterizations of the kernels  Yang   Zha    Zhou et al      Farajtabar

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

et al    they are of the form  ij       ijh    with
 ij      quantifying the intensity of the in uence of   on  
and         normalized  function that characterizes the timepro le of this in uence and that is shared by all couples of
nodes         most often  it is chosen to be either exponential
            or powerlaw            This is
highly nonrealistic  there is   priori no reason for assuming
that the timepro le of the in uence of   node   on   node  
does not depend on the pair        Moreover  assuming an
exponential shape or   powerlaw shape for      arbitrarily
imposes an event impact that is always instantly maximal 
and that can only decrease with time  while in practice  there
may exist   latency between an event and its impact 
In order to improve this and have more  exibility on the
shape of the kernels  nonparametric estimation is considered in  Lewis   Mohler    and extended to the multidimensional case in  Zhou et al      An alternative
method is proposed in  Bacry   Muzy    where nonparametric estimation is formulated as   WienerHopf equation  Another nonparametric strategy considers   decomposition of kernels on   dictionary of function            hK 
  hk    where the coef cients
aij
  are estimated  see  Hansen et al    Lemonnier  
Vayatis    and  Xu et al    where grouplasso is
used to induce   sparsity pattern on the coef cients aij
  that
is shared across                 
Such methods are heavy when   is large  since they rely
on likelihood maximization or least squares minimization
within an overparametrized space in order to gain  exibility
on the shape of the kernels  This is problematic  since the
original motivation for the use of Hawkes processes is to
estimate the in uence and causality of nodes  the knowledge of the full parametrization of the model being of little
interest by itself 

namely  ij       cid  

   aij

  Granger Causality

Since the question of   real causality is too complex in general  most econometricians agreed on the simpler de nition
of Granger causality  Granger    Its mathematical formulation is   statistical hypothesis test    causes   in the
sense of Granger causality if forecasting future values of  
is more successful while taking   past values into account 
In  Eichler et al    it is shown that for       multivariate Hawkes process     
       
    if and only if  ij        for        Since the kernels
take positive values  the latter condition is equivalent to
   ij   du    
In the following  we ll refer to learning the kernels  integrals
as uncovering causality since each integral encodes the
notion of Granger causality  and is also linked to the number
of events directly caused from   node to another node  as
described below at Eq   

  does not Grangercause    

 cid   

  Our contribution  cumulants matching

Our paper solves this problem with   different and more
direct approach  Instead of trying to estimate the kernels  ij 
we focus on the direct estimation of their integrals  Namely 
we want to estimate the matrix      gij  where

 cid   

gij  

 ij    du     for              

 

 

From the de nition of Hawkes process as   Poisson cluster
process  Jovanovi   et al    gij can be simply interpreted as the average total number of events of node   whose
direct ancestor is   given event of node    by direct we mean
that interactions mediated by any other intermediate event
are not counted  In that respect    not only describes the
mutual in uences between nodes  but it also quanti es their
direct causal relationships  Namely  introducing the counting function      
that counts the number of events of  
whose direct ancestor is an event of    we know from  Bacry
et al    that

 

  dN    

 

    gijE dN  

      gij jdt 

 

where we introduced    as the intensity expectation  namely
satisfying   dN  
       idt  Note that    does not depend on
time by stationarity of      which is known to hold under
the stability condition  cid   cid      where  cid   cid  stands for the
spectral norm of    In particular  this condition implies the
nonsingularity of Id     
The main idea is to estimate the matrix   directly using
  matching cumulants  or moments  method  Indeed the
cumulants write as centered moments  up to the third order 
For higher order  they are computable using the cumulant

generating function  First  we compute an estimation  cid  
Second  we look for   matrix  cid   that minimizes the    error
 cid    cid     cid   cid  This approach turns out to be particularly

of some moments       that are uniquely de ned by   

robust to the kernel shapes  which is not the case of all previous approaches for causality recovery with the Hawkes
model  We call this method NPHC  Non Parametric Hawkes
Cumulant  since our approach is of nonparametric nature 
This new approach is con rmed by   theoretical analysis
allowing to prove the consistency of the NPHC estimator  by
using tools from Generalized Method of Moments  see  Hall 
  and   technical original proof that is detailed in the
supplementary material  Note that moment and cumulant
matching techniques proved particularly powerful for latent topic models  in particular Latent Dirichlet Allocation 
see  Podosinnikova et al    Previous works  Da Fonseca   Zaatour      tSahalia et al    already used
method of moments with Hawkes processes  but only in  
parametric setting  Our work is the  rst to consider such
an approach for   nonparametric counting processes framework 

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

  NPHC  The Non Parametric Hawkes

Cumulant method

The simplest momentbased quantities   that can be explicitly written as   function of   are the integrated cumulants
of the Hawkes process 

  Integrated cumulants of the Hawkes process

  general formula for these cumulants is provided in  Jovanovi   et al    but  as explained below  for the purpose
of our method  we only need to consider cumulants up to the
third order  Given                  the  rst three integrated
cumulants of the Hawkes process can be de ned as follows
thanks to stationarity 

 idt     dN  
   

 cid 
 cid cid 

  

 cid   dN  
 cid   dN  

  dN  

  ijdt  

  ijkdt  

         dN  

     dN  

    

 

 cid 

 

 

 cid   
     dN  
    dN  
    dN  
    dN  

  dN  
     dN  
  dN  
  dN  
   dN  

   dN  
  cid 
      dN  
  cid 
    
  cid   dN  
   

      dN  
  cid   dN  

 cid 

 

  cid 

where Eq    is the mean intensity of the Hawkes process 
the secondorder cumulant   refers to the integrated covariance density matrix and the thirdorder cumulant  
measures the skewness of      Using the Laplace transform  Bacry   Muzy    or the Poisson cluster process
representation  Jovanovi   et al    one can obtain an
explicit relationship between these integrated cumulants and
the matrix    If one sets

     Id     

 

straightforward computations  see Section   lead to the
following identities 

  

  cid 
  cid 
  cid 

  

    

  ij  

  ijk  

Rim  

 mRimRjm

 RimRjmC km   RimC jmRkm

 

 

 

  

    imRjmRkm    mRimRjmRkm 

order to construct the operator that maps   candidate matrix
  to the corresponding cumulants       By looking for

 cid   that minimizes    cid   cid          cid   cid  we obtain  as

illustrated below  good recovery of the ground truth matrix
  using Equation  
The simplest case       has been considered in  Hardiman
  Bouchaud    where it is shown that one can choose
         in order to compute the kernel integral  Eq   
then reduces to   simple secondorder equation that has  
unique solution in    and consequently   unique    that
accounts for the stability condition  cid   cid     
Unfortunately  for       the choice        ij       is
not suf cient to uniquely determine the kernels integrals  In
fact  the integrated covariance matrix provides        
independent coef cients  while    parameters are needed 
It is straightforward to show that the remaining        
conditions can be encoded in an orthogonal matrix    re 
 ecting the fact that Eq    is invariant under the change
    OR  so that the system is underdetermined 
Our approach relies on using the third order cumulant tensor        ijk  which contains                     
independent coef cients that are suf cient to uniquely   
the matrix    This can be justi ed intuitively as follows 
while the integrated covariance only contains symmetric
information  and is thus unable to provide causal information  the skewness given by the third order cumulant in the
estimation procedure can break the symmetry between past
and future so as to uniquely       Thus  our algorithm
consists of selecting    thirdorder cumulant components 
namely        iij        In particular  we de ne the

estimator of   as  cid     argminRL    where
            cid Kc     cid Kc cid 

     cid         cid   cid 

 
 
where  cid     cid  stands for the Frobenius norm  Kc  
   iij       is the matrix obtained by the contraction
of the tensor   to    indices    is the covariance matrix 

while cid Kc and  cid   are their respective estimators  see Equa 

tions     below  It is noteworthy that the above mean
square error approach can be seen as   peculiar Generalized Method of Moments  GMM  see  Hall    This
framework allows to determine the optimal weighting matrix involved in the loss function  which is   question to be
addressed in an extended version of the present work  In this
work  we use the coef cient   to scale the two terms  by set 
  Finally the estimator

ting      cid cid Kc cid 

 cid cid Kc cid 

of   is straightforwardly obtained as
 

     cid cid   cid 
 cid     Id    cid  

 

Our strategy is to use   convenient subset of Eqs     
and   to de ne    while we use Eqs      and   in

from the inversion of Eq    Let us mention an important
point  the matrix inversion in the previous formula is not

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

the bottleneck of the algorithm  Indeed  its has   complexity
     which is cheap compared to the computation of the
cumulants when     maxi        cid     which is typically
satis ed  see next subsection  Solving the considered problem on   larger scale  say    cid    is an open question 
even with stateof theart parametric and nonparametric approaches  Zhou et al      Xu et al    Zhou et al 
    Bacry   Muzy    where the number of components   in experiments is always around   or smaller 
Actually  our approach leads to   much faster algorithm than
the considered stateof theart baselines  see Tables  
below 

  Estimation of the integrated cumulants

In this section we present explicit formulas to estimate the
three momentbased quantities listed in the previous section 
namely      and    We  rst assume there exists      
such that the truncation from     to        of
the domain of integration of the quantities appearing in
Eqs    and   introduces only   small error  In practice 
this amounts to neglecting border effects in the covariance
density and in the skewness density  and it is   good approximation if    the support of the kernel  ij    is smaller than
  and ii  the spectral norm  cid   cid  is suf ciently distant from
the critical point  cid   cid     
In this case  given   realization of   stationary Hawkes
process                  as shown in Section   we
can write the estimators of the  rst three cumulants    

compared to     then these estimated cumulants are
consistent estimators of the theoretical cumulants  see
Subsection  

Complexity  The computations of all the estimators of the
 rst  second and thirdorder cumulants have complexity respectively   nd    nd  and   nd  where
    maxi       However  our algorithm requires   lot
less than that  it computes only    thirdorder terms  of

the form  cid   iij  leaving us with only   nd  operations

to perform 

Symmetry  While the values of       ij and   ijk are symmetric under permutation of the indices  their estimators are generally not symmetric  We have thus chosen
to symmetrize the estimators by averaging their values
over permutations of the indices  Worst case is for the
estimator of Kc  which involves only an extra factor
of   in the complexity 

  The NPHC algorithm

The objective to minimize in Equation   is nonconvex 
More precisely  the loss function is   polynomial of   of
degree   However  by replacing   and   appearing in

Eq    and   with  cid  and  cid   helps us to decrease the deless dif cult  We denote  cid      this simpler objective func 

gree from   to   which makes the optimization problem

tion  where the expectations of cumulants    and   ij have
been replaced with their estimators in the righthand side
of Eqs    and   Thanks to  Choromanska et al   
we know that the loss function of   typical multilayer neural
network with simple nonlinearities can be expressed as  
polynomial function of the weights in the network  whose
degree is the number of layers  Since the loss function
of NPHC writes as   polynomial of degree   we expect
good results using optimization methods designed to train
deep multilayer neural networks  We used AdaGrad  Duchi
et al      variant of the Stochastic Gradient Descent
algorithm  It scales the learning rate coordinatewise using the online variance of the previous gradients  in order
to captures secondorder information  Our problem being
nonconvex  the choice of the starting point has   major
effect on the convergence  Here  the key is to notice that the
matrices   that match relation Eq    writes   OL 
with     diag  and   an orthogonal matrix  In our
setting  this algorithm gave nice convergence results for
    Id  The NPHC method is described schematically in
Algorithm  
Even though our main concern is to retrieve the matrix
   let us notice we can also obtain an estimation of the

baseline intensities  from Eq     cid     cid  

 cid  An

ef cient implementation of this algorithm with TensorFlow  see  Abadi et al    is available on GitHub 
https github com achab nphc 

 

 

 

and   as cid    
 cid   ij  
 cid   ijk  

        cid   cid 
        cid   cid 

   

 Zi

 
 

 
 

 
 

 Zi

 cid 
 cid 

   
 
 
          
   

 cid 
 cid 
 cid 
          
 cid 
        cid   cid 
   
 Zi
          
 cid 
 cid 
   cid  
   
      cid   cid   cid   

 cid Zk

 Zj

      cid     

 

Let us mention the following facts 

Bias  While the  rst cumulant    is an unbiased estimator

of     the other estimators  cid   ij and  cid   ijk introduce

  bias  However  as we will show  in practice this
bias is small and hardly affects numerical estimations
 see Section   This is con rmed by our theoretical
analysis  which proves that if   does not grow to fast

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

Algorithm   Non Parametric Hawkes Cumulant method
Input     

Output   cid  
  Estimate cid     cid   ij   cid   iij from Eqs       
  Design  cid      using the computed estimators 
  Minimize numerically  cid      so as to obtain  cid  
  Return  cid     Id    cid  

 

Table   Complexity of stateof theart methods  NPHC   complexity is very low since  especially in the regime    cid    
Method
ODE  Zhou et al     
GC  Xu et al   
ADM   Zhou et al        Nitern   
WH  Bacry   Muzy      nd         
NPHC
  nd    Niterd 

Total complexity
  NiterM           nd     
  NiterM     

  Complexity of the algorithm

Compared with existing stateof theart methods to
estimate the kernel functions       the ordinary differential
equationsbased  ODE  algorithm in  Zhou et al     
the Granger Causalitybased algorithm in  Xu et al   
the ADM  algorithm in  Zhou et al      and the
WienerHopf based algorithm in  Bacry   Muzy   
our method has   very competitive complexity  This can
be understood by the fact that those methods estimate the
kernel functions  while in NPHC we only estimate their
integrals  Let us recall that   is the number of components
and     maxi        cid    the maximum number of events on
  single component  Let us recall complexities given in  Xu
et al    together with other ones  The ODEbased
algorithm is an EM algorithm that parametrizes the kernel
function with   basis functions  each being discretized to
  points  The basis functions are updated after solving  
EulerLagrange equations  The complexity of one iteration
of the algorithm is then                nd      with
  the maximum number of events and   the dimension 
The Granger Causalitybased algorithm is similar to the
previous one  without the update of the basis functions 
that are Gaussian kernels  The complexity per iteration is
         The algorithm ADM  is similar to the two
algorithms above  as EM algorithm as well  with only
one exponential kernel as basis function  The complexity
per iteration is then        The WienerHopf based
algorithm is not iterative  on the contrary to the previous
ones  It  rst computes the empirical conditional laws on
many points  and then invert the WienerHopf system 
leading to     nd          computation  Similarly 
our method  rst computes the integrated cumulants  then
minimize the objective function with Niter iterations  and

invert the resulting matrix  cid   to obtain  cid    At the end  the

complexity of the NPHC method is   nd    Niterd  This
is summarized in Table  

function        of the data  where   is distributed with
respect to   distribution    which satis es the moment
conditions               if and only if       where
  is the  ground truth  value of the parameter  Based on
 cid  
       observed copies            xn of    the GMM method
minimizes the norm of the empirical mean over   samples 
 cid   
     xi   cid  as   function of   to obtain an estin
mate of   In the theoretical analysis of NPHC  we use
ideas from the consistency proof of the GMM  but the proof
actually relies on very different arguments  Indeed  the integrated cumulants estimators used in NPHC are not unbiased 
as the theory of GMM requires  but asymptotically unbiased 
Moreover  the setting considered here  where data consists
of   single realization       of   Hawkes process strongly
departs from the standard       setting  Our approach is
therefore based on the GMM idea but the proof is actually
not using the theory of GMM 
Now  we use the subscript   to refer quantities used or
computed when we observe the process on  Nt  on      
like the truncation term HT   the estimated integrated cothe next equation   cid  stands for the Hadamard product and
 cid  stands for the entrywise square of   matrix  We denote
     Id     
the true value of    and the       valued
 
vector functions

variance  cid CT   or the estimated kernel norm matrix  cid GT   In

    RLR cid 

 cid CT     cid LT   cid 

Kc     cid   cid        cid       RL   cid 

 cid gT      
      cid cid CT  cid        cid   cid CT     cid LT    cid 
 cid Kc
so that  cid LT     is   weighted squared Frobenius norm of
 cid gT     and cid gT    
        under the conditions of the
   stands for convergence in prob 

following theorem  where
ability 
Theorem    Consistency of NPHC  Suppose that  Nt 
is observed on    and assume that

 cid 
 cid 

      

 cid 

 cid 

  Theoretical guarantee  consistency

The NPHC method can be phrased using the framework of
the Generalized Method of Moments  GMM  GMM is  
generic method for estimating parameters in statistical models  In order to apply GMM  we have to  nd   vectorvalued

           if and only if       
        which is   compact set 
  the spectral radius of the kernel norm matrix satis es

 cid   cid     

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

  HT     and    

Then

 cid GT   Id  

        
 cid 

arg min
  

 cid       

 cid LT    

Remark   Assumption   is mandatory for stability of the
Hawkes process  and Assumptions   and   are suf cient to
prove that the estimators of the integrated cumulants de ned
in Equations     and   are asymptotically consistent 
Assumption   is   very mild standard technical assumption 
note   is compact so that the minima of the considered
functionals of   are reached within   Assumption   is
  standard asymptotic moment condition  that allows to
identity parameters from the integrated cumulants 

The proof of the Theorem is given in the supplementary
material 

  Numerical Experiments
Simulated datasets  We simulated several datasets with
Ogata   Thinning algorithm  Ogata    using the opensource library tick  each corresponding to   shape of
kernel 

exponential kernel          exp   
power law kernel               
rectangular kernel              

 
 
 

The integral of each kernel on its support equals     can
be regarded as   characteristic timescale and   is the scaling
exponent for the power law distribution and   delay parameter for the rectangular one  We consider   nonsymmetric
blockmatrix   to show that our method can effectively
uncover causality between the nodes  see Figure   The parameter   take the same constant value on the three blocks 
but we set three very different     and   from one block
to the other  with ratio          and       The
matrix   has constant entries on the blocks   gij     for
dimension   and gij     for dimension     and zero
outside  and the number of events is roughly equal to  
on average over the nodes  We ran the algorithm on three
simulated datasets     dimensional process with rectangular kernels named Rect     dimensional process with
power law kernels named PLaw  and    dimensional
process with exponential kernels named Exp 

MemeTracker dataset  We use events of the most active
sites from the MemeTracker dataset  This dataset contains
the publication times of articles in many websites blogs

 https github com XDataInitiative tick
 https www memetracker org data html

from August   to April   and hyperlinks between
posts  We extract the top   media sites with the largest
number of documents  with about   million of events  We
use the links to trace the  ow of information and establish
an estimated ground truth for the matrix    Indeed  when
an hyperlink   appears in   post in website    the link   can
be regarded as   direct ancestor of the event  Then  Eq   
shows gij can be estimated by      
     links    
     
   

    

 

 

 

 

 

       

       

Order book dynamics  We apply our method to  nancial
data  in order to understand the self and crossin uencing
dynamics of all event types in an order book  An order book is   list of buy and sell orders for   speci  
 nancial instrument  the list being updated in realtime
throughout the day  This model has  rst been introduced in  Bacry et al    and models the order book
via the following  dimensional point process  Nt  
      
  where      
 resp        counts the number of upward  resp  downward 
price moves         resp        counts the number of market
orders at the ask   resp  at the bid  that do not move the
price        resp       counts the number of limit orders at
the ask   resp  at the bid  that do not move the price  and
       resp        counts the number of cancel orders at the
ask   resp  at the bid  that do not move the price  The  nancial data has been provided by QuantHouse EUROPE ASIA 
and consists of DAX future contracts between  
and  

       

       

      

       

      

 

 

 

 

Baselines  We compare NPHC to stateof the art baselines  the ODEbased algorithm  ODE  by  Zhou et al 
    the Granger Causalitybased algorithm  GC  by  Xu
et al    the ADM  algorithm  ADM  by  Zhou et al 
    and the WienerHopf based algorithm  WH  by
 Bacry   Muzy   

Metrics  We evaluate the performance of the proposed
methods using the computing time  the Relative Error

 cid 

   

 aij   bij 

 aij 

RelErr        

 
  

 aij cid bij aij  

MRankCorr        

and the Mean Kendall Rank Correlation

  cid 
      Nconcordant        
where RankCorr        
Ndiscordant       with Nconcordant       the number of pairs

RankCorr ai   bi 

 
 

  

 

      buy orders that are executed and removed from the list
      buy orders added to the list
      the number of times   limit order at the ask is cancelled 
in our dataset  almost   of limit orders are cancelled before
execution 

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

       satisfying xi   xj and yi   yj or xi   xj and
yi   yj and Ndiscordant       the number of pairs       
for which the same condition is not satis ed  Note that
RankCorr score is   value between   and   representing rank matching  but can take smaller values  in absolute
value  if the entries of the vectors are not distinct 

Table   Metrics on Exp  comparable rank correlation  strong
improvement for relative error and computing time 

Method
RelErr
MRankCorr
Time    

ODE
 
 
 

GC
 
 
 

ADM  NPHC
 
 
 
 
 
 

Table   Metrics on MemeTracker  strong improvement in relative
error  rank correlation and computing time 

Method
RelErr
MRankCorr
Time    

ODE
 
 
 

GC
 
 
 

ADM  NPHC
 
 
 
 
 
 

baseline methods on   cores  to decrease the computing
time 
Our method consistently performs better than all baselines 
on the three synthetic datasets  on MemeTracker and on
the  nancial dataset  both in terms of Kendall rank correlation and estimation error  Moreover  we observe that our
algorithm is roughly   times faster than all the considered
baselines 
On Rect  PLaw  and Exp  our method gives very
impressive results  despite the fact that it does not uses any
prior shape on the kernel functions  while for instance the
ADM  baseline do  On these simulated datasets  NPHC
obtains   comparable or slightly better Kendall rank correlation  but improves   lot the relative error 
On MemeTracker  the baseline methods obtain   high relative error of from   to   while our method achieves  
relative error of   which is   strong improvement  Moreover  NPHC reaches   much better Kendall rank correlation 
which proves that it leads to   much better recovery of the
relative order of estimated in uences than all the baselines 
Indeed  it has been shown in  Zhou et al      that kernels of MemeTracker data are not exponential  nor power
law  This partly explains why our approach behaves better 
On the  nancial data  the estimated kernel norm matrix
obtained via NPHC  see Figure   gave some interpretable
results  see also  Bacry et al   

  Any       submatrix with same kind of inputs      
Prices changes  Trades  Limits or Cancels  is symmetric  This shows empirically that ask and bid have
symmetric roles 

  The prices are mostly crossexcited  which means that
  price increase is very likely to be followed by   price
decrease  and conversely  This is consistent with the
wavy prices we observe on  nancial markets 

Figure   Estimated  cid   via NPHC on DAX order book data 

Table   Metrics on Rect  comparable rank correlation  strong
improvement for relative error and computing time 
ADM  WH
 
 
 
 
 
 

Method
RelErr
MRankCorr
Time    

NPHC
 
 
 

ODE
 
 
 

GC
 
 
 

Table   Metrics on PLaw  comparable rank correlation  strong
improvement for relative error and computing time 
ADM  WH
 
 
 
 
 
 

Method
RelErr
MRankCorr
Time    

NPHC
 
 
 

ODE
 
 
 

GC
 
 
 

Discussion  We perform the ADM  estimation  with exponential kernel  by giving the exact value       of one
block  Let us stress that this helps   lot this baseline  in comparison to NPHC where nothing is speci ed on the shape
of the kernel functions  We used       basis functions
for both ODE and GC algorithms  and       quadrature
points for WH  We did not run WH on the  dimensional
datasets  for computing time reasons  because its complexity scales with    We ran multiprocessed versions of the

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

  The market  limit and cancel orders are strongly selfexcited  This can be explained by the persistence of
order  ows  and by the splitting of metaorders into
sequences of smaller orders  Moreover  we observe
that orders impact the price without changing it  For
example  the increase of cancel orders at the bid causes
downward price moves 

  Conclusion
In this paper  we introduce   simple nonparametric method
 the NPHC algorithm  that leads to   fast and robust estimation of the matrix   of the kernel integrals of   Multivariate
Hawkes process that encodes Granger causality between
nodes  This method relies on the matching of the integrated
order   and order   empirical cumulants  which represent
the simplest set of global observables containing suf cient
information to recover the matrix    Since this matrix fully
accounts for the selfand crossin uences of the process
nodes  that can represent agents or users in applications 
our approach can naturally be used to quantify the degree
of endogeneity of   system and to uncover the causality
structure of   network 
By performing numerical experiments involving very different kernel shapes  we show that the baselines  involving
either parametric or nonparametric approaches are very
sensible to model misspeci cation  do not lead to accurate
estimation  and are numerically expensive  while NPHC
provides fast  robust and reliable results  This is con rmed
on the MemeTracker database  where we show that NPHC
outperforms classical approaches based on EM algorithms
or the WienerHopf equations  Finally  the NPHC algorithm
provided very satisfying results on  nancial data  that are
consistent with wellknown stylized facts in  nance 

  Technical details
  Proof of Equation  

       cid 

 

We denote     the matrix

 cid 

 ij      Lz

      dN  

    

udN  
dudt

 cid 

    cid   

  where  cid   

where Lz     is the Laplace transform of    and     
refers to the nth autoconvolution
of     Then we use the characterization of secondorder
statistics   rst formulated in  Hawkes    and fully generalized in  Bacry   Muzy   

 

 

       Id         Id   Lz cid 

     Id       Id     cid 

previous equation gives

    RLR cid 

equation gives   ij  cid 

  Proof of Equation  

which gives us the result since the entry        of the last

   mRimRjm 

We start from  Jovanovi   et al    cf  Eqs    to  
and group some terms 

 

 cid 
 cid 
 cid 
 cid 

 

 

  ijk  

 

 

 

 mRimRjmRkm

 cid 
 cid 
 cid 

 

 

RimRjm

RimRkm

RjmRkm

 nRknL mn 
 nRjnL mn 
 nRinL mn 

 

 

 cid 

Using the relations   mn    Rmn    mn and   ij  

   mRimRjm  proves Equation  

  Integrated cumulants estimators

For       let us denote       
     Let
us  rst remark that  if one restricts the integration domain
to        in Eqs    and   one gets by permuting
integrals and expectations 

       

         

 idt     dN  
   
        
dN  

  ijdt     cid 
  ijkdt     cid 

        

 cid 
         
              

dN  

  dt iE cid 

      

              

 cid 
 cid 
         
         

 

The estimators   and   are then naturally obtained by
replacing the expectations by their empirical counterparts 
notably

  dN  
       
dt

   
 

 cid 

 Zi

     

       

For the estimator   we shall also notice that
 cid   cid 
              
         
 cid 
             cid   jk

 

 

          jk

  dt 

    cid dtdt cid 

where Lij      ij with  ij the Kronecker symbol  Since
Id   Lz     Id   Lz  taking       in the

We estimate the last integral with the remark above 

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

Acknowledgements
This work bene ted from the support of the  cole Polytechnique fund raising   Data Science Initiative  The authors
want to thank Marcello Rambaldi for fruitful discussions on
order book data   experiments 

References
Abadi     Agarwal     Barham     Brevdo     Chen    
Citro     Corrado        Davis     Dean     Devin 
   et al  Tensor ow  Largescale machine learning
on heterogeneous distributed systems  arXiv preprint
arXiv   

  tSahalia     CachoDiaz     and Laeven     JA  Modeling  nancial contagion using mutually exciting jump
processes  Technical report  National Bureau of Economic Research   

Bacry     and Muzy        Hawkes model for price and
trades highfrequency dynamics  Quantitative Finance 
   

Bacry     and Muzy       Firstand secondorder statistics
characterization of hawkes processes and nonparametric
estimation  IEEE Transactions on Information Theory 
   

Bacry     Mastromatteo     and Muzy       Hawkes processes in  nance  Market Microstructure and Liquidity   
   

Bacry     Jaisson     and Muzy       Estimation of slowly
decreasing hawkes kernels  application to highfrequency
order book dynamics  Quantitative Finance  pp   
 

Choromanska     Henaff     Mathieu     Ben Arous    
and LeCun     The loss surfaces of multilayer networks 
In AISTATS   

Crane     and Sornette     Robust dynamic classes revealed
by measuring the response function of   social system 
Proceedings of the National Academy of Sciences   
   

Eichler     Dahlhaus     and Dueck     Graphical modeling for multivariate hawkes processes with nonparametric
link functions  Journal of Time Series Analysis  pp      
       ISSN  

Farajtabar     Wang     Rodriguez     Li     Zha    
and Song     Coevolve    joint point process model
for information diffusion and network coevolution  In
Advances in Neural Information Processing Systems  pp 
   

GomezRodriguez     Leskovec     and Sch lkopf    
Modeling information propagation with survival theory 
Proceedings of the International Conference on Machine
Learning   

Granger           Investigating causal relations by econometric models and crossspectral methods  Econometrica 
    ISSN    

Hall        Generalized Method of Moments  Oxford uni 

versity press   

Hansen        ReynaudBouret     and Rivoirard     Lasso
and probabilistic inequalities for multivariate point processes  Bernoulli     

Hardiman        and Bouchaud       Branchingratio approximation for the selfexciting Hawkes process  Phys 
Rev       December   doi   
PhysRevE 

Hawkes        Point spectra of some mutually exciting
point processes  Journal of the Royal Statistical Society 
Series    Methodological      ISSN
 

Jovanovi       Hertz     and Rotter     Cumulants of Hawkes
point processes  Phys  Rev       April  
doi   PhysRevE 

Lemonnier     and Vayatis     Nonparametric markovian
learning of triggering kernels for mutually exciting and
mutually inhibiting multivariate hawkes processes  In Machine Learning and Knowledge Discovery in Databases 
pp    Springer   

Da Fonseca     and Zaatour     Hawkes process  Fast calibration  application to trade clustering  and diffusive limit 
Journal of Futures Markets     

Lewis     and Mohler       nonparametric em algorithm for
multiscale hawkes processes  Journal of Nonparametric
Statistics   

Daley        and VereJones     An Introduction to the
Theory of Point Processes Volume    Elementary Theory
and Methods  Springer Science   Business Media   

Duchi     Hazan     and Singer     Adaptive subgradient
methods for online learning and stochastic optimization 
The Journal of Machine Learning Research   
   

Mohler        Short        Brantingham        Schoenberg 
      and Tita        Selfexciting point process modeling
of crime  Journal of the American Statistical Association 
 

Ogata     On lewis  simulation method for point processes 
Information Theory  IEEE Transactions on   
 

Uncovering Causality from Multivariate Hawkes Integrated Cumulants

Ogata     Spacetime pointprocess models for earthquake
occurrences  Annals of the Institute of Statistical Mathematics     

Podosinnikova     Bach     and LacosteJulien     Rethinking lda  moment matching for discrete ica  In Advances
in Neural Information Processing Systems  pp   
 

ReynaudBouret     and Schbath     Adaptive estimation for
hawkes processes  application to genome analysis  The
Annals of Statistics     

Subrahmanian       Azaria     Durst     Kagan     Galstyan     Lerman     Zhu     Ferrara     Flammini 
   and Menczer     The darpa twitter bot challenge 
Computer     

Xu     Farajtabar     and Zha     Learning granger causality for hawkes processes  In Proceedings of The  rd International Conference on Machine Learning  pp   
   

Yang       and Zha     Mixture of mutually exciting
processes for viral diffusion  In Proceedings of the International Conference on Machine Learning   

Zhou     Zha     and Song     Learning triggering kernels
for multidimensional hawkes processes  In Proceedings
of the International Conference on Machine Learning  pp 
     

Zhou     Zha     and Song     Learning social infectivity in sparse lowrank networks using multidimensional
hawkes processes  AISTATS     

