Asymmetric Tritraining for Unsupervised Domain Adaptation

Kuniaki Saito   Yoshitaka Ushiku   Tatsuya Harada    

Abstract

It is important to apply models trained on   large
number of labeled samples to different domains
because collecting many labeled samples in various domains is expensive  To learn discriminative representations for the target domain  we
assume that arti cially labeling the target samples can result in   good representation  Tritraining leverages three classi ers equally to provide pseudolabels to unlabeled samples  however  the method does not assume labeling samples generated from   different domain  In this
paper  we propose the use of an asymmetric tritraining method for unsupervised domain adaptation  where we assign pseudolabels to unlabeled samples and train the neural networks as
if they are true labels 
In our work  we use
three networks asymmetrically  and by asymmetric  we mean that two networks are used to label unlabeled target samples  and one network
is trained by the pseudolabeled samples to obtain targetdiscriminative representations  Our
proposed method was shown to achieve   stateof theart performance on the benchmark digit
recognition datasets for domain adaptation 

  Inroduction
inWith the development of deep neural networks 
 CNN 
cluding deep convolutional neural networks
 Krizhevsky et al    the ability to recognize images
and languages has improved dramatically  Training deeplayered networks using   large number of labeled samples
enables us to correctly categorize samples in diverse domains  In addition  the transfer learning of   CNN has been
utilized in many studies  For object detection or segmentation  we can transfer the knowledge of   CNN trained using
  largescale dataset by  netuning it on   relatively small
Japan  RIKEN 
Japan  Correspondence to  Kuniaki Saito  ksaito mi   utokyo ac jp  Yoshitaka Ushiku  ushiku mi   utokyo ac jp 
Tatsuya Harada  harada mi   utokyo ac jp 

 The University of Tokyo  Tokyo 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

dataset  Girshick et al    Long et al     
One of the problems inherent to neural networks is that  although such networks perform well on samples generated
from the same distribution as the training samples  they
may  nd it dif cult to correctly recognize samples from
different distributions at the test time  An example of this
is images collected from the Internet  which may come in
abundance and are fully labeled  Such images have   distribution that differs from images taken from   camera  Thus 
  classi er that performs well on various domains is important for practical use  To realize such   classi er  it is
necessary to learn domaininvariantly discriminative representations  However  acquiring such representations is not
easy because it is often dif cult to collect   large number
of labeled samples  and because samples from different domains have domainspeci   characteristics 
In unsupervised domain adaptation  we try to train   classi er that works well on   target domain under the condition that we are provided labeled source samples and unlabeled target samples during training  Most of the previously developed deep domain adaptation methods operate mainly under the assumption that the adaptation can be
realized by matching the distribution of features from different domains  These methods have been aimed at obtaining domaininvariant features by minimizing the divergence between domains  as well as   category loss on
the source domain  Ganin   Lempitsky    Long et al 
      However  as shown in  BenDavid et al 
  if   classi er that works well on both the source and
the target domains does not exist  we theoretically cannot
expect   discriminative classi er to be applicable to the target domain  That is  even if the distributions are matched
with the nondiscriminative representations  the classi er
may not work well on the target domain  Because the direct learning discriminative representations for the target
domain  in the absence of target labels  is considered very
dif cult  we propose assigning pseudolabels to the target
samples and training the targetspeci   networks as if they
were true labels 
Cotraining and tritraining  Zhou   Li    leverage
multiple classi ers to arti cially label unlabeled samples
and retrain the classi ers  However  such methods do not
assume labeling samples from different domains  Because

Asymmetric Tritraining for Unsupervised Domain Adaptation

Figure Outline of our model  We assign pseudolabels to unlabeled target samples based on the predictions from two classi ers
trained on the source samples 

our goal is to classify unlabeled target samples that have
different characteristics from labeled source samples  we
propose the use of asymmetric tritraining for unsupervised
domain adaptation  By asymmetric  we mean that we assign different roles to three different classi ers 
In this paper  we propose   novel tritraining method for
unsupervised domain adaptation  where we assign pseudolabels to unlabeled samples  and train the neural networks
utilizing these samples  As described in Fig    two networks are used to label unlabeled target samples  and the
remaining network is trained using the pseudolabeled target samples  We evaluated our method using digit classi cation tasks  traf   sign classi cation tasks  and sentiment analysis tasks using the Amazon Review dataset  and
demonstrated its stateof theart performance for nearly all
of the conducted experiments  In particular  for the adaptation scenario  MNIST SVHN  our method outperformed
other methods by more than  
  Related Work
  number of previous methods have attempted to realize
adaptation by measuring the divergence between different
domains  Ganin   Lempitsky    Long et al     
Li et al    Such methods are based on the theory proposed in  BenDavid et al    which states that the expected loss for   target domain is bounded by three terms 
    the expected loss for the source domain   ii  the domain
divergence between the source and target  and  iii  the minimum value of   shared expected loss    shared expected
loss indicates the sum of the loss on the source and target
domains  Because the third term  which is usually considered to be very low  cannot be evaluated when labeled
target samples are absent  most methods attempt to minimize the  rst and second terms  With regard to the training of deep architectures  the maximum mean discrepancy
 MMD  or the loss of   domain classi er network  is utilized to measure the divergence corresponding to the second term  Gretton et al    Ganin   Lempitsky   
Long et al        Bousmalis et al    However  the third term is very important in training   CNN 
which simultaneously extracts and recognizes the representations  The third term can easily become large when
the representations are not discriminative for the target do 

main  Therefore  we focus on how to learn the targetdiscriminative representations to consider the third term 
In  Long et al    the focus was on this point  and  
targetspeci   classi er was constructed using   residual
network structure  Differing from their method  we constructed   targetspeci   network by providing arti cially
labeled target samples 
Several transductive methods use   similarity of features
to provide labels for unlabeled samples  Rohrbach et al 
  Khamis   Lampert    For unsupervised domain adaptation  in  Sener et al      method was proposed to learn the labeling metrics by utilizing the knearest
neighbors between unlabeled target samples and labeled
source samples  In contrast to this method  our method explicitly and simply backpropagates the category loss for the
target samples based on pseudolabeled samples 
Many methods have proposed giving pseudolabels to unlabeled samples by utilizing the predictions of   classi er
and retraining it  including pseudolabeled samples    process called selftraining  The underlying assumption of
selftraining is that one  cid   own highcon dence predictions
are correct  Zhu    As the predictions are mostly
correct  utilizing samples with high con dence will further improve the performance of the classi er  Cotraining
utilizes two classi ers  which have different views on one
sample  to provide pseudolabels  Blum   Mitchell   
Tanha et al    The unlabeled samples are then added
to the training set if at least one classi er is con dent
regarding the predictions  The generalization capability
of cotraining is theoretically ensured  Balcan et al   
Dasgupta et al    under certain assumptions  and applied to various tasks  Wan    Levin et al    In
 Chen et al    the idea of cotraining was incorporated into domain adaptation  Similar to cotraining  tritraining uses the output of three different classi ers to
provide pseudolabels to unlabeled samples  Zhou   Li 
  Tritraining does not require partitioning features
into different views  instead  tritraining initializes each
classi er in   different manner  However  tritraining does
not assume that the unlabeled samples follow different distributions from those the labeled ones are generated from 
Hence  we developed   tritraining method for domain
adaptation that utilizes three classi ers asymmetrically 
In  Lee    the effects of pseudolabels on   neural network were investigated  The authors argued that the effect
of training   classi er using pseudolabels is equivalent to
entropy regularization  thus leading to   lowdensity separation between classes  In our experiments  we observed
that the target samples are separated in hidden features 
  Method
In this section  we provide details of the proposed model
for domain adaptation  We aim to construct   target 

 Asymmetric Tritraining for Unsupervised Domain Adaptation

weights of    and    which are  rst applied to the feature
   xi  With this constraint  each network will learn from
different features  The objective for the learning of    and
   is de ned as

  
 
Ly         xi  yi 

 
  Ly          xi  yi 

 
 

  

  cid      cid       cid       

   cid jW 

     
 

Figure The proposed method includes   shared feature extractor      classi ers for labeled samples     and    that learn from
labeled source samples  and newly labeled target samples  In addition    targetspeci   classi er  Ft  learns from pseudolabeled
target samples  Our method  rst trains networks from only labeled source samples  and then labels the target samples based on
the output of    and    We train all architectures using these
samples under the assumption that they are correctly labeled 

speci   network by utilizing pseudolabeled target samples  Simultaneously  we expect two labeling networks to
acquire targetdiscriminative representations and gradually
increase the accuracy on the target domain 
Our proposed network structure is shown in Fig    Here   
denotes   network that outputs shared features from among
three different networks  and    and    classify the features generated from     Their predictions are utilized to
provide pseudolabels  The classi er Ft classi es features
generated from     which is   targetspeci   network  Here 
   and    learn from the source and pseudolabeled target
samples  and Ft learns only from the pseudolabeled target samples  The shared network   learns from all gradients from       and Ft  Without such   shared network 
another option for the network architecture is training the
three networks separately  although this is inef cient in
terms of training and implementation  Furthermore  by
building   shared network         and    can also harness
the targetdiscriminative representations learned through
the feedback from Ft 
The set of source samples is de ned as
Xs  the unlabeled target set is
pseudolabeled target set is
  Loss for Multiview Features Network

 cid 
 xi  yi 
 cid  Xt  and the
 cid  Xt

 mt
 nt

 xi 
 xi   yi 

 ms

 

 

 

  

  

  

  

In existing studies  Chen et al    on cotraining for domain adaptation  the given features are divided into separate parts  and considered to be different views 
Because we aim to label the target samples with high accuracy  we expect    and    to classify the samples based
on different viewpoints  Therefore  we make   constraint
for the weights of    and    to make their inputs different from each other  We add the term jW 
      to the cost
function  where    and    denote fully connected layer

where Ly denotes the standard softmax crossentropy loss
function  We determined the tradeoff parameter  cid  based
on   validation split 
  Learning Procedure and Labeling Method

samples will provide

Pseudolabeled target
targetdiscriminative information to the network  However 
because they certainly contain false labels  we have to pick
up reliable pseudolabels  which our labeling and learning
method is aimed at realizing 
The entire training procedure of the network is shown in
Algorithm   First  we train the entire network using the
source training set Xs  Here     and    are optimized
through Eq    and Ft is trained based on   standard category loss  After training on Xs  to provide pseudolabels 
we use the predictions of    and    namely          obtained from xk  When    and    denote the class that has
the maximum predicted probability for         we assign  
pseudolabel to xk if the following two conditions are satis ed  First  we require         to provide pseudolabels 
which means the two different classi ers agree with the
prediction  The second requirement is that the maximizing probability of     or     exceed the threshold parameter 
which we set as   or   in the experiment  We suppose
that unless one of the two classi ers is con dent of the prediction  the prediction is not reliable  If the two requirements are satis ed 
  
To prevent an over tting to the pseudolabels  we resample
the candidate for labeling the samples in each step  We set
the number of initial candidates Ninit to   We gradually increase the number of candidates Nt       cid    
where   denotes the number of all target samples  and  
denotes the number of steps  in addition  we set the maximum number of pseudolabeled candidates to   We
set   to   in the experiments  After the pseudolabeled
training set Xt
  is composed        and    are updated
based on the objective in Eq    for the labeled training
set     Xs   Xt
   Then    and Ft are simply optimized
based on the category loss for Xt
Discriminative representations will be learned by constructing   targetspeci   network trained only on the target
samples  However  if only noisy pseudolabeled samples
are used for the training  the network may not learn any

xk  yk          

is added to Xt

 

 

  

         DE   DF       DID               Asymmetric Tritraining for Unsupervised Domain Adaptation

Algorithm   iter denotes the iteration of the training 
The function Labeling indicates the labeling method  We
assign pseudolabels to samples when the predictions of
   and    agree  and at least one of them is con dent of
their predictions 

 

  

   Xt  

 xj 

  

  

 
     

 xi  ti 

Input  data
Xs  
Xt
for       to iter do

Train          Ft with   minibatch from the training
set  
end for
Nt   Ninit
Xt
    Xs   Xt
 
for   steps do

    Labeling         Xt  Nt 

for       to iter do
Train          with minibatch from training set  
Train    Ft with minibatch from training set Xt
      Nt       cid   
    Labeling         Xt  Nt 

end for
Xt
Xt
    Xs   Xt

 

 

end for

our method  The distribution of the source samples is denoted as    that of the target samples  as     and that of the
pseudolabeled target samples  as Tl 
In  BenDavid et al    an equation was introduced
showing that the upper bound of the expected error in the
target domain depends on three terms  which include the
divergence between different domains and the error of an
ideal joint hypothesis  The divergence between the source
and target domains    Hdistance  is de ned as follows 
dH        

   

sup

       

 

     cid   

  cid            

 

   

 cid cid cid 

 cid cid cid   

  cid            
 

 

   

joint hypothesis

RS       RT    

 cid 
is de ned as  

 
  and its corresponding error is

This distance is frequently used to measure the adaptability
between different domains 
The ideal
arg min
 cid 
    RS  
error for each hypothesis  The theorem is as follows 
Theorem    BenDavid et al   
Let   be the hypothesis class  Given two different domains    and     we have
        RT      cid  RS      

  where   denotes the expected

dH            

 cid 
    RT   

 

 
 

useful representations  We then use both the source samples and pseudolabeled samples for the training of      
and    to ensure the accuracy  In addition  as the learning proceeds    will learn targetdiscriminative representations  resulting in an improvement in accuracy for    and
   This cycle will gradually enhance the accuracy in the
target domain 
  Batch Normalization for Domain Adaptation

Batch normalization  BN   Ioffe   Szegedy    which
whitens the output of the hidden layer in   CNN  is an effective technique for accelerating the training speed and
enhancing the accuracy of the model  In addition  in domain adaptation  whitening the output of the hidden layer
is effective in improving the performance  and makes the
distribution in different domains similar  Sun et al   
Li et al   
The input samples of    and    include both pseudolabeled target samples and source samples  Introducing BN
will be useful for matching the distribution and improving
the performance  We add BN layers to       and    which
we detail in our supplementary material 
  Analysis
In this section  we provide   theoretical analysis to our approach  First  we provide insight into existing theory  and
then introduce   simple expansion of the theory related to

This theorem indicates that the expected error on the target domain is upper bounded by three terms  the expected
error on the source domain  the domain divergence measured by the disagreement of the hypothesis  and the error of the ideal joint hypothesis 
In an existing work
 Ganin   Lempitsky    Long et al        was disregarded because it was considered to be negligible  If we
are provided with  xed features  we do not need to consider
this term because it is also  xed  However  if we assume
that xs  cid    and xt  cid    are obtained from the last fully
connected layer of the deep models  we should note that  
is determined based on the output of the layer  as well as
the necessity of considering this term 
We consider the pseudolabeled target sample distributions
Tl given false labels at   ratio of  cid  The shared error of  
 cid 
on   Tl is denoted as  
  The following inequality then
holds 

        RT      cid  RS     
 
 

 cid  RS      

 
 

dH            
 

dH            

   cid 

 

We show   simple derivation of the inequality in the Supplementary materials section 
In Theorem   we cannot
measure   in the absence of labeled target samples  We
can evaluate and minimize it approximately using pseudolabels  Furthermore  when we consider the second term
on the righthand side  our method is expected to reduce

Asymmetric Tritraining for Unsupervised Domain Adaptation

  cid            

 

 

  cid            

this term  This term intuitively denotes the discrepancy between different domains in the disagreement of two clas 
  as    and    respectively 
si ers  If we regard   and  
    should be very low because the trainE
ing is based on the same labeled samples  Moreover  for the
    is expected to be low  alsame reason   
though we use the training set Xt
  instead of the genuine
labeled target samples  Thus  our method considers both
the second and third terms in Theorem  
  Experiment and Evaluation
We conducted extensive evaluations of our method on image datasets and   sentiment analysis dataset  We evaluated
the accuracy of the targetspeci   networks 
Visual Domain Adaptation For visual domain adaptation 
we conducted our evaluation on the digit and traf   sign
datasets  The digit datasets include MNIST  LeCun et al 
  MNISTM  Ganin   Lempitsky    Street
View House Numbers  SVHN   Netzer et al    and
Synthetic Digits  SYN DIGITS 
 Ganin   Lempitsky 
  We further evaluated our method on traf   sign
datasets including Synthetic Traf   Signs  SYN SIGNS 
 Moiseev et al    and the German Traf   Sign Recognition Benchmark  Stallkamp et al     GTSRB  In total   ve adaptation scenarios were evaluated during this
experiment  Because the datasets used for evaluation are
varied in previous studies  we extensively evaluated our
method using these  ve scenarios 
Many previous studies have evaluated the  netuning of
pretrained networks using ImageNet  This protocol assumes the existence of another source domain  In our work 
we want to evaluate   situation in which we have access to
only   single source domain and   single target domain 
Adaptation in Amazon Reviews To investigate its behavior on the language datasets  we evaluated our method
on the Amazon Review dataset
 Blitzer et al   
through the same preprocessing used by  Chen et al   
Ganin et al    The dataset contains reviews on four
types of products  books  DVDs  electronics  and kitchen
appliances  We evaluated our method under   domain
adaptation scenarios  The results are shown in Table  
Baseline Methods We compared our method with  ve
methods for unsupervised domain adaptation 
including stateof the art methods in visual domain adaptation  Maximum Mean Discrepancy  MMD   Long et al 
    Domain Adversarial Neural Network  DANN 
 Ganin   Lempitsky    Deep Reconstruction Classi cation Network  DRCN   Ghifary et al    Domain Separation Network  DSN   Bousmalis et al   
and kNearest Neighbor based adaptation  kNNAd 
 Sener et al    We cited the results of MMD from
 Bousmalis et al   
In addition  we compared our

method with CNN trained only on the source samples  We
compared our method with Variational Fair AutoEncoder
 VFAE   Louizos et al    and DANN  Ganin et al 
  in our experiment on the Amazon Review dataset 
  Implementation Detail
In our experiments on the image datasets  we employed the
architecture of CNN used in  Ganin   Lempitsky   
For   fair comparison  we separated the network at the
hidden layer from which  Ganin   Lempitsky    constructed discriminator networks  Therefore  when considering   single classi er  for example           the architecture is identical to   previous work  We also followed  Ganin   Lempitsky    with the other protocols 
Based on   validation  we set the threshold value for the
labeling method as   in MNIST SVHN  In other scenarios  we set it as   We used MomentumSGD for optimization  and set the momentum as   whereas the learning rate was set    cid  was set to   for all scenarios
based on our validation  In the Supplementary materials
section  we provide details of the network architecture and
the hyperparameters 
For our experiments on the Amazon Review dataset  we
used   similar architecture to that used in  Ganin et al 
  with the sigmoid activated  one dense hidden layer
with   hidden units  and   softmax output  We extended its
architecture to our method similarly to that of the CNN   cid 
was set to   based on   validation  Because the input is
sparse  we used Adagrad  Duchi et al    for optimization  We repeated this evaluation ten times  and reported
the mean accuracy 
  Experimental Result

In Tables   and   we show the main results of our experiments  When training only using source samples  the effect
of the BN is not clear  as shown in the Tables   However 
for most of the image recognition experiments  the effect
of the BN with our method is clear  at the same time  the
effect of our method is also clear when we do not use   BN
in the network architecture compared to the Source Only
method  The effect of the weight constraint is not obvious
in other than MNIST SVHN  This result indicates that we
can obtain suf ciently different classi ers when initializing
the layer parameters differently 
MNIST MNISTM First  we evaluated the adaptation
between the handwritten digit dataset  MNIST  and its
transformed dataset  MNISTM  MNISTM was composed
by merging clips of   background from the BSDS 
datasets  Arbelaez et al      patch was randomly
taken from the images in BSDS  and merged with the
MNIST digits  From   target training samples  we
randomly selected   labeled target samples as   validation split and tuned the hyperparameters 

Asymmetric Tritraining for Unsupervised Domain Adaptation

SOURCE MNIST

SVHN

MNIST

SYN DIGITS

SYN SIGNS

TARGET MNISTM MNIST
 

 

METHOD

Source Only     BN
Source Only with BN
MMD  Long et al     
DANN  Ganin   Lempitsky   
DRCN  Ghifary et al   
DSN  Bousmalis et al   
kNNAd  Sener et al   
Ours     BN
Ours     weight constraint  cid     
Ours

 
 
 

 

 
 
 
 
 

SVHN

 

 

 

 

 
 

 
 
 
 

SVHN

 

 
 
 

 

 

 

GTSRB
 

 
 
 

 

 

 

 
 
 

 
 
 

 
 
 
 
 
 
 
 
 

Table Results of the visual domain adaptation experiment on digit and traf   sign datasets  In every setting  our method outperforms
other methods by   large margin  In the sourceonly results  we show the results reported in  Bousmalis et al    and  Ghifary et al 
  in parentheses 

MNIST MNISTM  last pooling layer

MNIST SVHN  last shared hidden layer

    Nonadapted

    Adapted

    Nonadapted

    Adapted

Figure We con rmed the effects our method through   visualization of the learned representations using tdistributed stochastic
neighbor embedding  tSNE   Maaten   Hinton    The red points are the target samples  and the blue points are the source
samples          The case in which only source samples are used for training          Adaptation using our proposed method  In both
scenarios  MNIST SVHN and MNIST MNISTM  we can see that the target samples are more dispersed through adaptation 

Our method outperformed the other existing method by
about   Visualization of the features in the last pooling layer is shown in Fig        We observed that the
red target samples are more dispersed when adaptation is
achieved    comparison of the accuracy between the actual
labeling accuracy on the target samples during the training
and the test accuracy is shown in Fig    The test accuracy
is very low initially  but as the steps increase  the accuracy
becomes closer to that of the labeling accuracy  With this
adaptation  we can clearly see that the actual labeling accuracy gradually improves with the accuracy of the network 
SVHN MNIST We increased the gap between distributions during this experiment  We evaluated the adaptation
between SVHN  Netzer et al    and MNIST in   tenclass classi cation problem  SVHN and MNIST have distinct appearances  and thus this adaptation is   challenging scenario  particularly in MNIST SVHN  The images
in SVHN are colored  and some contain multiple digits 
Therefore    classi er trained on SVHN is expected to perform well on MNIST  but the reverse is not true  MNIST
does not include any samples containing multiple digits 

     

In Fig 

and most of the samples are centered in the images  and
thus adaptation from MNIST to SVHN is rather dif cult 
In both settings  we use   labeled target samples to  nd
the optimal hyperparameters 
We evaluated our method under both adaptation scenarios and achieved   stateof theart performance for both
datasets  In particular  for the adaptation MNIST SVHN 
our method outperformed the other methods by more
than  
the representations in
MNIST SVHN are visualized  Although the distributions
seem to be separated between domains  the red SVHN samples become more discriminative when using our method
compared with nonadapted embedding    comparison between the actual labeling method accuracy and the testing
accuracy is also shown in Fig        In this  gure  it can
be seen that the labeling accuracy rapidly decreases during
the initial adaptation stage  On the other hand  the testing accuracy continues to improve  and  nally exceeds the
labeling accuracy  There are two questions regarding this
interesting phenomenon  The  rst is why does the labeling method continue to decrease despite the increase in the

Asymmetric Tritraining for Unsupervised Domain Adaptation

    MNIST MNISTM

    SVHN MNIST

    MNIST SVHN

    SYNDIGITS SVHN

    SYNSIGNS GTSRB

    Adistance in MNIST MNISTM
Figure     cid      Comparison of the actual accuracy of the pseudolabels and the learned network accuracy during training  The blue
curve indicates the pseudolabel accuracy  and the red curve is the learned network accuracy  Note that the labeling accuracy is computed
using  the number of correctly labeled samples the number of labeled samples  The green curve shows the number of labeled target
samples in each step      Comparison of the accuracy of the three networks in our model  The accuracy of the three networks improved
almost simultaneously      Comparison of the Adistance of the different methods  Our model slightly reduced the divergence of the
domain compared with the sourceonly trained CNN 

    Comparision of accuracy of three networks on SVHN MNIST

testing accuracy  Target samples given pseudolabels always include mistakenly labeled samples  whereas those
given no labels are ignored in our method  Therefore  an
error will be reinforced in the target samples included in
the training set  The second question is why does the test
accuracy continue to increase despite the lower labeling accuracy  The assumed reason is that the network already
acquires target discriminative representations during this
phase  which can improve the accuracy when using source
samples and correctly labeled target samples 
In Fig      we show   comparison of the accuracy of
the three networks       and Ft in SVHN MNIST  The
accuracy of these networks is nearly the same during every step  The same situation was observed for the other
scenarios  Based on this result  we can state that targetdiscriminative representations are shared in three networks 
SYN DIGITS SVHN With this experiment  we aimed
to address   common adaptation scenario from synthetic
images to real images  The datasets of synthetic numbers  Ganin   Lempitsky    consist of   images generated from Windows fonts by varying the text 
positioning  orientation  background and stroke colors  and
the amount of blur  We used   source samples and
  target samples for training  and   target samples for testing  In addition  we used   SVHN samples
as the validation set 

Our method also outperformed the other methods during
this experiment  With this experiment  the effect of BN
is not clear as compared with the other scenarios  The
domain gap is considered small in this scenario  as the
performance of the sourceonly classi er illustrates 
In
Fig      although the labeling accuracy decreases  the
accuracy of the learned network prediction improves  as in
MNIST SVHN 
SYN SIGNS GTSRB This setting is similar to the previous one  adaptation from synthetic images to real images  but we have   larger number of classes  namely   
classes instead of ten  We used the SYN SIGNS dataset
 Ganin   Lempitsky    for the source  and the GTSRB
dataset  Stallkamp et al    for the target  which consist of real images of traf   signs  We randomly selected
  samples for the target training samples and evaluated the accuracy on the remaining samples    total of
  labeled target samples were used for validation 
Under this scenario  our method outperformed the other
methods  which indicates that our method is effective for
the adaptation from synthesized images to real images with
diverse classes  As shown in Fig      the same tendency as in MNIST SVHN was observed for this adaptation scenario 
Gradient Stop Experiment We evaluated the effects of  
targetspeci   network using our method  We stopped the

 Number of steps Accuracy Number of samples Accuracy of labeling methodAccuracy of learned networkNumber of labeled samples Number of steps Accuracy Number of samples Accuracy of labeling methodAccuracy of learned networkNumber of labeled samples Number of steps Accuracy Number of samples Accuracy of labeling methodAccuracy of learned networkNumber of labeled samples Number of steps Accuracy Number of samples Accuracy of labeling methodAccuracy of learned networkNumber of labeled samples Number of steps Accuracy Number of samples Accuracy of labeling methodAccuracy of learned networkNumber of labeled samples Number of steps AccuracyAccuracy of Target NetworkAccuracy of Network Accuracy of Network Asymmetric Tritraining for Unsupervised Domain Adaptation

Ft

Gradient stop branch
MNIST MNISTM  
MNIST SVHN
 
SYN SIGNS GTSRB  

     
 
 
 

None
 
 
 

Table Results of gradient stop experiment  When stopping the
gradients from Ft  we did not use backward gradients from Ft
to     and   only learned from    and    When stopping the
gradients from    and    we did not use backward gradients
from    and    on     and   learned from Ft  None denotes our
proposed method  in which we backwarded all gradients from all
branches to    

theoretical

gradient from the upper layer networks       and Ft to
examine the effect on Ft  Table   shows three scenarios 
including the case in which we stopped the gradients from
      and Ft 
In the experiment on MNIST MNISTM  we assumed
that only the backpropagation from    and    cannot construct discriminative representations for the target samples 
and con rmed the effect of Ft  For the adaptation on
MNIST SVHN  the best performance was realized when
  received all gradients from the upper networks  Backwarding all gradients ensures both targetspeci   discriminative representations in dif cult adaptations 
In SYN
SIGNS GTSRB  backwarding only from Ft results in the
worst performance because these domains are similar  and
noisy pseudolabeled samples worsen the performance 
Adistance Based
on
results
the
in
the Adistance is usually
 BenDavid et al   
used as   measure of domain discrepancy  The method
of estimating the empirical Adistance is simple  We
train   classi er to classify   domain from each domains 
feature  The approximate distance is then calculated as
 dA      cid    where   is   generalization error of the
classi er  We compared our method with the distribution
matching methods  DANN and MMD  We calculated
the distance using the last pooling layer features  We
followed the implementation of DANN  Ganin et al 
  for the training  For MMD training  we followed
the implementation in  Bousmalis et al   
In Fig 
    the Adistance calculated from each CNN feature is
shown  We used   linear SVM to calculate the distance 
From this graph  we can see that our method clearly
reduces the Adistance compared with the CNN trained on
only the source samples  In addition  when comparing the
distribution matching methods against our own  although
the former reduce the Adistance much more  our method
shows   superior performance as shown in Table  
Semisupervised domain adaptation We evaluated our
model in   semisupervised domain adaptation setting on
MNIST SVHN  We randomly selected the labeled target
samples for each class  and reported the mean accuracy for

Source Target
books dvd
books electronics
books kitchen
dvd books
dvd electronics
dvd kitchen
electronics books
electronics dvd
electronics kitchen
kitchen books
kitchen dvd
kitchen electronics

VFAE DANN Our method

 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 

Table Amazon Reviews experimental results  The accuracy
  of the proposed method is shown with the result of VFAE
 Louizos et al    and DANN  Ganin et al   

ten experiments  The resulting accuracy was   on average when using ten labeled target samples per class  We can
see the effectiveness of our method in   semisupervised
setting    detailed explanation of this is given in our Supplementary materials section 
Amazon Reviews The reviews were encoded in   dimensional vectors of bagof word unigrams and bigrams
with binary labels  Negative labels were attached to the
samples if they were ranked with   to   stars  Positive labels were attached if they were ranked with   or   stars  We
used   labeled source samples and   unlabeled target samples for the training  and between   and  
samples for the testing  We used   labeled target samples
for validation 
Based on the results in Table   our method performed better than VFAE  Louizos et al    and DANN
 Ganin et al    in nine out of twelve settings  Our
method was shown to be effective in learning   shallow network on different domains 
  Conclusion
In this paper  we proposed   novel asymmetric tritraining
method for unsupervised domain adaptation  which is implemented in   simple manner  We aimed at learning discriminative representations by utilizing pseudolabels assigned to unlabeled target samples  We utilized three classi ers  two networks assigned pseudolabels to unlabeled
target samples  and the remaining network  which learned
from them  We evaluated our method regarding both domain adaptation for   visual recognition and   sentiment
analysis  and the results show that we outperformed all
other methods  In particular  our method outperformed the
other methods by more than   for MNIST SVHN 
  Acknowledgement
This work was partially funded by the ImPACT Program of
the Council for Science  Technology  and Innovation  Cabinet Of ce  Government of Japan  and was partially supported by CREST  JST 

Asymmetric Tritraining for Unsupervised Domain Adaptation

References
Arbelaez  Pablo  Maire  Michael  Fowlkes  Charless  and
Malik  Jitendra  Contour detection and hierarchical image segmentation  PAMI     

Balcan  MariaFlorina  Blum  Avrim  and Yang  Ke  Cotraining and expansion  Towards bridging theory and
practice  In NIPS   

BenDavid  Shai  Blitzer  John  Crammer  Koby  Kulesza 
Alex  Pereira  Fernando  and Vaughan  Jennifer Wortman    theory of learning from different domains  Machine learning     

Blitzer 

John  McDonald  Ryan 

and Pereira  Fernando  Domain adaptation with structural correspondence learning  In EMNLP   

Blum  Avrim and Mitchell  Tom  Combining labeled and

unlabeled data with cotraining  In COLT   

Ioffe  Sergey and Szegedy  Christian  Batch normalization 
Accelerating deep network training by reducing internal
covariate shift  arXiv   

Khamis  Sameh and Lampert  Christoph    Coconut 
In

Coclassi cation with output space regularization 
BMVC   

Krizhevsky  Alex  Sutskever  Ilya  and Hinton  Geoffrey   
Imagenet classi cation with deep convolutional neural
networks  In NIPS   

LeCun  Yann  Bottou    eon  Bengio  Yoshua  and Haffner 
Patrick  Gradientbased learning applied to document
recognition  Proceedings of the IEEE   
   

Lee  DongHyun  Pseudolabel  The simple and ef cient
semisupervised learning method for deep neural networks  In ICML workshop on Challenges in Representation Learning   

Bousmalis  Konstantinos  Trigeorgis  George  Silberman 
Nathan  Krishnan  Dilip  and Erhan  Dumitru  Domain
separation networks  In NIPS   

Levin  Anat  Viola  Paul    and Freund  Yoav  Unsupervised improvement of visual detectors using cotraining 
In ICCV   

Chen  Minmin  Weinberger  Kilian    and Blitzer  John 

Cotraining for domain adaptation  In NIPS   

Dasgupta  Sanjoy  Littman  Michael    and McAllester 
In

David  Pac generalization bounds for cotraining 
NIPS   

Duchi  John  Hazan  Elad  and Singer  Yoram  Adaptive
subgradient methods for online learning and stochastic
optimization  JMLR     

Ganin  Yaroslav and Lempitsky  Victor  Unsupervised do 

main adaptation by backpropagation  In ICML   

Ganin  Yaroslav  Ustinova  Evgeniya  Ajakan  Hana  Germain  Pascal  Larochelle  Hugo  Laviolette  Franc ois 
Marchand  Mario  and Lempitsky  Victor  Domainadversarial training of neural networks  JMLR   
   

Ghifary  Muhammad  Kleijn    Bastiaan  Zhang  Mengjie 
Balduzzi  David  and Li  Wen  Deep reconstructionclassi cation networks for unsupervised domain adaptation  In ECCV   

Girshick  Ross  Donahue  Jeff  Darrell  Trevor  and Malik 
Jitendra  Rich feature hierarchies for accurate object detection and semantic segmentation  In CVPR   

Gretton  Arthur  Borgwardt  Karsten    Rasch  Malte   
Sch olkopf  Bernhard  and Smola  Alexander    kernel
twosample test  JMLR     

Li  Yanghao  Wang  Naiyan  Shi  Jianping  Liu  Jiaying 
and Hou  Xiaodi  Revisiting batch normalization for
practical domain adaptation  arXiv   

Long  Jonathan  Shelhamer  Evan  and Darrell  Trevor 
Fully convolutional networks for semantic segmentation 
In CVPR     

Long  Mingsheng  Cao  Yue  Wang  Jianmin  and Jordan 
Michael    Learning transferable features with deep
adaptation networks  In ICML     

Long  Mingsheng  Zhu  Han  Wang  Jianmin  and Jordan 
Michael    Unsupervised domain adaptation with residual transfer networks  In NIPS   

Louizos  Christos  Swersky  Kevin  Li  Yujia  Welling 
Max  and Zemel  Richard  The variational fair autoencoder  arXiv   

Maaten  Laurens van der and Hinton  Geoffrey  Visualizing

data using tsne  JMLR     

Moiseev  Boris  Konev  Artem  Chigorin  Alexander  and
Konushin  Anton  Evaluation of traf   sign recognition methods trained on synthetically generated data  In
ACIVS   

Netzer  Yuval  Wang  Tao  Coates  Adam  Bissacco 
Alessandro  Wu  Bo  and Ng  Andrew    Reading digits in natural images with unsupervised feature learning 
In NIPS workshop on deep learning and unsupervised
feature learning   

Asymmetric Tritraining for Unsupervised Domain Adaptation

Rohrbach  Marcus  Ebert  Sandra  and Schiele  Bernt 
In NIPS 

Transfer learning in   transductive setting 
 

Sener  Ozan  Song  Hyun Oh  Saxena  Ashutosh  and
Savarese  Silvio  Learning transferrable representations
for unsupervised domain adaptation  In NIPS   

Stallkamp  Johannes  Schlipsing  Marc  Salmen  Jan  and
Igel  Christian  The german traf   sign recognition
benchmark    multiclass classi cation competition  In
IJCNN   

Sun  Baochen  Feng  Jiashi  and Saenko  Kate  Return of

frustratingly easy domain adaptation  In AAAI   

Tanha  Jafar  van Someren  Maarten  and Afsarmanesh 
Hamideh  Ensemble based cotraining  In BNAIC   

Wan  Xiaojun  Cotraining for crosslingual sentiment clas 

si cation  In ACL   

Zhou  ZhiHua and Li  Ming  Tritraining  Exploiting unlabeled data using three classi ers  TKDE   
   

Zhu  Xiaojin 

Semisupervised learning literature survey  Technical report  University of WisconsinMadison 
 

