Identify the Nash Equilibrium in Static Games with Random Payoffs

Yichi Zhou   Jialian Li   Jun Zhu  

Abstract

We study the problem on how to learn the pure
Nash Equilibrium of   twoplayer zerosum static
game with random payoffs under unknown distributions via ef cient payoff queries  We introduce   multiarmed bandit model to this problem
due to its ability to  nd the best arm ef ciently
among random arms and propose two algorithms
for this problem LUCBG based on the con 
dence bounds and   racing algorithm based on
successive action elimination  We provide an
analysis on the sample complexity lower bound
when the Nash Equilibrium exists 

  Introduction
We consider the static zerosum game where two players
are involved with  nite pure strategies  From game theory  if both players use only pure strategies and the payoffs
are distinct from each other  at most one pure Nash Equilibrium  NE  exists  Osborne   Rubinstein    We
concentrate on the setting where all payoffs are random
variables under some unknown distributions  Samples  or
queries  can be obtained by submitting pure strategies of
the two players and receiving the associated payoffs  Our
target is to answer the questions    whether there is   pure
NE  and   how to identify it if exists using as few queries
as possible 
Our motivation for this problem comes from the need of
identifying NE in many practical competitive situations 
Since NE is   fundamental concept in game theory and
many other  elds  the computational complexity needed for
NE is of much interest  However  in practice we are often
given access to the data generated from some practical phenomena  rather than   clear rule for the payoffs of the game 
Hence  the empirical gametheoretic analysis  Wellman 
  Jordan et al    has received   lot of attention

 Dept  of Comp  Sci    Tech  TNList Lab  State Key Lab
for Intell  Tech    Systems  CBICR Center  Tsinghua University 
Correspondence to  Jun Zhu  dcszj tsinghua edu cn 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

to estimate the practical games through simulation  In the
empirical modeling  purestrategy pro les of players are
submitted to the game and we receive the associated payoffs  Fearnley et al    consider the process managed
in an online manner by algorithms and analyze the complexity of these payoffquery algorithms  The main focus
is on whether the query methods can  gure out mixed Nash
Equilibrium with only   fraction of pro les  Extensions
have been made to obtain query complexity on approximate
Nash Equilibrium  Babichenko    correlated equilibrium  Hart   Nisan    and wellsupported approximate correlated equilibrium  Goldberg   Roth   
The above work is essentially   revealedpayoff search
model  Jordan et al    where payoffs are deterministic
and every pro le only needs to be queried at most once  We
concentrate on the noisypayoff model  Jordan et al   
where the received payoff of   query is   sample of an underlying distribution  This random payoff setting is more
realistic in practice  where randomness naturally arises because of incomplete information  noise  or other stochastic
factors in the world    simple but wellknown example is
the coin  ipping game  where two players throw   coin and
guess its landing upper side  Since the physical process of
coin landing can be determined by many noisy factors  the
payoffs to the two players  which depend on the landing
results  are random  This notable discrepancy leads to different algorithms and complexity bounds for the two models  since for noisypayoff models  more queries are needed
for any pro le to get an estimated payoff near its expectation value with high probability and the additional computational cost can take   dominating role in complexity  Previous work has explored different methods for noisy payoff models  such as interleaving the samples  Walsh et al 
  and using regression for payoffs  Vorobeychik et al 
  This paper turns to bandit models    relatively natural direction from the view of online learning  since query
methods themselves hold   sequential property  Put another
way  we select   strategy to submit based on previous observations at each round of query methods 
This task can be viewed as   variant of best arm identi cation  BAI  in the literature of multiarmed bandits
 Jamieson   Nowak    where different pure strategy
pro les are regarded as arms  The classical BAI problem
is to identify which arm is the one with the highest mean 

Identify the Nash Equilibrium in Static Games with Random Payoffs

There are two basic settings for BAI problem xed budget and  xed con dence  Kaufmann et al    In this
paper  we focus on the  xed con dence setting  where the
purpose of an algorithm is to identify the best arm with  
 xed probability by as few pulls  queries  as possible 
Contributions  We study both the sample complexity
lower bound and algorithms in the  xed con dence setting
for twoplayer zerosum static games with random payoffs 
In Section   we discuss the sample complexity lower
bound for the case NE exists  Previous proofs on the lower
bound for BAI all rely on changes of distributions  Audibert   Bubeck    Kaufmann et al    Mannor  
Tsitsiklis   changes on   single arm can change the
best arm in the bandit model  For our problem  we prove
the lower bound for the arms in the same row or same column with the NE by similar techniques  However  this approach does not work for those arms that are in neither the
same row nor column with the NE  since changing the distribution of such an arm does not change the NE  details
are in Section   To get the lower bound on these arms 
we rephrase the arm selection as   hypothesis testing problem and use the minimax techniques for hypothesis testing  Tsybakov    to get the bound 
There are two types of algorithms for the BAI problem in the  xed con dence setting  Jamieson   Nowak 
 based on either con dence bound  Kalyanakrishnan et al    or successive eliminations on suboptimal
arms  Maron   Moore    In Section   we propose
two corresponding algorithms to identify NE for our problem in the  xed con dence setting  The  rst algorithm has
  provable bound on sample complexity  and we show that
the second one will stop in    nite number of time steps
with probability at least      
Related work  Garivier et al    also study the twoplayer zerosum game with random payoffs  They consider
the case that each player selects her strategy oneby one 
while we focus on the case that both players select their
strategies simultaneously  Our setting is suitable for the
case that each player chooses actions independently  Many
games are static  such as the tai sai game where players
independently guess the range of the outputs of three dices 
Much work has been done on Nash Equilibrium 
Daskalakis et al    shows that it is computationally
hard to recognize exact Nash Equilibrium  even for the
simplest twoperson game  Chen et al    As empirical gametheoretical analysis  Wellman    is proposed  Fearnley et al    studies the payoffquery algorithms and considers the query complexity as   criterion for
computational complexity  Following work  Babichenko 
  Goldberg   Roth    has extended this criterion
to some other approximate equilibrium  Query bounds for

NE have also been given on speci   games such as twostrategy anonymous games  Goldberg   Turchetta   
and bimatrix games  Fearnley   Savani   
  Preliminaries
We start by presenting the basic settings  notations and assumptions that will be used in the sequel 
  Basic settings
Twoplayer zerosum static game with random payoffs 
  static game is   model in which all players choose their
strategies once and simultaneously    twoplayer zerosum
game involves two players   and   and each player chooses
her own strategy si from   strategy set Si          After decisions are made  player   gets payoff rews    and
player   gets  rews    Each player tries to maximize her
payoff  The game can be represented by       nmatrix
where                 If rewi   is   deterministic
value for any       it is direct to identify the NE       
which has the minimum value in row    and the maximum
value in column    We consider the more practical games
with random payoffs  whose distributions are unknown 
This makes the identi cation of NE dif cult and hence we
employ query methods to learn the NE empirically  In each
query  the algorithm generates   pure strategy        and
the environment returns the associated payoff  Our target
is to determine whether the Nash Equilibrium  NE  exists 
and what it is if it does exist with as few queries as possible 
Multiarmed bandits  In   bandit model  an agent is facing   set of actions  or arms  and needs to select one arm
to pull every time  In our case  an arm is speci ed by    
          where     denotes the set        Successive pulls of an arm        yield   sequence of observations
        policy      It         
 or rewards       
denotes   sequence of random variables  where the variable
It             indicates which arm to pull at time step   
The classical best arm identi cation  BAI  problem is to
identify which arm is the one with the highest mean  There
are two basic settings for the BAI problem xed budget
and  xed con dence  Kaufmann et al    In this paper 
we focus on the identi cation of the NE of   static game or
detect its absence in the  xed con dence setting  That is 
we aim to identify the correct NE with probability at least
      with ef cient sampling  where         is the con 
 dence parameter  Algorithms satisfying this requirement
are known as  PAC algorithms  Kaufmann et al   
Following Kaufmann et al      practical BAI algorithm in the  xed con dence setting typically consists of 
  Policy  given   sequence of past observations   
  Stopping rule    stopping rule can be described as
 We focus on the NE of pure strategy  So NE may not exist 

policy determines which arms to pull 

         

Identify the Nash Equilibrium in Static Games with Random Payoffs

  series of observation sets Ft         When an
element     Ft is observed  the policy stops sampling 
  Recommendation rule    recommendation rule is

usually to recommend the best arm 

As we shall see  in our problem the best arm may not exist 
when the sampling process stops  the recommendation rule
determines whether the NE exists or not  and if exists  it
determines which is the NE 

    cid 

    cid 

      cid 

      cid 

  Basic assumptions and notations
Let Pi       be the underlying distribution of arm       
and   is   set of probability measures  For an arm    we
use    to denote the expectation of Ps  And let       denote the empirical mean of   at time step    we omit   for
simplicity when there is no ambiguity   Here  we consider
pulling an arm once as   time step  that is  time step   means
that we have pulled arms for   times  We use  Mt to denote
the empirical matrix with entry        representing the empirical mean of Pi   at time step    For            we
de ne row         cid       cid 
       col     
   cid       cid 
       nei      row      col    and
               
Let        denote the NE of matrix   
Formally 
           if there is an arm   such that     
mins cid row       cid  and      maxs cid col       cid  otherwise if
there is no such arm  we denote          none to show
that no Nash Equilibrium exists  Speci cally  we use  
to denote the matrix whose entry        is the expectation
of distribution Pi    Our target is to identify        For
convenience  let             Let Ri  Cj be the sets of
the arms corresponding to the ith row and the jth column
of   respectively  Our lower bound mainly focuses on the
case that the NE exists               cid  none  and our algorithms are  PAC  We assume that the expectations of the
arms are mutually different 
In the proof of the lower bound  it is natural to make  
abundant enough to include various continuous distributions while ruling out some extreme situations where distributions are not mutually absolutely continuous  So we
assume that   consists of parametric distributions continuously parameterized by their means  This assumption has
been widely used in studying multiarmed bandits  Lai  
Robbins    Kaufmann et al   
Assumption   For all          such that    cid     for all
     

           KL         KL         KL          

           KL         KL         KL          

Eq    Eq   Ep 

Eq    Eq   Ep 

Here KL       is the KLdivergence  Many distributions
are included in    such as the broad class of oneparameter

exponential family distributions 
  Lower bound
Let      denote the number of pulls on an arm   by    
PAC algorithm  For arm     nei    we provide   lower
bound of      in Lemma   which is obtained by the
classical technique of changes of distributions  Kaufmann
et al    Lai   Robbins    Audibert   Bubeck 
  and Theorem   in Kaufmann et al   
Theorem    Kaufmann et al    Let   and   cid  be two
bandit models with   arms  such that for all        
the distributions Pa and   cid 
  are mutually absolutely continuous  For any almostsurely  nite stopping time   with
respect to Ft  we have

    sa KL Pa    cid 

     sup
  Ft 

  Pv  Pv cid   

   
where             log             log       
Lemma   Let   cid    arg mins nei      KL Ps    Ps 
then the number of pulls on nei    of any  PAC algorithm has   lower bound as follows 

 cid 

 cid 

  nei   

        

 cid 
 cid 

 

KL Ps    Ps cid 
 

 cid 

 

  nei     

KL Ps  Ps   

log

 

 

 

Proof  By Assumption   for all arms     nei    there
exists an alternative model  in which the only arm modi ed
is arm    and the modi ed distribution   cid 

  satis es 

     KL Ps  Ps       

and EP cid 

  KL Ps  Ps      KL Ps    cid 
  KL Ps  Ps      KL Ps    cid 
  KL Ps    Ps cid    KL Ps      cid 

        for     row     
        for     col     
        cid  for   cid    col      or EP cid 

and EP cid 

and EP cid 
for   cid    row     

       KL Ps    Ps cid     
        cid 

     KL Ps  Ps       

In particular 

the NE for   cid 

Denote the original bandit model by   and the modi ed
one by   cid 
is no longer
   Consider the event     the recommendation rule
recommends    as NE  Any  PAC algorithm satis es
Pv            and Pv cid        so by Theorem  
 cid  log  
       Pv    Pv cid      log  
      KL Ps    cid 
   
Hence we have 
KL Ps Ps         cid    
         log  
KL Ps    cid 
  cid            
  
KL Ps    
Let       and we complete the proof 

log  

 

From the proof  we can see that the lower bound relies on the fact that we can change the best arm      
       in our case  by changing the distribution of   single arm  However  this proof technique is not suitable for

Identify the Nash Equilibrium in Static Games with Random Payoffs

    nei    because the NE will not change no matter what
the distribution of an arm     nei    is 
In theory  we only need to pull     nei    to identify NE
because of the same reason       the distributions of arm
    nei    won   change NE  In practice however   policy does not know which arm is in nei    in advance  so
it may make some pulls on     nei    before making
  suf cient number of pulls on nei    So we can consider the arm selection as   hypothesis testing problem  and
then use the lower bound techniques for the minimax risk
of hypothesis testing  See Chapter   in Tsybakov  
Speci cally  our proof is based on the following lemma 
Lemma   Let      PK be probability distributions
supported on some set     with Pi absolutely continuous
         For any measurable function             we

have    cid 

exp    cid 

Pk          
 

KL    Pk 
where Pk         Pk              for clarity 

  

  

Proof  This lemma is an extension of Lemma   in Tsybakov   from two distributions to multiple distributions  We put the proof in Appendix   

Now we show what the hypotheses to be tested in our problem are and how to apply Lemma   Without loss of generality  consider   game   with              Let  
consider   set of hypotheses  new games hi   constructed
by swapping the ith row with the  rst row and the jth column with the  rst column of    Obviously  these games
are essentially the same game up to permutation  We will
show the lower bound on the maximum number of pulls
among these hypotheses by arbitrary policies 
Formally  de ne fi     cid    cid       cid cid    cid cid  where   cid cid      cid  if
  cid         else   cid cid              cid  and   cid cid      cid  if   cid        
else   cid cid              cid  Let hi   specify   game such that
the distribution of arm    cid    cid  is Pfi      cid   cid  Let Ht hi   
be the sum of the expected number of pulls on arms    
nei       until time step   under hypothesis hi   
 It cid    nei       hi   

Ht hi     

 cid 

  cid  

and let Ht   maxi   Ht hi    be the maximum number
of pulls under any hypothesis  Then  theorem   shows the
lower bound of Ht 
Theorem   For any
let    
               Pi             Pi        
  cid      Pi cid  Pi cid     
where
Then 

 cid   cid cid  
  cid      Pi   cid      cid     cid   cid cid  

  KL         KL      

mM   Pi  Pi   
         
we have the lower bound 

nM        Pi   

   

    

 

Ht            
        

 

 

 cid Ht      Ht hi      Ht        Ht hi cid 
 cid cid 

Proof  With straightforward computations  we have 
Ht    
 
 
 
   It cid    nei       hi       It cid    nei         
   It cid    nei      hi 

 It cid    nei      

 cid 

  cid  

 

 cid 

 cid   cid 

  cid  

  cid   cid 

   
 

 cid 

  cid 

 It cid       cid    cid    

 cid 
 cid 

  cid 

 

 It cid       cid        

 

   It cid        hi     

 It cid        cid  hi 

De ne    
step   under the hypothesis ha    and de ne function

as the distribution of observations until time

ha  

 

   

    

     

      

  cid    cid     
  cid        cid     
  cid        cid     
  cid      cid     

    cid    cid   

  cid   cid       

Let    
selects arm   at time step    We have 

hg   cid     cid   

  Consider events ev       policy

  cid   cid ev   cid     cid    cid 
    cid 

KL     cid 

      cid 

  cid   cid 

Ht    
 
   
  

  cid  

  cid   cid 

 cid 
 cid 
exp cid 
 cid 
  cid 

  cid   cid 
exp   

  cid  

  cid 

   
  
         
        

 

 

     
note

  cid   cid     cid 

The second inequality is proven by Lemma   The third
is by the fact that let Pi         denote the distribution
of arm        under hypothesis hg     
then we have
 cid 
  cid   KL   It cid  Pi cid   cid It cid 
KL    
 
and
  cid cid   cid cid  KL     cid cid    cid cid  Pi cid   cid   cid cid    cid cid  summing over all
  cid    cid  we get the third inequality 
We can get   different lower bound by choosing   different
     in Theorem   and take the maximum one  Though our

that KL   It cid  Pi cid   cid It cid 

Identify the Nash Equilibrium in Static Games with Random Payoffs

lower bound is not on the expected number of pulls  it intuitively answers why the pulls on     nei    are unavoidable  Obviously        
      which suggests that there is   policy which pulls on     nei    for  
bounded number of times  This result inspires us to design
  policy with   bounded number of pulls on     nei   
as shown in Section  

       

  

  Algorithms
We now present two  PAC algorithms for our problem 
The  rst one is inspired by LUCB  Kalyanakrishnan et al 
  and UCB   Auer et al    while the second one
follows another line of BAI algorithms which are based on
the successive action eliminations  EvenDar et al   
Maron   Moore   

  LUCBG
We  rst present and analyze the LUCBG       LUCB for
Game  algorithm  as illustrated in Alg   
  ALGORITHM
Informally  our problem can be divided into       bandit
tasks   for identifying   
       arg mins Ri    and  
for   
        arg maxs Cj     So in each round  LUCBG can be divided into two stages  In the  rst stage  it selects
two bandit tasks   row and   column  Note that LUCBG
  and   
tries to identify   
  after each round  If before round
  it identi ed    
     as the arm with minimum mean in Ri 
or identi ed    
        as the arm with maximum mean in Cj 
then LUCBG will not select row   or column    That is to
say  we only select bandit models from the following rows
and columns at the  th round 
     not identi ed until round  
ar                  
ac                  
      not identi ed until round  
We ll introduce how to identify these arms later in this
section 
In the second stage  we pull arms according
to past observations and some con dence bound function
                which will be presented soon in
Section   Here we show our  rst policy in Alg   
We have   clock for each bandit task  and our con dence
bounds rely on them  De ne          as the set of all the
time steps   cid  that satisfy the two requirements      cid      
  at the round when   cid  takes place  row   is chosen  and at
least one line from   to   is executed  Similarly  de ne
         as the set of all the time steps   cid  that satisfy the two
requirements      cid         at the round when   cid  takes
place  column   is chosen  and at least one line from   to
  is executed 
The method of identifying    

      also relies on

     and    

 We pull arms for several times in each round 
 With   probability     

      cid    

     or    

       cid    

     

the con dence bound function   For an arm    de ne
                  cid                          cid      
And let Ts           It            Alg    determines
     and    
   
  If      Ri 

for all   cid    Ri    we have
     Ts          cid Ts cid    where
             then Alg    takes   as    

      at time step   as follows 

  If      Cj 

for all   cid    Cj    we have
    Ts           cid Ts cid    where
             then Alg    takes   as    

    

     

Now we introduce the stopping and recommendation rules
for Alg   
Stopping and recommendation rules  The policy stops
and recommends     as follows 

  If after round   there is an arm    Alg    takes it
      Then Alg    stops and

     and    

as    
recommends   as the NE 
  Else if after round      

     and    

      have all been
determined  Then the policy stops and the recommendation rule determines that the underlying game does
not have   NE 

   PAC

 cid  log mnt 

We now show that Alg    is    PAC algorithm  Lemma
  guarantees that if        satis es the requirements in
InEq    then the probability that there is an arm violating its con dence bounds is less than   Our choice of the
 
con dence bound function is         
which satis es this requirement  And Theorem   is   simple application of Lemma   since if no arm violates its
con dence bounds  the stopping and recommendation rules
won   make mistakes 
Lemma   Let                      be   function
such that 

  

 cid 

  cid 

  

  

exp            
  

 

 

Consider   bandit model   with   arms  for each arm 
there is   sequence               such that ti  
  such
ui  ti    ti  ui    ui  and   sequence   cid 
    ui  and then the probability that           such
that   cid 
that

    cid 

  cid 

  cid 

  

   
  cid 

 

           ui  ti 
   

is less than  
functions of   cid  but for convenience we omit the notation of   cid 
 

 In this paper  we have   cid       Thus in fact   and   are
 For convenience  let       So if               

Identify the Nash Equilibrium in Static Games with Random Payoffs

Proof  The proof can be found in Appendix   
Theorem   The probability of making mistakes by the recommendation and stopping rules of LUCBG is at most  

Proof  If all arms don   violate their con dence bounds 
then it is easy to see that we determine NE correctly  As
our choice of        satis es the condition in InEq   
we can use Lemma   to get the result 
  SAMPLE COMPLEXITY
We analyze the sample complexity of Alg    in this section  We provide   proof of the sample complexity when
        cid  none here  and the sample complexity when
         none is   straightforward application of the
result in LUCB  Kalyanakrishnan et al   

For convenience  let Hr       cid 
and Hc       cid 

  Ri   
     
        In the second
 
     
stage of each round  LUCBG pulls arms similarly as
LUCB and UCB  When the NE of the underlying game
exists  the pulls can be divided into three parts 

 
     

  Cj   

     

     

  part  Time steps   such that    is the NE of  Mt 
  part  Time steps   such that    cid     is the NE of  Mt 
  part  Time steps   such that there is no NE of  Mt 

time step   
 cid  arg mins cid row       cid    or   

Therefore  the total sample complexity can be decomposed
as the summation of the bounds for the three parts 
We  rst provide sample complexity bounds for the pulls in
part  and part  which appear because of the algorithm  
misjudgments on which arm is        during training 
while deferring the bound for part  to Lemma   which is
relatively standard 
if part  or part  hapObviously  at
 cid 
then   
pens 
arg maxs cid col       cid    Lemma   ensures that these
events will not happen with   high probability if Alg    selects row    and col    for   suf ciently large number
of times  The key idea is to use the UCB  policy  line  
   Auer et al    considering column    when the algorithm chooses it in the  rst stage  the algorithm pulls an
arm in Cj by UCB  This ensures that with   high probability  the policy pulls   suf ciently large number of times
on   
      and then by Hoeffding   inequality  we get the
bound    formal statement is in Lemma  
Lemma   Without loss of generality  consider column   
       cid  arg maxs cid Cj    cid  when Alg    selet        
   

lects column   for the  th time  let      cid 

Then  the expectation of   satis es the inequality 

       Hc   log        Hc            

 

where          are positive constants 

selr      selc        for                
if           Mt   cid  none then
selr      selc       

Algorithm   LUCBG
  Input  distribution matrix    con dence  
  Pull all arms
  Chr      Chc        for                          
  while Not stop do
 
 
 
 
 
 
 
 
 
 
 

Let      arg mini ar  Chr   
Let      arg minj ar  Chc   
selr      selc       

end if
if          selr        then

else

               
  log        
 Ts                   

Chr      Chr       
Pull      arg mins    
    
Pull arg mins    
Pull arg mins            Ts                   
end if
if          selc        then

     

 cid 

 cid 

Chc      Chc       
Pull      arg maxs    
Pull arg maxs    
Pull arg maxs             Ts                   
end if

               
  log        
 Ts                

     

    

 

 

 
 
 
 

 

 

 
  end while

If    cid    

Proof  Let    denote the time step when Alg    selects column   for the  th time and     arg maxs Cj      
           
      then we have
Let        
          or              
             
   
So let Set                 Set         
Set                    and Set         
          With the above
             
Set         
argument  for     Cj   
      we have   Set     
  Set       Set   
the policy pulls   for rounds    
Due to Alg   
Set    So by Hoeffding   inequality    Set     
                 
           
Now consider Set    which is computed as 

 cid 
  exp   

  Set       

   

             

           

 

Let       be the number of pulls on   
      at line   in Alg   
at that time step    By Hoeffding   inequality and straight 

   cid 

 Set   

   

 

Identify the Nash Equilibrium in Static Games with Random Payoffs

forward computations  we have

Then  the following inequality holds 

 cid 

 cid 

  Sw    

 

 cid 

 Hr     

 Hc   

 

 

       Hr       Hc   

 

 cid 

 cid 

 

           
 

   

  Set       cid   cid 
   cid   cid 
   cid 

  

 Set   
  exp 

 Set   

 Set   
             

          
 

 

           

 
          
 
          
   

 

 cid 

 

          
 

   

 

           

   

Note that Line   is the UCB  policy proposed by Auer
et al    So by Theorem   in Auer et al      
slightly modi cation on this theorem  see Appendix   
we have   cid         cid      Hc    log  cid  Then with
Markov inequality  we can get    cid         cid     cid   
  Hc    log  cid 
  that is          cid     cid      Hc    log  cid 
 
So let Set       Cj   

 cid 

 cid 

  Set     Hc       

 

 Set 

          
 

     Set    we have 

   cid 
   cid 
 Set cid 

 
 
 
   Hc        cid   Hc   log  Set cid 

   Hc       

   Hc       

  Hc    log  

  Hc   log 

 Set 

 

 

 

   Hc      Hc   log   Set 

where Set       Cj   
     Set    The third inequality is
by simple integration  and the last inequality holds because
         log    is   concave function for        Note that
     Set  With   Set        Set       Set   
we complete the proof 

It is noteworthy that although we do not have an analytical solution of    from InEq    it is obvious that the
solution is bounded  that is  it will not diverge as      
Then  we can get the sample complexity on part   and   as
in Lemma  
Lemma   Suppose              cid  none  let Sw  
 Rounds   such that Rs  or Cs  is not chosen by Alg   
Let     be the maximum value among all solutions that
satisfy the following inequality  constants          are the
same as in Lemma  

        log                  

   

Proof  We put the proof in Appendix   

The bound on part  is based on the result of LUCB  as in
Lemma   which has almost the same result on the sample
complexity as policy LUCB 
Lemma   Without loss of generality  considering column
   suppose    
      is identi ed by Alg    after being selected
for       rounds  then

 cid 

 cid 

          

Hc    log 

Hc   

 

 

 

Proof  The proof is the same as that of Theorem   in
 Kalyanakrishnan et al    except slightly changes on
description and constants  See Appendix   

With the above results  we are ready to get our major result
on the sample complexity of LUCBG  as in Theorem  
Theorem   When         cid  none  the sample complexity of LUCBG is 

Hr    log

 

Hr   

 

  Hc    log

Hc   

 

 cid 

 cid 

    Sw 

 

where   Sw 
         none  the sample complexity of LUCBG is 

is bounded as in Lemma   When

 cid 

 

 

Hr    log

Hr   

 

 

Hc    log

Hc   

 

 cid 

 

   

Proof  By Lemma   and Lemma   with straightforward
computations  we get the complexity 

Note that the sample complexity of LUCBG is optimal
within   constant gap if         cid  none  This is because
that   sw  is bounded and for some family              
the KLdivergence KL       has the same order as the
squared meandifference  EP    EP        normal distributions with unit variances  Therefore  we can replace
the KLdivergence terms in Lemma   by the corresponding
squared meandifference terms 

Identify the Nash Equilibrium in Static Games with Random Payoffs

Algorithm   Racing
  Input  distribution matrix    con dence  
       
  while Not stop do
 
 

Pull all arms except those have been eliminated 
For an active arm    if    cid    row         
       cid  and    cid    col         cid           then
we eliminate   
For all sequences of arms                   if
  satis es        
 
 

       row             col     
all arms are eliminated in row      col     
except       
                
                 

 
 
where sj          eliminate all arms in   
         

 

 
  end while

    racing algorithm
Finally  we present another algorithm  along the line of racing algorithms for BAI  EvenDar et al    Maron  
Moore      racing algorithm maintains   set of active
arms  and during each round it samples all the active arms
and then eliminates some arms according to certain rules 
However  we cannot eliminate an arm when the algorithm
 knows  it cannot be the NE immediately  Consider      
game  Suppose an algorithm determines      cid   sr 
and eliminates it immediately  Then we cannot determine
whether     is NE or not  Therefore  our racing algorithm eliminates arm   only if Alg    determines that
       
      Let
  Our racing algorithm is shown
   
in Alg    whose stopping and recommendation rules are 
  If only an arm is not eliminated after round   then

 cid  log cmn 

      or    

      cid     

recommend this arm as NE 

  If all arms are eliminated after round   then the algo 

        

 

rithm determines       none 

As shown in Theorem   this algorithm is  PAC and it will
terminate in  nite time step with probability at least      
Theorem   Alg    is  PAC and will terminate in  nite
time with probability at least      
Proof  We put the proof in Appendix   
  Experiments
We now empirically verify the sample complexity of our
algorithms  We choose   simple algorithm as our baseline
 denoted by ALL  which pulls all arms at each round until stopping  The stopping and recommendation rules are

Pulls

 

 

ALL
Racing

LUCBG

Pulls

 

 

 

ALL

Racing

 
       
     rstgame
Pulls

 

LUCBG
 

 
       
     rstgame

 

 

 

ALL

Racing
LUCBG

       
    secondgame

 

Figure   The results on two simulated games 

the same as LUCBG  and the con dence bound for this
baseline is slightly different  see Appendix   for details 
We evaluate on synthetic   games  where the payoffs are
all random Bernoulli variables  The  rst game has   NE 
while the second game has no NE  The results are shown
in Fig    where both axes are in logscale with base  
The number of pulls needed for both games are shown in
Fig      and Fig      separately and our algorithms outperform the baseline       ALL  Fig      shows the number of pulls on     nei    in the  rst game and we can see
that this number is bounded  agreeing with our analysis 

  Conclusions and Discussions
We analyze the twoplayer zerosum static game with random payoffs via ef cient sampling and give   lower bound
of the sample complexity in the case that the Nash Equilibrium  NE  exists  We then present two  PAC algorithms
to identify the NE  They follow two lines of algorithms for
the best arm identi cation problem in the  xed con dence
setting  The sample complexity of the  rst algorithm is optimal within   constant gap if NE exists 
As we cannot give an explicit form for the expectation
number of pulls wasting on arms in neither the row nor the
column of the NE  our lower bound can be loose to some
extent  It is worth of having   further study for tighter lower
bounds  Moreover  an analysis of the sample complexity in
the case that NE does not exist is still an open problem  and
we expect better work on it in the future 

Identify the Nash Equilibrium in Static Games with Random Payoffs

Acknowledgements
This work is supported by the National Basic Research
  Program of China  No   CB  NSFC
Projects  Nos    and   and the
Youth Topnotch Talent Support Program 

References
Audibert  JeanYves and Bubeck    ebastien  Best arm
In COLT th
identi cation in multiarmed bandits 
Conference on Learning Theory  pp       

Auer  Peter  CesaBianchi  Nicolo  and Fischer  Paul 
Finitetime analysis of the multiarmed bandit problem 
Machine learning     

Babichenko  Yakov  Query complexity of approximate
nash equilibria  Journal of the ACM  JACM   
 

Chen  Xi  Deng  Xiaotie  and Teng  ShangHua  Settling
the complexity of computing twoplayer nash equilibria 
Journal of the ACM  JACM     

Daskalakis  Constantinos  Goldberg  Paul    and Papadimitriou  Christos    The complexity of computing   nash
equilibrium  SIAM Journal on Computing   
   

EvenDar  Eyal  Mannor  Shie  and Mansour  Yishay 
Action elimination and stopping conditions for the
multiarmed bandit and reinforcement learning probJournal of machine learning research   Jun 
lems 
   

Fearnley  John and Savani  Rahul  Finding approximate
nash equilibria of bimatrix games via payoff queries 
ACM Transactions on Economics and Computation
 TEAC     

Fearnley  John  Gairing  Martin  Goldberg  Paul    and
Savani  Rahul  Learning equilibria of games via payoff queries  Journal of Machine Learning Research   
   

Garivier  Aur elien  Kaufmann  Emilie  and Koolen 
Wouter    Maximin action identi cation    new bandit framework for games  In  th Annual Conference on
Learning Theory  pp     

Goldberg  Paul   and Roth  Aaron  Bounds for the query
complexity of approximate equilibria  ACM Transactions on Economics and Computation  TEAC   
 

Goldberg  Paul   and Turchetta  Stefano  Query complexity of approximate equilibria in anonymous games  In International Conference on Web and Internet Economics 
pp    Springer   

Hart  Sergiu and Nisan  Noam  The query complexity of
correlated equilibria  Games and Economic Behavior 
 

Jamieson  Kevin and Nowak  Robert  Bestarm identi 
cation algorithms for multiarmed bandits in the  xed
con dence setting  In Information Sciences and Systems
 CISS     th Annual Conference on  pp    IEEE 
 

Jordan  Patrick    Vorobeychik  Yevgeniy  and Wellman 
Michael    Searching for approximate equilibria in emIn Proceedings of the  th international
pirical games 
joint conference on Autonomous agents and multiagent
systemsVolume   pp    International Foundation for Autonomous Agents and Multiagent Systems 
 

Kalyanakrishnan  Shivaram  Tewari  Ambuj  Auer  Peter 
and Stone  Peter  Pac subset selection in stochastic multiarmed bandits  In Proceedings of the  th International
Conference on Machine Learning  ICML  pp   
   

Kaufmann  Emilie  Capp    Olivier  and Garivier  Aur elien 
On the complexity of best arm identi cation in multiarmed bandit models  The Journal of Machine Learning
Research   

Lai  Tze Leung and Robbins  Herbert  Asymptotically ef 
 cient adaptive allocation rules  Advances in applied
mathematics     

Mannor  Shie and Tsitsiklis  John    The sample complexity of exploration in the multiarmed bandit problem  Journal of Machine Learning Research   Jun 
   

Maron  Oded and Moore  Andrew    The racing algorithm  Model selection for lazy learners  In Lazy learning  pp    Springer   

Osborne  Martin   and Rubinstein  Ariel    course in game

theory  MIT press   

Tsybakov  Alexandre    Introduction to nonparametric es 

timation  Springer   

Vorobeychik  Yevgeniy  Wellman  Michael    and Singh 
Satinder  Learning payoff functions in in nite games 
Machine Learning     

Identify the Nash Equilibrium in Static Games with Random Payoffs

Walsh  William    Parkes  David    and Das  Rajarshi 
Choosing samples to compute heuristicstrategy nash
In International Workshop on Agentequilibrium 
Mediated Electronic Commerce  pp    Springer 
 

Wellman  Michael    Methods for empirical gametheoretic
analysis  In Proceedings of the National Conference on
Arti cial Intelligence  volume   pp    Menlo Park 
CA  Cambridge  MA  London  AAAI Press  MIT Press 
   

