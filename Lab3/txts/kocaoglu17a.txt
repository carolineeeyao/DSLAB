CostOptimal Learning of Causal Graphs

Murat Kocaoglu   Alex Dimakis   Sriram Vishwanath  

Abstract

We consider the problem of learning   causal
graph over   set of variables with interventions 
We study the costoptimal causal graph learning problem  For   given skeleton  undirected
version of the causal graph  design the set of
interventions with minimum total cost  that can
uniquely identify any causal graph with the given
skeleton  We show that this problem is solvable
in polynomial time  Later  we consider the case
when the number of interventions is limited  For
this case  we provide polynomial time algorithms
when the skeleton is   tree or   clique tree  For  
general chordal skeleton  we develop an ef cient
greedy algorithm  which can be improved when
the causal graph skeleton is an interval graph 

inference is important

  Introduction
Causal
for many applications
including  among others  biology  econometrics and
medicine  Chalupka et al    GrosseWentrup et al 
  Ramsey et al    Randomized trials are the
golden standard for causal inference since they lead to reliable conclusions with minimal assumptions  The problem
is that enforcing randomization to different variables in  
causal inference problem can have signi cant and varying
costs    causal discovery algorithm should take these costs
into account and optimize experiments accordingly 
In this paper we formulate this problem of learning   causal
graph when there is   cost for intervening on each variable  We follow the structural equation modeling framework  Pearl    Spirtes et al    and use interventions       experiments  To perform each intervention   
scientist randomizes   set of variables and collects new data
from the perturbed system  For example  suppose the scientist wants to discover the causal graph between   set of
patient features  such as diet and blood sugar  and diabetes 

 The University of Texas at Austin  Austin  Texas  USA  Cor 

respondence to  Murat Kocaoglu  mkocaoglu utexas edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

Suppose she decides to perform an intervention on the diet
variable  This entails forcing the desired dietary restrictions
on   random subset of the participating patients  Next  suppose she decides to perform an intervention on the blood
sugar variable  This intervention requires the scientist to
adjust the blood sugar directly  for example through injection of glucose rather than through diet control  An intervention on the blood sugar is arguably harder to perform
than   dietary restriction  Hence  the blood sugar variable
should be assigned   larger intervention cost than the diet
variable  Performing an intervention on the variable diabetes is impractical and also unethical  Hence it should be
potentially given the cost of in nity 
In this paper we study the following problem  We want to
learn   causal graph where each variable has   cost  For
each intervention set  the cost is the sum of the costs of all
the variables in the set  Total cost is the sum of the costs
of the performed interventions  We would like to learn  
causal graph with the minimum possible total cost 
Our Contributions  This is   natural problem that  to the
best of our knowledge  has not been previously studied except for some special cases as we explain in the related
work section  Our results are as follows 

  We show that the problem of designing the minimum
cost interventions to learn   causal graph can be solved
in polynomial time 

  We study the minimum cost intervention design problem when the number of interventions is limited  We
formulate the costoptimum intervention design problem as an integer linear program  This formulation allows us to identify two causal graph families for which
the problem can be solved in polynomial time 

  For general graphs  we develop an ef cient greedy algorithm  We also propose an improved variant of this
algorithm  which runs in polynomial time when the
skeleton of the causal graph is an interval graph 

Our machinery is graph theoretic  We rely on the connection between graph separating systems and proper colorings  Although this connection was previously discovered 
it does not seem to be widely known in the literature 

CostOptimal Learning of Causal Graphs

  Background and Notation
In this section  we present   brief overview of Pearl  
causality framework and illustrate how interventions are
useful in identifying causal relations  We also present the
requisite graph theory background  Finally  we explain separating systems  Separating systems are the central mathematical objects for nonadaptive intervention design 

  Causal Graphs  Interventions and Learning
  causal graph is   directed acyclic graph  DAG  where
each vertex represents   random variable of the causal system  Consider   set of random variables       directed
acyclic graph   on the vertex set   and edge set   
           is   causal graph if the arrows in the edge
set   encode direct causal relations between the variables 
  directed edge       represents   direct causal relation
between   and       is said to be   direct cause of    
In the structural causal modeling framework  Pearl   
every variable   can be written as   deterministic function
of its parent set in the causal graph   and some unobserved
random variable EX  EX is called an exogenous variable
and it is statistically independent from the nondescendants
of    Thus          aX  EX  where   aX is the set of
the parents of   in   and   is some deterministic function  We assume that the graph is acyclic   DAG  and all
the variables except the exogenous variables are observable
 causal suf ciency 
The functional relations between the observed variables
and the exogenous variables induce   joint probability distribution over the observed variables  It can be shown that
the underlying causal graph   is   valid Bayesian network
for the joint distribution induced over the observed variables by the causal model  To identify the causal graph 
we can check the conditional independence relations between the observed variables  Under the faithfulness assumption  Spirtes et al    every conditional independence relation is equivalent to   graphical criterion called
the dseparation  
In general  there is no unique Bayesian network that corresponds to   given joint distribution  There exists multiple
Bayesian networks for   given set of conditional independence relations  Thus  it is not possible to uniquely identify
the underlying causal graph using only these tests in general  However  conditional independence tests allow us to
identify   certain induced subgraph  Immoralities       in 

 Treatment of cyclic graphs require mechanics different than
independent exogenous variables  or   time varying system  and
is out of the scope of this paper 

 The set of unfaithful distributions are shown to have measure
  This makes faithfulness   widely employed assumption  even
though it was recently shown that almost faithful distibutions may
have signi cant measure  Uhler et al   

duced subgraphs on three nodes of the form            
An undirected graph   is called the skeleton of   causal
directed graph    if every edge of   corresponds to   directed edge of    and every nonedge of   corresponds
to   nonedge of    PC algorithm  Spirtes et al   
and its variants use conditional independence tests  They
 rst identify the graph skeleton  and then determine all the
immoralities  The runtime is polynomial if the underlying
graph has constant vertex degree 
The set of invariant causal edges are not only those that
belong to an immorality  For example  one can identify
additional causal edges based on the fact that the graph is
acyclic  Meek developed   complete set of rules in  Meek 
      to identify every invariant edge direction  given  
set of causal edges and the skeleton  Meek rules can be iteratively applied to the output of the PC algorithm to identify
every invariant arrow  The graph that contains every invariant causal arrow as   directed edge  and the others as
undirected edges is called the essential graph of    Essential graphs are shown to contain undirected components
which are always chordal  Spirtes et al    Hauser  
  hlmann       
Performing experiments is the most de nitive way to learn
the causal direction between variables  Randomized clinical trials  which aim to measure the causal effect of  
drug are examples of such experiments  In Pearl   causality framework  an experiment is captured through the do
operator  The do operator refers to the process of assigning   particular value to   set of variables  An intervention is an experiment where the scientist collects data after performing the do operation on   subset of variables 
This process is fundamentally different from conditioning 
and requires scientist to have the power of changing the underlying causal system  For example  by forcing   patient
not to smoke  the scientist removes the causal effect of the
patient   urge to smoke which may be caused by   gene 
An intervention is called perfect if it does not change any
other mechanism of the causal system and only assigns the
desired value to the intervened variable    stochastic intervention assigns the value of the variable of interest to
the realizations of another variable instead of    xed value 
The assigned variable is independent from the other variables in the system  This is represented as do         for
some independent random variable   
Due to the change of the causal mechanism  an intervention
removes the causal arrows from   aX to    This change in
the graph skeleton can be detected by checking the conditional independences in the postinterventional distribution  The edges still adjacent to   must have been directing away from   before the experiment  The edges that

   graph is chordal if its every cycle of length   or more con 

tains   chord 

CostOptimal Learning of Causal Graphs

are missing must have been the parents of    Thus  an
intervention on   enables us to learn the direction of every edge adjacent to    Similarly  intervening on   set of
nodes       concurrently enables us to learn the causal
edges across the cut     Sc 
Given suf cient data and computation power  we can apply the PC algorithm and Meek rules to identify the essential graph  To discover the rest of the graph we need to
use interventions on the undirected components  We assume that we work on   single undirected component after
this preprocessing step  Hence  the graphs we consider
are chordal without loss of generality  since these components are shown to always be chordal  Hauser     hlmann 
    After each intervention  we also assume that the
scientist can apply the PC algorithm and Meek rules to uncover more edges    set of interventions is said to learn  
causal graph given skeleton    if every causal edge of any
causal graph   with skeleton   can be identi ed through
this procedure    set of   interventions is called an intervention design and is shown by                    Im 
where Ii     is the set of nodes intervened on in the ith
experiment 
An intervention design algorithm is called nonadaptive if
the choice of an intervention set does not depend on the outcome of the previous interventions  Yet  we can make use
of the Meek rules over the hypothetical outcomes of each
experiment  Adaptive algorithms design the next experiment based on the outcome of the previous interventions 
Adaptive algorithms are in general hard to design and analyze  They are also impractical when the scientist needs to
design the interventions before the experiment starts      
for parallelized experiments 
In this paper we are interested in the problem of learning
  causal graph given its skeleton where each variable is associated with   cost  The objective is to nonadaptively design the set of interventions that minimizes the total interventional cost  We prove that  any set of interventions that
can learn every causal graph with   given skeleton needs
to be   graph separating system for the skeleton  This is 
to the best of our knowledge  the  rst formal proof of this
statement 

  Separating systems  Graphs  Colorings
  separating system on   set of elements is   collection
of subsets with the following property  For every pair of
elements from the set  there exists at least one subset which
contains exactly one element from the pair 

De nition   For set                            col 
 It is shown that learning additional edges in an undirected
component does not help identify edges in another undirected
component  Hauser     hlmann     

lection of subsets of                      Im  is called  
separating system if for every pair                     such
that either     Ii and     Ii  or     Ii and     Ii 

The subset that contains exactly one element from the pair
is said to separate the pair  The number of subsets in the
separating system is called the size of the separating system  We can represent   separating system with   binary
matrix 

De nition   Consider   separating system    
             Im  for the set       binary matrix    
       is called the separating system matrix for   if
for any element                     if     Ii and   otherwise 

Thus  each set element has   corresponding row coordinate 
and the rows of   represent the set membership of these
elements  Each column of   is     vector that indicates
which elements belong to the set corresponding to that column  See Figure     for two examples  The de nition of
every pair being separated by some set then translates to
every row of   being different 
Given an undirected graph    graph separating system is  
separating system that separates every edge of the graph 

De nition   Given an undirected graph             
set of subsets of                      Im  is   Gseparating
system if for every pair            for which            
         such that either     Ii and     Ii  or     Ii and
    Ii 

Thus  graph separating systems only need to separate pairs
of elements adjacent in the graph  Graph separating systems are considered in  MaoCheng    It was shown
that the size of the minimum graph separating system is
dlog     where   is the coloring number of    Based on
this  we can trivially extend the de nition of separating system matrices to include graph separating systems 
  coloring of an undirected graph is an assignment of  
set of labels  colors  to every vertex    coloring is called
proper if every adjacent vertex is assigned   different color 
  proper coloring for   graph is optimal if it is the proper
coloring that uses the minimum number of colors  The
number of colors used by an optimal coloring is the chromatic number of the graph  Optimum coloring is hard
to  nd in general graphs  however it is in   for perfect
graphs  Since chordal graphs are perfect  the graphs we are
interested in in this paper can be ef ciently colored using
minimum number of colors  For   given undirected graph
           the vertex induced subgraph on       is
shown by GS         

CostOptimal Learning of Causal Graphs

  Related Work
The framework of learing causal relations from data has
been extensively studied under different assumptions on
the causal model  The additive noise assumption asserts
that the effect of the exogenous variables are additive in the
structural equations  Under the additional assumptions that
the data is Gaussian and that the exogenous variables have
equal variances  Peters     hlman   shows that the
causal graph is identi able  Recently  under the additive
linear model with jointly Gaussian variables Peters et al 
  proposed using the invariance of the causal relations
to combine   given set of interventional data 
For the case of two variable causal graphs  there is   rich
set of theoretical results for datadriven learning  Hoyer
et al    and Shimizu et al    show that we can
learn   twovariable causal graph under different assumptions on the function or the noise term under the additive
noise model  Alternatively  an information geometric appraoch that is based on the independence of cause and effect is suggested by Janzing et al    LopezPaz et al 
  recently proposed using   classi er on the datasets
to label each dataset either as   causes   or   causes   
The lack of large real causal datasets forced him to generate
arti cial causal data  which makes this approach dependent
on the data generation process  An entropic causal inference framework is recently proposed for the twovariable
causal graphs by Kocaoglu et al   
The literature on learning causal graphs using interventions without assumptions on the causal model is more limited  For the objective of minimizing the number of experiments  Hauser     hlmann     proposes   coloringbased algorithm to construct the optimum set of interventions  Eberhardt et al    introduced the constraint on
the number of variables intervened in each experiment  He
proved in  Eberhardt    that  when all causal graphs
are considered  the set of interventions to fully identify the
causal DAG needs to be   separating system for the set
of variables  For example for complete graphs  separating
systems are necessary  Hyttinen et al    draws connections between the combinatorics literature and causality via
known separating system constructions  Shanmugam et al 
  illustrates several theoretical  ndings  They show
that the separating systems are necessary even under the
constraint that each intervention has size at most    identify an information theoretic lower bound on the necessary
number of experiments  and develop an adaptive algorithm
that leverages the Meek rules  To the best of our knowledge  the fact that   graph separating system is necessary
for   given causal graph skeleton was unknown until this
work  Also  none of these works has an explicit cost function associated with interventions 

  Graph Separating Systems  Proper
Colorings and Intervention Design

In this section  we illustrate the relation between graph colorings and graph separating systems  and show how they
are useful for nonadaptive intervention design algorithms 
Given   graph separating system                    Im  for
the skeleton   of   causal graph  we can construct the set
of interventions as follows  For experiment    intervene on
the set of variables in the set Ii  Since   is   graph separating system  for every edge in the skeleton  there is some
  for which Ii intervenes on only one of the variables adjacent to that edge  Since the edge is cut  it can be learned
by learning the skeleton of the postinterventional graph 
as explained in Section   Since every edge is cut at least
once  an intervention design based on   Gseparating system identi es any causal graph with skeleton   
Graph separating systems provide   structured way of designing interventions that can learn any causal graph  Their
necessity however is more subtle  One might suspect that
using the Meek rules in between every intervention may
eliminate the need for the set of interventions to correspond
to   graph separating system  Suppose we designed the  rst
      experiments  Applying the Meek rules over all possible outcomes of our  rst       experiments on   may enable us to design the mth experiment in an informed manner  even though we do not get to see the outcome of our
experiments  Eventually it might be possible to uncover
the whole graph without having to separate every edge  In
the following we show that Meek rules are not powerful
enough to accomplish this  and we actually need   graph
separating system  This fact seems to be known  Eberhardt 
  Hauser     hlmann      however we could not
locate   proof  We provide our own proof 
Theorem   Consider an undirected graph      set of
interventions   learns every causal graph   with skeleton
  if and only if   is   graph separating system for   
Proof  See the supplementary material 

  Any Graph Separating System is Some Coloring
In this section  we explain the relation between graph separating systems and proper graph colorings  This relation 
which is already known  Hauser     hlmann      is
important for us in reformulating the intervention design
problem in the later sections 
Let              be   proper graph coloring for graph
  which uses            colors in total  Colors are labeled by lengthm binary vectors  First construct matrix
  as follows  Let ith row of   be the label corresponding to the color of vertex              Then   is   Gseparating system matrix  Let Ii be the set of row indices

CostOptimal Learning of Causal Graphs

of   for which the corresponding entries in the ith column are   Let                    Im  be the set of subsets
constructed in this manner from   columns of    Then
  is   graph separating system for    To see this  consider
any pair of vertices      that are adjacent in               
Since the coloring is proper  the color labels of these vertices are different  which implies the corresponding rows
of           and        are different  Hence  there is
some column of   which is   in exactly one of the uth
and vth rows  Thus  the subset constructed from this column separates the pair of vertices      
Therefore any proper graph coloring can be used to construct   graph separating system  It turns out that the converse is also true  Any graph separating system can be used
to construct   proper graph coloring  This is shown by
Cai in  MaoCheng    within his proof that shows that
the minimum size of   graph separating system is dlog    
where   is the chromatic number  We repeat this result for
completeness 
Lemma    MaoCheng    Let                    Im 
be   graph separating system for the graph           
Let   be the separating system matrix for    ith column of
  is the binary vector of length      which is   in the rows
that are contained in Ii  Then the coloring              
is   proper coloring for   

This connection between graph colorings and graph separating systems is important  Ultimately  we want to use
graph colorings as   tool for searching over all sets of interventions  and  nd the one that minimizes   cost function 
This is possible due to the characterization in Lemma   and
the fact that the set of interventions has to correspond to
  graph separating system in order to identify any causal
graph by Theorem  
Along this direction  we have the following simple  yet important observation  We observe that   minimum graph
separating system does not have to correspond to an optimum coloring  We illustrate this with   simple example 
Proposition   Consider the undirected graph in Fig     
There does not exist any proper   coloring of this graph 
for which the graph separating system given in Fig     
separates every node across color classes 

Proof  Notice that the chromatic number of the given
graph is   Hence the minimum separating system size is
dlog       Thus the given graph separating system
is   minimum graph separating system  In any proper  
coloring      and     must have different colors  Hence 
any colorseparating system separates     and     How 

 Note that this lemma is not formally stated in  MaoCheng 
  but rather verbally argued within   proof of another statement 

ever the rows of the graph separating system which correspond to     and     are the same  In other words  any
 coloring based graph separating system separates     and
    whereas the graph separating system given in Fig     
does not 

This problem can be solved by assigning both vertices    
and       new color  hence coloring the graph by       colors  We can conclude the following  Suppose we consider
the costoptimum intervention design problem with at most
dlog   interventions  When we formulate it as   search
problem over the graph colorings  we need to consider the
colorings with at most  dlog   colors instead of   colors 

  CostOptimal Intervention Design
In this section  we  rst de ne the costoptimal intervention
design problem  Later we show that this problem can be
solved in polynomial time 
Suppose each variable has an associated cost wi of being
intervened on  We consider   modular cost function  The

cost of intervening on   set   of nodes is       Pi   wi 
Our objective is to  nd the set of interventions with minimum total cost  that can identify any causal graph with the
given skeleton  Given the causal graph skeleton     nd the
set of interventions                    Sm  that can identify any causal graph with the skeleton    with minimum
total costPiPj Si
wj  In this section  we do not assume
that the number of experiments are bounded and we are
only interested in minimizing the total cost  We have the
following theorem 
Theorem   Let            be   chordal graph  and
           be   cost function on its vertices  Let an intervention on set   have costPi   wi  Then the optimal set of
interventions with minimum total cost  that can learn any
causal graph   with skeleton   is given by      Ii   
where Ii is the color class for color   for any   coloring
of the graph GV                where   is the maximum
weighted independent set of   

Proof  See the supplementary material 

In other words  the optimum strategy is to color the vertex induced subgraph obtained by removing the maximum
weighted independent set   and intervening on each color
class individually  After coloring the maximum weighted
independent set  the remaining graph can always be colored
by at most   colors       the chromatic number of    The
remaining graph is still chordal  Since optimum coloring
and maximum weighted independent set can be found in
polynomial time for chordal graphs    can be constructed
in polynomial time 

CostOptimal Learning of Causal Graphs

  

  

  

  

  

    An undirected graph

  
    
    
    
    
    

  
 
 
 
 
 

  
    
    
    
    
    

  
 
 
 
 
 

  
 
 
 

Red
Green
Blue

  
 
 
 

Graph separating  

system

Color separating  

system

    Graph separating system vs  color separating system

Figure       An undirected graph with   proper   coloring        graph separating system  which does not separate color classes for any
proper coloring of the graph  An example colorseparating system is also provided 

  Intervention Design with Bounded Number

of Interventions

In this section  we consider the costoptimum intervention design problem for   given number of experiments 
We construct   linear integer program formulation for this
problem and identify the conditions under which it can be
ef ciently solved  As   corollary we show that when the
causal graph skeleton is   tree or   clique tree  the costoptimal intervention design problem can be solved in polynomial time  Later  we present two greedy algorithms for
more general graph classes 
To be able to uniquely identify any causal graph  we need
  graph separating system by Theorem   Hence  we need
    dlog   since the minimum graph separating system
has size dlog   due to  MaoCheng   
  Coloring formulation of CostOptimum

Intervention Design

One common approach to tackle combinatorial optimization problems is to write them as linear integer programs 
Often binary variables are used with   linear objective function and   set of linear constraints  The constraints determine the set of feasible points  One can construct   convex object    convex polytope  based on the set of feasible
points by simply taking their convex hull  However this
object can not always be described ef ciently 
If it can 
then the linear program over this convex object can be ef 
 ciently solved and the result is the optimal solution of the
original combinatorial optimization problem  We develop
an integer linear program formulation for  nding the costoptimum intervention design using its connection to proper
graph colorings 
From Theorem   we know that we need the set of interventions to correspond to   graph separating system for the

skeleton  From Lemma   we know that any graph separating system can be constructed from some proper coloring  Based on these  we have the following key observation  To solve the costoptimal intervention design problem given   skeleton graph  it is suf cient to search over
all proper colorings  and  nd the coloring that gives the
graph separating system with the minimum cost  We use
the following  standard  coloring formulation  Suppose we
are given an undirected graph   with   vertices and   colors are available  Assign   binary variable xi        
to every vertexcolor pair        xi       if vertex   is
colored with color    and   otherwise  Each vertex is assigned   single color  which can be captured by the equality

Pk    xi       Since coloring is proper  every pair of adjacent vertices are assigned different colors  which can be
captured by xi     xj                        Based
on our linear integer program formulation given in the supplementary material  we have the following theorem 
Theorem   Consider the costoptimal nonadaptive intervention design problem given the skeleton            of
the causal graph  Let each node be associated with an intervention cost  and the cost of intervening on   set of variables be the sum of the costs of each variable  Then  the
nonadaptive intervention design that can learn any causal
graph with the given skeleton in at most   interventions
with the minimum total cost can be identi ed in polynomial
time  if the following polytope can be described using polynomially many linear inequalities 

    conv     Rn  

xi               

 Xk   
xi     xj                
xi                       

Proof  See the supplementary material 

CostOptimal Learning of Causal Graphs

Donne in  Donne   Marenco    identi es that when
the graph is   tree  one can replace the constraints xi    
    with xi       for all                    without
changing the polytope in   He also shows that when the
graph is   cliquetree    graph that can be obtained from
  tree by replacing the vertices of the tree with cliques   
simple alternative characterization based on the constraints
on the maximum cliques of the graph exists  which can be
ef ciently described  Based on this and Theorem   we
have the following corollary 
Corollary   The costoptimal nonadaptive intervention
design problem can be solved in polynomial time if the
given skeleton of the causal graph is   tree or   clique tree 

We can identify another special case for the costoptimum
intervention design problem when the graph is uniquely
colorable  See the supplementary material for the corresponding result and the details 

  Greedy algorithms
In this section  we present two greedy algorithms for the
minimum cost intervention design problem for more general graph classes 

Algorithm   Greedy Intervention Design for Total Cost
Minimization for Chordal Skeleton
  Input    chordal graph    maximum number of interven 

tions    cost wi assigned to each vertex   

                                    
      All binary vectors of length   
  while     do
 
 
 
  Gt     Vt     Vt    Vt St  Gt  is the induced
 
  end while
  Color Gt  with minimum number of colors 
  Assign the remaining lengthm binary vectors as rows of  

Find maximum weighted independent set St of Gt 
Find     arg minx       Break ties arbitrarily 
Assign           to every     St 
subgraph on the uncolored nodes 
                              

to different color classes 

  Output    

We have the following observation  Consider   coloring
            which uses up to   colors  Consider the graph
separating system matrix   constructed using this coloring  as described in Section   Recall that the ith row
of   is       vector which represents the label for the
color of vertex    and jth column is the indicator vector for
the set of variables included in intervention    We call the
    vector used for color   as the coloring label for color
   The separating property does not depend on the color
labels  Using different labels for different colors is suf 
cient for the graph separating property to hold  However 
the number of    of   coloring label determines how many

Algorithm   Greedy Intervention Design for Total Cost
Minimization for Interval Skeleton
  Input  An interval graph    maximum number of interven 

tions    cost wi assigned to each vertex   

 

                                    

  while     

       do

 

  colorable induced subFind maximum  weighted    
graph St
Assign all weight   binary vectors of length   as rows of
   St    to different color classes 
  Gt     Vt     Vt    Vt St  Gt  is the induced
     is the number of unused available colors 
 
 
  end while
  Color Gt  with minimum number of colors 
  Assign the remaining lengthm binary vectors as rows of  

        

subgraph on the uncolored nodes 

         

to different color classes 

  Output    

times that variable is intervened on using the corresponding intervention design  Hence  we can choose the coloring
labels from the binary vectors with small weight  given the
choice  Moreover  the column index of     in   certain row
does not affect the cost since in   nonadaptive design  every intervention counts towards the total cost  we cannot
stop the experiments earlier unlike adaptive algorithms 
Based on this observation  we can try to greedily color the
graph as follows  Suppose we are allowed to use up to
  interventions  Thus the corresponding graph separating
system matrix   can have up to   columns  which allows
up to    distinct coloring labels  We can greedily color the
graph by choosing labels with small weight  rst  Choose
the color label with smallest weight from the available labels  Find the maximum weighted independent set of the
graph  Assign the coloring label to the rows associated with
the vertices in this independent set  Remove the used coloring label from the available labels  update the graph by
removing the colored vertices and iterate 
However  this type of greedy coloring could end up using
many more colors than allowed  Indeed one can show that
greedily coloring   chordal graph using maximum independent sets at each step cannot approximate the chromatic
number within an additive gap for all graphs  Thus  this
vanilla greedy algorithm may use up all    available colors and still have uncolored vertices  even though      
To avoid this  we use the following modi ed greedy algorithm  For the  rst        steps  greedily color the graph
using maximum weighted independent sets  Use the last  
colors to color the remaining uncolored vertices  Since the
graph obtained by removing colored vertices have at most
the same chromatic number as the original graph    colors
are suf cient  The remaining graph is also chordal since removing vertices do not change the chordal property  hence

Cost of Greedy Design vs  No  of Experiments       

  
  
  
  
  

 

 

 

 

 

 

 

 

 
 
 
 
 
 
 

 

 
 

 
 
 
 
 

 

 

 

 

 

 

 

 

 
 
 
 
 
 
 

 

 
 

 
 
 
 
 

  
  
  
  
  

 
 
 
 
 
 
 

 

 
 

 
 
 
 
 

 

 

 

 

 

 

 

 

 

 

 

 

  
  
  
  
  

 

 

 

 
 
Number of Experiments

 

CostOptimal Learning of Causal Graphs

Cost of Greedy Design vs  No  of Experiments       

Cost of Greedy Design vs  No  of Experiments       
 

 

 

 

 

 
 
Number of Experiments

 

 

 

 

 

 

 

 
 
Number of Experiments

 

      

      

      

Figure   Exponential weights wi   exp     no  of vertices     Sparsity parameter of the chordal graph  Each datapoint is the
average cost incurred by the greedy intervention design over   randomly sampled causal graphs for   given number of experiments 
The expected average cost of all the edges is   wi      The cost incurred by the intervention design is normalized by    As observed 
the cost incurred increases gradually as the number of experiments are reduced  or graph becomes denser  For sparse graphs  proposed
construction incurs low cost even for up to   experiments 

 nding   coloring that uses   colors can be done ef ciently 
This algorithm is given in Algorithm  
We can improve our greedy algorithm when the graph is
an interval graph  which is   strict subclass of the chordal

graphs  Note that there are  
with weight    When we use these  

   binary labels of length  
   vectors as the color 

ing labels  the corresponding intervention design requires
every variable with these colors to be intervened on exactly
  times in total  Then  rather than  nding the maximum
independent set at iteration    we can  nd the maximum

weighted  

  colorable subgraph  and use all the coloring

labels of weight    The cost of the colored vertices in the intervention design is   times their total cost  We expect this
to create   better coloring in terms of the total cost  since
it colors   larger portion of the graph at each step  Finding
the maximum weighted   colorable subgraph is hard for
nonconstant   in chordal graphs  however it can be solved
in polynomial time if the graph is an interval graph  Yannakakis   Gavril    This modi ed algorithm is given
in Algorithm   Notice that when     log    the number
of possible coloring labels is superpolynomial in    which
seem to make the algorithms run in superpolynomial time 
However  when     log    we can only use the  rst  
color labels with the lowest weight  since   proper coloring
on   graph with   vertices can use at most   colors in total 

  Experiments
In this section  we test our greedy algorithm to construct intervention designs over randomly sampled chordal graphs 
We follow the sampling scheme proposed by Shanmugam
et al     See the supplementary material for details 
The costs of the vertices of the graph are selected from       

samples of an exponential random variable with mean  
The total cost of all variables is then the same as the number of variables   in expectation  We normalize the cost
incurred by our algorithm with   and compare this normalized cost for different regimes  The parameter   is   parameter that determines the sparsity of the graph  Graphs
with larger   are expected to have more edges  See the supplementary material for the details of how the parameter  
affects the probability of an edge  We limit the simulation
to at most   experiments  xaxis  and observe the effect
of changing the number of variables   and parameter   
Algorithm   requires   subroutine that can  nd the maximum weighted independent set of   given chordal graph 
We implement the lineartime algorithm by Frank  Frank 
  for  nding the maximum weighted independent set
of   chordal graph  For the details of Frank   algorithm  see
the supplementary material 
We observe that the main factor that determines the average incurred cost is sparsity of the graph  The number of
edges compared to the number of nodes  For    xed    reducing   results in   smaller average cost by increasing the
sparsity of the graph  For    xed    increasing   reduces
the sparsity  which is also shown to reduce the average cost
incurred by the greedy intervention design  See the supplementary material for additional simulations where the
costs are chosen as the        samples from   uniform random variable over the interval    

Acknowledgements
This research has been supported by NSF Grants CCF
          ONR
   and ARO YIP   NF 

CostOptimal Learning of Causal Graphs

References
Chalupka  Krzysztof  Bischoff  Tobias  Perona  Pietro  and
Eberhardt  Frederick  Unsupervised discovery of el nino
using causal feature learning on microlevel climate data 
In Proc  of UAI   

Donne  Diego Delle and Marenco  Javier  Polyhedral studies of vertex coloring problems  The standard formulation  Discrete Optimization     

Eberhardt  Frederich  Glymour  Clark  and Scheines 
Richard  On the number of experiments suf cient and in
the worst case necessary to identify all causal relations
among   variables  In Proceedings of the  st Conference on Uncertainty in Arti cial Intelligence  UAI  pp 
   

Eberhardt  Frederick  Phd thesis  Causation and Interven 

tion  Ph    Thesis   

Etesami  Jalal and Kiyavash  Negar  Discovering in uence

structure  In IEEE ISIT   

Frank  Andr    Some polynomial algorithms for certain
graphs and hypergraphs 
In Proc  of the Fifth British
Combinatorial Conference  Congressus Numerantium
XV   

Gao  Weihao  Kannan  Sreeram  Oh  Sewoong  and
Viswanath  Pramod  Causal strength via shannon capacity  Axioms  estimators and applications 
In Proceedings of the   rd International Conference on Machine
Learning   

Granger  Clive    Investigating causal relations by econometric models and crossspectral methods  Econometrica  Journal of the Econometric Society  pp   
 

GrosseWentrup  Moritz 

Janzing  Dominik  Siegel 
Markus  and Sch lkopf  Bernhard 
Identi cation of
causal relations in neuroimaging data with latent confounders  An instrumental variable approach  NeuroImage  Elsevier     

Hauser  Alain and   hlmann  Peter  Characterization and
greedy learning of interventional markov equivalence
classes of directed acyclic graphs  Journal of Machine
Learning Research       

Hauser  Alain and   hlmann  Peter  Two optimal strategies for active learning of causal networks from interventional data  In Proceedings of Sixth European Workshop
on Probabilistic Graphical Models     

Hoyer  Patrik    Janzing  Dominik  Mooij  Joris  Peters 
Jonas  and Sch lkopf  Bernhard  Nonlinear causal discovery with additive noise models 
In Proceedings of
NIPS    

Hyttinen  Antti  Eberhardt  Frederick  and Hoyer  Patrik 
Experiment selection for causal discovery  Journal of
Machine Learning Research     

Janzing  Dominik  Mooij  Joris  Zhang  Kun  Lemeire  Jan 
Zscheischler  Jakob  Daniu is  Povilas  Steudel  Bastian 
and Sch lkopf  Bernhard 
Informationgeometric approach to inferring causal directions  Arti cial Intelligence     

Kocaoglu  Murat  Dimakis  Alexandros    Vishwanath 
Sriram  and Hassibi  Babak  Entropic causal inference 
In AAAI   

Kontoyiannis  Ioannis and Skoularidou  Maria  Estimating
the directed information and testing for causality  IEEE
Trans  Inf  Theory    Aug   

LopezPaz  David  Muandet  Krikamol  Sch lkopf  Bernhard  and Tolstikhin  Ilya  Towards   learning theory of
causeeffect inference 
In Proceedings of ICML  
 

MaoCheng  Cai  On separating systems of graphs  Dis 

crete Mathematics     

Meek  Christopher  Causal inference and causal explanation with background knowledge  In Proceedings of the
eleventh international conference on uncertainty in arti 
 cial intelligence     

Meek  Christopher  Strong completeness and faithfulness
in bayesian networks 
In Proceedings of the eleventh
international conference on uncertainty in arti cial intelligence     

Pearl  Judea  Causality  Models  Reasoning and Inference 

Cambridge University Press   

Peters  Jonas and   hlman  Peter  Identi ability of gaussian structural equation models with equal error variances  Biometrika     

Peters  Jonas    hlmann  Peter  and Meinshausen  Nicolai 
Causal inference using invariant prediction  identi cation and con dence intervals  Statistical Methodology 
Series           

Quinn  Christopher  Kiyavash  Negar  and Coleman  Todd 
Directed information graphs  IEEE Trans  Inf  Theory 
  Dec   

Raginsky  Maxim  Directed information and pearl   causal
calculus  In Proc   th Annual Allerton Conf  on Communication  Control and Computing   

CostOptimal Learning of Causal Graphs

Ramsey  Joseph    Ramsey  Hanson  Stephen Jos  Hanson  Catherine  Halchenko  Yaroslav    Poldrack  Russell  and Glymour  Clark  Six problems for causal inference from fmri  NeuroImage  Elsevier   
 

Shanmugam  Karthikeyan  Kocaoglu  Murat  Dimakis 
Alex  and Vishwanath  Sriram  Learning causal graphs
with small interventions  In NIPS    

Shimizu     Hoyer        Hyvarinen     and Kerminen       
  linear nongaussian acyclic model for causal discovery  Journal of Machine Learning Research   
   

Spirtes  Peter  Glymour  Clark  and Scheines  Richard 
Causation  Prediction  and Search    Bradford Book 
 

Uhler  Caroline  Raskutti  Garvesh    hlmann  Peter  and
Yu  Bin  Geometry of the faithfulness assumption in
causal inference  Annals of Statistics     

Yannakakis  Mihalis and Gavril  Fanica  The maximum
kcolorable subgraph problem for chordal graphs  Information Processing Letters     

Ziebart  Brian    Bagnell     Andrew  and Dey  Anind   
The principle of maximum causal entropy for estimating
interacting processes  IEEE Transactions on Information
Theory         

