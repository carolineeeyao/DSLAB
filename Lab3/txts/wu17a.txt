  Uni ed View of MultiLabel Performance Measures

XiZhu Wu   ZhiHua Zhou  

Abstract

Multilabel classi cation deals with the problem
where each instance is associated with multiple
class labels  Because evaluation in multilabel
classi cation is more complicated than singlelabel setting    number of performance measures
have been proposed  It is noticed that an algorithm usually performs differently on different
measures  Therefore  it is important to understand which algorithms perform well on which
measure    and why 
In this paper  we propose   uni ed margin view to revisit eleven performance measures in multilabel classi cation 
In particular  we de ne labelwise margin and
instancewise margin  and prove that through
maximizing these margins  different corresponding performance measures are to be optimized 
Based on the de ned margins    maxmargin approach called LIMO is designed and empirical
results validate our theoretical  ndings 

  Introduction
Multilabel classi cation aims to build classi cation models for objects assigned with multiple labels simultaneously  which is   common learning paradigm in realworld
applications 
In text categorization    document may be
associated with   range of topics  such as science  entertainment  and news  Schapire   Singer    in image
classi cation  an image can have both  eld and mountain
tags  Boutell et al    in music information retrieval   
piece of music can convey various messages such as classic  piano and passionate  Turnbull et al   
In traditional supervised classi cation  generalization performance of the learning system is usually evaluated by accuracy  or Fmeasure if misclassi cation costs are unequal 
In contrast to singlelabel classi cation  performance evaluation in multilabel classi cation is more complicated  as

 National Key Laboratory for Novel Software Technology 
Nanjing University  Nanjing   China  Correspondence to 
ZhiHua Zhou  zhouzh lamda nju edu cn 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

each instance can be associated with multiple labels simultaneously  For example  it is dif cult to tell which mistake
of the following two cases is more serious  one instance
with three incorrect labels vs 
three instances each with
one incorrect label  Therefore    number of performance
measures focusing on different aspects have been proposed 
such as Hamming loss  ranking loss  oneerror  average
precision  coverage  Schapire   Singer    microF 
and macroF   Tsoumakas et al   
Multilabel learning algorithms usually perform differently
on different measures  however  there are only   few studies about multilabel performance measures  Dembczynski et al    showed that Hamming loss and subset
  loss could not be optimized at the same time  Gao
  Zhou   proposed to study the Bayes consistency
of surrogate losses for multilabel learning  they proved
that none of convex surrogate loss is consistent with ranking loss  and gave   consistent surrogate loss function for
Hamming loss in deterministic case  There are   number of
studies about Fmeasure  mostly focusing on singlelabel
tasks  including multilabel learning as application  For
example  Ye et al    gave justi cations and connections about Fmeasure optimization using decision theoretic approaches  DTA  and empirical utility maximization
approaches  EUM  Later  Waegeman et al    studied
the Fmeasure optimality of inference algorithms from the
DTA perspective  Koyejo et al    devoted to study
of EUM optimal multilabel classi ers  These theoretical
studies offer much insight  though lacking   uni ed understanding of relation among   variety of multilabel performance measures  Moreover  some performance measures
which have been popularly used in evaluation  Zhang  
Wu    have not been theoretically studied 
In this paper  we try to disclose some shared properties among different measures and establish   uni ed understanding for multilabel performance evaluation  We
propose   margin view to revisit eleven commonly used
multilabel performance measures 
including Hamming
loss  ranking loss  oneerror  coverage  average precision 
macro  microand instanceaveraging Fmeasures and
AUCs  Speci cally  we propose the concepts of labelwise margin and instancewise margin  based on which the
corresponding effectiveness of multilabel classi ers is de 
 ned and then used as bridge to connect different perfor 

  Uni ed View of MultiLabel Performance Measures

mance measures  Our theoretical results show that by maximizing instancewise margin  macroAUC  macroF  and
Hamming loss are to be optimized  whereas by maximizing labelwise margin  the other eight performance measures except microAUC are to be optimized 
Inspired
by the theoretical  ndings  we design the LIMO  Labelwise and Instancewise Margins Optimization  approach to
maximize both the two margins  Experiments validate our
theoretical  ndings and demonstrate    exible way to optimize different measures through one approach by different
parameter settings 
The rest of the paper is organized as follows  Section   introduces the notation and de nitions of eleven multilabel
performance measures  Section   proposes the labelwise
and instancewise margins  and presents our theoretical results  Section   presents the LIMO approach  Section  
reports the results of experiments  Finally  Section   concludes and indicates several future issues 

  Preliminaries
  Notation
Assume that xi   Rd  is   real value instance vector 
yi         is   label vector for xi    denotes the number of training samples  Therefore yij                      
             means the jth label of the ith instance  and
yij     or   means the jth label is relevant or irrelevant 
The instance matrix is     Rm   and the label matrix
is                 Rd        is the multilabel
classi er  which consists of   models  one for   label  so
                hl  and hj xi  denotes the prediction of
yij  Moreover      Rd   Rl is the multilabel predictor
and the predicted value can be regarded as the con dence of
relevance  Similarly    can be decomposed as             fl 
where fj xi  denotes the predicted value of yij 

  can be induced from   via thresholding functions  For
example  hj xi     fj xi      xi  uses   thresholding
function based on the instance xi and outputs   if predicted
value is higher than the threshold    returns   if predicate
  holds  and   otherwise 

    or    

For simpli cation  we use      to denote the ith row vector
and      to denote the jth column vector of the label matrix 
Furthermore     
     denotes the index set of relevant
         yij    
 or irrelevant  labels of      Formally     
         yij     In terms of jth column of label
and    
matrix             yij     denotes the index set of positive
         yij     denotes
instances of the jth label and    
the set of negative instances similarly  We use   to denote
the cardinality of   set  thus  the number of relevant labels
of xi is     
    

  Multilabel Performance Measures

Table   summarizes the eleven multilabel performance
measures commonly used in previous studies  The  rst  ve
measures  Hamming loss  ranking loss  oneerror  coverage  average precision  are considered in Schapire   Singer
  and   multitude of works       Huang et al   
and Zhang   Wu   The next six measures are extensions of Fmeasure and AUC  the Area Under the ROC
Curve  in multilabel classi cation via different averaging
strategies  These Fmeasures are popluar both in algorithm
evaluation  Liu   Tsang    and theoretical analysis
 Koyejo et al    AUCs are used for algorithm evaluation such as in Lampert   Pham et al    and
Zhang   Wu  

Some of these measures are de ned on classi er   
and they care about the binary classi cation performance 
While some of these measures are de ned on predictor    
and they usually measure the ranking performance of the
predictor  We have noticed that some performance measures on ranking are illde ned when   is   constant function  For example  if   outputs   for all labels  then oneerror         coverage         and various AUCs will be
  which are the optimal values respectively  In multilabel
learning community  there is often an underlying assumption that   total ranking can be induced from continuous
realvalue predictions  which is common in practical cases 
In this paper  we still stick to the convention in previous
works and assume that no tie happens in continuous prediction to solve this de nition  aw 

  Theoretical Results
Here we de ne two new concepts  labelwise margin and
instancewise margin 
De nition   Given   multilabel predictor     Rd   Rl
and                 fl    training set         the labelwise margin on instance xi is de ned as 

 fu xi    fv xi                

        
    

is the set of all the  relevant  irrelevant  label

 label
    min
   
        
   
  
index pairs of instance   
De nition   Given   multilabel predictor     Rd   Rl
and                 fl    training set         the instancewise margin on label      is de ned as 

 inst
    min
   

 fj xa    fj xb                       
    

   is the set of all the  positive  negative  instance

          
index pairs of label   
Labelwise margin and instancewise margin describe the
discriminative ability of     The larger the labelwise mar 

  Uni ed View of MultiLabel Performance Measures

Table   De nitions of eleven multilabel performance measures

Note

 hij  cid  yij  

The fraction of misclassi ed labels

   
rank         fu xi    fv xi              

      

The average fraction of reversely ordered label pairs of each instance 

 
    

The fraction of instances whose most
con dent label is irrelevant 

The number of more labels on average should include to cover all relevant labels

The average fraction of relevant labels ranked higher than one other relevant label 

Fmeasure averaging on each label 

Fmeasure averaging on each instance 

Fmeasure averaging on the prediction matrix 

AUC averaging on each label  Smacro
is the set of correctly ordered instance
pairs on each label 

AUC averaging on each instance 
Sinstance is the set of correctly ordered
label pairs on each instance 

AUC averaging on prediction matrix 
Smicro is the set of correct quadruples 

Measure

Hamming loss

ranking loss

oneerror

coverage

average precision

macroF 

instanceF 

microF 

macroAUC

instanceAUC

microAUC

Formulation

  cid 
  cid 
  cid 

  

  

  

 
 

    
rank 
 
     
    
    

hloss     

 
ml

rloss      

  

 
 

  cid 
  cid 
  cid 

  

 
 

oneerror      

 arg max    xi       
    

rankF  xi        

coverage      

avgprec      

  max
   
 
  

 cid 

   ij

precision 

 
    
    

 
 
rankF  xi    
    rankF  xi       rankF  xi    

   

 
  

  

  ij
precision           

microF     

  

  

 
 

 
 

   hij

   hij

 cid  

   yij hij

   yij hij

macroF     

instanceF     

 cid  
  cid 
 cid  
   yij  cid  
 cid  
  cid 
   yij  cid  
 cid  
 cid  
 cid  
 cid  
   yij  cid  
 cid  
  cid 
    
macro 
 
 
        
    
 
  
 
    fj  xa    fj  xb 
   
macro                    
  cid 
  
 
    fu xi    fv xi 

instanceAUC      
   
instance               

    
instance 
 
    
     
    

 
 
      

macroAUC      

   yij hij

  

  

  

   hij

microAUC      

       
Smicro                               

     

 
    

 
     fi xa    fj  xb 

 cid  

 Smicro 

        cid  

gin  the easier to distinguish relevant and irrelevant labels
of an instance  Meanwhile  the larger the instancewise
margin  the easier for   to distinguish positive and negative instances of   particular label  Therefore  we want
to maximize labelwise instancewise margin to get better
performance 
Although we prefer maximizing these two margins  with
respect to performance measures  the objective can be relaxed  We de ne three properties   predictor   can have 
labelwise effective  instancewise effective and double effective 
De nition   If all the labelwise margins of   on   dataset
            are positive  this predictor   is labelwise
effective on   

De nition   If all the instancewise margins of   on  
dataset             are positive  this predictor   is
instancewise effective on   
De nition   If all the labelwise margins and instancewise margins of   on   dataset             are positive 
this predictor   is double effective on   

Roughly speaking  labelwise effective means   can exactly distinguish relevant and irrelevant labels of each instance and instancewise effective means   can exactly distinguish positive and negative instances of every label  Not
surprisingly  double effective   has the strongest ability in
distinguishing 
In the next two subsections  we use the effectiveness to an 

  Uni ed View of MultiLabel Performance Measures

alyze different performance measures  and summarize the
analysis results in Section  

  Performance Measures on Ranking

Several multilabel performance measures can be empirically optimized according to the following theorems 
Theorem   If   multilabel predictor   is labelwise effective on    then ranking loss  oneerror  coverage  average
precision and instanceAUC are optimized on the dataset 
Proof 
    Ranking loss  From the de nition of labeli       
wise effective  for every pair             
     we have
fu xi    fv xi  Therefore  the reversed set    
rank  in Table   ranking loss  is empty and the cardinality of the set is
zero  which implies the cardinality sum of all reversed sets
rloss         Ranking loss is optimized 

    Oneerror  For   labelwise effective     because labelwise margin is positive on an instance xi  we have 
           
    

fv xi        

fu xi    max

max

 

 

Then

 xi  arg max    xi       
    

Thus   arg max    xi       
and oneerror         Oneerror is optimized 

         for every instance xi 

    Coverage  When   is labelwise effective  the maximum rank of   relevant label is less than the minimum rank
of an irrelevant label  which means 

rankF  xi    

 

max
     
  
max
     
  

rankF  xi       min
 
   
  
    
rankF  xi           
 cid  

Therefore  coverage can be calculated as 

coverage      

 
 

    

        

  

Which is the optimal value of coverage 

    Average precision  Assume that   is   relevant label of
instance    it follows from Equation   that 
rankF  xi               
Since rankF  xi     is exactly the de nition of   ij
avgprec              average precision is optimized 

    rankF  xi       rankF  xi    
precision 

    InstanceAUC  Because of labelwise effective  for an
instance xi  we have 

fu xi    fv xi            

        
    

Therefore  the size of the correct ordered prediction value
pair on instance   is 
       
    
            
So instanceAUC         and instanceAUC is optimized 

    fu xi    fv xi        

        

Similar to the proof of instanceAUC  we can prove the result of macroAUC 
Theorem   If   multilabel predictor   is instancewise
effective on    then macroAUC is optimized 
Proof  Because of instancewise effective  for   label vector       we have 

fj xa    fj xb                   
    

Therefore  the size of the correct ordered prediction value
pair on label   is 

                   

    fj xa    fj xb              
    
So macroAUC         and macroAUC is optimized 

MicroAUC sees the label matrix as   whole and cannot be
optimized by instancewise effective   or labelwise effective     However  the double effective   is much more powerful  We now prove the following result of microAUC 
Theorem   If   multilabel predictor   is double effective
on    then as the number of instances grows  microAUC
is optimized 
Proof  We  rst prove   result of
random variables
Ai        If   random variables         An are drawn
from uniform distribution       for   random constant   
the event that at least one Ai is smaller than   is 
Pr Ai  Ai                    

Another random variable   is uniformly distributed in
  min Ai  and the probability that   random variable
          is bigger than   is 

Pr          Pr           Ai  Ai     

     
 

            

 

For any small    we can choose   large enough   to make
Equation   close to  
Given   label matrix            and the corresponding prediction matrix             because predictor  
is double effective  the prediction matrix satis es the following conditions 

Fij   Fiu if Yij       Yiu    
Fij   Fvj if Yij       Yvj    

  Uni ed View of MultiLabel Performance Measures

To force the value in   is in     we further assume  
uniform distribution Fij         when Yij    
If Yij     then Fij should be less than Fiu if Yiu    
and Fvj if Yvj     Suppose that the minimum value   is
de ned as 

 Fiu Yiu    cid 

 

    min

 Fvj Yvj     min

 

min

 

 cid 

Then Fij is drawn from        And we can choose  
small constant value       
According to Equation   the probability that   random
pair              to be   correct micro pair is 

Pmicro   Pr Fij   Fuv Yij     Yuv    

            

       
 
          

 
ml

where    

In the practical case  the number of labels is proportional
to the number of instances         We assume     pm
where   is   constant smaller than   

      lim
lim
  

              
 
 
 Smicro 
       

        cid  

 cid  

lim
  

       

       lim

   Pmicro    

Therefore  microAUC is to be optimized as the number of
instances grows 

With the above analysis  we can conclude that   labelwise
effective   can optimize ranking loss  oneerror  coverage  average precision  instanceAUC  microAUC and an
instancewise effective   can optimize macroAUC  For
microAUC    double effective   can optimize it as the
number of instances increases 

  Performance Measures on Classi cation

As mentioned in Section   there are some measures evaluating classi er   instead of predictor     There are many
thresholding or binarization strategies  Fan   Lin   
  urnkranz et al    Read et al    For simplicity 
we focus on two main strategies  thresholding on each instance and thresholding on each label 
  labelwise effective   can be equipped with   thresholding function based on each instance such as   xi  and
construct the   by hj xi     fj xi      xi  However 
using   xi  on an instancewise effective   is unreasonable since the predicted values on different labels may not
be comparable  In   word  we should use suitable threshold function on different effective             xi  on each
instance for labelwise effective     and tj on each label

for instancewise effective     It is reasonable to use either
  xi  or tj for double effective    
To formally analyze the performance measures on classi 
cation  we de ne the threshold error 
De nition   Given   descending ordered realvalue sequence               xk with an optimal cut number   
where        and             For   real value
threshold      xk            the threshold error    
  arg mini xi       where xi     

Intuitively  the threshold error   counts how many items
are incorrectly classi ed on   descending ordered sequence
where the correct answer is    Based on the threshold error  we propose the following theorems about performance
measures on classi cation 
Theorem   For   labelwise effective     if the thresholding function makes at most    error on each instance    the
microF  instanceF  and Hamming loss are bounded as
follows 

microF      instanceF   

 cid      

  cid 
 cid  

  

min

   

  

   
 
hloss       
ml

          
         

    
    
         

    

 

    

 cid 

 

The main idea of the above theorem is that  given the
threshold error and the number of relevant labels  we can
compute the gap between the worst possible and the perfect
contingency table  Hence the Fmeasure is based on the
contingency table  the lower bound can be deduced  The
detailed proof of Theorem   is in Appendix   
Similar to Theorem   we can prove the results for labelwise effective    
Theorem   For an instancewise effective     if the thresholding function makes at most    error on each label    then
the macroF  and Hamming loss are bounded as follows 

 cid               
            

       
            

 

 cid 

 

  cid 
 cid  

  

min

   

  

macroF       
 
hloss       
ml

The detailed proof of Theorem   is in Appendix   
With the above analysis  we can conclude that   labelwise effective   can optimize instanceF  and microF 
an instancewise effective   can optimize macroF  Both
the two effective     can optimize Hamming loss  For  
double effective     because it enjoys both the properties 
it can optimize all the above mentioned performance measures if proper thresholds are used 

  Uni ed View of MultiLabel Performance Measures

Table   Summary of performance measures optimized by xeffective multilabel predictor       cid  means   in this cell is
proved to optimize this measure    means   in this cell does
not necessarily optimize the measure    means the calculation is with without thresholding 

xeffective  

labelwise instwise double

Threshold

 
 
 
 
 
 
 
 
 
 
 

 cid 
 cid 
 cid 
 cid 
 cid 
 cid 
 cid 
 cid 
 cid 
 cid 
 cid 

 
 
 
 
 
 cid 
 
 cid 
 
 
 cid 

 cid 
 cid 
 cid 
 cid 
 cid 
 
 
 
 cid 
 cid 
 cid 

Measure

ranking loss
avg  precision

oneerror
coverage

instanceAUC
macroAUC
microAUC
macroF 
instanceF 
microF 

Hamming loss

  Summary

  Formulation

Suppose that   is   linear predictor  which means        
      where              wl  We propose the
following formulation 

arg min

   

       cid 

  

 cid 

  cid 

 wi     

 cid 
  xi        uv

  cid 
  cid 
 uv
     
  xi     cid 
     
for           and             
  xa     cid 
ab    
  cid 
for           and                    
    

  xb         

        
  

ab    

   uv

     

  

  

 

     

 

  
ab

 

and   

 
Here  uv
ab are the slack variables  and     are the
tradeoff parameters  When both   and   are positive 
both labelwise and instancewise margins are considered 
If we set        or       then only the instancewise
 or labelwise  margin is considered  In this paper  if the
approach only considers instancewise  or labelwise  margin   we call the approach as LIMOinst  or LIMOlabel 
And LIMO considers both the two margins 

Table   summarizes our theoretical results in Section  
and   Each row shows the results of one multilabel performance measure  Note that double effective is   special
case of labelwise effective and instancewise effective and
thus  if one performance measure is optimized by either
labelwise or instancewise effective predictor  it will also
be optimized by double effective predictor 
In the light of the analysis  the performance on different
performance measures through optimizing margins can be
expected  For example  if one maximizes instancewise
margin on each label    he will get good performance on
macroAUC but may suffer higher loss on ranking loss 
coverage and some other measures where   marked in the
instwise column  If one tries to maximize the labelwise
margin but pay no attention to instancewise margin    he
may perform well on average precision but poor on macroF        Elisseeff   Weston   Maximzing both the
labelwise margin and instancewise margins to get   double effective   is expected to be the best choice 

  The LIMO Approach
The above analysis reveals that maximizing different margins will optimize different measures  and if possible  double effective   is prefered since it enjoys the bene ts of
maximizing both the labelwise margin and the instancewise margin  Therefore  we propose the LIMO approach 
LIMO is   single approach which can optimize both the two
margins  and it can also be degenerated to optimize either
margin seperately via parameter setting 

Algorithm   LIMO
Input 

Data matrix     Rm    label matrix            
step size   tradeoff parameters     and the maximium iteration number    

 
Procedure 
  Initialize     with      
  Compute the weight vector cinst of each instance 

    cid  
    cid  

   random values 
       
       
    
             
    

        
cinst

       
            

clabel
 

 
 
 
 
 
 

  Compute the weight vector clabel of each label 
  for             do
 
 

Random sample an instance xt
  using weight cinst 
Random sample   positive label yiu and   negative
label yiv of instance xt
  
if       cid 
      cid 
      then
  xt
  xt
     xt
    wt 
    wt 
   
wt
     xt
    wt 
    wt 
 
wt
end if
Random sample index   of label using weight clabel 
Random sample   positive instance xt
  and   negab on label   
tive instance xt
if       cid 
      cid 
  xt
 
     xt
    wt 
wt
 
 cid  
end if
 
  end for
       
 
Output 

      then
    xt

     wt 

       

  xt

 

 

 

Multilabel linear model    

  Uni ed View of MultiLabel Performance Measures

  Algorithm

The objective Equation   is dif cult to solve directly because of the large number of constraints and slack variables  For   training set with   instances and   labels  the
number of constraints will be         ml  which may
exceed memory limit in realworld applicaitons 
In order to deal with the computational problem  we solve
Equation   by stochastic gradient descent  SGD  with
 xed step size and the default averaging technique in
ShalevShwartz   BenDavid   Chapter   The
key point of SGD is to  nd out   random vector  whose
expected value at each iteration equals the gradient direction  We randomly sample two kinds of triplets and use
them to compute the correct direction  At each iteration   
   yiu  yiv  where yiu is relevant and
we sample   triplet  xt
yiv is irrelevant  and   triplet     xt
  is   positive instance and xt
  is   negative instance both on label   
Then we use the two triplets to compute the random gradient vector for SGD  The detailed algorithm is presented
in Algorithm   and the proof that the random vector is an
unbiased estimation of the gradient direction is available in
Appendix   
After the training procedure  we can use the linear model to
predict continuous con dence values on the training data 
then choose the best threshold value by optimizing   speci   classi cation measure 

   where xt

   xt

  Experiments
We conduct experiments with LIMO on both synthetic and
benchmark data  Note that the main purpose of our work
is to study multilabel performance measures from the aspect of margin optimization  and thus  the goal of our experiments is to validate our theoretical  ndings rather than
claim that LIMO is superior  although its performance is
really highly competitive 

  Synthetic Data

We conduct experiments on synthetic data with   labels 
  data points are randomly generated from      
square  and the labels are assigned as in Figure    
data are held out for testing  The synthetic data is designed
to simulate   typical realworld circumstance  The number
of cooccurrent labels varies  the regions of each label are
different and the data cannot be perfectly seperated by  
linear learner 
To demonstrate the relationship between margins and performance measures  we degenerate LIMO to only consider
either margin by setting the tradeoff parameter   or  
to zero  LIMOinst sets       and LIMOlabel sets
      The other parameter is set to   and LIMO sets

Figure   Input
space consists of
four regions with different assignments of the label set             
The center point is with coordinate
   

          Ten replications of the experiment are
conducted and the average results are reported  Because
the range of performance measure coverage is not    
while some performance measures are better when higher 
and some are better when lower  we rescale all the performance values into relative values for clearer visualization 
The best one is rescaled to   and the worst one is rescaled to
  Figure   shows the relative results  where the originally
worst performance value is given on the right 

Figure   Summary of the relative performance on ranking measures  The more to the left  the better the performance 

The results shown in Figure   support our theoretical  ndings in Table   For example  microAUC is considered to
be optimized by double effective   but not the other two 
therefore LIMO  the red circle  gets the best relative value 
For some measures proved to be optimized by labelwise
margin such as ranking loss  average precision  coverage
and instanceAUC  LIMOlabel beats LIMOinst  While
for macroAUC  LIMOinst wins  For oneerror  all three
versions of LIMO do extremely well and get less than  
absolute value  which may be the reason why the relative
values are unexpected 

Figure   Summary of the relative performance on classi cation
measures  The more to the left  the better the performance 

Figure   shows the relative performance on classi cation 
We use two types of thresholding discussed in Section  

ABCDABDBCA  instance   macro   micro   Hamming loss  LIMOinst   LIMOinst      LIMOlabel   LIMOlabel      LIMOt LIMOt   relative valueabsolute worst valuemicroAUCinstance AUCmacroAUCcoverageone erroravg  precisionranking loss  LIMOinst LIMOlabel LIMO relative value absolute worst value  instance   macro   micro   Hamming loss  LIMOinst   LIMOinst      LIMOlabel   LIMOlabel      LIMOt LIMOt   relative valueabsolute worst valuemicroAUCinstance AUCmacroAUCcoverageone erroravg  precisionranking loss  LIMOinst LIMOlabel LIMO relative value absolute worst value    Uni ed View of MultiLabel Performance Measures

threshold function based on each instance or each label  denoted by       or    in the legend  The thresholds are estimated on training data  This  gure exactly shows our theoretical results  LIMOlabel equipped with      can optimize instanceF  and microF  LIMOinst equipped with
  can optimize macroF  By considering both labelwise
margin and instancewise margin  LIMO works well on all
four classi caiton measures 

  Benchmark Data

We conduct experiments on eleven multilabel performance measures to further show that optimizing the labelwise or the instancewise margin can lead to different results  as revealed in our theoretical analysis 
Five benchmark multilabel datasets  are used in our experiments  We choose them because they denote different domains        music dataset CAL   ii  an email dataset
enron   iii    clinical text dataset medical   iv  an image
dataset corel          tagging dataset bibtex  We randomly
split each dataset into two parts         for training and
  for testing  The experiments are repeated ten times 
and the averaged results are reported 
Because our algorithm optimizes   linear model  three linear methods called Binary Relevance  BR   Zhang   Zhou 
  MLkNN  Zhang   Zhou    and GFM  Waegeman et al    are provided for fair comparison  As
in experiments on synthetic data  we degenerate LIMO
          to LIMOinst             and LIMOlabel             The step size of SGD is set to  
For BR    regularized SVM  Chang   Lin    with
   is used as base learner  For MLkNN and GFM  the
number of nearest neighbors is   Suitable thresholds discussed in Section   are used for classi cation measures 
We take the default parameter settings recommended by authors of the compared methods respectively  Because on
one hand  we believe the parameter settings recommended
by their authors are meaningful  on the other hand  it is hard
to say which parameter setting is better in terms of eleven
performance measures 
Because some measures are better when higher  and some
measures are better when lower  to demonstrate the results more clearly  we compute the average rank of each
approach over all datasets on   speci   measure  For example  when we want to examine how LIMO performs on
ranking loss  we  rst compute the ranks on each dataset 
LIMO ranks  st on CAL  enron  bibtex and ranks  nd
on medical  corel    Then the average rank of LIMO on
ranking loss is   Figure   shows the average ranks  Due to the space limit  the detailed results
used to compute the ranks are provided in Appendix   

 http mulan sourceforge net datasetsmlc html

Figure   Average rank on benchmark data  The smaller the rank
value  the better the performance 

The results in Figure   are consistent with our theoretical
 ndings  LIMOinst  the square  performs well on marcoF  and macroAUC  while LIMOlabel  the triangle  performs well on other performance measures  LIMO  the circle  almost ranks top on every performance measure 
The experiments on synthetic and benchmark data support
our theoretical analysis  Although different performance
measures focus on different aspects  they share the common property which is formalized in our work as labelwise margin and instancewise margin  In practice  it is recommended to use higher weight   on speci   margin to optimize the required performance measure  LIMO
with nonlinear predictors may perform better  which needs
  novel optimization algorithm 

  Conclusion
In this paper  we establish   uni ed view for   variety of
multilabel performance measures  Based on the proposed
concepts of labelwise instancewise margins  we prove
that some performance measures are to be optimized by
labelwise effective classi ers  whereas some by instancewise effective classi ers  Inspired by the theoretical  ndings  we design the LIMO approach which can be adjusted
to labelwise instancewise effective via different parameter settings 
Our work discloses that there are some shared properties
among different subsets of multilabel performance measures  This explains why some measures seem to be redundant in experiments  and suggests that in future empirical
studies  rather than randomly grasp   set of measures for
evaluation  it is more informative to evaluate using measures with different properties  such as some measures optimized by labelwise effective predictors and some optimized by instancewise effective predictors  In the future 
it is encouraging to study the asymptotic properties of these
performance measures when the two margins are suboptimal  The margin view also sheds   light for the design of
novel multilabel algorithms 

microAUCmicro   macroAUCmacro   instanceAUCinstance   Hamming losscoverageoneerroravg  precisionranking loss  average rank BR MLkNN GFM LIMOinst LIMOlabel LIMO   Uni ed View of MultiLabel Performance Measures

Read  Jesse  Pfahringer  Bernhard  Holmes  Geoff  and
Frank  Eibe  Classi er chains for multilabel classi 
cation  Machine Learning     

Schapire  Robert   and Singer  Yoram  Boostexter   
boostingbased system for text categorization  Machine
Learning     

ShalevShwartz  Shai and BenDavid  Shai  Understanding
Machine Learning  From Theory to Algorithms  Cambridge University Press   

Tsoumakas  Grigorios  Katakis  Ioannis  and Vlahavas 
Ioannis    Random klabelsets for multilabel classi cation  IEEE Trans  Knowledge and Data Engineering   
   

Turnbull  Douglas  Barrington  Luke  Torres  David    and
Lanckriet  Gert       Semantic annotation and retrieval
of music and sound effects  IEEE Trans  Audio  Speech
  Language Processing     

Waegeman  Willem  Dembczynski  Krzysztof  Jachnik 
Arkadiusz  Cheng  Weiwei  and   ullermeier  Eyke  On
the bayesoptimality of Fmeasure maximizers  Journal
of Machine Learning Research     

Ye  Nan  Chai  Kian Ming Adam  Lee  Wee Sun  and
Chieu  Hai Leong  Optimizing Fmeasure    tale of two
approaches  In ICML   

Zhang  MinLing and Wu  Lei  LIFT  Multilabel learning
with labelspeci   features  IEEE Trans  Pattern Analysis and Machine Intelligence     

Zhang  MinLing and Zhou  ZhiHua  MLKNN   
lazy learning approach to multilabel learning  Pattern
Recognition     

Zhang  MinLing and Zhou  ZhiHua    review on multilabel learning algorithms  IEEE Trans  Knowledge and
Data Engineering     

Acknowledgements
This research was supported by the NSFC    
Program  CB  and the Collaborative Innovation Center of Novel Software Technology and Industrialization  Authors want to thank reviewers for helpful comments  and thank ShengJun Huang  XiuShen Wei  Miao
Xu for reading   draft 

References
Boutell  Matthew    Luo  Jiebo  Shen  Xipeng  and
Brown  Christopher    Learning multilabel scene classi cation  Pattern Recognition     

Chang  ChihChung and Lin  ChihJen  LIBSVM    library for support vector machines  ACM Trans  Intelligent Systems and Technology     

Dembczynski  Krzysztof  Waegeman  Willem  Cheng 
Weiwei  and   ullermeier  Eyke  Regret analysis for performance metrics in multilabel classi cation  the case
of hamming and subset zeroone loss  In ECML PKDD 
pp     

Elisseeff  Andr   and Weston  Jason    kernel method
for multilabelled classi cation  In NIPS  pp   
 

Fan  RongEn and Lin  ChihJen    study on threshold
selection for multilabel classi cation  National Taiwan
University  Technical Report  pp     

  urnkranz 

Johannes    ullermeier  Eyke  Menc   
Eneldo Loza  and Brinker  Klaus  Multilabel classi cation via calibrated label ranking  Machine Learning   
   

Gao  Wei and Zhou  ZhiHua  On the consistency of multilabel learning  Arti cial Intelligence     

Huang  ShengJun  Yu  Yang  and Zhou  ZhiHua  Multilabel hypothesis reuse  In ACM SIGKDD  pp   
 

Koyejo  Oluwasanmi  Natarajan  Nagarajan  Ravikumar 
Pradeep  and Dhillon  Inderjit    Consistent multilabel
classi cation  In NIPS  pp     

Lampert  Christoph    Maximum margin multilabel struc 

tured prediction  In NIPS  pp     

Liu  Weiwei and Tsang  Ivor    On the optimality of clasIn NIPS  pp 

si er chain for multilabel classi cation 
   

Pham  Anh    Raich  Raviv  Fern  Xiaoli    and Arriaga 
Jes us   erez  Multiinstance multilabel learning in the
presence of novel class instances  In ICML  pp   
   

