Meritocratic Fairness for CrossPopulation Selection

Michael Kearns   Aaron Roth   Zhiwei Steven Wu  

Abstract

We consider the problem of selecting   pool of
individuals from several populations with incomparable skills       soccer players  mathematicians  and singers  in   fair manner  The quality
of an individual is de ned to be their relative rank
 by cumulative distribution value  within their
own population  which permits crosspopulation
comparisons  We study algorithms which attempt to select the highest quality subset despite
the fact that true CDF values are not known  and
can only be estimated from the  nite pool of
candidates  Speci cally  we quantify the regret
in quality imposed by  meritocratic  notions of
fairness  which require that individuals are selected with probability that is monotonically increasing in their true quality  We give algorithms
with provable fairness and regret guarantees  as
well as lower bounds  and provide empirical results which suggest that our algorithms perform
better than the theory suggests 

  Introduction
Consider the following common academic  or similar  hiring scenario  The dean has promised your department  
faculty slots  in any areas  Your goal is to hire the best
candidates possible   but how should you identify them 
An immediate problem is that candidates are incomparable
across sub elds  because  among other things  standards of
publication  citation counts  and letterwriting styles can
vary considerably across sub elds  An attractive way to
rank candidates is according to how strong they are relative to others working in the same  eld  to whom they are
directly comparable  If we model each sub eld as corresponding to   different distribution over metrics that are
monotonically increasing in candidate quality  this is the
value we get when we evaluate the CDF function of the
distribution on   candidate   realized value  But because
 University of Pennsylvania  Philadelphia  USA  Correspon 

dence to  Zhiwei Steven Wu  steven woo gmail com 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

the number of candidates each year is small  simply comparing each candidate to their direct competitors this year
       taking their empirical CDF values as truth   would
lead to   noisy ranking  it could be that due to chance  the
best candidate this year in sub eld   would be   mediocre
candidate in   typical year  and the top two candidates in
sub eld   would each be the top candidate in   typical year 
We would prefer to evaluate our success by considering the
unknown true CDF value of each candidate  Similar situations  in which we must select   high quality set of candidates from multiple  mutually incomparable groups  arise
frequently  Some af rmative action policies are premised
on the assertion that SAT scores and other measures may
not be directly comparable across different groups       due
to only advantaged groups having the  nancial resources
for test preparation courses and multiple retakes 
For various reasons  in these settings we may also be concerned with the fairness of our choices  But what should
fairness mean  In this paper  we take inspiration from
 Dwork et al    who propose that fairness should mean
that  similar individuals are treated similarly  where  similarity  is measured with respect to some task speci   metric  In our setting  the natural taskspeci   metric is the true
withingroup CDF value for each individual  On its own 
this is compatible with the goal of selecting the best candidates  but in our work  the main obstacle is that we do not
know the true CDF value of each individual  and can only
approximate this from data  We study the degree to which
fairness and optimality are compatible with one another in
this setting 

  Our Results

We study   setting in which we wish to select   individuals out of   pool of   for some task  The individuals are
drawn from   populations  each represented by   different

 Letters of recommendation often seek to communicate this
information  with statements like  This candidate is among the
top   students   have seen in my   years as   professor 

 With respect to men   and women   sports  equal opportunity
is legislated in Title IX  With respect to faculty hiring  fairness
concerns can arise because the proportion of women can vary substantially across sub elds  For example  as reported in  Cohoon
et al    the percentage of female authors varies from  
to   across ACM conferences  when averaged over the   year
period from  

Meritocratic Fairness for CrossPopulation Selection

distribution over real numbers  The number of draws from
each distribution may differ  The  quality  of an individual
is de ned to be their  true  CDF value  as evaluated on the
distribution from which they were drawn  An algorithm is
evaluated based on the  expected  quality of the   individuals it selects 
The meritocratic fairness de nition we propose informally
asks that lower quality individuals are never  probabilistically  favored over higher quality individuals  When formulating this de nition  we have   choice as to how to incorporate randomness  The strongest formulation possible
 expost fairness  does not involve randomness  and simply
requires that every individual actually selected has quality
at least that of every individual not selected  The weakest formulation  exante fairness  incorporates the randomness of the selection of the population from the underlying distribution  and informally requires that for any pair
of individuals  the higher quality individual is selected with
weakly higher probability than the lower quality individual 
where the randomness is over the realization of the population from the underlying distributions  as well as any internal randomness of the mechanism  An intermediate formulation  exinterim fairness  requires informally that higher
quality individuals be selected with weakly higher probability than lower quality individuals  where the probability
is computed over the randomness of the mechanism  but
not over the selection of the population  Roughly speaking 
these choices correspond to what an individual may know
and still be satis ed by   promise of  fairness  Individuals should be satis ed with expost fairness even after the
choices of the mechanism are made  with full knowledge
of the applicant pool   that is  they should be satis ed
with the actual outcome  regardless of the algorithm used
to reach it  In contrast  individuals with full knowledge of
the applicant pool should still be satis ed with exinterim
fairness before the mechanism makes its decisions   that
is  they should feel satis ed that the algorithm used is fair 
An individual should only be satis ed by exante fairness
if she has no knowledge of the applicant pool  and so can
consider it   random variable  before the choices are made 
Given such   spectrum of fairness constraints  we observe
that the strongest expost fairness is impossible to achieve 
whereas the weakest exante fairness is sometimes easy to
achieve  when the population sizes are the same  it is satis ed by the mechanism that simply selects the   individuals with highest empirical CDF values  Our main results

 We study the simple setting in which each individual is represented by    dimensional  score           credit score    time
in the    dash  etc    which itself may encapsulate or summarize many features into   single value  Generalizing this work to
richer representations is an interesting direction for future work 
 However  for the cases in which the populations are not the
same size  we do not know of better utility guarantees for exante

therefore concern the cost  in terms of the expected quality
of the selected applicants  of asking for the stronger notion
of exinterim fairness  We show that satisfying an exact
variant of this constraint requires the selection algorithm
to select uniformly at random amongst all individuals  and
hence obtain only trivial utility guarantees  but that subject
to an approximate relaxation of this constraint  it is possible to recover asymptotically optimal utility bounds  We
show that when we further relax the problem  to allow the
algorithm to select approximately   individuals  rather than
exactly    it is possible to recover asymptotically optimal
utility bounds while satisfying expost fairness guarantees
within each subpopulation  and approximate exinterim
fairness guarantees across populations  We summarize our
results in Table   We complement our theoretical results
with empirical simulations which emphasize that both the
utility and fairness guarantees of our algorithms are better
in practice than our theorems promise 
Finally  we remark on an interesting property of our upper
bounds  they are oblivious  in the sense that they do not
make use of the raw scores associated with each individual
  only their empirical CDF ranking  As such  our upper
bounds can be viewed as universal distributions over permutations  of empirical CDF rankings  that satisfy   fairness guarantee  rather than algorithms  Our lower bounds
apply not just to oblivious algorithms  but to any algorithm 
even those that can make use of raw scores  or indeed  even
knowledge of the family of distributions from which populations are drawn 

  Related Work

This paper  ts into   rapidly growing line of work studying  fairness  in learning settings that is now too large to
summarize fully  and so we discuss only the most closely
related work  Our de nition of fairness is in the spirit of
 Dwork et al    who propose that individual fairness
should mean that  similar individuals are treated similarly 
with respect to some underlying taskspeci   metric  As
with the work of  Joseph et al    Jabbari et al   
we de ne the metric to be   measure of quality already
present in the model  in our case  the CDF values of individuals  but unknown to the algorithm  except through
samples  It is this necessity to learn the underlying metric that poses the tension between the fairness constraint
and the accuracy goal  Although in this line of work  we
adopt   de nition that merely requires  better individuals
be treated better  according to the true unknown metric 
this necessarily requires that  similar individuals be treated
similarly  with respect to empirical estimates of the metric 
Technically  our work includes adaptations of techniques in

fairness than those we derive for the stronger notion of exinterim
fairness 

Meritocratic Fairness for CrossPopulation Selection

ExAnte
ExInterim

ExPost

Exact Fairness

Regret       Lemma  
Regret    Theorem  

Impossible

Approximate Fairness

Regret       Lemma  
 
 
Regret    
      Theorem  
Regret    
      Theorem  

Table   An informal summary of results  The bounds are stated in the case when the populations have sizes within   constant factor
of one another   see the theorem statements for the precise bounds    When the population sizes are the same   Exact expost fairness
within each population  approximate exinterim fairness between populations  and selects approximately   individuals 

differential privacy  Dwork et al    Speci cally  we
adopt variants of the  report noisy max  algorithm  Dwork
  Roth    and Raskhodnikova and Smith    exponential mechanism for scores with varying sensitivities 
 Raskhodnikova   Smith    which is itself   variant of
the exponential mechanism  McSherry   Talwar   

indexed by   

  Model and Preliminaries
There are   different populations 
For
each population    there is   pool of candidates with their
raw scores  and henceforth observations  drawn        from
some unknown continuous distribution Fj over    Let
             Fd denote the product distribution  We
will slightly abuse notation and write xij to denote both
the individual   in the population   and her associated observation  and write   to denote the set of all candidates 
Let mj be the size of the candidate pool from population
  mj be the size of the total population  and
    minj mj be the smallest population size  Each individual xij is associated with the following values 

        cid 

    cumulative distribution function  CDF  value
value  cid Fj xij     
Fj xij    PrFj      xij  and an empirical CDF

mj

    complementary cumulative distribution function
 CCDF  value  pij       Fj xij  and an empirical
CCDF value  pij    
mj

  cid       xi cid   

 cid mj
 cid mj
  cid       xi cid   

  selection algorithm   takes all the   observations  
drawn from different distributions as input  and  randomly 
selects   individuals as outputs  We will write      xij 
 or Aij for simplicity  to denote the selection probability
over the individual xij  The utility for selecting an individual xij is her true CDF value Fj xij  Equivalently  the
loss for selecting an individual xij is the true CCDF value
pij  The loss for an algorithm   on input   is then de ned
as

 cid 

xij  

         

 
 

     xij    Fj xij 

 We adopt   slightly different de nition from the standard one 

Fj xij    PrFj      xij 

and the expected loss of the algorithm is EX           

  Fairness Formulation

Our goal is design selection algorithms subject to   meritocratic fairness notion that requires that less quali ed candidates  in terms of CDF values  are never preferred over
more quali ed ones  We will present three different formulations of such notion based on the different forms of
randomness we are considering 
First  the weakest formulation is the following exante fairness  which guarantees fairness over the randomness of
both the random draws of the candidates and the coin  ips
of the algorithm 
De nition    ExAnte Fairness  An algorithm   satis 
 es exante fairness if for any pair of candidates xij  xi cid   cid 
with CDF values Fj xij    Fj cid xi cid   cid  their selection
probabilities  when they are in the pool  satisfy
        xij            xi cid   cid 

where the expectations are taken over the        random
draws of all the other candidates 

An intermediate formulation of fairness is the following exinterim fairness  which guarantees fairness over the randomness of the algorithms  but not the realizations of   
on almost all of inputs drawn from the distribution 
De nition    Exact ExInterim Fairness  Let        
An algorithm   satis es  exact exinterim fairness if with
probability at least     over the realized observations   
for any pair of individuals xij  xi cid   cid      
     xij         xi cid   cid  only if Fj xij    Fj cid xi cid   cid 

We also consider the following relaxation 
De nition    Approximate ExInterim Fairness  An algorithm   satis es    approximate exinterim fairness
if with probability at least       over the realized observations    for any pair of individuals xij  xi cid   cid      
     xij            xi cid   cid  only if Fj xij    Fj cid xi cid   cid 
Remark   We note that this relaxation of exinterim
fairness bears   similarity to the de nition of differential

Meritocratic Fairness for CrossPopulation Selection

privacy  Dwork et al    and indeed  techniques from
the differential privacy literature will prove useful in designing algorithms to satisfy it 

Perhaps the strongest formulation is the following expost
fairness condition  which requires that an individual is selected only if   more quali ed individual is also selected 
De nition    Expost Fairness  An algorithm   satis es
expost fairness if any pair of individuals xij and xi cid   cid  such
that Fj xij    Fj cid xi cid   cid  the individual xi cid   cid  is admitted
only if xij is also selected 

Note that any algorithm that satis es expost fairness must
admit   pre   of individuals from each population  which is
also suf cient to guarantee within population expost fairness  but that this is not suf cient to satisfy the constraint
between populations 
It is not hard to see that satisfying expost fairness in the
generality that we have de ned it is impossible  since it
requires perfectly selecting the   true best CDF values from
only sample data  Thus  the primary focus of our paper is
on exinterim fairness  Unless we specify differently  the
term  fair  and  fairness refer to exinterim fairness 

  Oblivious Algorithms

  special class of selection algorithms is the class of oblivious algorithms  which select candidates with probabilities
that only depend on their empirical CDF values  not on
their observations 
De nition    Oblivious Algorithms  An algorithm   is
oblivious if for any pair of input observations   and   cid 
that induce the same empirical CDF values over the candidates             cid 
All of our algorithms presented in this paper are oblivious 
As   result  we need to make no assumption on the underlying distributions to achieve both fairness and utility
guarantees  Moreover  the utility guarantee of an oblivious
algorithm can be characterized as follows 
Lemma   The expected loss achieved by any oblivious
algorithm   is the expected average empirical CCDF values among the selected candidates 

  very simple example of an oblivious algorithm is
GREEDY which selects the   individuals with the highest
empirical CDF values  breaking ties uniformly at random 
Lemma   Suppose that the populations sizes are the
same 
The algorithm
GREEDY satis es exante fairness and has an expected loss
at most  

that is  mj     for each   

   
      

To simplify our bounds on the expected loss  we will use
    as our benchmark and de ne the regret of an algorithm   to be        EX               
    

  An Approximately Fair Algorithm
In this section  we provide an algorithm that satis es approximate fairness in the sense of De nition   We will
present our solution in three steps 

  First  we provide con dence intervals for the candidates  CCDF values pij based on their empirical
CCDF values  pij  As we show  our bound has  
tighter dependence on pij  which gives better utility
guarantee than using the standard DKW inequality
of Dvoretzky et al   

  Next  we give   simple subroutine NOISYTOP that
randomly selects   individuals out of   based on their
 scores  We show that individuals with similar scores
will have close selection probabilities under this subroutine  This subroutine is similar to the  Report
Noisy Max  algorithm  Dwork   Roth   

  Then  we will use the deviation bound in the  rst
step to assign scores to the candidates  We show that
running NOISYTOP based on these scores give approximate fairness and low regret guarantees  These
scores are computed in   way similar to the generalized exponential mechanism of Raskhodnikova  
Smith  

  Con dence Intervals for CCDF Values

We will  rst give the following concentration inequality
specialized for the uniform distribution over    
Lemma   Fix any        Let               xn be       
draws from the uniform distribution over     Then with
probability at least       for any        

 cid cid    

 cid 

 

 
 

 

          cid ln   
 cid  

    xi     

where       
 

To translate this result into   deviation bound on the CCDF
values   rst note that CCDF values for any distribution Fj
are drawn from the uniform distribution over     so the
bound applies immediately to the CCDF values  By   standard calculation  we can also get   bound in terms of the
empirical CCDF value  pij as shown below 
Lemma   For each         draw mj points Xj  
 xij mj
          from Fj  For each point xij  let pij be its
true CCDF value and  pij be its empirical CCDF value in
Fj  Then with probability at least       over the   random
draws 

 cid 
where     minj mj and    cid  

 pij    pij     

ln   

 pij
 
   mj 

of    cid    Our bound gives   tighter dependence for

Remark   The standard DKW inequality gives   bound

Meritocratic Fairness for CrossPopulation Selection
Pr yi   min      
Pr yj   min      

small empirical CCDF value  pij  For example  when  pij  
    we obtain   bound of        

 cid 
 cid 

  min      Pr yi      dr
  min      Pr yj      dr

 
  exp 

  The NoisyTop Subroutine
Given   set of individuals with scores                 yn 
the subroutine NOISYTOP will  rst perturb each score by
adding independent noise drawn from the Laplace distribution  and output the   individuals with the minimum
noisy scores  ties broken arbitrarily  We will now show
that NOISYTOP has the following desirable  Lipschitz 
property individuals with similar scores are chosen with
similar probabilities  This is crucial for obtaining approximate fairness 
Algorithm   NOISYTOP               yn      

Input    numbers                yn  and parameter  

For each         let  yi   yi   Lap 
Output  the   indices with the smallest  yi

Lemma   Let            be such that     yi   yj    
Let Pi and Pj denote the probabilities that the two indices
  and   are output by NOISYTOP               yn    respectively  Then Pi   Pj   Pi exp 

Proof  Let  yi and  yj be the noisy scores for   or    We will
introduce   new random variable   to denote the value of
the       st lowest noisy value  not counting  yi and  yj 
We will slightly abuse notation and write Pr        as  
shorthand for the pdf of any random variable   evaluated
at    The ratio Pi
Pj

    Pr yj      Pr yi   min      dt cid  dq
    Pr yi      Pr yj   min      dt cid  dq

    Pr       cid cid 
 cid 
    Pr       cid cid 
 cid 

can then be written as

 
For any  xed value        we also have the following
based on the Laplace distribution 

By the triangle inequality we know that    yj   yi   
  It follows that for any   and   
exp    Pr yi     
Pr yj     
 

 As shown in Corollary   this also gives an improvement

     versus    cid   

  exp 

and 

 The Laplace distribution Lap    has density function        

over regret when   is small      
exp     

Pr yi     
Pr yj     

 

 cid   yi 
 cid   yj 
 cid     yj 

 cid 
 cid 
       yi 

 

 

 
  exp
 
  exp

 

 

 cid 

  exp

 
Plugging these bounds into Equation   we get Pi
Pj
exp  The inequality that Pi Pj     follows directly from yi   yj 

  Wrapping Up

We will present our algorithm FAIRTOP by combining
the methods in the previous two sections  In the light of
Lemma   we will de ne the following con dence interval width function on the empirical CCDF values

         ln   cid    

and   normalized score function                We have
that any candidate is guaranteed   score not much lower
than   less quali ed one 
Lemma   Let            be the  true  CCDF values
for two individuals such that        Let        be the empirical CCDF values respectively  Suppose that               
and                 then                

Algorithm   FAIRTOP      xij           

Input  candidates  observations    fairness parameters
    number of selected individuals    and smallest population size  

For each individual xij    

Compute the empirical CCDF value  pij and the
associated score   pij 

Run NOISYTOP   pij      

Our algorithm FAIRTOP  presented in Algorithm   proceeds by  rst computing the normalized score of every candidates based on their empirical CCDF values  and then
calling NOISYTOP to output   individuals  We will  rst
establish the approximate fairness guarantee 
Theorem   The algorithm FAIRTOP instantiated with
parameters   and   satis es    approximate fairness 

Proof sketch  By Lemma   we know that with probability       for every candidate xij  the true and empirical
CCDF values satisfy  pij    pij      pij  This means
that for any pair of individuals   and   cid  with CCDF values pa   pa cid   that is    is more quali ed than   cid  we also
have   pa      pa cid      by Lemma   Finally  by the
result of Lemma   and the instantiation of NOISYTOP 
we guarantee that   cid  will not be selected with substantially
higher probability  Aa exp    Aa cid  which recovers the
approximate fairness guarantee 

Meritocratic Fairness for CrossPopulation Selection

Our algorithm also has   diminishing regret guarantee 
Theorem   Fix any         Then with probability
at least       the algorithm FAIRTOP instantiated with
fairness parameters   and   has regret bounded by

Algorithm   ABOVETHRE      xij           

Input  observations    fairness parameters     target
number of selected individuals    smallest population
size  

 cid 

 cid cid   

 
 

 cid   

 cid 

 

 
 

 

 

 

  

 

  polylog       

Thus for example  as the smallest sampled population size
  grows  xing   and   our regret rapidly approaches  
To understand the utility guarantee better  we will state the
regret bound for the following natural scaling  which is also
examined in the simulations of Section  
Corollary   Consider an instance with two population
of sizes    and    such that          for some constant
      Suppose we instantiate FAIRTOP with parameter
      then the regret is at most   

 cid 

 cid 

 
 

 

  Within Population ExPost Fairness
In this section  we provide   variant of the FAIRTOP algorithm that satis es approximate exinterim fairness across
different populations  but also expost fairness within each
population  The key idea here is that since we know the
ranking of the candidates true qualities within each population  we can guarantee expost fairness within populations
as long as we select   pre   of candidates in each population  This will however come at   cost   our algorithm
will no longer select exactly   individuals  but only approximately   individuals 
Similar to FAIRTOP 
the algorithm ABOVETHRE  presented in Algorithm   also computes the normalized
scores for each candidate  Instead of perturbing the scores 
ABOVETHRE computes   noisy threshold Tj for each population by adding Laplace noise to        The algorithm
then selects all candidates with scores above the noisy
threshold  Because the algorithm selects   pre   of the raw
scores within each population  within population expost
fairness is immediate  We also show that ABOVETHRE
also achieves approximate exinterim fairness 
Theorem   The algorithm ABOVETHRE instantiated
with fairness parameters   and   satis es both    
approximate exinterim fairness and expost fairness within
each population 

Note that were the algorithm to take all the individuals with
scores above        it would select         fraction from
each population and therefore select   people in total  Due
to the noisy thresholds  the algorithm will only select approximately   individuals  We will now establish the utility
 
guarantee of ABOVETHRE and show that the number of selected individuals is roughly        
   when        

For each individual xij

Compute her empirical CCDF value  pij
and the associated score   pij 

For each population  

Compute   noisy threshold Tj           where
   is drawn from Lap 
Select candidates xij with scores   pij  above Tj

Theorem   Fix any         With probability at least
      the algorithm ABOVETHRE instantiated with fairness parameters   and   has regret bounded by

 cid 

 
 

 
    

 

 
mn

 cid 

  polylog          

and selects   total number of    individuals with

              

  polylog          

 cid 

 cid 

 
 
nk
 
 

 
    

  Lower Bound for Exact Fairness
We will show that it is impossible to achieve exact exinterim fairness with nontrivial regret guarantees 
Theorem   Fix any       and any  fair algorithm    There exist two distributions    and    over the
two populations such that if algorithm   takes   observations drawn from each distribution as input  and must
select at least         individuals for any      
  incurs   regret of  
The main idea is to show that there exist distributions   
and    such that any fair algorithm will essentially have to
select uniformly at random across     individuals  which
incurs regret   We will proceed via Bayesian reasoning  Suppose that the observations from the two populations are drawn from two different unitvariance Gaussian
distributions       and       and both means  
and   are themselves drawn from the prior       The
following lemma characterizes the posterior distribution on
the mean given   collection of observations 
Lemma    Murphy    Suppose that   mean parameter   is drawn from   prior distribution       Let
                   xm  be          draws from the distribution       Then the posterior distribution of   conditioned on   is the Gaussian distribution       where
   

 cid 
  xi
   and      

    

Meritocratic Fairness for CrossPopulation Selection

The result above shows that conditioned on any   draws
from the Gaussian distribution  there is constant probability
 
that the true mean will be bounded away from the posterior
   With
maximum likelihood estimate by at least  
this observation  we will partition the real line into the following intervals  Given any posterior mean   any integer
      let the two intervals    
    and   
    be
 
 
                
   
         
 
 
            
             
  

and

  

  

The intervals capture the uncertainty we have regarding
the CDF values of the observations xij  Let Xj  
 cid 
                   xmj  denote the   draws from each distribution Fj      
  xij
   be the posterior mean for    conditioned on the draws  Consider two individuals xi  and xi cid 
such that xi       
    and xi cid       
   Even though
 xi cid         xi      there is   constant probability
that their CDF values satisfy   xi      xi cid  Any
fair algorithm therefore must play these two individuals in
these  neighboring  intervals with equal probabilities 
Next  we show that with high probability over the realizations of the true mean   and the   draws    all of the
    log    intervals around the posterior mean will be
 hit  by points in   
Lemma   Fix any       and        
 
mean   be drawn from           
and                    xm  be         
      Let    
   exp
and    the following holds

 cid      
  for all           cid  ln  there exist two draws
 cid  ln 

Let
cm log      
 cid 
 cid 
draws from
  xi
     Then except with probability
    over the joint realizations of  

   
  the number of points that are bigger than         

      such that   

    and   

      

       

      
  

  is no more than

           cid  ln 

 

  

 

We show that the event that all of the consecutive intervals
are occupied for both populations will force   fair algorithm to play all the individuals in these intervals with equal
 
probability  More formally     any   and suf ciently small
cn log       and let      xij   xij  
constant   let     
        xij     
   
Consider the following events 

      for some           cid  ln 
  FULLCHAIN       for all           cid  ln 

and         both the intervals    
contain at least one point in Xj 

        

     

  UARCHAIN          the points in   are selected

by the algorithm   with equal probabilities 

Lemma   Fix any  fair algorithm   for some    
  With probability at least   over the realizations
of        and    the event FULLCHAIN       implies UARCHAIN         

Proof sketch for Theorem   The combination of Lemmas   and   shows that with constant probability over
    and      will need to select     individuals with
equal probabilities  which leads to an expected regret of
  over the draws of     This means there exist distributions         
    under which
  incurs   regret 

    and         

  Sequential Batch Setting
We brie   mention an extension to the sequential batch
setting  in which the algorithm selects individuals in  
rounds  In each round    for each population    there are mj
new candidates with their observations drawn        from
the distribution Fj  At each round    the algorithm needs
to select   individuals from this pool  Let St
  be the set
of observations from population   accumulated after the
In particular  for any observation   and
 rst   rounds 
population    let the historical CCDF value be  qt
      
   cid       As   grows large  the empirical
 mj   
CCDF values become better estimates for the true CCDF
values  We give   variant of the FAIRTOP algorithm that
achieves    approximate fairness in every round  and incurs average regret over time diminishing as   
 

 cid   

 cid 

  cid St

 cid 

 

 

 

mT

  Simulations
We conclude by discussing some illustrative simulation results for FAIRTOP  along with comparisons to simpler algorithms without fairness guarantees  The simulations were
conducted on data in which the raw scores for each population         were drawn from         respectively 
and the    themselves were chosen randomly from      
Thus be tting the motivation for our model  the raw scores
are not directly comparable between populations  While
we varied the population sizes  they were held in the  xed
ratio          and      cid        cid 
For such   simulation with population sizes       
and        Figure     shows the underlying scores
computed by FAIRTOP  which depend only on the empirical CDF values  for each member of both populations  but
sorted according to their true CDF values so that the transpositions that occur between emprical and true CDFs are
apparent  the red points are for the larger population and
green for the smaller  Overlaid on this arc of underlying
scores is   black plot illustrating sample postnoise scores

Meritocratic Fairness for CrossPopulation Selection

   

   

   

Figure       Sample underlying and noisy scores as   function of true CDF rank for           Empirical distribution of selection
counts as   function of true CDF rank for           Regret as   function of population sizes  for        green     red  and    blue 

imately approximately   of trials under the simulation
parameters above  and approaches   as populations
grow in  xed ratio 
Perhaps the most natural  learning  approach is to use
the raw scores to obtain estimated population means   
 or more generally to estimate the unknown parameters of
some known or assumed parametric form  and then use the
CDFs of         and         to select the   best individuals across the two populations  This again has generally lower regret than FAIRTOP  but is deterministic and
without fairness guarantees  with approximately   of
trials resulting in unbounded unfairness ratio  approaching
  as populations grow in  xed ratio 
But the main drawback of such   learning approach in comparison to the dataoblivious FAIRTOP is its need for realizability  For instance  if we change the population   scores
to be drawn from the uniform distribution over   wide
range  but the learning approach continues to assume normality in each population  it will virtually always choose
only members of population     clear and dramatic violation of any intuitive notion of fairness  This is of course
due the fact that the highest scores in population   appear
to have extraordinarily high CDF values when  incorrectly 
assumed to have been drawn from   normal distribution  In
contrast FAIRTOP  since it doesn   even consider the actual
scores but only generic properties of the relationship between empirical and true CDF values  will behave exactly
the same  in both fairness and regret  regardless of how the
underlying scores are generated 

when       As we can see  resorting the points by their
noisy scores will result in   signi cant amount of additional
reshuf ing 
Figure     illustrates the induced distribution over chosen individuals  here we show the results of resampling the
Laplace noise  again at       for   trials  and
choosing the top   postnoise scores across populations 
The ordering is again by true CDF values and the same
color coding is used  At this value of   the distribution
is biased towards better true CDF values but still enjoys
strong fairness properties  For example  the  unfairness ratio   maximum ratio of the number of times   worse CDF
value is chosen to   better CDF value is chosen  is only
   note that this is substantially stronger than the bound
of    guaranteed by our theorem  It is also visually clear
that FAIRTOP is treating similar CDF values similarly  both
within and between populations 
Nevertheless  the regret of FAIRTOP for these population
sizes and   is nontrivial  roughly   regret compared to
the best   true CDF values  Of course  as per Theorem  
by increasing   we can reduce regret to any desired level
at the expense of weakened fairness guarantees  However 
as per Corollary   even for  xed    and therefore  xed
fairness properties  regret diminishes rapidly in the natural scaling where the population sizes grow  but in    xed
ratio  This is illustrated empirically in Figure     where
for varying choices of   we plot regret as          
with         
We now brie   compare the properties of FAIRTOP to simpler approaches that generally enjoy lower regret but have
no fairness properties  Perhaps the simplest is to pick the
  highest ranked individuals by empirical CDF rank  This
method will in general have very low regret  but since it
is deterministic  any trial in which it doesn   select the top
  true CDF values has no fairness guarantee       the unfairness ratio will be in nite  and this happens in approx 

Meritocratic Fairness for CrossPopulation Selection

References
Cohoon 

  McGrath  Nigai 

and Kaye 
Joseph Jo sh 
Gender and computing conference
papers  Communications of the ACM   
 

Sergey 

Dvoretzky     Kiefer     and Wolfowitz     Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator  Ann 
Math  Statist        doi   
aoms 
URL http dx doi org 
 aoms 

Dwork  Cynthia and Roth  Aaron 

The algorithmic
foundations of differential privacy  Foundations and
Trends   cid  in Theoretical Computer Science   
   

Dwork  Cynthia  McSherry  Frank  Nissim  Kobbi  and
Smith  Adam  Calibrating noise to sensitivity in private
In Theory of Cryptography Conference 
data analysis 
pp    Springer   

Dwork  Cynthia  Hardt  Moritz  Pitassi  Toniann  Reingold 
Omer  and Zemel  Richard  Fairness through awareness  In Proceedings of the  rd Innovations in Theoretical Computer Science Conference  pp    ACM 
 

Jabbari  Shahin 

Joseph  Matthew  Kearns  Michael 
Fair learnarXiv preprint

Morgenstern  Jamie  and Roth  Aaron 
ing in Markovian environments 
arXiv   

Joseph  Matthew  Kearns  Michael  Morgenstern  Jamie   
and Roth  Aaron  Fairness in learning  Classic and contextual bandits  In Advances in Neural Information Processing Systems  pp     

McSherry  Frank and Talwar  Kunal  Mechanism design
via differential privacy  In Foundations of Computer Science    FOCS   th Annual IEEE Symposium on 
pp    IEEE   

Murphy  Kevin   

Conjugate Bayesian analyURL

the Gaussian distribution 

 
sis of
https www cs ubc ca murphyk 
Papers bayesGauss pdf 

Raskhodnikova  Sofya and Smith  Adam    Lipschitz extensions for nodeprivate graph statistics and the generalized exponential mechanism 
In Dinur  Irit  ed 
IEEE  th Annual Symposium on Foundations of Computer Science  FOCS     October   Hyatt
Regency  New Brunswick  New Jersey  USA  pp   
  IEEE Computer Society    doi   FOCS 
  URL http dx doi org 
FOCS 

