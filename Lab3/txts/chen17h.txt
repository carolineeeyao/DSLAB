Online Partial Least Square Optimization 

Dropping Convexity for Better Ef ciency and Scalability

Zhehui Chen   Lin    Yang   Chris    Li   Tuo Zhao  

Abstract

Multiview representation learning is popular for
latent factor analysis  Many existing approaches
formulate the multiview representation learning
as convex optimization problems  where global
optima can be obtained by certain algorithms
in polynomial time  However  many evidences
have corroborated that heuristic nonconvex approaches also have good empirical computational
performance and convergence to the global optima  although there is   lack of theoretical justi 
 cation  Such   gap between theory and practice
motivates us to study   nonconvex formulation
for multiview representation learning  which can
be ef ciently solved by   simple stochastic gradient descent method  By analyzing the dynamics of the algorithm based on diffusion processes 
we establish   global rate of convergence to the
global optima  Numerical experiments are provided to support our theory 

  Introduction
Multiview data have become increasingly available in
many popular realworld data analysis and machine learning problems  These data are collected from diverse domains or different feature extractors  which share latent factors  Existing literature has demonstrated different scenarios  For instance  the pixels and captions of images can
be considered as twoview data  since they are two different features describing the same contents  More motivating examples involving two or more data sets simultaneously can be found in computer vision  natural language processing  and acoustic recognition  See  Hardoon
et al    Socher and FeiFei    Kidron et al   
Chaudhuri et al    Arora and Livescu    Bharadwaj et al    Vinokourov et al    Dhillon et al 

 Georgia Institute of Technology   Johns Hopkins Univer 
 Princeton University  Correspondence to  Tuo Zhao

sity 
 tourzhao gatech edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

  Although these data are usually unlabeled  there exist underlying association and dependency between different views  which allows us to learn useful representations
in   unsupervised manner  Here we are interested in  nding   representation that reveals intrinsic lowdimensional
structures and decomposes underlying confounding factors  One ubiquitous approach is partial least square  PLS 
for multiview representation learning  Speci cally  given
  data set of   samples of two sets of random variables
 views      Rm and     Rd  PLS aims to  nd an
rdimensional subspace      min       that preserves
most of the covariance between two views  Existing literature has shown that such   subspace is spanned by the
leading   components of the singular value decomposition

 SVD  of  XY            XY    Arora et al   
where we sample         from some unknown distribution
   Throughout the rest of the paper  if not clear speci ed 
we denote          by   for notational simplicity 
  straightforward approach for PLS is  Sample Average
Approximation   SAA   Abdi    Ando and Zhang 
  where we run an of ine  batch  SVD algorithm
on the empirical covariance matrix after seeing suf cient
data samples  However  in the  big data  regime  this approach requires unfeasible amount of storage and computation time  Therefore  it is much more practical to consider
the multiview learning problem in    data laden  setting 
where we draw independent samples from an underlying
distribution   over Rm   Rd  one at   time  This further
enables us to formulate PLS as   stochastic  online  optimization problem  Here we only consider the rank  case
       for simplicity  and solve

 bu  bv    argmax

  Rm   Rd

          

subject to                

 

Several nonconvex stochastic approximation  SA  algorithms have been proposed in  Arora et al    These
algorithms work great in practice  but are lack of theoretic
justi cations  since the nonconvex nature of   makes
the theoretical analysis very challenging  To overcome
this obstacle   Arora et al    propose   convex relaxation of   by lifting  Lasserre    Speci cally  by  
reparametrization     uv   Recall that we are interested

Online Partial Least Square Optimization

in the rank  PLS  they rewrite   as

  Rd   hM   XY  

cM   argmax

subject to kMk      and kMk     

 

where  XY   EXY   and kMk  and kMk  are the spectral norm      the largest singular value of    and nuclear
norm      the sum of all singular values of    of   respectively  By examining the KKT conditions of   one

can verify that cM   bubv  is the optimal solution  where
bu bv are the leading left and right singular vectors of  XY  

       pair of global optimal solutions to   for      
Accordingly  they propose   projected stochastic gradienttype algorithm to solve   which is often referred to the
Matrix Stochastic Gradient  MSG  algorithm  Particularly 
at the       th iteration  MSG takes

Mk    Fantope Mk    XkY     

where Xk and Yk are independently sampled from    and
 Fantope  is   projection operator to the feasible set of
  They further prove that given   prespeci ed accuracy   MSG requires

       log 

iterations such that hcM   Exy     hMN   Exy       with

high probability 
Despite of the attractive theoretic guarantee  MSG does not
present superior performance to other heuristic nonconvex
stochastic optimization algorithms for solving   Although there is   lack of theoretical justi cation  many
evidences have corroborated that heuristic nonconvex approaches not only converge to the global optima in practice  but also enjoy better empirical computational performance than the convex approaches  Zhao et al    Candes et al    Ge et al    Cai et al    Another drawback of MSG is the complicated projection step
at each iteration  Although  Arora et al    further propose an algorithm to compute the projection with   computational cost cubically depending on the rank of the iterates
 the worst case       such   sophisticated implementation signi cantly decreases the practicability of MSG  Furthermore  MSG is also unfavored in   memoryrestricted
scenario  since storing the update      requires   md 
In contrast  the heuristic algorithm
real number storage 
analyzed in this paper requires only          real number
storage 
We aim to bridge the gap between theory and practice
for solving multiview representation learning problems by
nonconvex approaches  Speci cally  we analyze the convergence properties of one heuristic stochastic optimization
algorithm for solving   based on diffusion processes 

Our analysis takes advantage of the strong Markov properties of the stochastic optimization algorithm updates and
casts the trajectories of the algorithm as   diffusion process
 Ethier and Kurtz    Li et al      By leveraging
the weak convergence from discrete Markov chains to their
continuous time limits  we demonstrate that the trajectories
are essentially the solutions to stochastic differential equations  SDE  Such SDEtype analysis automatically incorporates the geometry of the objective and the randomness
of the algorithm  and eventually demonstrates three phases
of convergence 

  Starting from an unstable equilibrium with negative
curvature  the dynamics of the algorithm can be described by an OrnsteinUhlenbeck process with  
steady driven force pointing away from the initial 

  When the algorithm is suf ciently distant from initial
unstable equilibrium  the dynamics can be characterized by an ordinary differential equation  ODE  The
trajectory of this phase is evolving directly toward the
desired global maximum until it reaches   small basin
around the optimal 

  In this phase  the trajectory can be also described by
an OrnsteinUhlenbeck process oscillating around the
global maximum  The process has   drifting term that
gradually dies out and eventually becomes   nearly
unbiased random walk centered at the maximum 

The sharp characterization in these three phases eventually allows us to establish strong convergence guarantees  Speci cally  we show the nonconvex stochastic gradient algorithm guarantees an  optimal solution in

   log 

iterations with high probability  which is   signi cant
improvement over convex MSG by   factor of  
Our theoretical analysis reveals the power of the nonconvex optimization in PLS  The simple heuristic algorithm drops the convexity  but achieves much better
ef ciency 

Notations  Given   vector                        Rd 
we de ne vector norms  kvk    Pj       kvk 
   
Pj      and kvk    maxj       Given   matrix    
Rd    we use Aj           Adj  to denote the jth colF  Pj kAjk 
umn of   and de ne the matrix norms kAk 
 
and kAk  as the largest singular value of   

Online Partial Least Square Optimization

  Nonconvex Stochastic Optimization
Recall that we solve  

  EXY   

 bu bv    argmax
subject to kuk 

   

     

      kvk 

 
where         follows some unknown distribution    Due
of global optimum  All our analysis holds for both optima 
Throughout the rest of paper  if it is not clearly speci ed 

to symmetrical structure of    bu bv  is also   pair
we consider  bu bv  as the global optimum for simplicity 

We apply   straightforward projected stochastic gradient algorithm  PSG  Speci cally  at the kth iteration  we have
the iterates uk and vk  We then independently sample Xk
and Yk from    and take

uk     uk    XkY    vk 
vk     vk    YkX   uk 

 
 
where     is the step size parameter  and   is the projection operator on the unit sphere  As can be seen from
  we have XkY    vk as   unbiased estimator of the gradient of the objective function  The projected stochastic
gradient algorithm has been studied for convex optimization  and their rates of convergence have been characterized in  BenTal and Nemirovski    Nemirovski et al 
  The problem   however  is nonconvex  and existing literature in optimization only shows that the stochastic gradient algorithms converge to   stationary solution 

  Global Convergence by ODE
Before we proceed with our analysis  we  rst impose some
mild assumptions on the problem 
Assumption   Xk  Yk            are data samples
identically independently distributed as        Rd respectively satisfying the following conditions 

    Bd  kY   

  kXk 
                         where      are the

    Bd for   constant   

singular values of  XY   EXY  

Note that here we assume   and   are of the same dimensions              and  XY is full rank for convenience
of analysis  The extension to       and rank de cient
settings is straightforward 
Assumption   Given the observed random vectors  
and     there exist two orthogonal matrices OX  OY  
Rd   such that     OXX      OY     where
   

   

 

 

      

     

  and       

     

    Rd

are the latent variables satisfying 

   

    and  

    are uncorrelated if        so that OX
and OY are the left and right singular matrices of  XY
respectively 

   

  Var  
   

        Var  
   

   

 

 

 

   

       

       ij

   

The next proposition characterizes the strong Markov property of our algorithm 

Proposition   Using   and   we get   sequence
of  uk  vk               They form   discretetime
Markov process 

With Proposition   we can construct   continuous time
process to derive an ordinary differential equation to analyze the algorithmic convergence  Before that  we  rst
compute uk    uk and vk    vk to see how much they
change in each iteration  We denote the ith coordinate of
uk and vk by     
Proposition   Suppose Assumption   holds  Given
Bd     

  the following results hold 

  and     
   

  There exist random variables     
      and     
the increments     

  and     

  with     
         
          vkX    
         ukY    

         

  with      
     
            such that
          
          

  are

   

   

        XkY    vku   
        YkX   ukv   

    
         
    
         
  Furthermore 
fk       and gk       satisfying
max fk      gk               for            
such that conditioning on uk and vk  the expectation of the
increments in   can be represented as

there are two deterministic functions

  uk    uk   uk  vk 
 XY vk        XY vkuk        fk uk  vk 
  vk    vk   uk  vk 
 XY uk        XY ukvk        gk uk  vk 

Proposition   is obtained by Taylor expansion  Its proof
is presented in Appendix    Result   enables us to compute the in nitesimal conditional mean and variance for
the projected stochastic gradient algorithm  Speci cally 
as the  xed step size       two processes       
ub tc         vb tc based on the sequence generated
by   and   converge to the solution of the following

Online Partial Least Square Optimization

ODE system in probability  See more details in  Ethier and
Kurtz   

Theorem   Given   we write the ODE in each component      

dU
dt
dV
dt

 XY       XY       
 XY        XY       

 

 

where          and          To highlight the sequence generated by   and   depending on   we
rede ne       uk        vk 
Theorem   As      
the processes         
weakly converge to the solution of the ODE system in  
and   with initial                  

The proof of Theorem   is presented in Appendix   
Under Assumption   the above ODE system admits  
closed form solution  Speci cally  we solve   and   simultaneously  since they are coupled together in   and
    To simplify them   we de ne

   

 

         and wk  

 

            

We then rewrite   and   as

dW
dt

  QW      QW   

 

where        

 XY

XY

    By Assumption   OX

and OY are left and right singular matrices of  XY respectively      

 XY   EXY     OXEXY       

where EXY   is diagonal  For notational simplicity  we
de ne     diag         such that

 XY   OXDO    

One can verify            where

   

 

   OX OX

OY  OY            

        

 

By left multiplying     both sides of   we obtain

                with dH
dt

        HH 

 

which is   coordinate separable ODE system  Accordingly 
we de ne     

     as 

hk      wk

and     

         wk 

 

Thus  we can obtain   closed form solution to   based
on the following theorem 

 
dt

             

 dXj 

               

 

where           when        This ODE System has  
closed form solution as follows 

               

for               where

        exp  it 

 

      

 dXj       exp  jt 

is   normalization function such that kH         
The proof of Theorem   is presented in Appendix   
Without loss of generalization  we assume        
We can get           as       We have successfully
characterized the global convergence performance of our
algorithm with an approximate error    The solution to
the ODE system in   however  does not fully reveal the
algorithmic behavior  more precisely  the rate of convergence  near the equilibria of the ODE system  This further
motivates us to exploit the stochastic differential equation
approach to characterize the dynamics of the algorithm 

  Global Dynamics by SDE
We analyze the dynamics of the algorithm near the equilibria based on stochastic differential equation by rescaling
analysis  Speci cally  we characterize three stages for the
trajectories of solutions 

  Neighborhood around unstable equilibria   minimiz 

ers and saddle points of  

  Neighborhood around stable equilibria   maximizers

of   and

  deterministic traverses between equilibria  Moreover 
we provide the approximate the number of iterations
in each phase until convergence 

  Phase    Escaping from unstable equilibria
Suppose that the algorithm starts to iterate around   unstable equilibrium        saddle point  Different from our previous analysis  we rescale two aforementioned processes
     and      by   factor of   This eventually allows us to capture the uncertainty of the algorithm updates
by stochastic differential equations  Roughly speaking  the
ODE approximation is essentially   variant of law of large

Online Partial Least Square Optimization

number for Markov process  while the SDE approximation
serves as   variant of central limit theorem accordingly 
Recall that   is an orthonormal matrix for diagonalizing   
and   is de ned in   Let     
   denote the ith
coordinates of

  and     

         and           

respectively  The following theorem characterizes the dynamics of the algorithm around the unstable equilibrium 
Theorem   Suppose    is initialized around some saddle point or minimizer       jth column of   with      
              and          for        Then as
      for all            
   weakly converges to   diffusion
process        satisfying the following SDE 

dZ                      dt    ijdB   
where      is   brownian motion   ij is de ned as 

 

 ij  

 

                    
                    

 

if             
or                   
otherwise 

where           for                  for        similar
de nition of  ij for       or       

The proof of Theorem   is provided in Appendix   
Note that   is   FokkerPlanck equation  which admits
  closed form solution as follows 

                   jZ  
 

  exp           

 
 

  

  

 

exp            dB   

  

  
for       

 

 

 

Such   solution is well known as the OrnsteinUhlenbeck
process  ksendal    and also implies that the distribution of     
   can be well approximated by the normal distribution of        for   suf ciently small step size  This
continuous approximation further has the following implications 

  exp          dB     
    For               ijR  
     is essentially   random variable with mean
     and variance smaller than
       The
larger   is  the closer its variance gets to this upper
bound  While      exp           essentially

ampli es    by   factor exponentially increasing in
   This tremendous ampli cation forces        to
quickly get away from   as   increases 

 
ij

    For         we have

                exp             
Var         

 
ij

           exp           

As has been shown in     that   does not need to be
large for        to get away from   Here we only
consider relatively small    Since the initial drift for
         is very small       tends to stay at   As  
increases  the exponential decay term makes the drift
quickly become negligible  Moreover  by mean value
theorem  we know that the variance is bounded  and
increases far slower than the variance in     Thus 
roughly speaking         oscillates near  

    For          we have                 and
ij  This implies that        also

Var           
tends to oscillate around   as   increases 

Overall speaking      is dominative so that it is the major
driving force for the algorithm to escape from this unstable equilibrium  More precisely  let us consider one special
case for Phase    that is we start from the second maximum singular value  with   
        We then approximately calculate the number of iterations to escape Phase
  using the algorithmic behavior of   
    
   
Proposition   Given prespeci ed     and suf 
ciently small   there exists some       where    
    is   generic constant  such that the following result
holds  We need at most

        
      with        by the following proposition 

log       
     
   
     
iterations such that    
          with probability at
   
least       where     is the CDF of standard normal
distribution 

   

    

 

 

The proof of Proposition   is provided in Appendix   
Proposition   suggests that SGD can escape from unstable equilibria in   few iterations  After escaping from the
saddle  SGD gets into the next phase  which is   deterministic traverse between equilibria 

  Phase II  Traverse between equilibria
When the algorithm is close to neither the saddle points
nor the optima  the algorithm   performance is nearly deterministic  Since      is   rescaled version of      their
trajectories are similar  Like before  we have the following proposition to calculate the approximate iterations    
following our results in Section   We restart the counter of
iteration by Proposition  

Online Partial Least Square Optimization

Proposition   After restarting counter of iteration 
given suf ciently small   and   de ned in Proposition  
we need at most

    

 

     

log

     
 

iterations such that   
   

       

The proof of Proposition   is provided in Appendix   
Combining Propositions   and   we know that after
        iteration numbers  SGD is close to the optimum
with high probability  and gets into its third phase       convergence to stable equilibria 

  Phase III  Convergence to stable equilibria
Again  we restart the counter of iteration by the strong
Markov property  The trajectory and analysis are similar
to Phase    since we also characterize the convergence using an OrnsteinUhlenbeck process  The following theorem characterizes the dynamics of the algorithm around the
stable equilibrium 
Theorem   Suppose    is initialized around some
maximizer  the  rst column of                  
  and
         for       Then as       for all           
  
weakly converges to   diffusion process        satisfying
the following SDE for      

dZ                     dt      dB   

 

where      is   brownian motion  and

     

 

 

                
                

The proof of Theorem   is provided in Appendix   
Similar to   the closed form solution to   for      
is as follow 

              exp          

        

 

exp               dB   

By the property of the OU process  we characterize the
expectation and variance of        for      
EZ             exp            
        

  exp          

       

 
  

 

     

 

 
  

       

Recall that the distribution of     
   can be well approximated by the normal distribution of        for   suf 
ciently small step size  This further implies that after suf 
 ciently many iterations  SGD enforces     
       except
      Meanwhile  SGD behaves like   biased random
walk towards the optimum  when it iterates within   small
neighborhood the optimum  But unlike Phase    the variance gradually becomes   constant 
Based on theorem   we establish an iteration complexity
bound for SGD in following proposition 

Proposition   Given   prespeci ed       suf 
ciently small   and   de ned in Proposition   after
restarting counter of iteration  we need at most

     

           max
    

 

    

     

log 
      
   
iterations such thatP  

at least  

    with probability

     

 

The proof of Proposition   is provided in Appendix   
Combining Propositions     and   we obtain   more
re ned result in the following corollary 

Corollary   Given   suf ciently small prespeci ed  
  we choose

 

      

      log   
 
iterations such that we have ku   buk 
 kv   bvk 

with probability at least  

     

The proof of Corollary   is provided in Appendix   
We can further improve the probability to       for some
    by repeating   log   replicates of SGD  We then
compute the geometric median of all outputs  See more
details in  Cohen et al   

  Numerical Experiments
We  rst provide   simple example to illustrate our theoretical analysis  Speci cally  we choose           We  rst
generate the joint covariance matrix for the latent factors  

if           
otherwise 

We need at most

   

     
  max      

  

 

Online Partial Least Square Optimization

and   as

 
 
 

Cov      XX  
Cov          XY  

   
   

       
     

   
   
   

 
 

and        XX  We then generate two matrices eU and
eV with each entry independently sampled from      
Then we convert eU and eV to orthonormal matrices   and

  by GrandSchmidt transformation  At last  we generate
the joint covariance matrix for the observational random
vectors   and   using the following covariance matrix
Cov        XXU  Cov            XY   

and Cov                

      we have uk  bu and vk  bv       global

We consider the total sample size as           and
choose       The initialization solution        is
  pair of singular vectors associated with the second largest
singular value of  XY        saddle point  We repeat the
simulation with update   and   for   times  and
plot the obtained results 
Figure     illustrates the three phases of the SGD algorithm  Speci cally  the horizontal axis is the number of
iterations  and the vertical axis is   
  de ned in   As
  
optima  This is due to the symmetric structure of the problem as mentioned in Section   Figure     is consistent
with our theory  In Phase    the algorithm gradually escapes
from the saddle point  In Phase II  the algorithm quickly
moves towards the optimum  In Phase III  the algorithm
gradually converges to the optimum 
Figure     further zooms in Phase   of Figure     We
see that the trajectories of all   simulations behave very
similar to an OU process  Figure     illustrates the three
phases by   
    As our analysis suggests  when   
     
we have   
      We see that the trajectories of all  
simulations also behave very similar to an OU process in
Phase III  These experimental results are consistent with
our theory 
Also  we illustrate    in Phase   and    in Phase III
are OU process by showing that   simulations of   
follow   gaussian distribution in     and   iteration and those of    follow   gaussian distribution in
        and       iteration  This is consistent
with the Theorems   and   in Section   Also as we can
see that in the Phase    the variance of    becomes larger
and larger when iteration number increases  Similarly  in
the Phase III  the variance of    becomes closer to    xed
number 

We then provide   real data experiment for comparing the
computational performance our nonconvex stochastic gradient algorithm for solving   with the convex stochastic
gradient algorithm for solving   We choose   subset
of the MNIST dataset  whose labels are       or   The
total sample size is       and           As
 Arora et al    suggest  we choose       pk
or       for the convex stochastic gradient algorithm  For our nonconvex stochastic gradient algorithm  we
choose either         or              
Figure   illustrates the computational performance in terms
of iterations and wall clock time  As can be seen  our nonconvex stochastic gradient algorithm outperforms the convex counterpart in iteration complexity  and signi cantly
outperforms in wall clock time  since the nonconvex algorithm does not need the computationally expensive projection in each iteration  This suggests that dropping convexity for PLS can boost both computational scalability and
ef ciency 

  Discussions
We establish the convergence rate of stochastic gradient
descent  SGD  algorithms for solving online partial least
square  PLS  problems based on diffusion process approximation  Our analysis indicates that for PLS  dropping convexity actually improves ef ciency and scalability  Our
convergence results are tighter than existing convex relaxation based method by   factor of    where   is   prespeci ed error  We believe the following directions should
be of wide interests 

  Our current results hold only for the top pair of left
and right singular vectors             For       we
need to solve

 bU   bV    

argmax

  Rm      Rd  

  tr           

subject to       Ir 

       Ir 

 

Our approximations using ODE and SDE  however 
do not admit an unique solution due to rotation  Thus 
extension to       is   challenging  but also an important future direction 

  Our current results are only applicable to    xed step
size         Our experiments suggest that
the diminishing step size

            log   

  from   to    where   is the sample complexity
from theory  achieves   better empirical performance 
One possible probability tool is Stein   method  Ross
et al   

Online Partial Least Square Optimization

Phase III

 
 
 
  
 

 

  
 
 

 
 

 

 
 
 

 

 

 
Phase II

Phase  

 
Phase II

Phase III
Number of Iteration

    All Three Phases of   
   

 
 
 
  
 

 

  
 
 

 
 

 

 
 
 

 

 

 
 
 
  
 

 

  
 
 

 
 

 

 
 
 

 

 

Phase  

Phase II

Phase III

Number of Iteration
    Phase   of   
   

Number of Iteration

    All Three Phases of   
   

Figure   An illustrative examples of the stochastic gradient algorithm  The three phases of the algorithm are consistent with our theory 
In Phase    the algorithm gradually escapes from the saddle point  In Phase II  the algorithm quickly iterates towards the optimum  In
Phase III  the algorithm gradually converges to the optimum 

 
 
 
 
 
 
 
 
 
 
 
 

  iteration

  iteration

  iteration

 
 
 
 
 
 
 
 
 
 
 
 

  iteration

    iteration
    iteration

  
   

 
 

             

  
   

 
 

             

    The estimated density of    in Phase   

    The estimated density of    in Phase III 

Figure   The estimated density based on   simulations  obtained by kernel density estimation using  fold cross validation  at
different iterations in Phase   and Phase III shows that   
     in Phase III behave very similar to OU processes 
which is consistent our theory 

     in Phase   and   

 

 
  
  
 
 
  
  
 
 

 
 
 
 

 

 
 
 
 
 
 
 
 
 
 

SGD
SGD
SGD
SGD
MSG
MSG

   
   
   
  
  
   

 

 
  
  
 
 
  
  
 
 

 
 
 
 

 

 
 
 
 
 
 
 
 
 
 

SGD

SGD

SGD

SGD

MSG

MSG

   
   
   
  
  
   

Number of Iteration

    Comparison by Iteration

Computational time  seconds 
    Comparison by Time

Figure   Comparison between nonconvex SGD and convex MSG with different step sizes  We see that SGD not only has   better
iteration complexity  but also is more computationally ef cient in wall clock time than convex MSG 

  Our current results rely on the classical central limit
theoremtype analysis by taking       Connecting our analysis to discrete algorithmic proofs  such
as  Jain et al    Shamir    Li et al     

is an important direction  Barbour and Chen   
One possible tool for addressing this is Stein   method
 Ross et al   

Online Partial Least Square Optimization

References
ABDI       Partial least square regression  pls regression  Encyclopedia for research methods for the
social sciences  

ANDO        and ZHANG         framework for
learning predictive structures from multiple tasks and
unlabeled data  Journal of Machine Learning Research
   

ARORA     COTTER     LIVESCU     and SREBRO    
  Stochastic optimization for pca and pls  In Communication  Control  and Computing  Allerton   
 th Annual Allerton Conference on  IEEE 

ARORA     and LIVESCU       Kernel cca for
multiview learning of acoustic features using articulatory measurements  In MLSLP  Citeseer 

ARORA     MIANJY     and MARINOV      
Stochastic optimization for multiview representation
learning using partial least squares 
In Proceedings of
The  rd International Conference on Machine Learning 

BARBOUR        and CHEN             An intro 

duction to Stein   method  vol    World Scienti   

BENTAL     and NEMIROVSKI       Lectures on
modern convex optimization  analysis  algorithms  and
engineering applications  SIAM 

BHARADWAJ     ARORA     LIVESCU     and
HASEGAWAJOHNSON       Multiview acoustic
feature learning using articulatory measurements  In Intl 
Workshop on Stat  Machine Learning for Speech Recognition  Citeseer 

CAI        LI     MA     ET AL    Optimal rates of
convergence for noisy sparse phase retrieval via thresholded wirtinger  ow  The Annals of Statistics    
 

DHILLON     FOSTER        and UNGAR         
Multiview learning of word embeddings via cca 
In
Advances in Neural Information Processing Systems  
    ShaweTaylor        Zemel        Bartlett     Pereira
and       Weinberger  eds  Curran Associates  Inc 
 

ETHIER        and KURTZ          Markov processes  characterization and convergence  vol   
John Wiley   Sons 

EVANS       Partial differential equations 

GE     HUANG     JIN     and YUAN       Escaping from saddle pointsonline stochastic gradient for
tensor decomposition  In COLT 

HARDOON        SZEDMAK     and SHAWETAYLOR 
     Canonical correlation analysis  An overview
with application to learning methods  Neural computation    

JAIN     JIN     KAKADE        NETRAPALLI     and
SIDFORD       Streaming pca  Matching matrix
bernstein and nearoptimal  nite sample guarantees for
oja   algorithm  In  th Annual Conference on Learning
Theory 

KIDRON     SCHECHNER        and ELAD      
Pixels that sound 
In Computer Vision and Pattern
Recognition    CVPR   IEEE Computer Society Conference on  vol    IEEE 

LASSERRE          Global optimization with polynomials and the problem of moments  SIAM Journal on
Optimization    

LI        WANG     LIU     and ZHANG    
    Nearoptimal stochastic approximation for online principal component estimation 
arXiv preprint
arXiv   

CANDES        LI     and SOLTANOLKOTABI      
Phase retrieval via wirtinger  ow  Theory and algoIEEE Transactions on Information Theory  
rithms 
 

LI        WANG     and LIU         Online ica  Understanding global dynamics of nonconvex optimization
via diffusion processes  In Advances in Neural Information Processing Systems 

CHAUDHURI     KAKADE        LIVESCU     and
SRIDHARAN       Multiview clustering via
canonical correlation analysis 
In Proceedings of the
 th annual international conference on machine learning  ACM 

COHEN        LEE        MILLER     PACHOCKI    
and SIDFORD       Geometric median in nearly
linear time 
In Proceedings of the  th Annual ACM
SIGACT Symposium on Theory of Computing  ACM 

NEMIROVSKI     JUDITSKY     LAN     and SHAPIRO 
     Robust stochastic approximation approach to
stochastic programming  SIAM Journal on optimization
   

 KSENDAL       Stochastic differential equations 

In Stochastic differential equations  Springer   

ROSS     ET AL    Fundamentals of stein   method 

Probab  Surv    

Online Partial Least Square Optimization

SHAMIR       Fast stochastic algorithms for svd
and pca  Convergence properties and convexity  arXiv
preprint arXiv   

SOCHER     and FEIFEI       Connecting modalities  Semisupervised segmentation and annotation of
images using unaligned text corpora 
In Computer Vision and Pattern Recognition  CVPR    IEEE Conference on  IEEE 

VINOKOUROV     SHAWETAYLOR     and CRISTIANInferring   semantic representation of
In NIPS 

INI      
text via crosslanguage correlation analysis 
vol   

ZHAO     WANG     and LIU         nonconvex
optimization framework for low rank matrix estimation 
In Advances in Neural Information Processing Systems 

