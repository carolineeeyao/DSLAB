The Price of Differential Privacy for Online Learning

Naman Agarwal   Karan Singh  

Abstract

We design differentially private algorithms for
the problem of online linear optimization in the
full information and bandit settings with optimal
   pT   regret bounds  In the fullinformation
setting  our results demonstrate that  differential
privacy may be ensured for free   in particular 
the regret bounds scale as   pT          
  For
pT 
posed algorithm achieves   regret of      
was      

bandit linear optimization  and as   special case 
for nonstochastic multiarmed bandits  the pro 

while the previously known best regret bound

 

     

 

  Introduction
In the paradigm of online learning    learning algorithm
makes   sequence of predictions given the  possibly incomplete  knowledge of the correct answers for the past
queries 
In contrast to statistical learning  online learning algorithms typically offer distributionfree guarantees 
Consequently  online learning algorithms are well suited
to dynamic and adversarial environments  where realtime
learning from changing data is essential making them ubiquitous in practical applications such as servicing search advertisements  In these settings often these algorithms interact with sensitive user data  making privacy   natural concern for these algorithms    natural notion of privacy in
such settings is differential privacy  Dwork et al   
which ensures that the outputs of an algorithm are indistinguishable in the case when   user   data is present as
opposed to when it is absent in   dataset 
In this paper  we design differentially private algorithms for
online linear optimization with nearoptimal regret  both in

 Equal contribution

 Computer Science  Princeton University  Princeton  NJ  USA  Correspondence
Naman Agarwal  namana cs princeton edu  Karan Singh
 karans cs princeton edu 

to 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

 Here the     notation hides polylog     factors 

the full information and partial information  bandit  settings  This result improves the known best regret bounds
for   number of important online learning problems   including prediction from expert advice and nonstochastic
multiarmed bandits 

 

  FullInformation Setting  Privacy for Free
For the fullinformation setting where the algorithm gets
to see the complete loss vector every round  we design
 differentially private algorithms with regret bounds that

ing an open question to improve the previously best known

scale as   pT         
   Theorem   partially resolvpT  posed in  Smith   Thakurta   
bound of     
  decomposition of the bound on the regret bound of this
form implies that when      pT   the regret incurred by
the differentially private algorithm matches the optimal regret in the nonprivate setting       differential privacy is
free  Moreover even when      pT   our results guarantee
  subconstant regret per round in contrast to the vacuous
constant regret per round guaranteed by existing results 
Concretely  consider the case of online linear optimization
over the cube  with unit   normbounded loss vectors  In
this setting   Smith   Thakurta    achieves   regret
pN     which is meaningful only if      
bound of     
   
Our theorems imply   regret bound of    pN      
 
    This
is an improvement on the previous bound regardless of the
value of   Furthermore  when   is between  
    the
previous bounds are vacuous whereas our results are still
meaningful  Note that the above arguments show an improvement over existing results even for moderate value of
  Indeed  when   is very small  the magnitude of improvements are more pronounced 
Beyond the separation between   and   the key point of
our analysis is that we obtain bounds for general regularization based algorithms which adapt to the geometry of
the underlying problem optimally  unlike the previous algorithms  Smith   Thakurta    which utilizes euclidean
regularization  This allows our results to get rid of   polynomial dependence on    in the pT term  in some cases 
Online linear optimization over the sphere and prediction
with expert advice are notable examples 

  and  

The Price of Differential Privacy for Online Learning

We summarize our results in Table  

  Bandits  Reduction to the Nonprivate Setting
In the partialinformation  bandit  setting  the online learning algorithm only gets to observe the loss of the prediction it prescribed  We outline   reduction technique that
translates   nonprivate bandit algorithm to   differentially
private bandit algorithm  while retaining the    pT   dependency of the regret bound on the number of rounds of
play  Theorem   This allows us to derive the  rst  
differentially private algorithm for bandit linear optimization achieving    pT   regret  using the algorithm for the
nonprivate setting from  Abernethy et al    This answers   question from  Smith   Thakurta    asking if
   pT   regret is attainable for differentially private linear
bandits  
An important case of the general bandit linear optimization
framework is the nonstochastic multiarmed bandits problem Bubeck et al      with applications for website
optimization  personalized medicine  advertisement placement and recommendation systems  Here  we propose
an  differentially private algorithm which enjoys   re 
 pN   log      Theorem   improving on the
gret of      
previously best attainable regret of      
   Smith  
Thakurta   
We summarize our results in Table  

       

  Related Work
The problem of differentially private online learning was
 rst considered in  Dwork et al    albeit guaranteeing privacy in   weaker setting   ensuring the privacy of
the individual entries of the loss vectors 
 Dwork et al 
  also introduced the treebased aggregation scheme
for releasing the cumulative sums of vectors in   differentially private manner  while ensuring that the total amount
of noise added for each cumulative sum is only polylogarithmically dependent on the number of vectors  The
stronger notion of privacy protecting entire loss vectors was
 rst studied in  Jain et al    where gradientbased algorithms were proposed that achieve    differntial pri 
 Smith  
Thakurta    proposed   modi cation of Followthe 

 
vacy and regret bounds of      
pT log  
ApproximateLeader template to achieve      
bound of      
is possible to obtain regret bounds that scale as      
it is possible to achieve   regret of     

  log    
pT  for general convex functions  In addi 
 
 pT log    While

 Dwork et al      Jain   Thakurta    proved that
in the special case of prediction with expert advice setting 

tion  they also demonstrated that under bandit feedback  it

     

 

regret for strongly convex loss functions  implying   regret

 

most algorithms for differentially private online learning
are based on the regularization template   Dwork et al 
    used   perturbationbased algorithm to guarantee
   differential privacy for the problem of online PCA 
 Tossou   Dimitrakakis    showed that it is possible
to design  differentially private algorithms for the stochastic multiarmed bandit problem with   separation of    
for the regret bound  Recently  an independent work due
to  Tossou   Dimitrakakis    which we were made
aware of after the  rst manuscript  also demonstrated  

pT  regret bound in the nonstochastic multiarmed

bandits setting  We match their results  Theorem   as
well as provide   generalization to arbitrary convex sets
 Theorem  

     

 

Information Setting  We consider

  Overview of Our Techniques
Full
the two
well known paradigms for online learning  Folllowthe 
RegularizedLeader  FTRL  and Folllowthe PerturbedLeader  FTPL  In both cases  we ensure differential privacy by restricting the mode of access to the inputs  the
loss vectors  In particular  the algorithm can only retrieve
estimates of the loss vectors released by   tree based aggregation protocol  Algorithm   which is   slight modi 
cation of the protocol used in  Jain et al    Smith  
Thakurta    We outline   tighter analysis of the regret
minimization framework by crucially observing that in case
of linear losses  the expected regret of an algorithm that
injects identically  though not necessarily independently 
distributed noise per step is the same as one that injects  
single copy of the noise at the very start of the algorithm 
The regret analysis of Followthe Leader based algorithm
involves two components    bias term due to the regularization and   stability term which bounds the change in the
output of the algorithm per step 
In the analysis due to
 Smith   Thakurta    the stability term is affected by
the variance of the noise as it changes from step to step 
However in our analysis  since we treat the noise to have
been sampled just once  the stability analysis does not factor in the variance and the magnitude of the noise essentially appears as an additive term in the bias 
Bandit Feedback  In the bandit feedback setting  we show
  general reduction that takes   nonprivate algorithm and
outputs   private algorithm  Algorithm   Our key observation here  presented as Lemma   is that on linear
functions  in expectation the regret of an algorithm on  
noisy sequence of loss vectors is the same as its regret on
the original loss sequence as long as noise is zero mean 
We now bound the regret on the noisy sequence by conditioning out the case when the noise can be large and using exploration techniques from  Bubeck et al      and
 Abernethy et al   

The Price of Differential Privacy for Online Learning

FUNCTION CLASS    DIMENSIONS 

PREVIOUS
KNOWN REGRET

BEST

OUR REGRET BOUND

PREDICTION WITH EXPERT ADVICE

ONLINE LINEAR OPTIMIZATION OVER
THE SPHERE
ONLINE LINEAR OPTIMIZATION OVER
THE CUBE

ONLINE LINEAR OPTIMIZATION

 

 

    pT log  
    pN  
   
    pN  
   
    pT
   

 

  pT log       log   log   
  pT     log   
 
  pN       log   
 
  pT   log   
   

 

 

 

NON 

BEST
PRIVATE
REGRET
  pT log    

  pT  

  pN    

  pT  

Table   Summary of our results in the fullinformation setting  In the last row we suppress the constants depending upon      

FUNCTION CLASS    DIMENSIONS 

PREVIOUS
KNOWN REGRET

BEST

OUR REGRET BOUND

BANDIT LINEAR OPTIMIZATION

NONSTOCHASTIC
BANDITS

MULTARMED

 
 

     
   
       
   

 
 

    pT
   
    pT   log  

 

 

NON 

BEST
PRIVATE
REGRET

  pT  

  pN    

Table   Summary of our results in the bandit setting  In the  rst row we suppress the speci   constants depending upon      

  Model and Preliminaries
This section introduces the model of online  linear  learning  the distinction between full and partial feedback scenarios  and the notion of differential privacy in this model 
FullInformation Setting  Online linear optimization
 Hazan et al    ShalevShwartz    involves repeated decision making over   rounds of play  At the beginning of every round  say round    the algorithm chooses
  point in xt      where    RN is    compact  convex
set  Subsequently  it observes the loss lt     RN and
suffers   loss of hlt  xti  The success of such an algorithm 
across   rounds of play  is measured though regret  which
is de ned as

Regret      TXt 

hlt  xti   min
   

hlt  xi 

TXt 

where the expectation is over the randomness of the algorithm 
In particular  achieving   sublinear regret       
corresponds to doing almost as good  averaging across  
rounds  as the  xed decision with the least loss in hindsight  In the nonprivate setting    number of algorithms
have been devised to achieve   pT   regret  with additional dependencies on other parameters dependent on the
properties of the speci   decision set   and loss set   
 See  Hazan et al    for   survey of results 
Following are three important instantiations of the above

framework 

  Prediction with Expert Advice  Here the underlying
decision set is the simplex              Rn  
xi    Pn
   xi     and the loss vectors are constrained to the unit cube      lt   RN   kltk     
  OLO over the Sphere  Here the underlying decision is
the euclidean ball          Rn   kxk      and the
loss vectors are constrained to the unit euclidean ball
     lt   RN   kltk     

  OLO over the Cube  The decision is the unit cube
         Rn   kxk      while the loss vectors
are constrained to the set      lt   RN   kltk     
PartialInformation Setting  In the setting of bandit feedback  the critical difference is that the algorithm only gets
to observe the value hlt  xti  in contrast to the complete
loss vector lt   RN as in the full information scenario 
Therefore  the only feedback the algorithm receives is the
value of the loss it incurs for the decision it takes  This
makes designing algorithms for this feedback model challenging  Nevertheless for the general problem of bandit
linear optimization   Abernethy et al    introduced  
computationally ef cient algorithm that achieves an optimal dependence of the incurred regret of   pT   on the
number of rounds of play  The nonstochastic multiarmed

The Price of Differential Privacy for Online Learning

bandit  Auer et al    problem is the bandit version of
the prediction with expert advice framework 
Differential Privacy  Differential Privacy  Dwork et al 
  is   rigorous framework for establishing guarantees
on privacy loss  that admits   number of desirable properties such as graceful degradation of guarantees under
composition and robustness to linkage acts  Dwork et al 
   
De nition      Differential Privacy    randomized
online learning algorithm   on the action set   and the
loss set   is    differentially private if for any two sequence of loss vectors               lT        and     
                     differing in at most one vector   that is to
say                         lt         for all         
it holds that

                               

Remark   The above de nition of Differential Privacy
is speci   to the online learning scenario in the sense that
it assumes the change of   complete loss vector  This has
been the standard notion considered earlier in  Jain et al 
  Smith   Thakurta    Note that the de nition
entails that the entire sequence of predictions produced by
the algorithm is differentially private 

 

Notation  We de ne kYkp   max kltkp
lt  
          and    
   kXkp   max kxkp
maxl        hl  xi  where       is the lp norm  By
Holder   inequality  it is easy to see that     kYkpkXkq
for all          with  
      We de ne the distribution LapN   to be the distribution over RN such that
each coordinate is drawn independently from the Laplace
distribution with parameter  

     

  FullInformation Setting  Privacy for Free
In this section  we describe an algorithmic template  Algorithm   for differentially private online linear optimization  based on Followthe RegularizedLeader scheme 
Subsequently  we outline the noise injection scheme  Algorithm   based on the Treebased Aggregation Protocol
 Dwork et al    used as   subroutine by Algorithm  
to ensure input differential privacy  The following is our
main theorem in this setting 
Theorem   Algorithm   when run with     LapN  
where     kYk  log  
  regularization      decision set
  and loss vectors          lt  the regret of Algorithm   is
bounded by

 

Regret  vuutDR

TXt 

max
   

 kltk 

         DLap

where

DLap   EZ   max

    hZ  xi 

    hZ  xi   min
       min
   

    

DR   max
   

and    is the distribution induced by the sum of dlog Te
independent samples from         
       represents the
dual of the norm with respect to the hessian of    Moreover 
the algorithm is  differentially private      
the sequence
of predictions produced  xt            is  differentially
private 

   ls 

  Sample   

        ndlog Te

Algorithm   FTRL Template for OLO
input Noise distribution    Regularization     
  Initialize an empty binary tree   to compute differentially private estimates ofPt
       Pdlog Te
Choose xt   argminx   hx   Lt         
Observe lt      and suffer   loss of hlt  xti 
   Lt       TreeBasedAgg lt             

 
 
ni
  for       to   do
 
 
 
  end for

independently from   

  

The above theorem leads to following corollary where we
show the bounds obtained in speci   instantiations of online linear optimization 
Corollary   Substituting the choices of        listed
below  we specify the regret bounds in each case 

  Prediction with Expert Advice 

Choosing    

   xi log xi 

  log  

 

and       PN
Regret     pT log    

  log    log  

 

 

  OLO over the Sphere Choosing    

pN log  

 

and

       kxk 

 

Regret     pT  

  log   

 

 

  OLO over the Cube With     log  
 

and        kxk 

 

Regret     pN    

  log   

 

 

The Price of Differential Privacy for Online Learning

Algorithm   TreeBasedAgg lt             
input Loss vector lt  Binary tree    Round    Noise distribution    Time horizon  
               PrivateSum lt                Algorithm    Jain et al    with the noise added at
each node   be it internal or leaf   sampled independently from the distribution   
  st   the binary representation of   as   string 
  Find the minimum set   of already populated nodes in
  that can computePt
  De ne           dlog Te  De ne rt   dlog Te     
  Sample   
   Lt         Prt

          nrt
independently from   
 
  
   ni

output    Lt    

   ls 

  Proof of Theorem  
We  rst prove the privacy guarantee  and then prove the
claimed bound on the regret  For the analysis  we de ne
the random variable Zt to be the net amount of noise injected by the TreeBasedAggregation  Algorithm   on the
true partial sums  Formally  Zt is the difference between
cumulative sum of loss vectors and its differentially private
estimate used as input to the argmin oracle 

li

Zt    Lt  

tial sums of the loss vectors  Pt

tXi 
Further  let    be the distribution induced by summing of
dlog Te independent samples from   
Privacy   To make formal claims about the quality of
privacy  we ensure input differential privacy for the algorithm   that is  we ensure that the entire sequence of pars  ls            is  
differentially private  Since the outputs of Algorithm   are
strictly determined by the pre   sum estimates produced
by TreeBasedAgg  by the postprocessing theorem  this
certi es that the entire sequence of choices made by the
algorithm  across all   rounds of play   xt            is  
differentially private  We modify the standard Treebased
Aggregation protocol to make sure that the noise on each
output  partial sum  is distributed identically  though not
necessarily independently  across time  While this modi 
cation is not essential for ensuring privacy  it simpli es the
regret analysis 
Lemma    Privacy Guarantees with Laplacian Noise 
Choose any     kYk  log  
  When Algorithm           
is run with     LapN   the following claims hold true 
  Privacy  The sequence    Lt
         is  
differentially private 
  Distribution            Zt   Pdlog Te

ni  where

  

 

 

each ni is independently sampled from LapN  

Proof  By Theorem    Jain et al    we have that the
sequence                   is  differentially private  Now the
sequence    Lt            is  differentially private because
differential privacy is immune to postprocessing Dwork
et al     
Note that the PrivateSum algorithm adds exactly     independent draws from the distribution   toPt
   ls  where
  is the minimum set of already populated nodes in the tree
that can compute the required pre   sum  Due to Line   in
Algorithm   it is made certain that every pre   sum released is   sum of the true pre   sum and dlog Te independent draws from   
Regret Analysis  In this section  we show that for linear loss functions any instantiation of the Followthe 
RegularizedLeader algorithm can be made differentially
private with an additive loss in regret 
Theorem   For any noise distribution    regularization
     decision set   and loss vectors          lt  the regret
of Algorithm   is bounded by

Regret  vuutDR

TXt 

max
   

 kltk 

         DD 

where DD    EZ     maxx   hZ  xi   minx   hZ  xi 
DR   maxx          minx        and      
      
represents the dual of the norm with respect to the hessian
of   

Proof  To analyze the regret suffered by Algorithm   we
consider an alternative algorithm that performs   oneshot
noise injection   this alternate algorithm may not be differentially private  The observation here is that the alternate algorithm and Algorithm   suffer the same loss in expectation and therefore the same expected regret which we
bound in the analysis below 
Consider the following alternate algorithm which instead
of sampling noise Zt at each step instead samples noise at
the beginning of the algorithm and plays with respect to
that  Formally consider the sequence of iterates  xt de ned
as follows  Let       
        

 xt   argminx    hx     Xi
hlt  xti    EZ    TXt 

EZ ZT     TXt 

hlt   xti   
To see the above equation note that EZt    hlt   xti   
EZ    hlt  xti  since     xt have the same distribution 

lii       

We have that

The Price of Differential Privacy for Online Learning

Therefore it is suf cient to bound the regret of the sequence
           xt  The key idea now is to notice that the addition
of one shot noise does not affect the stability term of the
FTRL analysis and therefore the effect of the noise need
not be paid at every time step  Our proof will follow the
standard template of using the FTLBTL  Kalai   Vempala    lemma and then bounding the stability term in
the standard way  Formally de ne the augmented series of
loss functions by de ning

      

 
 

       hZ  xi

where       is   sample  Now invoking the Follow the
Leader  Be the Leader Lemma  Lemma    Hazan et al 
  we get that for any  xed     

TXt 

lt     

lt xt 

TXt 

Therefore we can conclude that

TXt 
TXt 
TXt 

 

 

 lt xt    lt   

 

 lt xt    lt xt               

 lt xt    lt xt   

 
 

DR   DZ

 

where DZ   maxx   hZ  xi    minx   hZ  xi  Therefore we now need to bound the stability term lt xt   
lt xt  Now  the regret bound follows from the standard
analysis for the stability term in the FTRL scheme  see for
instance  Hazan et al    Notice that the bound only
depends on the change in the cumulative loss per step     

   Pt lt      for which the change is the loss vector  lt 

across time steps  Therefore we get that
      ltk 

lt xt    lt xt    max

       

 

Combining Equations       we get the regret bound
in Theorem  

  Regret Bounds for FTPL
In this section  we outline algorithms based on the Followthe PerturbedLeader template Kalai   Vempala   
FTPLbased algorithms ensure lowregret by perturbing the
cumulative sum of loss vectors with noise from   suitably chosen distribution  We show that the noise added in
the process of FTPL is suf cient to ensure differential privacy  More concretely  using the regret guarantees due to

  log  

 Abernethy et al    for the fullinformation setting 
we establish that the regret guarantees obtained scale as
  pT        
    While Theorem   is valid for all instances of online linear optimization and achieves   pT  
regret  it yields suboptimal dependence on the dimension
of the problem  The advantage of FTPLbased approaches
over FTRL is that FTPL performs linear optimization over
the decision set every round  which is possibly computationally less expensive than solving   convex program every round  as FTRL requires 

   ls 

Algorithm   FTPL Template for OLO            on the
action set     the loss set   
  Initialize an empty binary tree   to compute differentially private estimates ofPt
       Pdlog Te

independently from   

        ndlog Te

  Sample   

Choose xt   argminx Xhx   Lt   
Observe the loss vector lt      and suffer hlt  xti 
   Lt       TreeBasedAgg lt             

 
 
ni
  for       to   do
 
 
 
  end for

  

Theorem    FTPL  Online Linear Optimization  Let
kXk    supx   kxk  and kYk    suplt   kltk  Choosing     max kYk   TpN log  
log   log log  
    and
         IN   we have that RegretA          is
   
   
log  

 kXk kYk pT  

log    log

NkXk 

pN
 

 

 

 

Moreover the algorithm is  differentially private 

The proof of the theorem is deferred to the appendix 

  Differentially Private MultiArmed Bandits
In this section  we state our main results regarding bandit
linear optimization  the algorithms that achieve it and prove
the associated regret bounds  The following is our main
theorem concerning nonstochastic multiarmed bandits 
Theorem    Differentially Private MultiArmed Bandits  Fix loss vectors           lT   such that kltk     
When Algorithm   is run with parameters     LapN  
  and algorithm     Algorithm   with
where      
the following parameters       
       log      
     Np      log     and the exploration distribuO pN   log   log  

    The regret of the Algorithm   is

tion        

 

log  

 

Moreover  Algorithm   is  differentially private

The Price of Differential Privacy for Online Learning

Bandit Feedback  Reduction to the Nonprivate Setting
We begin by describing an algorithmic reduction that takes
as input   nonprivate bandit algorithm and translates it into
an  differentially private bandit algorithm  The reduction
works in   straightforward manner by adding the requisite
magnitude of Laplace noise to ensure differential privacy 
For the rest of this section  for ease of exposition we will
assume that both   and   are suf ciently large 

Algorithm            Reduction to the Nonprivate Setting for Bandit Feedback
Input  Online Algorithm    Noise Distribution   
  for       to   do
 
 
 
 
  end for

Receive  xt    from   and output  xt 
Receive   loss value hlt   xti from the adversary 
Sample Zt     
Forward hlt  xti   hZt   xti as input to   

Algorithm   EXP  with exploration  
Input  learning rate   mixing coef cient   distribution  

         

        

  for               do
 
 

     RN 
Let pt        qt     and play it   pt
Estimate loss vector lt by  lt      
  eiteT
Pt   Ei pt eieT
  

Update the exponential weights 

 

itlt  with

qt     

  hei ltiqt   

Pi    hei   ltiqt   

  end for

RN  

is in the set   

The following Lemma characterizes the conditions under
which Algorithm   is   differentially private
Lemma    Privacy Guarantees  Assume that each
loss vector lt
such that
maxt       hl xti
  xtk     For     LapN   where      
   
the sequence of outputs    xt            produced by the
Algorithm        is  differentially private 
The following lemma charaterizes the regret of Algorithm
 
In particular we show that the regret of Algorithm  
is  in expectation  same as that of the regret of the input
algorithm   on   perturbed version of loss vectors 
Lemma    Noisy Online Optimization  Consider   loss
sequence           lT   and   convex set     De ne   perturbed
version of the sequence as random vectors  lt           
as  lt   lt   Zt where Zt is   random vector such that
          Zt  are independent and   Zt      for all         
Let   be   full information  or bandit  online algorithm
which outputs   sequence  xt               and takes as

input  lt  respectively   lt   xti  at time    Let        be  
 xed point in the convex set  Then we have that

  Zt EA  TXt 
 hlt   xti   hlt      
    Zt EA  TXt   lt xti     lt      

We provide the proof of Lemma   and defer the proof of
Lemma   to the Appendix Section   

Proof of Lemma   Consider   pair of sequence of loss
vectors that differ at exactly one time step   say    
          lt          lT   and                             lT   Since
the prediction of produced by the algorithm at time step
any time   can only depend on the loss vectors in the past
          lt  it is clear that the distribution of the output
of the algorithm for the  rst    rounds            xt  is unaltered  We claim that         it holds that

  hlt    Zt   xt              hl      Zt   xt       

Before we justify the claim  let us see how this implies that
desired statement  To see this  note that conditioned on the
value fed to the inner algorithm   at time    the distribution of all outputs produced by the algorithm are completely determined since the feedback to the algorithm at
other time steps  discounting    stays the same  in distribution  By the above discussion  it is suf cient to demonstrate  differential privacy for each input fed  as feedback 
to the algorithm   
For the sake of analysis  de ne lF ict
as follows  If  xt    
de ne lF ict
  RN to be such
 
if and only if     argmaxi   xi 
that  lF ict
and   otherwise  where argmax breaks ties arbitrarily  De 
 ne  lF ict
  Zt  Now note that   lF ict
  lF ict
   xti  
hlt  xti   hZt   xti 
It suf ces to establish that each  lF ict
is  differentially
private  To argue for this  note that Laplace mechanism
 Dwork et al      ensures the same  since the    norm
of  lF ict

      RN  Else  de ne lF ict
     hlt   xti xi

is bounded by   

 

 

 

 

 

 

 

 

  Proof of Theorem  
Privacy  Note that since maxt       hl xti
  xtk    kYk     
as  xt   ei            Therefore by Lemma   setting
     
Regret Analysis  For the purpose of analysis we de ne the
following pseudo loss vectors 

  is suf cient to ensure  differential privacy 

 lt   lt   Zt

The Price of Differential Privacy for Online Learning

where by de nition Zt   LapN   The following follows
from Fact    proved in the appendix 

  kZtk 

      log         

 
   

Taking   union bound  we have

    kZtk 

      log         

 
 

 

To bound the norm of the loss we de ne the event    
      log       We have from   that
     kZtk 
         

    We now have that

  Regret      Regret                Regret    

Since the regret is always bounded by   we get that the
second term above is at most   Therefore we will concern
ourselves with bounding the  rst term above  Note that
Zt remains independent and symmetric even when conditioned on the event      Moreover the following statements
also hold 

     Zt          
           log     

     kZtk 

 
 

Equation   follows by noting that Zt remains symmetric around the origin even after conditioning  It can now
be seen that Lemma   still applies even when the noise
is sampled from LapN   conditioned under the event   
 due to Equation   Therefore we have that

   

  Regret           Zt EA  TXt   lt   xti     lt      

 
To bound the above quantity we make use of the following
lemma which is   specialization of Theorem   in  Bubeck
et al      to the case of multiarmed bandits 
Lemma    Regret Guarantee for Algorithm   If   is
such that  hei   lti      we have that the regret of Algorithm   is bounded by
pt   hei   lti 
Now note that due to the conditioning kZtk 
  log      and therefore we have that

     Xt Xi

Regret       

   

log  

 

maxt     hZt  xi      log     

It can be seen that the condition  hei   lti      in Theorem
  is satis ed for exploration        
  and under the
condition    as long as

         log          

which holds by the choice of these parameters  Finally

  Regret      

    Zt EA  TXt   lt   xti     lt      
   
   
    Zt  log  
         
    Zt  log  
         
    kZtk 

TXt 
Nk ltk 
TXt 

             log             

   kltk 

log  

   

   

 

 

 

 

   

    qT   log         log       
    pN   log   log  

 

 

  Differentially Private Bandit Linear Optimization
In this section we prove   general result about bandit linear
optimization over general convex sets  the proof of which
is deferred to the appendix 
Theorem    Bandit Linear Optimization  Let    RN
be   convex set  Fix loss vectors           lT   such that
maxt      hlt  xi       We have that Algorithm   when
run with parameters     LapN    with     kYk 
 
and algorithm     SCRiBLe Abernethy et al   
with step parameter      
  we have
the following guarantees that the regret of the algorithm is
bounded by
  pT log TsN       

 kYk 
NkXk 
 

          NkXk 

 

  log  

 

 

where   is the selfconcordance parameter of the convex
body     Moreover the algorithm is  differentially private 
  Conclusion
In this work  we demonstrate that ensuring differential privacy leads to only   constant additive increase in the incurred regret for online linear optimization in the full feedback setting  We also show nearly optimal bounds  in terms
of    in the bandit feedback setting  Multiple avenues for
future research arise  including extending our bandit results to other challenging partialinformation models such
as semibandit  combinatorial bandit and contextual bandits  Another important unresolved question is whether it
is possible to achieve an additive separation in     in the
adversarial bandit setting 

The Price of Differential Privacy for Online Learning

Jain  Prateek  Kothari  Pravesh  and Thakurta  Abhradeep 
In COLT  vol 

Differentially private online learning 
ume   pp     

Kalai  Adam and Vempala  Santosh  Ef cient algorithms
for online decision problems  Journal of Computer and
System Sciences     

ShalevShwartz  Shai  Online learning and online convex optimization  Foundations and Trends in Machine
Learning     

Smith  Adam and Thakurta  Abhradeep Guha 

 nearly 
optimal algorithms for private online learning in fullinformation and bandit settings  In Advances in Neural
Information Processing Systems  pp     

Tossou  Aristide and Dimitrakakis  Christos  Algorithms
for differentially private multiarmed bandits  In AAAI
   

Tossou  Aristide       and Dimitrakakis  Christos  Achieving privacy in the adversarial multiarmed bandit 
In
 th International Conference on Arti cial Intelligence
 AAAI    

References
Abernethy  Jacob  Hazan  Elad  and Rakhlin  Alexander 
Competing in the dark  An ef cient algorithm for bandit
linear optimization  In COLT  pp     

Abernethy  Jacob  Lee  Chansoo  Sinha  Abhinav  and
Tewari  Ambuj  Online linear optimization via smoothing  In COLT  pp     

Abernethy  Jacob    Hazan  Elad  and Rakhlin  Alexander  Interiorpoint methods for fullinformation and bandit online learning  IEEE Transactions on Information
Theory     

Auer  Peter  CesaBianchi  Nicolo  Freund  Yoav  and
Schapire  Robert    The nonstochastic multiarmed bandit problem  SIAM journal on computing   
 

Bubeck    ebastien  CesaBianchi  Nicolo  Kakade 
and
Sham    Mannor  Shie  Srebro  Nathan 
Williamson  Robert   
Towards minimax policies
for online linear optimization with bandit feedback  In
COLT  volume      

Bubeck    ebastien  CesaBianchi  Nicolo  et al  Regret
analysis of stochastic and nonstochastic multiarmed
bandit problems  Foundations and Trends    in Machine
Learning       

Dwork  Cynthia  McSherry  Frank  Nissim  Kobbi  and
Smith  Adam  Calibrating noise to sensitivity in private
data analysis 
In Theory of Cryptography Conference 
pp    Springer   

Dwork  Cynthia  Naor  Moni  Pitassi  Toniann  and Rothblum  Guy    Differential privacy under continual observation  In Proceedings of the fortysecond ACM symposium on Theory of computing  pp    ACM   
Dwork  Cynthia  Roth  Aaron  et al  The algorithmic
foundations of differential privacy  Foundations and
Trends    in Theoretical Computer Science   
     

Dwork  Cynthia  Talwar  Kunal  Thakurta  Abhradeep  and
Zhang  Li  Analyze gauss  optimal bounds for privacypreserving principal component analysis  In Proceedings
of the  th Annual ACM Symposium on Theory of Computing  pp    ACM     

Hazan  Elad et al  Introduction to online convex optimization  Foundations and Trends    in Optimization   
   

Jain  Prateek and Thakurta  Abhradeep     near  dimension
independent risk bounds for differentially private learning  In Proceedings of the  st International Conference
on Machine Learning  ICML  pp     

