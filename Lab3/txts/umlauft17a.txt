Learning Stable Stochastic Nonlinear Dynamical Systems

Jonas Umlauft   Sandra Hirche  

Abstract

  datadriven identi cation of dynamical systems requiring only minimal prior knowledge
is promising whenever no analytically derived
model structure is available       from  rst principles in physics  However  metaknowledge on
the system   behavior is often given and should
be exploited  Stability as fundamental property
is essential when the model is used for controller
design or movement generation  Therefore  this
paper proposes   framework for learning stable stochastic systems from data  We focus on
identifying   statedependent coef cient form of
the nonlinear stochastic model which is globally
asymptotically stable according to probabilistic
Lyapunov methods  We compare our approach
to other state of the art methods on realworld
datasets in terms of  exibility and stability 

  Introduction
An accurate identi cation of the system dynamics is the
 rst and very crucial step to many modern control methods 
Although reinforcement learning also allows modelfree
search for optimal policies  it is known to be less ef cient
and dif cult to analyze  Therefore  classical control engineers employ system identi cation techniques to obtain
parametric model descriptions of dynamical systems from
observation data       in the linear case ARX and ARMAX
models  The identi cation focuses on model selection      
 nding the model structure and the corresponding set of parameters  But often this set of model candidates is dif cult
to  nd  especially for complex  possibly nondeterministic 
systems  Ljung    Therefore  the need for datadriven
models has emerged recently as control engineering is increasingly applied in areas without analytic description of
the dynamical system  We consider the following two application scenarios  First  assume   set of trajectories for  

 Chair of Informationoriented Control  Technical University
of Munich  Munich  Germany  Correspondence to  Jonas Umlauft  jonas umlauft tum de 

Proceedings of the  th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

robotic task is given through human demonstrations      
object grasping  The goal is to represent the motion with  
dynamical system  To ensure the reproduction terminates
at the desired  nal point  object to grasp  we introduce the
stability constraint  Second  consider   dynamical system
which is known to be stable         pendulum which rests
in hanging position  The goal is to identify the dynamics
precisely without further physical insights 
Bayesian nonparametric methods  more particularly Gaussian Processes  GPs  where successfully employed by Kocijan et al    and Wang et al    for system identi cation  Other approaches focus on learning switching
linear systems  Fox et al    or employ an EM algorithm  Ghahramani   Roweis    for nonlinear systems 
However  these approaches neglect the prior assumption
that the dynamical system is stable  which becomes crucial when the learned model is used as   generative process such as in movement generation for robotics  Ijspeert
et al    If stability is not considered during learning 
the identi ed model suffers from spurious attractors which
are not part of the true dynamics or instability 
Only little work has merged the extensive knowledge on
stability theory from control engineering with the powerful
datadriven approaches for system identi cation  For example Boots et al    and Chiuso   Pillonetto  
take stability constraints for learning dynamical systems
into account but are limited to linear systems  The work
by KhansariZadeh   Billard   ensures stability of
the system by constraining the optimization of   Gaussian Mixture Model  GMM  to stability conditions derived
from Lyapunov methods  The work by Paraschos et al 
  relies on   phase variable to ensure stability  which
makes the approach timedependent and therefore less robust  Control Lyapunov functions are used by KhansariZadeh   Billard   to ensure global stability for the
learned system  These approaches partially employ probabilistic models  GP  GMM  but limit the analysis to the
deterministic part by only considering the mean regression 
By discarding the true underlying probability distribution 
information regarding reliability of the model provided by
the data is lost  This leads to overcon dent conclusions
regarding performance or safety on the real system 
Therefore  this work proposes   framework for learning

Stable Stochastic Nonlinear Dynamical Systems

probabilistic nonlinear dynamical systems from observation  which takes the prior assumption of stability into account  The required stochastic stability conditions of the
discretetime Markov processes are derived from Lyapunov
theory  We provide simulation results to validate the proposed approach and compare it to previously mentioned
methods for identifying dynamical systems 

  Problem Formulation
We consider an autonomous  dynamical  discretetime system with continuousvalued state xk       Rd  The state
evolves according to an unknown stochastic process 

This also implies the following type of convergence  which
might be more intuitive to the reader 
De nition    Convergence in probability  The chain  xk 
converges to the origin in probability if   cid xk cid         
for each      

We do not consider any control input here  thus the identi 
cation takes place for the closedloop system for   existing
controller or an uncontrolled system 

  Stability Conditions for the Model
  The Model

xk        xk     

 

Consider the statedependent coef cient form of    

with initial value        and    is   random variable from
the probability space       with sample space   the
corresponding  algebra   and the probability measure   
Since xk     is  xed at each step    describes   state dependent distribution over xk    realization of        is
drawn at every time step  yielding   realization of the next
step  As the distribution for xk  only depends on the state
at time step       is   Markov process  denoted by  xk 
We assume that consecutive measurements of the state are
available  thus   data pairs are given in the trainings set
   Based on these measurements  we
     xn   xn  
model the unknown dynamics    including the distribution    using the prior knowledge  that the stochastic process   converges to the origin xk     The model consists of the mapping     and   encoding of the random variable   de ned by    nite parameter vector       As the
model     must best possibly explain the data    the problem is formulated as constrained likelihood maximization

  cid 

  

 cid xn xn     

 cid   

    arg max

 

log  

      xk  converges to the origin for      

As different stochastic stability concepts exist  the convergence in     is de ned as convergence with probability one
       Kushner   
De nition    Convergence       xk  converges to the
origin      if  for each        cid xk cid      only  nitely often 
 Notation  Bold symbols denote vectors or multivariate functions  capital letters matrices and Ip the       identity matrix     cid    denotes positive de niteness of the matrix   
    the expected value      the variance of   random variable
and     the covariance between two random variables  where
                    denotes   realization of the random variable
  
Imitating Matlab indexing       denotes the ith column 
     the jth row and      the  rst and second element in the
ithe column of    The ith entry of the vector xk is denoted xk   

   

   

xk      xk xk 

 

where  for    xed xk    is   random variable from the probability space    FA PA  with the sample space     
Rd    The probability density function of   is speci ed
by the vector       which is state dependent through
          This mapping is itself parametrized by  
vector   At each step    realization of    denoted by    
is drawn and multiplied by the state xk to proceed by one
step  This is visualized in Figure   along with the twolayer
model structure  The  rst layer maps current state xk    
onto the parameter       denoted by           The
mapping is parametrized by   The second layer is the
probability distribution on   which assigns to each element
in the sample space      probability based on  

Figure   Illustration of the two layer design of the proposed
model and the process of simulation 

To illustrate this multilayer design  we give   brief example
in the scalar case       Assume   xk  follows  for  
given xk    Gaussian distribution           Therefore 
 cid 
the parameter vector is         
with              
thus             The dependency of these parameters
on the current state xk is expressed in  
 

      

   

   xk   

 

 

 cid xk 

 cid 

 xk 

 cid wxk

 cid 

zx 
 

   xk   FA PA Axk xk samplexk       ModelSimulationStable Stochastic Nonlinear Dynamical Systems

where linear dependency of the mean on the state and  
quadratic relation between variance and the state is as 
 cid 
sumed  The parameters de ning  
 
here are          
 
Generally  the  rst layer           can be any state of
the art parametric regression method which is parametrized
by   For layer two  any probability distribution with  
 xed set of parameters is applicable for   
Leaving the stochastic aspect aside  model   is the statedependent coef cient  SDC  form which is reached by factorizing   nonlinear system into   linearlike structure  It
was shown  that for   any continuous differentiable function   with         their exists   matrixvalued function
     such that                see Cimen   Thus 
the SDC form is not limiting the expressive power of our
model  It also re ects the setup of many realworld system 
     consider an actuator whose output is generally noisy
and the magnitude of the noise is dependent on the temperature  By modeling the temperature as   state  the model  
allows to capture this varying precision of the actuator 
The structure of the model   combines two important criteria  First  it provides more  exibility than   linear system with random parameters  so it encodes also nonlinear
dynamics Second  it is simple enough to allow   quadratic
Lyapunov function analysis and therefore the derivation of
analytic constraints for convergence as needed for the optimization in  

  Stability Analysis

For approaching the problem as formulated in Section  
an analytic condition for the constraint in the optimization
problem     given that     is of the form   is needed 
The literature on stability criteria for dynamical systems is
very rich and for nonlinear systems Lyapunov type methods are often used  They are based on the following idea 
If there is   function representing the  energy  in the system  called Lyapunov function  which constantly decreases
over time  the state will converge to    zero energy  state 
the origin  More precise  the Lyapunov function must be
positive de nite and it must be strictly decreasing over
time  except in the origin  Using the stochastic discretetime version of Lyapunov methods and the BorelCantelli
Lemma leads to the following conditions for exponential
stability  which implies convergence      as de ned in
De nition  

Theorem    Exponential Stability 
Given   positive de nite function    xk      for which

 Kushner   

      xk xk    xk        xk   xk        
 

for any         
Proof  Considering
   xk     
Theorem   in   is given as

 cid 
kP xk with    cid   

 

 cid 

 cid 
    xk xk 

 cid 
  
kP xk     

 cid 
kP xk 

which yields for the stochastic  process xk      xk xk

  cid  

 cid 
      

 cid 

 

for some       then

      xk   xk         mV  xk  and
   xk        for            

 
 

For the class of systems in     quadratic function    xk 
is   proper Lyapunov function to derive suf cient stability
constraints for arbitrary distributions on   as shown in the
following proposition 
Proposition    Stability of the model   Consider  
stochastic process generated from   where in each step  
realization of   is drawn from sample space      Rd   
The process is globally exponentially stable at xk     if
there exists      cid    such that
    

 xk         xk               cid     xk      
 

 cid 

for some       where   is de ned as

       cid     xk        xk cid 

 

      xk   

 cid 

 

quadratic Lyapunov

function
the inequality from

 
 xk      

Now  an expression for the trace is derived as follows

Tr       Axk    Tr

 

          xk   Tr       Axk 

 cid 
        
kP xk    

   

    xk  

 cid cid 

 cid cid 
 cid 
 cid 
xk ixk     cid          
 cid  xk ixk       
 cid 

  
 cid 
 cid 
       cid            
 cid   cid 
                         

     

   

xk    

  Tr

 

 cid 
 

 

 cid 
kQxk

where de nition of   in   was substituted  Using this
simpli cation    is rewritten as

which must hold for  xk       To ensure this  the ma 
 cid 
trix      
                 must be negative semide nite  which concludes the proof 

 The xk dependency of the random process   as been dropped

for notational convenience 

Stable Stochastic Nonlinear Dynamical Systems

 cid 

The interpretation of Proposition   is analogue to the linear deterministic case xk    Axk which is stable if there
exists   matrix   for which  
            In the nonlinear case in   the negative de niteness must be ful lled
for   xk   xk       The probabilistic nature of the system   in addition requires    buffer  which here is   
The deterministic case is reconstructed if   has zero variance  The scalar case  considered in the following remark 
also allows an intuitive insight to the Proposition   There
is   tradeoff between the magnitude of the expected value
and the variance of   as follows 
Remark   In the scalar case             in   with
           xk  condition   simpli es for any       to

     xk         xk         

 xk      

 

  Stable Learning with Various Distributions
Our learning framework consists of three major steps 

  Chose any probability distribution for the random
variable   in   which is given by    xed set of parameters       and whose  rst two moments are
available 
It is assumed that subset       for
which   is ful lled is nonempty  thus    cid   

  Chose any parametric regression method to represent
the mapping           The parameters of this
mapping are denoted by       The set of all   for
which all xk     map to   is denoted by  
  The likelihood maximization under constraints

  cid 

  

 cid 

xn xn   cid 

 

 

    arg max
 

log  

is solved  where       is equivalent to constraint  
with    cid    and      

The optimization   is   general constrained nonlinear
program in   rather high dimensional space  depending on
number of parameters of the regression method in step  
However  independent of the optimality  the model     of
the form   is exponentially stable  thus any sample path
of the system converges  For computational simplicity  we
focus on two types of distribution which naturally ful ll the
constraints as explained in the next sections 

  Stability with Beta Distribution

For certain choices of distributions  constraint   is ful 
 lled for all possible parameter   thus       which

 Even though         are scalars here  we keep them capital 

ized for notational consistency 

makes the optimization unconstrained  One example of
such   distribution is the Beta distribution as given in the
following corollary 
Corollary   The scalar system xk      xk xk
where   xk         xk      with Beta distributed
   xk        xk    xk  and             with state
 cid 
dependent parameters    xk    xk 
   xk  with any
 
               
Proof  Applying the af ne transformation to mean and
 cid 
 cid 
variance leads to 
 cid 

   
  is exponentially stable 

 cid   

     xk     

      

 cid 
 cid 

   xk 

 cid 

 cid 

   

 

 

ab

     xk       

   xk 

 
   

                

 

Condition   is rewritten to
      xk           xk         
 xk      
choice
for   minimizes
where
the best possible
leaves the largest possi 
      xk  because it
ble range for   As       is in the interval     the
minimization is achieved with the choice      
  Then 
condition   divided by   on both sides  evaluates to

  

         

 

 cid 

 

 

ab

 

                
 
   

     
 

 

 

 

     
ab

 cid cid 

   
 

 
 

 cid 

                

As       can be chosen arbitrarily small this condition
holds for every       Hence  according to Theorem  
the system xk      xk xk is exponentially stable 

To ensure maximal  exibility of the model        is set
for further considerations  This leads to the conclusion that
  Therefore  in the optimization  no conB          
 
straints on   must be considered  thus      

  Stability with Dirichlet Distribution

Constructing   from   Dirichlet distribution also allows for
unconstrained optimization as it also leads to stable behavior as shown in the following corollary 
Corollary   The ddimensional system xk      xk xk
where each row of   xk  consists of the  rst   elements of
        dimensional Dirichlet distributed vector  thus 

 cid 

 cid 

           

    with         
               
              is asymptotically stable     
 The state dependency of      is dropped for notational conve 

  
   xk 

 

with any   

nience 

Stable Stochastic Nonlinear Dynamical Systems

Proof  By construction the sample space of       contains
only elements for which

                     

and

          

  cid 

  

                 
               

 

Consider now   realization of   xk  denoted by    and
since the following statements hold for any realization in
the sample space  we omit writing            It follows

                 max

   

           

   cid     cid    max

   

             

  cid 

  

  cid 

  

  cid 

  

where the last inequality holds because all elements of   
are strictly positive and  cid     cid  denotes the Maximum Absolute Row Sum Norm  Consider now   consecutive realizations       with                  For the maximum norm
of state in the Mth step holds

 cid cid cid cid cid    cid 
 cid 

  

 cid cid cid cid cid 
 cid cid cid       cid cid cid 

 

 cid cid cid       cid cid cid 

  cid 
 cid  

  

     xk

 

 

 

max

 

 

 cid xk cid 

 cid xk   cid 

   cid xk cid 
    
where the submultiplicativity property of induced matrices
 Horn   Johnson    is used  As convergence towards
the origin holds for each element in the sample space  the
system is stable with probability one  Therefore  the parameter space is unrestricted  
Remark   Note that this approach only allows to represent the special class of positive systems  Nevertheless 
positive systems play an important role in control engineering for modeling the evolution of strictly positive quantities
as shown in  Farina   Rinaldi   
Remark   An af ne transformation  as shown for
Beta distribution is not possible here because absolute values are taken in the row sum 
Thereconclude
cannot
fore 

 cid  
                     for any      

from  cid  

                 one

         Rd 
   

  Simulations
  Setup
We validate our approach  labeled LeSSS  for Learning
Stable Stochastic Systems  using synthetic and human motion data and the simulation of   chemical reactor  For
the Beta distribution  Gaussian Mixture Regression  GMR 

Figure   Comparison of true and inferred xk dependent variance
 top  and mean  bottom  function 

   

is used for the mapping from the state to the parameters
             Thus  the parameter vector   is the concatenation of the prior     the means    and the covariances
   for                 The code  based on Calinon  
includes kmeans clustering initialization and   transformation of    and    to make it an unconstrained optimization 
To evaluate the likelihood function for each training point
 xn   xn  the Beta distribution parameters are computed
 cid 
   xn  using GMR  Then  the log likelihood
 an bn 
of  An    xn xn given the parameters  an bn  is evaluated using the density function of the Beta distribution  As
 cid 
  lead to stability 
all possible parameter           
 nding   is an unconstrained optimization problem 
For the Dirichlet distribution  the mapping from the state
to the parameters  
           uses   nearest neighbor
approach for computational simplicity  The        closest
data points are considered for  tting the training parameters of the Dirichlet distribution locally  Then   training
point is placed at the center of these four points  At reproduction  the closest such training point and its Dirichlet
parameters are taken for regression  This does not necessarily maximize the likelihood  but shows accurate results for
reproduction  We compare the following models from literature regarding reproduction precision and convergence
properties 

    

  The approach introduced by Boots et al   
learns stable linear dynamical system  stable LDS 
from data 
It constraints the search of the deterministic dynamic matrix   to ensure the stability

         xk inferredV   xk true xk       TrainingDataE   xk inferredE   xk trueStable Stochastic Nonlinear Dynamical Systems

of xk    Axk 

  Gaussian Process Dynamical Models  GPDM   Wang
et al    represent dynamical system in the general form xk       xk  with Gaussian Process
    GP    xk    cid    We employ   zero prior mean
function and   squared exponential kernel  The hyperparameters of the kernel are optimized using the likelihood as described by Rasmussen   Williams  
In reproduction  this method can either be used in deterministic setting by only taking the posterior mean
prediction  GP xk  thus xk     GP xk  or the
stochastic setting xk       GP xk   GP xk 
where  GP xk  is the posterior variance  GPDMs are
bounded  Beckers   Hirche        but not stable 
  The Stable Estimator of Dynamical Systems  SEDS 
as introduced by KhansariZadeh   Billard  
constraints the likelihood optimization of GMR parameters to   class of mean stable dynamical timeThe GMR maps from curcontinuous systems 
rent state   to the time derivative    
focuses on deterministic systems by only considering stability criteria for the mean prediction of the
GMR   GMM    while ignoring the stochastic nature of GMMs   its variance prediction  GMM  We
also run this method in   stochastic setting  where
        GMM     GMM    For our simulations 
 ve mixtures are employed 

It

Figure   The inferred mean and variance function for the training
set of the projected Zshape movement are shown along with the
training data  the realizations of the random variable    

Before starting the comparison to existing approaches 
LeSSS is demonstrated on   synthetic dataset 

  Simulation   Synthetic Data

Figure   Comparison of simulations for        for stable
LDS and the mean predictions from the models GPDM  SEDS
and LeSSS 

For the  rst simulation  the task is to identify the stable
nonlinear stochastic system given by

 cid xk      xk    cid   

 

xk      xk xk 

where   xk     

           

The learning algorithm is given   training points
   equally spaced in the state space interval
 xn   xn 
    which are drawn from the state dependent Beta distribution   Here       was chosen for the number of
mixtures in the GMR for the mapping  
Figure   compares the mean and variance of the original
system   to the one inferred by our model 
It clearly
shows that the model offers suf cient  exibility to reconstruct the original system  Note  It is also possible to verify
the parameter functions   xk    xk  as given in   but
we directly look at the mean and variance functions as there
exists   unique mapping and it is more intuitive for interpretation  It must be omitted  that the data was generated
from the same model which the algorithm is learning  This

explains the good  tting  but is of course not often the case
in practical application  Therefore  we continue with   real
world dataset in the following 

  Simulation   Human Motion Data

For the next simulation  we use the data set for lettershaped motions provided by KhansariZadeh   Billard
  The   trainings points of   trajectories of the two
dimensional Zshaped motion are projected on the yaxis 
The GMR for  
           is trained with two mixtures 
Figure   shows the training data along with the    of the
mean and variance functions  The mean function shows  
smoothed estimate of the training data  The model identi es properly that the training data has higher variability
 around xk     and captures this in its variance function 
Figure   compares the reproduction of the models stable
LDS  GPDM  SEDS and LeSSS if taking the deterministic
 mean  output of each model  all starting from the same

 xk       TrainingDataE   xk inferredV   xk inferred     kxkTrainingDatastableLDSGPDMSEDSLeSSSStable Stochastic Nonlinear Dynamical Systems

Figure   Comparison of simulations for        with the
stochastic models of GPDM  SEDS and LeSSS 

initial point  The stable LDS approach leads to   converging trajectory  but fails to capture the complexity of the
dynamic  as the true dynamic is nonlinear  The GPDM
converges to   spurious attractor at       which is
undesired but not surprising  SEDS and LeSSS both lead
to asymptotic stable reproductions of the movement  Since
the data does not contain the full state  due to the projection
on the yaxis  it is not possible to reproduce the movement
precisely with   dynamical system model 
Figure   compares the reproduction of the three stochastic
dynamical models GPDM  SEDS and LeSSS based on three
sample paths drawn from each model  The GPDM again
converges to the spurious attractor  SEDS clearly shows
that convergence of the mean is not suf cient for converging trajectories of   stochastic system  as the drawn sample paths are strongly oscillating around the origin without
In the stochastic case only LeSSS
tendency to converge 
generates converging trajectories 
Figure   shows an example for the human motion imitation
in the    case on   different training data set 
It shows
the deterministic trajectory and   sample path realizations 
where all of them show high reproduction precision and
convergence to the orign 

  Simulation   Chemical Reactor Simulation

For the last validation  we utilize simulated data from  
simpli ed chemical reactor  Einarsson    The closedloop reactor is modeled by   piecewise af ne system with
two states  the  uid level    and the temperature    Both
states are physically positive quantities  therefore the approach in Section   is suitable  The switching between
different dynamic matrices is state dependent and occurs
at        and        which corresponds to   discrete
change of the control inputs  The training data consists of  
trajectories of   steps each  which are pairwise initialized
at the   different regions of the dynamics and perturbed

Figure      simulation for human motion data set with LeSSS 

Error stable 
deterministic

stochastic

stable LDS GPDM
 no
 no

 yes

   

SEDS
 yes
 no

LeSSS
 yes
 yes

Table   Comparison of the reproduction error in terms of area
between each demonstration and its corresponding reproduction
for the stochastic and deterministic case for the chemical reactor
simulation  The area is computed for each of the   initial points
separately and cumulated for each of the approaches  It also indicates which models are stable 

with white noise with       for both states 
Figure   shows the training data along with the reproduction using stable LDS  GPDM  SEDS and LeSSS in the deterministic setting  The initial points in the test case were
set close to the one in the training data  The stable LDS is
not capable to capture the varying behavior in the different
regions of the piecewise af ne system and therefore fails in
accuracy of the reproduction  GPDM leads again to convergence outside the origin  which is undesirable  SEDS and
LeSSS are both converging as it is enforced by design  Figure   shows that similar to the    case GPDM and SEDS
fail to converge in the stochastic case while LeSSS is stable in all sample paths  Table   compares the methods
with regard to the reproduction precision quantitatively  It
shows that LeSSS outperforms other methods in this measure while providing the necessary guarantees regarding
convergence 

  Discussion

The simulations show that LeSSS is powerful enough to
represent various nonlinear dynamics  while capturing the
probabilistic nature of the process  The incorporation of
the prior knowledge on goal convergence ensures that the
learned model is stable in probability 
The computational complexity for learning the parameters
of the model using interiorpoint methods  is mainly determined by the employed mapping in the  rst layer   The

 NoconvergencetooriginOscillationbutnoconvergencekxkTrainingDataGPDMSEDSLeSSS     TrainingDataDeterministicStochasticStable Stochastic Nonlinear Dynamical Systems

Figure   Training data  black  of chemical reactor and the deterministic simulation for stable LDS  GPDM  SEDS and LeSSS approach 

Figure   Training data  black  of chemical reactor and the stochastic simulation for GPDM  SEDS and LeSSS approach 

Simulation  
Time
Simulation  
Time

LDS
  
LDS
  

GPDM SEDS
  
  
GPDM SEDS
  
  

LeSSS
  
LeSSS
  

Table   Computation times for model learning and simulation for
all compared approaches 

computation times on      CPU  GHz    Cores and  GB
RAM are given for Simulation   and   in Table   Since the
GPDM  SEDS and LeSSS all solve nonconvex optimization problems  their commutation times are in the same order of magnitude  The linear model has advantage here 
Regarding the scalability with more training points  the parameter  tting performs similarly to other approaches requiring likelihood computation since this is the major factor  However  the scalability strongly depends on the employed distribution and the mapping in the  rst layer  
This work only deals with system with   single equilibrium
point  but could be extended to system with more complex attractor dynamics  However  further knowledge is
required because   in addition to the position of all equilibrium points   their regions of attraction must be known 

  Conclusion
This work proposes   framework for learning nonlinear stable stochastic dynamical systems from data  We introduce
   exible model  which builds on the statedependent coef cient form and derive exponential stability conditions
based on stochastic Lyapunov methods  The criteria is applicable to various probability distributions  while we focus
to investigate the application to Beta and Dirichlet distributions  Simulation results verify suf cient  exibility of the
model and the correct identi cation of the system   uncertainty  In comparison to existing approaches it showed advantages in reproduction precision and convergence properties on human motion data and simulated data from   real
system 

Acknowledgment
The research leading to these results has received funding
from the European Research Council under the European
Union Seventh Framework Program  FP  ERC
Starting Grant  Control based on Human Models  conhumo  agreement number   We also would like
to thank the reviewers for very constructive feedback 

 Reproductionveryimprecisex uidlevelx temperaturestableLDS Noconvergencetooriginx uidlevelGPDM Reproductionveryimprecisex uidlevelSEDS Precisereproductionandconvergencex uidlevelLeSSS Noconvergencetooriginx uidlevelx temperatureGPDM Oscillationhindersconvergencex uidlevelSEDS Precisereproductionandconvergencex uidlevelLeSSSStable Stochastic Nonlinear Dynamical Systems

References
Beckers  Thomas and Hirche  Sandra  Equilibrium distributions and stability analysis of Gaussian process state
space models  In Conference on Decision and Control
 CDC  pp       

Beckers  Thomas and Hirche  Sandra  Stability of GausIn European Control

sian process state space models 
Conference  pp       

Boots  Byron  Gordon  Geoffrey    and Siddiqi  Sajid     
constraint generation approach to learning stable linear
dynamical systems  In Advances in Neural Information
Processing Systems  NIPS  pp    Curran Associates  Inc   

Calinon  Sylvain  Robot Programming by Demonstration 

  Probabilistic Approach  EPFL CRC Press   

Chiuso  Alessandro and Pillonetto  Gianluigi  Learning
sparse dynamic linear systems using stable spline kernels and exponential hyperpriors  In Advances in Neural
Information Processing Systems  NIPS  pp   
Curran Associates  Inc   

Cimen  Tayfun  Statedependent Riccati equation  SDRE 
IFAC Proceedings Volumes   

control    survey 
   

Einarsson  Valur  On Veri cation of Switched Systems using Abstractions  PhD thesis  Linkoping University  Automatic Control  The Institute of Technology   

Farina  Lorenzo and Rinaldi  Sergio  Positive linear systems  Theory and applications  John Wiley Sons   
Fox  Emily  Sudderth  Erik    Jordan  Michael    and
Willsky  Alan    Nonparametric Bayesian learning
In Advances
of switching linear dynamical systems 
in Neural Information Processing Systems  NIPS  pp 
  Curran Associates  Inc   

Ghahramani  Zoubin and Roweis  Sam    Learning nonlinear dynamical systems using an EM algorithm 
In
Advances in Neural Information Processing Systems
 NIPS  pp    MIT Press   

Horn  Roger    and Johnson  Charles    Matrix analysis 

Cambridge Univ  Press  Cambridge   

Ijspeert  Auke Jan  Nakanishi  Jun  and Schaal  Stefan 
Movement imitation with nonlinear dynamical systems
In International Conference on
in humanoid robots 
Robotics and Automation  ICRA  IEEE   

KhansariZadeh  Seyed Mohammad and Billard  Aude 
Learning stable nonlinear dynamical systems with Gaussian mixture models  IEEE Transactions on Robotics   
   

KhansariZadeh  Seyed Mohammad and Billard  Aude 
Learning control Lyapunov function to ensure stability of dynamical systembased robot reaching motions  Robotics and Autonomous Systems   
   

Kocijan     Girard     Banko     and MurraySmith 
   Dynamic systems identi cation with Gaussian processes  Mathematical and Computer Modelling of Dynamical Systems       

Kushner  Harold Joseph  Introduction to stochastic control 

Holt  Rinehart and Winston New York   

Ljung  Lennart  System Identi cation  Prentice Hall PTR 

NJ  USA   

Paraschos  Alexandros  Daniel  Christian  Peters  Jan  and
Neumann  Gerhard  Probabilistic movement primitives 
In Advances in Neural Information Processing Systems
 NIPS  pp     

Rasmussen  Carl Edward and Williams  Christopher KI 
Gaussian Processes for Machine Learning  MIT Press 
Cambridge  MA  USA  January  

Wang  Jack    Fleet  David    and Hertzmann  Aaron 
In Advances
Gaussian process dynamical models 
in Neural Information Processing Systems  NIPS  pp 
   

