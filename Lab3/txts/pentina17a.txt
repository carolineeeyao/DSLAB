Multitask Learning with Labeled and Unlabeled Tasks

Anastasia Pentina   Christoph    Lampert  

Abstract

In multitask learning    learner is given   collection of prediction tasks and needs to solve all
of them  In contrast to previous work  which required that annotated training data is available for
all tasks  we consider   new setting  in which for
some tasks  potentially most of them  only unlabeled training data is provided  Consequently 
to solve all tasks  information must be transferred between tasks with labels and tasks without labels  Focusing on an instancebased transfer method we analyze two variants of this setting  when the set of labeled tasks is  xed  and
when it can be actively selected by the learner 
We state and prove   generalization bound that
covers both scenarios and derive from it an algorithm for making the choice of labeled tasks
 in the active case  and for transferring information between the tasks in   principled way  We
also illustrate the effectiveness of the algorithm
by experiments on synthetic and real data 

  Introduction
In the multitask learning setting  Caruana      learner
is given   collection of prediction tasks that all need to be
solved  The hope is that the overall prediction quality can
be improved by processing the tasks jointly and sharing information between them  Indeed  theoretical as well as experimental studies have shown that information transfer can
reduce the amount of annotated examples per task needed
to achieve good performance under various assumptions on
how the learning tasks are related 
All existing multitask learning approaches have in common  however  that they need at least some labeled training
data for every task of interest  In this paper  we study  
new and more challenging setting  in which for   subset of
the tasks  typically the large majority  only unlabeled data

 IST Austria 

 apentina ist ac at 

Correspondence to  Anastasia Pentina

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

is available  In practice  it is highly desirable to be able to
handle this situation for problems with   very large number
of tasks  such as sentiment analysis for market studies  for
different products different attributes matter and  thus  each
product should be have its own predictor and forms its own
learning task  At the same time annotating data for each
such task is prohibitive  especially when new products are
constantly added to the market  Another example are prediction problems  for which the  xed cost of obtaining any
labels for   task can be high  even when the variable cost
per label are reasonable  This is   wellknown issue when
using crowd sourcing for data annotation  recruiting and
training annotators  rst imposes   large overhead  and only
afterwards many labels can be obtained within   short time
and at   low cost 
  distinctive feature of the setting we study is that it requires two types of information transfer  between the labeled tasks and from labeled to unlabeled ones  While the
 rst type is common in multitask learning  none of the existing multitask methods is able to handle the second type 
In contrast  information transfer from labeled to unlabeled
tasks is commonly studied in domain adaptation research 
where  however  transfer of the  rst type is typically not
considered  Thus  the setting of multitask learning with
labeled and unlabeled tasks can be seen as   blend of traditional multitask learning and domain adaptation 
In this work we focus on   transfer method that learns  
predictor for every task of interest by minimizing   taskspeci   convex combination of training errors on the labeled tasks  BenDavid et al    Mansour et al   
We choose this method because it allows us to capture both
types of information transfer   between the labeled tasks
and from labeled to unlabeled ones   in   uni ed fashion 
Clearly  the success of this approach depends on the choice
of the weights in the convex combinations  Moreover  one
can expect it also to depend on the subset of labeled tasks
as well  because some subsets of tasks might be more informative and representative than the others  This suggests
that it will be bene cial if the labeled subset is not arbitrary
but if it can be chosen in   datadependent way  We refer
to this learning scenario  where initially every task is represented only by   set of unlabeled examples and the learner
can choose for which tasks to request some labels  as active
task selection 

Multitask Learning with Labeled and Unlabeled Tasks

Our main result is   generalization bound that quanti es
both of the aforementioned effects  it relates the total multitask error to quantities that depend on the subset of labeled
tasks and on the taskspeci   weights used for information
transfer  Using the computable quantities in the bound as
an objective function and minimizing it numerically  we
obtain   principled algorithm for selecting which tasks to
have labeled  in the active task selection scenario  and for
choosing taskspeci   weights and predictors for all tasks 
labeled as well as unlabeled  We highlight the practical usefulness of the derived method by experiments on synthetic
and real data 
The success of any information transfer approach  regardless whether it is applied in the multitask or the domain
adaptation scenario  depends on the relatedness between
tasks of interest  Indeed  one cannot expect to bene   from
information transfer between the labeled tasks or to be able
to obtain solutions of reasonable quality for the unlabeled
ones if the given tasks are completely unrelated  An advantage of the method we propose is that from the associated generalization bound we can read off explicitly under
which conditions the algorithm can be expected to succeed 
In particular  it suggests that the proposed method is likely
to succeed if the given set of tasks satis es the following
assumption of task smoothness  if two tasks are similar in
their marginal distributions  then their optimal prediction
functions are also likely to be similar    more formal definition will be given in Section   The task smoothness
assumption resembles the classical smoothness assumption
of semisupervised learning  Chapelle et al    It can
be expected to hold in many realworld settings with   large
number of tasks  for example in the aforementioned case
of sentiment analysis 
if two products are described using similar words  these words would likely have similar
connotation for both products  Note  also  that   similar
assumption appears implicitly in  Blanchard et al   

  Related Work

Most existing multitask learning methods work in the
fully supervised setting and aim at improving the overall prediction quality by sharing information between the
tasks  For this they employ different types of transfer 
instancetransfer methods reuse training samples from
different tasks  Crammer   Mansour    parametertransfer methods assume that the predictors for all tasks
are similar to each other in some norm and exploit this fact
through speci   regularizers  Evgeniou   Pontil   
representationtransfer approaches assume that the predictors for all tasks share   common  lowdimensional  representation that can be learned from the data  Argyriou
et al      Followup works extended and generalized these concepts       by learning the relatedness of
tasks  Saha et al    Kang et al    or sharing only

In fact 

between subgroups of tasks  Xue et al    Kumar  
Daum   III    Barzilai   Crammer    However 
all of the above methods require at least some labeled data
for each task 
To our knowledge  the only existing multitask method
that can be applied in the considered setting where for
some tasks only unlabeled data is available is  Khosla
et al    Motivated by the problem of dataset bias 
this method relies on the assumption that different tasks
are minor modi cations       biased versions  of the same 
true prediction problem  Similarly to  Evgeniou   Pontil 
  it uses speci   regularizers and trains predictors for
all tasks jointly as small perturbations of   common predictor  which corresponds to the hypothetical unbiased task
and can potentially be applied to unseen problems  Thus 
applied in the considered setting  this method provides one
predictor for all unlabeled tasks and treats the labeled ones
as slight variations of them 
Information transfer from labeled to unlabeled tasks is
the question typically studied in domain adaptation research 
if the set of labeled tasks is  xed 
any domain adaptation technique might be used to obtain solutions for unlabeled tasks  in particular those based
on source reweighting  Shimodaira    representation
learning  Pan et al    Glorot et al    or semisupervised transfer  Xing et al    However  by design
all domain adaptation methods aim at  nding the best predictor on   single target task given    xed set of source
tasks  Therefore none of them can readily be applied in the
active task selection setting  where the learner needs to select the labeled tasks that would lead to good performance
across all tasks 
  second related setting is zeroshot learning  Larochelle
et al    Lampert et al    Palatucci et al   
where contextual  usually semantic  information is used to
solve   learning task for which no training data is available  The situation we are interested in is more speci   than
this  though  as we assume that unlabeled data of the tasks
is available  not context in an arbitrary form  As we will
show  this allows us to derive formal performance guarantees that zeroshot learning methods typically lack 
The active task selection scenario is directly related to the
question of identifying   representative set of source tasks
in domain adaptation    question that has previously been
raised in the context of sentiment analysis  Blitzer et al 
  It also shares some features with active learning 
where the learner is given   set of unlabeled samples and
can choose   subset to obtain labels for    fundamental difference is  however  that in active learning the learner needs
to  nd   single prediction function for all labeled and unlabeled data while in the multitask setting each task  including unlabeled ones  potentially requires its own predictor 

In the multitask or zeroshot setting  active learning has so
far not found widespread use  Exemplary works in this direction are  Reichart et al    Saha et al    Gavves
et al    which  however  use active learning on the
level of training examples  not tasks  The idea of choosing tasks was used in active curriculum selection  Ruvolo
  Eaton    Pentina et al    where the learner can
in uence the order in which tasks are processed  However
these methods nevertheless require annotated examples for
all tasks of interest 

  MTL with Labeled and Unlabeled Tasks
In the multitask setting the learner observes   collection of prediction tasks and its goal is to learn all of
them  Formally  we assume that there is   set of   tasks
 cid      cid         cid DT   fT cid  where each task   is de ned by
  marginal distribution Dt over the input space   and   deterministic labeling function ft          The goal of the
learner is to  nd   predictors            hT in   hypothesis
set                 that would minimize the average
expected risk 

  cid 

  

er            hT    

 
 
where ert ht     
  Dt

ert ht 

 

 cid ht    ft   

          xt

In this work we concentrate on the case of binary classi 
cation tasks          and  loss   cid           if
        and  cid           otherwise 
In the fullysupervised setting the learner is given   training set of annotated examples for every task of interest  In
contrast  we consider the scenario where every task   is repn  of   unlabeled examresented by   set St    xt
ples sampled        according to the marginal distribution
Dt  For   subset of   tasks             ik  which are either
prede ned or  in the active scenario  can be selected based
on the unlabeled data  the learner is given labels for   random subset Sij   Sij of   points 
To obtain   predictor for any task  labeled or unlabeled 
we consider   method that minimizes   convex combination of training errors of the labeled tasks  This choice allows us to capture  in   uni ed fashion  both types of information transfer   between the labeled tasks and from
labeled to unlabeled ones  Formally  for   set of tasks
                ik                 we de ne 

    

          

       supp      

 

 cid 

 cid 

  cid 

  

for supp                             cid    Given   weight
vector         the  weighted empirical error of   hypoth 

     

Multitask Learning with Labeled and Unlabeled Tasks

esis       is de ned as follows 

 cid er     
where  cid eri     

 cid 

   
 
 

   cid eri   
 cid 

     Si

 

 

 cid        

In order to obtain   solution for any task   the learner min 

imizes  cid er      for some          where   is the set of

labeled tasks  potentially in combination with some regularization 
The success of this approach depends on the subset   of
tasks that are labeled and on the weights                The
following theorem quanti es both of these effects and will
later be used to chose              and potentially   in  
principled way 
Theorem   Let   be the VC dimension of the hypothesis set      be the number of labeled tasks             ST be
       Di  and            ST
  sets of size   each  where Si
be their random subsets of size   each  for which labels
would be provided if the corresponding task is selected
as labeled  Then for any       with probability at least
      over            ST and            ST uniformly for all
choices of labeled tasks                 ik  and weights
                   provided that they are fully determined
by the unlabeled data only  and for all possible choices of
           hT     the following inequality holds 

  cid 

  

 
 

ert ht   
 

  cid 

  

 cid er   ht 

 
 

 

 cid cid   
 
 

 
 

 cid cid        

 
 

  cid 
 cid 
 cid 
  cid 

   

  

  

  

   

  disc St  Si 

  

  ti 

 

   is the empirical discrepancy between unlabeled samples St and Si  and

    cid   xi

 

    cid   cid erSt      cid   cid erSi       cid 
 cid  

     cid xi

where

disc St  Si    max

with  cid erSi      cid     
 cid cid 

 ij   min

 cid cid   

    eri      erj   

 cid cid cid cid cid 
 cid    cid 
    cid cid   
 cid 
 cid   

log 

     

   

  

  

 

log

 

 

 cid 

  
 

 

 
 

 

  

   

   log ekm   

 

 log       log enT    

  

  cid 
 cid 
 cid 
 cid 

   log        log       log 

 

 

   

   

Multitask Learning with Labeled and Unlabeled Tasks

Proof Sketch  the full proof can be found in the supplemental material  By Theorem   in  BenDavid et al 
  for any two tasks   and   the following inequality
holds for every       

ert      eri      disc Dt  Di     ti 

 
Thus  we obtain the following bound on the average expected error over all tasks in terms of the error on the labeled tasks 

  cid 

  

  cid 

  

 
 

ert ht   
 

  cid 

 cid 
 cid 

  

 

 
 

   
with er   ht   

  

er   ht 

  disc Dt  Di   

  cid 

 cid 

  

   

 
 

 

  

  ti 

 cid ht    fi    and  

  
 

 
  Di
 cid        cid    and

   
erDi      cid     
  Di
    cid    erDt      cid erDi      cid 
disc Dt  Di    max

is the discrepancy between two distributions  Kifer et al 
  Mansour et al    BenDavid et al   
In
order to prove the statement of the theorem we need to relate the  weighted expected errors and discrepancies between the marginal distributions in   to their empirical
estimates 
The proof consists of three steps  First  we show that  conditioned on the unlabeled data   
    er   can be upper
 
bounded in terms of  
 

 cid  
 cid  
  cid er    where 
  cid 
 cid 

 cid 

 er     

    eri     

 cid   xi

   fi xi

  

  
 

   

  

   

 cid  

This quantity can be interpreted as   training error if the
learner would receive the labels for all the samples for the
chosen tasks    Note that in case of       this step is
not needed and we can avoid the corresponding complexity
terms  In the second step we relate the average  weighted
    er    In the third step we conexpected errors to  
 
clude the proof by bounding the pairwise discrepancies in
terms of their empirical estimates 
Step   Fix the unlabeled sets            ST   They fully
determine the choice of labeled tasks   and the weights
               Therefore  conditioned on the unlabeled data 
these quantities can be considered constant and the bound
has to hold uniformly only with respect to            hT  
In order to simplify the notation we assume that    
             and de ne 

  cid 

 er   ht   cid er   ht 

  

 

            Sk    sup

  hT

 
 

Note that one could analyze this quantity using standard
techniques from Rademacher analysis  if the labeled examples were sampled from the unlabeled sets             with
replacement  However  since we assume that for every  
Si is   subset of Si       the labeled examples are sampled randomly without replacement  there are dependencies between the labeled examples  Therefore we utilize
techniques from the literature on transductive learning  ElYaniv   Pechyony    instead  We  rst apply Doob  
construction to   in order to obtain   martingale sequence
and then use McDiarmid   inequality for martingales  McDiarmid    As   result we obtain that with probability
at least       over sampling labeled examples 

 cid cid cid cid    cid 

 cid    cid 

  

  

  
 

 cid cid 

     

  Sk

   

 
 

log 

  

   

Now we need to upper bound     Using results from  Tolstikhin et al    and  Hoeffding    we observe that 

 

 

 

  Sk

            Sk     

     Sk

               Sk 

 

where  Si is   set of   points sampled from Si        with
replacement  in contrast to sampling without replacement
corresponding to Si  This means that we can upper bound
the expectation of   over samples with dependencies by the
expectation over independent samples  By doing so  applying the symmetrization trick  and introducing Rademacher
random variables  we obtain that 

 cid cid cid cid    cid 

  cid 

  

  

 cid 

 

  Sk

     
 

  

  

   log ekm   

 

   

  combination of   and   shows that  conditioned
on the unlabeled data  with probability at least      
over sampling labeled examples uniformly for all choices
of            hT the following holds 

  cid 

  

 
 

 er   ht     
 

  cid 

  

 cid er   ht     
 cid  

 cid cid   

 
 

 cid  

 
 

 cid cid 
 

    er   to  

Step   Now we relate  
 
 
The choice of the tasks to label    
the corresponding
weights    and the predictors     all depend on the unlabeled data  Therefore  we aim for   bound that is uniform
in all three parameters  We de ne 

   er   

sup

 

sup

     

sup

  hT

 
 

  eri ht     eri ht 
  

            ST    

  cid 

  cid 

  

  

Multitask Learning with Labeled and Unlabeled Tasks

  cid 

  

 
 

  cid 

  

 cid 

The main instrument that we use here is   re ned version
of McDiarmid   inequality  which is due to  Maurer   
It allows us to use the standard Rademacher analysis  while
taking into account the internal structure of the weights
               As   result we obtain that with probability
at least       simultaneously for all choices of tasks to
be labeled     weights                   and hypotheses
           hT  

er   ht     
 

 er   ht      

 

Step   To conclude the proof we bound the pairwise discrepancies in terms of their  nite sample estimates  According to Lemma   in  BenDavid et al    for any
pair of tasks      and any       with probability at least
     

disc Di  Dj    disc Si  Sj 

   log      log 

 

 

We apply this result to every pair of tasks and combine the
results using the uniform bound argument  This yields the
remaining two terms on the right hand side  the weighted
average of the samplebased discrepancies and the constant
   By combining the result with   and   we obtain
the statement of the theorem 

  Explanation and Interpretation
The lefthand side of inequality   is the average expected
error over all   tasks  the quantity of interest that the
learner would like to minimize but cannot directly compute  It is upperbounded by the sum of two complexity
terms and  ve taskdependent terms  weighted training errors on the labeled tasks  weighted averages of the distances
to the labeled tasks in terms of the empirical discrepancies 
two mixed norms of the weights   and   weighted average
of    
The

  cid   log nT     and converge to zero when the
 cid cid     cid cid      behaves as   cid   log km    and

number of unlabeled examples per task     tends to in nity 
   cid cid  in the worst case of
In contrast   

terms   and   behave

   cid cid     

complexity

converges to zero when the number of labeled examples
per labeled task     tends to in nity 
In order for these
     for the uncertainty coming
terms to be balanced 
from the estimation of discrepancy to not dominate the
uncertainty from the estimation of the  weighted risks 
the number of unlabeled examples per task   should be
signi cantly  for    cid      larger than    However  this
is not   strong limitation under the common assumption
that obtaining enough unlabeled examples is signi cantly
cheaper than annotated ones 

as

  cid 

 cid 

  

   

 
 

The remaining terms on the righthand side of   depend
on the set of labeled tasks    the tasksspeci   weights   
and hypotheses hs  Thus  by minimizing them with respect to these quantities one can expect to obtain values
for them that are bene cial for solving all tasks of interest based on the given data  For the theorem to hold  the
set of labeled tasks and the weights may not depend on the
labels  The part of the bound that can be estimated based
on the unlabeled data only  and therefore to select    in the
active scenario  and              is 

  

  disc St  Si   

 cid cid   

 
 

 
 

 cid cid   

The  rst term in   is the average weighted distance from
every task to the labeled ones  as measured by the discrepancy between the corresponding unlabeled training samples  This term suggests that for every task   the largest
weight       the highest impact in terms of information
transfer  should be put on   labeled task   that has   similar
marginal distribution  Note that the employed  similarity 
which is captured by the discrepancy  directly depends on
the considered hypothesis class and loss function and  thus 
is tailored to   particular setting of interest  At the same
time  the mixednorm terms  cid cid  and  cid cid  prevent the
learner from putting all weight on the single closest labeled
task and can be seen as some form of regularization  In particular  they encourage information transfer also between
the labeled tasks  since minimizing just the  rst term in  
for every labeled tasks       would result in all weight to
be put on task   itself and nothing on other tasks  because
by de nition disc Si  Si     
The  rst mixednorm term   cid cid  in uences every    independently and encourages the learner to use data from
multiple labeled tasks for adaptation  Thus  it captures the
intuition that sharing from multiple labeled tasks should
improve the performance  In contrast   cid cid  connects the
weights for all tasks  This term suggests to label tasks that
all would be equally useful  thus preventing spending resources on tasks that would be informative for only   few of
the remaining ones  Also  it prevents the learner from having superin uential labeled tasks that share with too many
others  Such cases would be very unstable in the worst case
scenario  mistakes on such tasks would propagate and have
  major effect on the overall performance 
The effect of the mixednorm terms can also be seen
through the lens of the convergence rates  Indeed  as already mentioned above  in the case of every    having only
one nonzero component   cid cid  and  cid cid  are equal to

  and thus the convergence rate  is    cid    However 

in the opposite extreme  if every    weights all the labeled
       for all                  and
tasks equally         

      is an analog of    that hides logarithmic factors

Multitask Learning with Labeled and Unlabeled Tasks

Figure   Schematic illustration of active task selection  Left  eight unlabeled tasks need to be solved  Center  the subset of tasks to be
labeled and betweentask weights are determined by minimizing   Right  annotated data for labeled tasks is obtained  and prediction
functions  black vs  white  for each task are learned using the learned weighted combinations  Sharing can occur between labeled tasks 

       then  cid cid     cid cid      

rate improves to    cid km  which is the best one can

and the convergence

 

expect from having   total of km labeled examples 
The only term on the righthand side of   that depends
on the hypotheses            hT and can be used to make
  favorable choice is the weighted training error on the
labeled tasks  Thus  the generalization bound of Theorem  
suggest the following algorithm  Figure  

Algorithm  
  estimate pairwise discrepancies between the tasks

based on the unlabeled data

  choose the tasks   to be labeled  in the active case 

and the weights              by minimizing  

  receive labels for the labeled tasks  
  for every task   train   classi er by minimizing  

using the obtained weights    

Note  that this procedure is justi ed by Theorem   all
choices are done in agreement with the conditions of the
theorem and  because the inequality   holds uniformly for
all eligible choices of labeled tasks  weights and predictors 
the guarantees also hold for the resulting solution 
Algorithm   is guaranteed to perform well  if the solution it
 nds leads to   low value of the righthand side of   By
construction  it minimizes all datadependent terms in  
except for one quantity that cannot be estimated from the
available data 

  

  ti 

 

  cid 

 cid 

  

   

 
 

the

While discrepancy captures
similarity between
marginal distributions  the  terms re ect the similarity
between labeling functions  for every pair of task     and
labeled task         the corresponding value  ti is small if
there exists   hypothesis that performs well on both tasks 
Thus  Algorithm   can be expected to perform well  if for
any two given tasks   and   that are close to each other in
terms of discrepancy  and thus in the minimization of  
the corresponding   
  is large  there exists   hypothesis

that performs well on both of them       the corresponding
 ti is small  We refer to this property of the set of learning
tasks as task smoothness 
Training predictors for every task of interest using data
from all labeled tasks improves the statistical guarantees
of the learner  However  it results in empirical risk minimization on up to km samples for   different weighted
combinations  Since we are most interested in the situation
when   is large  one might be interested in way to reduce
the amount of necessary computation  One way to do so
is to drop the mixednorm terms from the objective function   in which case it reduces to

  cid 

 cid 

  

   

 
 

  

  disc St  Si 

 

This expression is linear in   and thus minimizing it for
   xed set   will lead to assigning each task to   single
labeled task that is closest to it in terms of empirical discrepancy  Each labeled task will be assigned to itself  Consequently  the learner must train only   predictors  one for
each labeled task  using only its   samples  The expression   can be seen as the kmedoids clustering objective
with tasks corresponding to points in the space with  semi 
 metric de ned by empirical discrepancy and labeled tasks
correspond to the centers of the clusters  Thus  this method
reduces to kmedoids clustering  resembling the suggestion
of Blitzer et al    Note that  nevertheless  the conditions of Theorem   are ful lled  and thus its guarantees will
hold for the obtained solution  The guarantees will be more
pessimistic  however  than those from Algorithm   as the
minimization ignores parts of the bound   and will not use
the potentially bene cial transfer between labeled tasks 

  Experiments
To illustrate that the proposed algorithm can also be practically useful  we performed experiments on synthetic and
real data  In both cases we choose   to be the set of all
linear predictors with   bias term on     Rd 
Synthetic data  We generate       binary classi ca 

 Multitask Learning with Labeled and Unlabeled Tasks

    Synthetic data  complete transfer

    Product reviews  complete transfer

    Synthetic data  singlesource transfer

    Product reviews  singlesource transfer

Figure   Experimental results on synthetic and real data  average test error and standard deviation over   repeats 

tion tasks in    For each task   its marginal distribution
Dt is   unitvariance Gaussian with mean    chosen uniformly at random from the set           The label
  is assigned to all points that have angle between   and
  with     computed counterclockwise  the other points
are labeled   We use       unlabeled and      
labeled examples per task 
Real Data  We curate   Multitask dataset of product reviews  from the corpus of Amazon product data   McAuley
et al        We select the products for which there are
at least   positive reviews  with scores   or   and at
least   negative reviews  with scores   or   Each of the
resulting   products we treat as   binary classi cation
task of predicting whether   review is positive or negative 
For every review we extract features by  rst preprocessing
 removing all nonalphabetical characters  transforming the
rest into lower case and removing stop words  and then applying the sentence embedding procedure of  Arora et al 
  using  dimensional GloVe word embedding  Pennington et al    We use       unlabeled samples
per task and label   subset of       examples for each
of the selected tasks  The remaining data is used for testing 
Methods  We evaluate the proposed method in the case
when the set of labeled tasks is prede ned  referred to
as DA  by setting the set   to be   random subset of
tasks and minimizing   only with respect to    and in
the active task selection scenario where   is minimized

 http cvml ist ac at productreviews 
 http jmcauley ucsd edu data amazon 

with respect to both   and     referred to as Active DA 
We compare these methods to   multitask method based
on  Khosla et al    also with random labeled tasks
 the same ones as for DA  Speci cally  we solve 

 cid 

 wTx     

 

 
km
            bt      

        St

 

 cid vt cid cid 
 cid 

   

 cid cid   cid   
 cid 
 cid 

 
 

 wT   vT

   

     St

min
     

 

 

 
km

for                   and use        for making predictions on all unlabeled tasks and      vt      bt  for each
labeled task        For every number of labeled tasks we
report the result for   that has the best test performance averaged over   repeats  denoted by Multitask  as an upper
performance bound on what could be achieved by model
selection 
We also evaluate the discussed simpli cation of the proposed methods that consists of minimizing   We refer
to these as DASS  for random prede ned labeled tasks  and
as Active DASS  in the active task selection scenario  The
SS stands for single source  as in this setting  each task is
solved based on information from only one labeled tasks 
To provide further context for the results we also report
the results of learning independent ridge regressions with
access to labels for all tasks  denoted by Fully Labeled 
However  this baseline has access to many more annotated
examples in total than all other methods  In order to quantify this effect we also consider the setting when the learner

 fraction of labeled tasks in  test error in  Fully LabeledMultitask Khosla PL MultitaskDAActive DA fraction of labeled tasks in  test error in  Fully LabeledMultitask Khosla PL MultitaskDAActive DA fraction of labeled tasks in  test error in  Fully LabeledPartially LabeledDASSActive DASS fraction of labeled tasks in  test error in  Fully LabeledPartially LabeledDASSActive DASSMultitask Learning with Labeled and Unlabeled Tasks

has access to labels for all tasks  but fewer of them  namely 
when the number of labeled tasks is    the number of labels per task is mk          the total amount of labeled examples is mk  the same as for all other methods  In this
case we evaluate two methods  The  rst one learns ridge
regressions for every task independently and thus can be
seen as   reference point for the methods that do not involve information transfer between the labeled tasks      
DASS and Active DASS  The second reference method is
based on  Evgeniou   Pontil    and consists of minimizing   with   set to   and processing all tasks as labeled  This approach transfers information between all the
tasks and therefore we refer to it when evaluating the methods that involve information transfer between the labeled
tasks       DA  Active DA and Multitask 
Implementation  We estimate the empirical discrepancies between pairs of tasks by  nding   hypothesis in  
that minimizes the squared loss for the binary classi cation
problem of separating the two sets of instances  as in  BenDavid et al    To minimize   for   given set of
labeled tasks we use gradient descent 
It is also used as
  subroutine when minimizing   with respect to both  
and     for which we employ the GraSP algorithm  Bahmani et al    Active DASS involves the minimization of the kmedoid risk   which we perform using  
local search as in  Park   Jun    For both methods
for the active task selection scenario we used the heuristic
from kmeans   Arthur   Vassilvitskii    for initialization  To obtain classi ers for the individual tasks in all
scenarios we use leastsquares ridge regression  Regularization constants for all methods we selected from the set
            by  fold cross validation 
Results  The results are shown in Figure   First  one can
see that the proposed domain adaptationinspired method
DA outperforms the multitask method   This could
be due to higher  exibility of DA compared to Multitask
as the latter provides only one predictor for all unlabeled
tasks 
Indeed  the difference is most apparent in the experiment with synthetic data  where by design there is no
single predictor that could perform well on   large fraction
of tasks  Results on the product reviews indicate that DA  
 exibility of learning   speci   predictor for every task can
be advantageous in more realistic scenarios as well 
Second  on both datasets both methods for active task selection       Active DA and Active DASS  outperform the
corresponding passive methods       DA and DASS  systematically across various fractions of the labeled tasks  In
particular  both active task selection methods require substantially fewer tasks labeled to achieve the same accuracy
as their analogs with randomly chosen tasks  This con rms
the intuition that selecting which tasks to label in   datadependent way is bene cial and demonstrates that Theo 

rem   is capable of capturing this effect 
Another interesting observation that can be made from the
results in Figure   is that both active and passive domain
adaptationinspired methods clearly outperform the corresponding partially labeled baselines  especially for small
fractions of labeled tasks  This indicates that having more
labels for fewer tasks rather than only few labels for all
tasks could be bene cial not only in terms of annotation
costs  but also in terms of prediction accuracy 
As the number of labeled tasks gets larger       half of all
tasks  the performance of the active task selection learner
becomes almost identical to the performance of the Fully
Labeled method  even improving over it in the case of
multisource transfer on synthetic data  This con rms the
intuition that in the case of many related tasks even   fraction of the tasks can contain enough information for solving
all tasks 

  Conclusion
In this work we introduced and studied   variant of multitask learning in which annotated data is available only for
some of the tasks  This setting combines aspects of traditional multitask learning  namely the transfer of information between labeled tasks  with aspects typical for domain
adaptation problems  namely transferring information from
labeled tasks to solve tasks for which only unlabeled data
is available  The success of the learner in this setting depends on the effectiveness of information transfer and informativeness of the set of labeled tasks  We analyzed two
scenarios    passive one  in which the set of labeled tasks is
prede ned  and the active task selection scenario  in which
the learner decides for which tasks to query labels 
Our main technical contribution is   generalization bound
that quanti es the informativeness of the set of labeled
tasks and the effectiveness of information transfer  We
demonstrated how the bound can be used to make the
choice of labeled tasks  in the active scenario  and to transfer information between the tasks in   principled way  We
also showed how the terms in the bound have intuitive interpretations and provide guidance under which assumption of tasks relatedness the induced algorithm is expected
to work well  Our empirical evaluation demonstrated that
the proposed methods work also well in practice 
For future work we plan to further exploit the idea of active learning in the multitask setting  In particular  we are
interested in identifying whether by allowing the learner
to make its decision on which tasks to label in an iterative
way  rather than forcing it to choose all the tasks at the same
time  one could obtain better learning guarantees as well as
more effective learning methods 

Multitask Learning with Labeled and Unlabeled Tasks

Acknowledgments
We thank Alexander Zimin and Marius Kloft for useful
discussions  This work was in parts funded by the European Research Council under the European Union   Seventh Framework Programme  FP ERC grant
agreement no  

References
Argyriou  Andreas  Evgeniou  Theodoros  and Pontil  Massimiliano  Multitask feature learning  In Conference on
Neural Information Processing Systems  NIPS   

Argyriou  Andreas  Evgeniou  Theodoros  and Pontil  Massimiliano  Convex multitask feature learning  Machine
Learning   

Arora  Sanjeev  Liang  Yingyu  and Ma  Tengyu    simple
but toughto beat baseline for sentence embeddings  In
International Conference on Learning Representations
 ICLR   

Arthur  David and Vassilvitskii  Sergei  kmeans  the
advantages of careful seeding  In Symposium on Discrete
Algorithms  SODA   

Bahmani  Sohail  Raj  Bhiksha  and Boufounos  Petros   
Journal of

Greedy sparsityconstrained optimization 
Machine Learning Research  JMLR     

Barzilai  Aviad and Crammer  Koby  Convex multitask
learning by clustering  In Conference on Uncertainty in
Arti cial Intelligence  AISTATS   

BenDavid  Shai  Blitzer  John  Crammer  Koby  and
Pereira  Fernando  Analysis of representations for domain adaptation  In Conference on Neural Information
Processing Systems  NIPS   

BenDavid  Shai  Blitzer  John  Crammer  Koby  Kulesza 
Alex  Pereira  Fernando  and Vaughan  Jennifer Wortman    theory of learning from different domains  Machine Learning   

Blanchard  Gilles  Lee  Gyemin  and Scott  Clayton  Generalizing from several related classi cation tasks to  
new unlabeled sample  In Conference on Neural Information Processing Systems  NIPS   

Blitzer  John  Dredze  Mark  and Pereira  Fernando  Biographies  Bollywood  boomboxes and blenders  Domain adaptation for sentiment classi cation  In Annual
Meeting of the Association for Computational Linguistics  ACL   

Caruana  Rich  Multitask learning  Machine Learning 

 

Chapelle  Olivier  Sch olkopf  Bernhard  and Zien  Alexan 

der  Semisupervised learning  The MIT Press   

Crammer  Koby and Mansour  Yishay  Learning multiple
tasks using shared hypotheses  In Conference on Neural
Information Processing Systems  NIPS   

ElYaniv  Ran and Pechyony  Dmitry 

Transductive
Rademacher complexity and its applications  In Workshop on Computational Learning Theory  COLT   

Evgeniou  Theodoros and Pontil  Massimiliano  Regularized multitask learning  In Conference on Knowledge
Discovery and Data Mining  KDD   

Gavves  Efstratios  Mensink  Thomas  Tommasi  Tatiana 
Snoek  Cees  and Tuytelaars  Tinne  Active transfer
learning with zeroshot priors  Reusing past datasets for
future tasks  In International Conference on Computer
Vision  ICCV   

Glorot  Xavier  Bordes  Antoine  and Bengio  Yoshua  Domain adaptation for largescale sentiment classi cation 
  deep learning approach  In International Conference
on Machine Learing  ICML   

Hoeffding  Wassily  Probability inequalities for sums of
bounded random variables  Journal of the American Statistical Association   

Kang  Zhuoliang  Grauman  Kristen  and Sha  Fei  Learning with whom to share in multitask feature learning  In
International Conference on Machine Learing  ICML 
 

Khosla  Aditya  Zhou  Tinghui  Malisiewicz  Tomasz 
Efros  Alexei  and Torralba  Antonio  Undoing the damIn European Conference on Comage of dataset bias 
puter Vision  ECCV   

Kifer  Daniel  BenDavid  Shai  and Gehrke  Johannes  De 

tecting change in data streams  In VLDB   

Kumar  Abhishek and Daum   III  Hal  Learning task
In Intergrouping and overlap in multitask learning 
national Conference on Machine Learing  ICML   

Lampert  Christoph    Nickisch  Hannes  and Harmeling 
Stefan  Attributebased classi cation for zeroshot visual object categorization  IEEE Transactions on Pattern
Analysis and Machine Intelligence  TPAMI   

Larochelle  Hugo  Erhan  Dumitru  and Bengio  Yoshua 
Zerodata learning of new tasks  In Conference on Arti 
 cial Intelligence  AAAI   

Mansour  Yishay  Mohri  Mehryar  and Rostamizadeh  Afshin  Domain adaptation  Learning bounds and algorithms  In Workshop on Computational Learning Theory
 COLT   

Multitask Learning with Labeled and Unlabeled Tasks

Maurer  Andreas  Concentration inequalities for functions
of independent variables  Random Structures and Algorithms   

Shimodaira  Hidetoshi  Improving predictive inference under covariate shift by weighting the loglikelihood function  Journal of Statistical Planning and Inference   

Tolstikhin     Blanchard     and Kloft     Localized complexities for transductive learning  In Workshop on Computational Learning Theory  COLT   

Xing  Dikan  Dai  Wenyuan  Xue  GuiRong  and Yu 
Yong  Bridged re nement for transfer learning  In European Conference on Principles and Practice of Knowledge Discovery in Databases  PKDD   

Xue  Ya  Liao  Xuejun  Carin  Lawrence  and Krishnapuram  Balaji  Multitask learning for classi cation with
Dirichlet process priors  Journal of Machine Learning
Research  JMLR     

McAuley        Pandey     and Leskovec     Inferring networks of substitutable and complementary products  In
Conference on Knowledge Discovery and Data Mining
 KDD     

McAuley        Targett     Shi     and van den Hengel    
Imagebased recommendations on styles and substitutes 
In International Conference on Research and Development in Information Retrieval  SIGIR     

McDiarmid  Colin  On the method of bounded differences 

In Surveys in Combinatorics   

Palatucci  Mark  Pomerleau  Dean  Hinton  Geoffrey   
and Mitchell  Tom    Zeroshot learning with semantic output codes  In Conference on Neural Information
Processing Systems  NIPS   

Pan  Sinno Jialin  Tsang  Ivor    Kwok  James    and
Yang  Qiang  Domain adaptation via transfer compoIEEE Transactions on Neural Networks
nent analysis 
 TNN   

Park  HaeSang and Jun  ChiHyuck    simple and fast
algorithm for kmedoids clustering  Expert Systems with
Applications     

Pennington 

Jeffrey  Socher  Richard  and Manning 
Christopher    Glove  Global vectors for word representation  In Conference on Empirical Methods on Natural
Language Processing  EMNLP   

Pentina  Anastasia  Sharmanska  Viktoriia  and Lampert 
Christoph    Curriculum learning of multiple tasks  In
Conference on Computer Vision and Pattern Recognition
 CVPR   

Reichart  Roi  Tomanek  Katrin  Hahn  Udo  and Rappoport  Ari  Multitask active learning for linguistic
In Annual Meeting of the Association for
annotations 
Computational Linguistics  ACL   

Ruvolo  Paul and Eaton  Eric  Active task selection for
In Conference on Arti cial

lifelong machine learning 
Intelligence  AAAI   

Saha  Avishek  Rai  Piyush  Daum   III  Hal  and Venkatasubramanian  Suresh  Active online multitask learning 
In ICML Workshop on Budget Learning   

Saha  Avishek  Rai  Piyush  Daum   III  Hal  and Venkatasubramanian  Suresh  Online learning of multiple tasks
and their relationships  In Conference on Uncertainty in
Arti cial Intelligence  AISTATS   

