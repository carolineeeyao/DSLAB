Bayesian inference on random simple graphs

with power law degree distributions

Juho Lee   Creighton Heaukulani   Zoubin Ghahramani     Lancelot    James   Seungjin Choi  

Abstract

 BFRY 

We present   model for random simple graphs
with power law       heavytailed  degree distributions  To attain this behavior 
the edge
probabilities in the graph are constructed from
Bertoin Fujita Roynette Yor
random
variables  which have been recently utilized in
Bayesian statistics for the construction of power
law models in several applications  Our construction readily extends to capture the structure
of latent factors  similarly to stochastic blockmodels  while maintaining its power law degree distribution  The BFRY random variables
are well approximated by gamma random variables in   variational Bayesian inference routine 
which we apply to several network datasets for
which power law degree distributions are   natural assumption  By learning the parameters of the
BFRY distribution via probabilistic inference  we
are able to automatically select the appropriate
power law behavior from the data 
In order to
further scale our inference procedure  we adopt
stochastic gradient ascent routines where the gradients are computed on minibatches       subsets  of the edges in the graph 

  Introduction
In statistical applications  random graphs serve as Bayesian
models for network data  that is  data consisting of objects
and the observed linkages between them  Here we will focus on models for random simple graphs  that is  graphs
with edges that take binary values  which are appropriate
for applications where we observe either the presence or

 Pohang University of Science and Technology  Pohang 
South Korea  University of Cambridge  Cambridge  UK  Uber
AI Labs  San Francisco  CA  USA  Hong Kong University
of Science and Technology  Hong Kong 
Correspondence
to  Juho Lee  stonecold postech ac kr  Seungjin Choi  seungjin postech ac kr 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

absence of links between objects in the network  For example  in social networks  nodes may represent individuals
and   link         nonzero value of an edge  could represent
friendship  In   proteinprotein interaction network  nodes
may represent proteins and links could represent an observed physical or chemical interaction between proteins 
Many domains involving network data  including social
and proteinprotein interaction networks  have been shown
to exhibit power law       heavytailed  degree distributions
 Barab asi   Albert    Models for random graphs with
power law degree distributions  also called scalefree random graphs  have therefore become one of the most actively studied areas of graph theory and network science
 Bollob as et al    Albert   Barab asi    Dorogovtsev   Mendes    In this paper we present   model
for simple  scalefree random graphs  which we apply as  
probabilistic model for several network datasets 
The model we present in this paper is   special case of the
generalized random graph de ned by Britton et al   
and studied further by van der Hofstad   Ch   
which outlines   framework for de ning scalefree random
graphs  but does not provide practical constructions  much
less algorithms for performing statistical inference on the
model components given data  Here we provide one such
practical construction  along with   variational inference
routine  Jordan et al    for ef cient posterior inference  What   more  our construction readily generalizes to
include the structure of latent factors clusters  as captured
by the popular stochastic blockmodels  Nowicki   Snijders    Airoldi et al    while maintaining power
law behavior in the graph 
Applying Bayesian inference algorithms on network
datasets is   challenge because likelihood computations 
in general  scale with the number of edges in the graph 
which is      in   network with   nodes  To help overcome these dif culties  we follow Hoffman et al   
and develop   stochastic variational inference algorithm in
which we approximate many likelihood computations on
only subsets of the data  called minibatches  In the case of
  network dataset  the minibatches are comprised of subsets
of edges in the graph 
We apply this inference procedure to several network

Power law simple graphs

datasets that are commonly observed to possess power law
structure  Our experiments show that accurately capturing
this power law structure improves performance on tasks
predicting missing edges in the networks 

  Bayesian models for simple graphs
We represent   simple graph with   nodes by an adjacency
matrix      Xi          where Xi       if there is  
link between nodes   and   and Xi       otherwise  Here
we will only consider undirected graphs  in which case  
represents   symmetric matrix  Furthermore  we do not allow self links  so the diagonal entries in   are meaningless  Most probabilistic models for simple graphs take the
entries in   to be conditionally independent Bernoulli random variables  in particular  for every           let pi   be
the  random  probability of   link between nodes   and   
and let Xi     pi     Bernoulli pi    For every simple
graph      xi          we may then write the likelihood
for the parameters      pi        given   as

               

        pi   xi    
pxi  

 

 cid 

     

where in our case it should be clear that the product is only
over          such that       and    cid     Random simple
graphs date back to the Erd os   enyi model  which may be
reviewed  along with the more general theory of random
graphs  in the text by Bollob as     random graph is
called scalefree when the fraction of nodes in the network
having   connections to other nodes behaves like    for
large values of   and some exponent       More prej cid   Xi   denote the  random  degree
of node    for every        Then   is  asymptotically 
scalefree when  for every node       

cisely  let Dn    cid 

  Dn          ck   

as      

 

for some constant         power law exponent       and
  suf ciently large  Here the notation       denotes that
the ratio         in the speci ed limit 
In order to model scalefree random graphs  Britton et al 
  suggested reparameterizing the model in Eq    by
  sequence of odds ratios ri     pi      pi    for every            which factorize as ri     UiUj  for some
                Un  The nodespeci   factors Ui are then
  for some sequence of nonnegmodeled as Ui   Wi 
ative random variables                 Wn  and where
   Wi  In   series of results   Britton et al   
Thms        and  van der Hofstad    Cor     
Thm    assert conditions on the random variables   so
that the limiting distribution of the degrees Dn   is   mixed
Poisson distribution  We will further detail these previous
results in Section  

   cid  

 

The distribution of Wi is interpreted here as   prior distribution for the degree Dn   of node    and if its distribution
has heavy tails  then so will the distribution of Dn    Conversely  if the distribution of Wi does not have heavy tails 
then neither will the distribution of the degrees Dn    We
explore this alternative in Section  
Previous authors did not suggest any particular choices for
the distribution of Wi  and so we elect to model them with
BFRY random variables  Bertoin et al    Devroye  
James    which have   heavytailed distribution and
have recently played   role in the construction of several
power law models in Bayesian statistics  Other heavy tailed
distributions  such as those exhibited by log normal random
variables  may also be used to model the Wi  and these options may be explored  One bene   of the BFRY distribution is that the thickness of its tails  and thus the power law
behavior of the resulting graph  may be straightforwardly
controlled by the discount parameter  

    generalized random graph
Consider the model from the previous section  parameterized by the odds ratios      ri                De ne

      

    ri     

    UiUj 

 

 cid 

     

 cid 

     

and note that the conditional likelihood in Eq    may be
rewritten in terms of the degrees Dn   as

                      cid 
      cid 

     

 UiUj xi  

  Dn  

 

 

   

 

 

The random simple graph   is called   generalized random
graph  and we will henceforth write         GRG      
Let         which we call the discount parameter  and
let             be   sequence of positive values satisfying

   Cn     and

lim

      
lim

        

Let the weights            Wn be        with density
fn                 Cn 

 

 

 These are truncated BFRY random variables and will be
discussed  along with   method for simulation  in Section   Then the corresponding generalized random
graph has an  asymptotic  power law degree distribution
with power law exponent           We summarize this
construction in the following theorem 
Theorem   For every    let            Wn be        with
density fn and let  Dn       be the degrees of the generalized random graph         GRG       where

Power law simple graphs

Figure   The number of nodes with various degrees for two simulated graphs with       nodes and differing values for  

Figure   The average number of links in simulated graphs with
varying sparsity parameter  

     ri         is the sequence of odds ratios
          

ri     WiWj   

 

and    cid 

  Wi  Then the following hold 

  For    cid      Dn          cy  for every node  

and for some constant    as      
totically independent  as      

  For any    the collection Dn          Dn   are asymp 

This construction is closely related to the model described
by van der Hofstad   Thm    and the proof of
Theorem   which is provided in the supplementary material  follows analogously to the results by Britton et al 
  Thms        Note that the power law exponent
          of the graph  as described by Eq    is determined by the parameter         and takes values in
    While power law exponents in     has often been
suggested in the past  it has more recently been shown that
exponents within the     range of our model is more appropriate in many domains  van der Hofstad    Ch   
 Crane   Dempsey   

  Truncated BFRY random variables

  random variable   with density function fn given by
Eq    is   ratio of gamma and beta random variables  upper truncated at Cn  In particular let

and     beta   

    gamma       

 
be independent  then the ratio         has density       
          on    by construction  which is
known as the BertoinFujita RoynetteYor  BFRY  distribution  Bertoin et al    Devroye   James    and
has been used in the construction of power law models in
some recent applications in machine learning  James et al 
  Lee et al    The random variable   is then

obtained by upper truncating the random variable   at Cn 
By our requirements on the sequence Cn       Eq    the
density function fn of   approaches the density function
of the BFRY random variable   as       that is 
         

 

 

lim
   fn     

     

which is heavytailed with in nite moments  It is straightforward to simulate these truncated BFRY random variables by repeatedly simulating   and   as in Eq    accepting         as   sample when     Cn 
The truncation of   at Cn produces   random variable
with  nite mean  for       which is essential when
constructing the generalized random graph and motivates
the construction by van der Hofstad   Thm    alluded to earlier  see Section   For simplicity  one could
take Cn      but the  exibility to set this parameter allows
us to control other properties of the model  For example  in
the next section we show how to vary this truncation level
to control the sparsity of the graph 

  Controlling power law and sparsity in the graph
The discount parameter         controls the power law
behavior of the graph  where decreasing   results in heavier tails in the degree distribution of the nodes in the graph 
We can visualize this behavior by simulating graphs at different values of   In Section   we set Cn     and show
the number of nodes of varying degrees in two simulated
graphs  one with       and one with      
The degree distribution of the nodes in   graph of course
affects the sparsity of the graph  to characterize this relationship  we can upper bound the expected number of links
in the graph as follows 
Theorem   Let En be the number of positive edges in
the graph  Then   En      nC  

 

 

 nodeswithdegree degree nodes links Power law simple graphs

The derivation of this result is provided in the supplementary material  While varying   can thus control the sparsity of the graph in addition to the power law behavior 
we often want to decouple these behaviors  in which case
we could parameterize the truncation level as Cn     
for some sparsity parameter       Note the restriction
    min    must be enforced in order to ensure
that the conditions in Eq    are satis ed  In this case  the
bound in Theorem   becomes   En        
The interpretation here is that increasing the upper bound
Cn increases the likelihood that any particular node will
link to others  but does not affect the  asymptotic  power
law characterized by Theorem   In Section   we display the average number of positive edges in graphs that
were simulated with  xed       and varying values of
the sparsity parameter   We note that in simulations  we
encountered numerical issues in       regimes 

  Related work
Referring to the construction for generalized random
graphs in Section   Britton et al    Thm    shows
that when the weights Wi have  nite  rst and second moments  then the limiting distribution of the degree Dn   is
  mixed Poisson distribution  Most such distributions are
lighttailed  however  in which case the degrees will not
exhibit power law behavior  Britton et al    Thm   
therefore provides an alternative construction in which Wi
may have in nite moments  so that it may exhibit   heavy
tail  which results in   graph with   power law exponent of
      Finally  van der Hofstad   Thm    suggests
yet another construction where the Wi are upper truncated
to be of order      where   is the number of nodes in the
graph  The resulting random variables therefore have  nite
moments  yet exhibit   heavy tail  and the resulting random
graph has   heavy tailed degree distribution with an arbitrary power law exponent  None of these results suggest  
particular choice for the distribution of Wi  however  and
so we have elected to use BFRY random variables  which
are heavy tailed  that are upper truncated  so that they have
 nite moments  We note that the requirements on our truncation level       Eq    is less strict than the      criterion
of the van der Hofstad   Thm    construction 
The reader may consult the surveys by Bollob as   Riordan   Albert   Barab asi   Dorogovtsev  
Mendes   for   background on scalefree random
graphs  which is too large to review here  While these models are numerous  the following recent pieces of work in the
Bayesian statistics and machine learning communities may
be of interest to the reader  Caron   Fox   Veitch
  Roy   Crane   Dempsey   Cai   Broderick   This collection of work discusses power law
degree distributions  albeit in some cases in multigraphs

      graphs with nonnegative integervalued edges  and in
some cases the power law behavior is not characterized 
only numerically observed in simulations  Many of these
models can be seen to invoke their power law properties
from the Pitman Yor process  Pitman   Yor     or related stochastic processes  where the extent of this behavior is controlled by the discount parameter         of
the Pitman Yor model  which  like the BFRY distribution 
is related to   stable subordinator of index  

  Incorporating latent factors
Latent factor models for relational data assume that   set
of latent clusters underlie the network  For example  in  
social network  the latent factors could be the unobserved
hobbies or interests of individuals  which determine the observed friendships in the network  Bayesian models for latent factors in relational data are widespread  with some of
the most popular based on stochastic blockmodels  where
models for unsupervised learning  or clustering  are used
to infer the latent factors  Nowicki   Snijders    Kemp
et al    Airoldi et al    Miller et al    In this
section  we present extensions of the generalized random
graph that incorporate latent factors by scaling the odds ratios  while maintaining their power law degree distribution 
We will  rst provide   general result showing how to incorporate random scaling variables into the model  followed by speci   examples that model these scaling variables with latent clusters  Let the odds ratios in the generalized random graph be given by ri     Ai jUiUj for
some Ai       Note that pi       as Ai       and
pi       as Ai       and so the edgespeci   weight
Ai   simply scales the link probability  The random graph
        GRG       then has the likelihood

                      cid 

Axi  
   

  Dn  

 

 

 

 cid 

   

     

where the normalization term      in Eq    is now

 cid 
 cid 

     

 cid 

      

 

     

 

where

the  nal

equality follows

 cid 
simply because
                    So constructed  the odds
ratios   will in uence the link probabilities in the generalized random graph  but will not affect
the power
law behavior of the degree distributions  under some
assumptions on the random variables Ai    We summarize
this construction in the following theorem  the proof for
which is provided in the supplementary material 

    Ai jUiUj 

Axi  
   

  Dn  

 

 

 cid 

   

 

 

Power law simple graphs

Theorem   Let  Wi     be        random variables with
density function fn     in Eq    Let  Ai         be  
collection of uniformly bounded random variables  where 
for every        the collection  Ai       is exchangeable  Let  Dn       be the degrees of the random graph
        GRG       where      ri         is the sequence of odds ratios

and where    cid 

ri     Ai jWiWj   

          

 
  Wi  Then the degrees  Dn       sat 

isfy statements   and   in Theorem  

For example  we may construct stochastic blockmodels 
such as those introduced by Nowicki   Snijders   as
follows  For every        let Zi be   random variable taking values in              indicating which one  and only
one  of   different factors to associate with node    We
want the latent cluster assignments for two nodes   and  
to in uence their link probability  which we could capture
with   set of parameters    cid  for     cid                 Then the
parameter  Zi Zj could represent  or in uence  the probability of   link between nodes   and    Taking   Bayesian
approach  the indicator variables Zi may be modeled with
  Dirichletcategorical conjugate distribution and their values may be inferred via probabilistic inference  An example of such   model could be summarized as follows  Let

      
where      
 cid        
          

Zi   categorical 
    Dirichlet     
 cid     gamma      
Ai      Zi Zj  

 
 
 
 
and construct the random graph   as in Theorem  
Kemp et al    developed   nonparametric extension
of   similar model that in   sense takes the limit      
allowing an appropriate number of clusters to be automatically inferred from the data  In this case  the marginal law
of the indicator variables            Zn is given by   Chinese
restaurant process  with concentration parameter   
Several generalizations of the stochastic blockmodel allow
the clusters underlying the network to overlap  leading to
mixed membership stochastic blockmodels  Airoldi et al 
  or the related latent feature relational models  Miller
et al    To capture this structure  we may generalize
the indicators Zi to now represent   binary Kvector with
entry Zi       indicating node   is associated with cluster    now called   feature  and Zi       otherwise  One
example of such   model could be summarized as follows 
 
 
 

             
       and         
 cid                 
          

Zi     Bernoulli pk 
pk   beta        
 cid     gamma      
   cid Zi kZj cid 
Ai    

 cid 

 

  cid 

 cid 

 cid 

and construct the random graph   as in Theorem  
Miller et al    derived   nonparametric extension of
this model that in   sense takes the limit       in which
case the marginal law of the vectors            Zn is that of
an Indian buffet process  with mass parameter   and concentration parameter     Ghahramani et al   

  Variational inference
We derive   variational Bayesian inference algorithm  Jordan et al    that approximates the  optimal state of
the  posterior distribution of the model components  given
  network dataset  We approximate the required gradients in this procedure with stochastic gradient ascent  Bottou    Hoffman et al    computed on minibatches
      subsets  of edges in the graph 

  The variational lower bound

In variational inference  we approximate the posterior distribution on the latent variables                 Wn 
with   variational distribution         the parameters  
of which are    to maximize the following lower bound on
the marginal likelihood

log        Eq    

                  

       

log

 

 

where           is the likelihood function computed as
in Eq    and         is the prior on   represented by
the density function in Eq    The  non random  discount
parameter   is inferred by corresponding gradient ascent
updates maximizing the likelihood of the model  which is
described in Section  
We specify   mean  eld variational distribution          
     Wi      We considered several approximations
for the marginals   Wi      including truncated BFRY and
truncated gamma distributions  however  in our experiments we found that the following recti ed gamma distribution performed well 

 cid  

    Cn 

Wi    min    cid 
    gamma   shp     rte 
   cid 

 
 
independently for every        where    shp and    rte denote the shape and rate parameters of the gamma distribution  respectively  and the notation    emphasizes that this
formula holds under the variational distribution   

  Stochastic gradient ascent

We maximize the lower bound on the right hand side of
Eq    by stochastic gradient ascent  where on the tth
step of the algorithm  we make the following updates to the

parameters in parallel

  Minibatches of edges in the graph

Power law simple graphs

   
 

     

        

 
for       and some sequence       of positive numbers satisfying the Robbins Monro criterion  Robbins  

                   
 

Monro   cid 

      and where

   

             log              log        

         and cid 
 cid 

 

log   Xi          

log   Wi   

  cid 

  

 

      

    cid 

  

log   Wi     

 
where   denotes the observed edges  both links and nonlinks  in the dataset  We cannot evaluate the expectation
 with respect to the recti ed gamma distributions        
analytically  and so we elect to use   particular Monte Carlo
approximation of this gradient detailed by Knowles  
which was developed for gamma variational distributions
and easily applies to the recti ed gamma case 
for every        create the collection of
Brie   
  Monte Carlo samples from the variational distribution as follows 
let
    Uniform    and set      
    
      where
        min    
    is the inverse
of the cumulative distribution function for   gamma random variable  For convenience  we recall that
ta   btdt 

Independently for       
    Cn  and    

 
For every        the gradient with respect to the parameters    is then approximated by
  

         

 cid   

ba
   

Fa       

 

 

 

 

 WkL                  

       

 

 cid 

Eq              
   
 

 

                 

where               
    This estimator is unbiased and has low enough variance that often   single sample
suf ces for the approximation  Salimans   Knowles   
Kingma   Welling    The gradient of   is nonzero
      Cn  in which case we may imonly when     
     
mediately obtain the partial derivative with respect to the
 cid      
rate parameter  in particular  we have

  

 

 

   rte
 

if    
     
otherwise 

  

      Cn 

 

   rte     

         

The partial derivative with respect to the shape parameter
   shp      
        does not have   closed form solution and
must be approximated  Different approximation routines
are suggested by Knowles   for different regimes of
the shape parameter    shp  and we found these approximations to be accurate and ef cient in our experiments 

Computing the   required gradients in Eq    may
be done in parallel  and this computation  whether performed analytically or with automatic differentiation methods  scales with the number of edges in the graph  This can
be prohibitive for many network datasets  and we therefore introduce   further approximation where this gradient
is evaluated on subsets         minibatches  of the dataset 
  technique from stochastic gradient ascent  Bottou   
adopted in the context of variational Bayesian inference by
Hoffman et al    In the case of   network dataset 
we may select minibatches that are subsets of the observed
edges in the graph 
In particular  write the gradient of
Eq    with respect to the variable Wk  which is required
by Eq    as

 WkL          

                 

 

      
   Wk  log   Xi  

       
where                
    log           log         is the gradient that
ignores all but one edge of the graph  We may therefore
compute the unbiased estimate of this gradient

 cid 

 WkL              
   

 cid 

      

                 

 

on   minibatch       of the observed edges 

  Inference on the parameters   and  

Without good prior knowledge of how to set the discount
parameter   and the sparsity parameter   controlling the
power law and sparsity behaviors of the graph  respectively 
we infer their values from the data  First consider the discount parameter  which we infer with gradient ascent  After
every update to the latent variables     we    them to their
mean under the distribution                             Wn 
where  Wi   Eq Wi   Wi  and take   step in the direction
of the gradient

  cid 
  cid 

  

  

 cid  Cn

  log            

 

  log     Wi   

 cid   

  

  log   Wi 

 cid 

 

 

 

which is straightforward to derive from the density function
in Eq    and where the normalization term

    

          dw

 

 

is   function of   and   if we let Cn      as suggested
in Section   We do not have   closed form solution for

Power law simple graphs

Table   Comparision between the BFRY model and the Gamma
baseline model on the air traf    blogs  and social network
datasets  The test loglikelihoods were averaged over the last
  of   gradient descent updates 

dataset model
BFRY
 Air
Gamma
polblogs BFRY
Gamma
BFRY
Gamma
BFRY
Gamma

Fb 

open 

max test loglikel
     
     
     
     
     
     
     
     

avg test loglikel
     
     
     
     
     
     
     
     

Figure   Trace plots of the discount parameter   during   different inference runs  each time simulating   dataset from the model
with either             and intializing   randomly 

Table   Comparision between the BFRY model and the Gamma
baseline model when   is known  The test loglikelihoods were
averaged over the last   of   gradient descent updates 

true  

     

     

     

model
BFRY
Gamma
BFRY
Gamma
BFRY
Gamma

max test loglikel
     
     
     
     
     
     

avg test loglikel
     
     
     
     
     
     

       cid  Cn

this term when Cn     and  unfortunately  inference on
model parameters where the likelihood is dif cult to evaluate is   challenging problem  for example  see the approaches taken by Murray et al    on such problems 
which those authors call doubly intractable distributions 
Accurate inference for   is important in our model  because it controls the power law behavior of the graph  In
our experiments  we approximate the gradient in Eq   
for  xed   by approximating     via Eq    and
             log   dw  with line
integrals 
In the Section   we demonstrate that this approximation works well in various regimes of   with slight
overestimation for moderate values 
Similar approaches to infer   may be derived with  
nite difference approximations  we did not  nd these approaches successful in our experiments  however  and so
we instead select   by cross validation 

  Experiments
We  rst demonstrate how the inference procedure in Section   can correctly differentiate between various regimes

of   We ran an experiment where for each value    
        we simulated   datasets from the
model with         nodes  while  xing       For
each simulated dataset  we ran an instance of the inference
routine with   randomly initialized 
In Fig    we show
the trace plots of alpha during each instance of the inference routine  For comparison  the true values of   are also
shown as horizontal dashed lines  We can see that the inference routine can correctly distinguish between these different regimes of   with slight overestimation in the moderate   regime  Interestingly  despite random initializations
of         the algorithm always immediately in ates  
to around   and then slowly decreases this value during
inference  regardless of what value of   generated the data 
We next demonstrate that accurately capturing power law
structures in datasets will improve predictive performance 
While  xing       we simulate three network datasets
with   nodes from our model with discount parameters
        and   respectively  which therefore exhibit
increasingly lightertailed degree distributions  The generated graphs have     and   links  respectively  To establish   baseline model that does not exhibit
power law degree distributions but is otherwise comparable
to our model  we implement the generalized random graph
where the nodespeci   weights are constructed from the
gamma random variables Wi   gamma    for some
positive parameter          for every node        Note
that the parameter   controls the sparsity of the generated
graph  larger values of   imply denser graphs  It follows
analogously to Theorem   that

  Dn            
     

 
for    cid    as       This model therefore does not exhibit power law behavior  as desired  We refer to this model
as  Gamma  and the power law graph model as  BFRY 
We ran an experiment holding out   of the edges in the

 iteration Power law simple graphs

Table   Inferred hyperparameters in the experiments 

BFRY    
Gamma    
BFRY    

true      
     
     

 

true      
     
     

 

true      
     
     

 

 Air

     
     
     

polblogs
     
     
     

Fb 

     
     
     

open 

     
     
     

simulated graphs as test sets  training the two models on
the remaining   of the edges  We used   minibatch size
of   edges  note that the training dataset corresponds
to almost   million observed edges  We ran each inference procedure for   steps of stochastic gradient ascent updates  using Adam  Kingma   Ba    to adjust
the learning rates at each step  We repeated each experiment   times  each time holding out   different test set and
using   different random initialization  Again  for this experiment we  xed       In Table   we report   mean loglikelihood metric for the test datasets  where the metric for
each run is obtained by averaging the test loglikelihoods
across the states for the last   steps of the inference
procedure  the displayed intervals are at   standard deviation about the metric  from across the   repeats  We also
report   max loglikelihood metric  which simply records
the maximum test loglikelihood across the last   steps
of the inference procedure  instead of the average  The best
performing method is highlighted in bold  which in each
case was the BFRY model 
In each case  we see that the BFRY model achieves higher
test loglikelihood metrics than the Gamma model  as expected  implying that accurately capturing   power law degree distribution improves predictive performance  when
power law behavior is truly present in the network 
In
Table   we report the inferred values for   which were
reasonably accurate  though we see slight overestimation
for some regimes  as seen in the demonstration earlier  For
the baseline Gamma model  we optimized the hyperparameter   using gradient ascent maximizing the evidence lower
bound of the model       Eq    and the inferred values
are also reported in Table  
Next  we ran similar experiments on the following network
datasets  each of which are expected to exhibit power law
degree distributions 

   USTop Airports    nodes    links
   open ights    nodes    links
   polblogs    nodes    links
   Facebook    nodes    links

Where appropriate  we saved only the upper triangular
parts of the adjacency matrices  The  USTop Airports 
dataset contains the  undirected  unweighted   ight connections between the   busiest US airports  The similar 

though much larger   open ights  dataset contains the  ight
connections between nonUS airports  Scalefree networks
have been proposed for such traf   networks  detailed for
these datasets by Colizza et al    The  polblogs 
dataset contains the links between political blogs  judged
by hyperlinks between the front webpages of the blogs  in
the period leading up to the   US presidential election 
which is observed to exhibit power law degree distributions
by Adamic   Glance   The  Facebook  dataset
contains  friendships  between users of   Facebook app 
collected by Leskovec   McAuley   social networks
are widely studied for their power law degree distributions 
For both the Gamma and BFRY models  we ran our variational inference procedure for   steps on each dataset 
As before  we repeated the experiment   times for each network  each time holding out   different   of the edges
in the network as   testing set  We selected the value of
  from among the grid           with  fold
cross validation on the training set  We set the minibatch
size to be equal to the number of nodes in the graph  for
example  we used minibatches of   edges for the polblog dataset  The evaluation metrics on the test datasets
are summarized in Table   and the inferred hyperparameter values are reported in Table   We see that the BFRY
model once again outperforms the Gamma baseline model 
according to the test loglikelihood metrics 
Probabilistic inference on   by the BFRY model provides
some of the most interesting analyses here  With      
 under owing our machine   precision  the Facebook 
social network has the degree distribution with the heaviest tails  followed by the USTop Airports traf   network
with       the polblog citation network with      
and the open ights network has the lightest tailed degree
distribution with      

  Future work
Future work could focus on implementing the latent factor
modeling generalizations presented in Section   which are
natural assumptions in many domains where networks are
expected to exhibit power law degree distributions  Alternative approaches to inference on the sparsity parameter  
should also be explored  since controlling the sparsity in
the graph was important for good predictive performance 

Power law simple graphs

Acknowledgements
The authors thank Remco van der Hofstad for helpful advice and anonymous reviewers for helpful feedback     Lee
and    Choi were partly supported by an Institute for Information   Communications Technology Promotion  IITP 
grant  funded by the Korean government  MSIP   No 
  Basic Software Research in Humanlevel Lifelong Machine Learning  Machine Learning Center  and
Naver  Inc     Heaukulani undertook this work in part
while   visiting researcher at the Hong Kong University
of Science and Technology  who along with       James
was funded by grant rgchkust   of the Hong Kong
Special Administrative Region 

References
Adamic        and Glance    

The political blodivided they
gosphere and the   US election 
the  rd international
blog 
workshop on Link discovery 
 
URL http www cise ufl edu research 
sparse matrices Newman polblogs 

In Proceedings of

pp   

Airoldi        Blei        Fienberg        and Xing 
      Mixed membership stochastic blockmodels  In Advances in Neural Information Processing Systems   

Albert     and Barab asi  AL  Statistical mechanics of complex networks  Reviews of modern physics   
 

Barab asi     and Albert     Emergence of scaling in ran 

dom networks  Science     

Bertoin     Fujita     Roynette     and Yor     On  
particular class of selfdecomposable random variables 
the durations of bessel excursions straddling independent exponential times  Probability and Mathematical
Statistics     

Bollob as     Random graphs  Springer   

Bollob as     and Riordan        Mathematical results on
scalefree random graphs  Handbook of graphs and networks  from the genome to the internet  pp     

Bollob as     Riordan     Spencer     and Tusn ady     The
degree sequence of   scalefree random graph process 
Random Structures   Algorithms     

Bottou     Largescale machine learning with stochastic

gradient descent  In COMPSTAT   

Britton     Deijfen     and MartinL of     Generating
simple random graphs with prescribed degree distribution  Journal of Statistical Physics   
 

Cai     and Broderick     Completely random measures
for modeling power laws in sparse graphs  In NIPS  
Workshop on Networks in the Social and Information
Sciences   

Caron     and Fox        Sparse graphs using exchangeable random measures  arXiv preprint arXiv 
 

Colizza    

PastorSatorras    

and Vespignani 
Reaction diffusion processes and metapopA 
networks 
ulation
models
Nature Physics 
URL
https sites google com site cxnets 
usairtransportationnetwork 

heterogeneous
 

in
 

Crane     and Dempsey     Atypical scaling behavior persists in real world interaction networks  arXiv preprint
arXiv   

Crane     and Dempsey     Edge exchangeable models for

network data  arXiv preprint arXiv   

Devroye     and James        On simulation and properties
of the stable law  Statistical methods   applications   
   

Dorogovtsev        and Mendes           Evolution of net 

works  Advances in physics     

Ghahramani     Grif ths        and Sollich     Bayesian
nonparametric latent feature models  Bayesian Statistics 
    See also the discussion and rejoinder 

Hoffman        Blei        Wang     and Paisley       
Journal of Machine

Stochastic variational inference 
Learning Research     

James        Orbanz     and Teh        Scaled subordinators and generalizations of the Indian buffet process 
arXiv preprint arXiv   

Jordan        Ghahramani     Jaakkola        and Saul 
      An introduction to variational methods for graphical models  Machine learning     

Kemp     Tenenbaum        Grif ths        Yamada    
and Ueda     Learning systems of concepts with an in 
nite relational model  In AAAI   

Kingma        and Ba     Adam    method for stochastic

optimization  In ICLR   

Kingma        and Welling     Autoencoding variational

Bayes  In ICLR   

Knowles       

Stochastic gradient variational Bayes
for gamma approximating distributions  arXiv preprint
arXiv   

Power law simple graphs

Lee     James        and Choi     Finitedimensional
BFRY priors and variational Bayesian inference for
power law models  In Advances In Neural Information
Processing Systems  pp     

social circles

in ego networks 

Leskovec     and McAuley       

Learning to disIn Adcover
vances in Neural Information Processing Systems  
 
URL https snap stanford edu 
data egonetsFacebook html 

Miller     Jordan        and Grif ths        Nonparametric
latent feature models for link prediction  In Advances in
neural information processing systems   

Murray     Ghahramani     and MacKay           Mcmc

for doublyintractable distributions  In UAI   

Nowicki     and Snijders           Estimation and prediction for stochastic blockstructures  Journal of the American Statistical Association     

Pitman     and Yor    

The twoparameter Poisson 
Dirichlet distribution derived from   stable subordinator 
The Annals of Probability  pp     

Robbins     and Monro       stochastic approximation
method  The Annals of Mathematical Statistics   
   

Salimans     and Knowles        Fixedform variational
posterior approximation through stochastic linear regression  Bayesian Analysis     

van der Hofstad     Random graphs and complex networks  Volume   Cambridge Series in Statistical
and Probabilistic Mathematics  Cambridge University
Press    URL http www win tue nl 
 rhofstad NotesRGCN pdf 

Veitch     and Roy        The class of random graphs arising from exchangeable random measures  arXiv preprint
arXiv   

