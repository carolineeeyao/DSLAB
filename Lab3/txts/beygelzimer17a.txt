Ef cient Online Bandit Multiclass Learning with        Regret

Alina Beygelzimer   Francesco Orabona   Chicheng Zhang  

Abstract

We present an ef cient secondorder algorithm
     regret for the bandit online mulwith      
 
ticlass problem  The regret bound holds simultaneously with respect to   family of loss functions
parameterized by   for   range of   restricted
by the norm of the competitor  The family of
loss functions ranges from hinge loss      
to squared hinge loss       This provides  
solution to the open problem of  Abernethy    
and Rakhlin     An ef cient bandit algorithm
for     regret in online multiclass prediction 
In COLT    We test our algorithm experimentally  showing that it also performs favorably
against earlier algorithms 

  Introduction
In the online multiclass classi cation problem  the learner
must repeatedly classify examples into one of   classes  At
each step    the learner observes an example xt   Rd and
In the fullinformation case 
predicts its label  yt      
the learner observes the true label yt       and incurs loss
 yt   yt  In the bandit version of this problem   rst considered in  Kakade et al    the learner only observes
its incurred loss  yt   yt       whether or not its prediction was correct  Bandit multiclass learning is   special
case of the general contextual bandit learning  Langford  
Zhang    where exactly one of the losses is   and all
other losses are   in every round 
The goal of the learner is to minimize its regret with respect to the best predictor in some reference class of predictors  that is the difference between the total number of
mistakes the learner makes and the total number of mis 
 Yahoo Research  New York  NY  Stony Brook University 
Stony Brook  NY  University of California  San Diego  La Jolla 
CA  Correspondence to  Alina Beygelzimer  beygel yahooinc com  Francesco Orabona  francesco orabona com 
Chicheng Zhang  chichengzhang ucsd edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

      hides logarithmic factors 

takes of the best predictor in the class  Kakade et al   
proposed   bandit modi cation of the Multiclass Perceptron algorithm  Duda   Hart    called the Banditron 
that uses   reference class of linear predictors  Note that
even in the fullinformation setting  it is dif cult to provide
  true regret bound  Instead  performance bounds are typically expressed in terms of the total multiclass hinge loss
of the best linear predictor    tight upper bound on   loss 
The Banditron  while computationally ef cient  achieves
only       expected regret with respect to this loss 
where   is the number of rounds  This is suboptimal as the
Exp  algorithm of Auer et al    can achieve       
regret for the   loss  albeit very inef ciently  Abernethy
  Rakhlin   posed an open problem  Is there an ef 
 cient bandit multiclass learning algorithm that achieves
expected regret of        with respect to any reasonable
loss function 
The  rst attempt to solve this open problem was by Crammer   Gentile   Using   stochastic assumption about
the mechanism generating the labels  they were able to
show          regret  with   secondorder algorithm 
Later  Hazan   Kale   following   suggestion by
Abernethy   Rakhlin   proposed the use of the logloss coupled with   softmax prediction  The softmax depends on   parameter that controls the smoothing factor 
The value of this parameter determines the expconcavity
of the loss  allowing Hazan   Kale   to prove
worstcase regret bounds that range between   log     and
    again with   secondorder algorithm  However  the
   
choice of the smoothing factor in the loss becomes critical
in obtaining strong bounds 
The original Banditron algorithm has been also extended
in many ways  Wang et al    have proposed   variant
based on the exponentiated gradient algorithm  Kivinen  
Warmuth    Valizadegan et al    proposed different strategies to adapt the exploration rate to the data in
the Banditron algorithm  However  these algorithms suffer
from the same theoretical shortcomings as the Banditron 
There has been signi cant recent focus on developing ef 
 cient algorithms for the general contextual bandit problem  Dud   et al    Agarwal et al    Rakhlin  
Sridharan    Syrgkanis et al        While solving

 

Ef cient Online Bandit Multiclass Learning

  more general problem that does not make assumptions
on the structure of the reward vector or the policy class 
these results assume that contexts or context reward pairs
are generated        or the contexts to arrive are known beforehand  which we do not assume here 
In this paper  we follow   different route  Instead of designing an adhoc loss function that allows us to prove strong
guarantees  we propose an algorithm that simultaneously
satis es   regret bound with respect to all the loss functions
in   family of functions that are tight upper bounds to the  
  loss  The algorithm  named Second Order Banditron Algorithm  SOBA  is ef cient and based on the secondorder
Perceptron algorithm  CesaBianchi et al    The regret bound is of the order of        providing   solution
to the open problem of Abernethy   Rakhlin  

  De nitions and Settings
We  rst introduce our notation  Denote the rows of   matrix
    Rk   by               vk  The vectorization of   is
de ned as vec                      vk     which is   vector
in Rkd  We de ne the reverse operation of reshaping   kd 
  vector into        matrix by mat     using   rowmajor
order  To simplify notation  we will use   and vec    
interchangeably throughout the paper  For matrices   and
   denote by     their Kronecker product  For matrices
  and   of the same dimension  denote by          
     Xi jYi   their inner product  We use       to denote
the   norm of   vector  and        to denote the Frobenius
norm of   matrix  For   positive de nite matrix    we use
          Ax  to denote the Mahalanobis norm of  
with respect to    We use    to denote the vector in Rk
whose entries are all    
We use Et  to denote the conditional expectation given
the observations up to time       and xt  yt  that is       
            xt  yt   yt  xt  yt 
Let     denote              the set of possible labels  In our
setting  learning proceeds in rounds 
For                    

learner  and commits to   hidden label yt      
    is   probability distribution over    

  The adversary presents an example xt   Rd to the
  The learner predicts   label  yt   pt  where pt  
  The learner receives the bandit feedback  yt   yt 
The goal of the learner is to minimize the total number of
mistakes  MT   
We will use linear predictors speci ed by   matrix
    Rk    The prediction is given by        
arg maxi          where        is the ith element of

 yt   yt 

  

the vector      corresponding to class   
  useful notion to measure the performance of   competitor
    Rk   is the multiclass hinge loss

              max
   

                    

 

where     max   
    History of Loss Functions
As outlined in the introduction    critical choice in obtaining strong theoretical guarantees is the choice of the loss
function  In this section we introduce and motivate   family of multiclass loss functions 
In the full information setting  strong binary and multiclass
mistake bounds are obtained through the use of the Perceptron algorithm  Rosenblatt      common misunderstanding of the Perceptron algorithm is that it corresponds
to   gradient descent procedure with respect to the  binary
or multiclass  hinge loss  However  it is well known that
the Perceptron simultaneously satis es mistake bounds that
depend on the cumulative hinge loss and also on the cumulative squared hinge loss  see for example Mohri   Rostamizadeh   Note also that the squared hinge loss is
not dominated by the hinge loss  so  depending on the data 
one loss can be better than the other 
We show that the Perceptron algorithm satis es an even
stronger mistake bound with respect to the cumulative loss
of any power of the multiclass hinge loss between   and  
Theorem   On any sequence                 xT   yT   with
 xt      for all          and any linear predictor    
Rk    the total number of mistakes MT of the multiclass
Perceptron satis es  for any        

MT    

   
   

 

 
 

MH                MT  

it simultaneously satis es the following 

         xt  yt    In particular 

          LMH    
          LMH      

where LMH           
MT   LMH             
MT   LMH         
For the proof  see Appendix   
  similar observation was done by Orabona et al   
who proved   logarithmic mistake bound with respect to
all loss functions in   similar family of functions smoothly
interpolating between the hinge loss to the squared hinge
loss 
In particular  Orabona et al    introduced the
following family of binary loss functions

         

 

       

          
       

 

Ef cient Online Bandit Multiclass Learning

Algorithm   Second Order Banditron Algorithm  SOBA 
Input  Regularization parameter       exploration pa 

rameter        

  

Receive instance xt   Rd
 yt   arg maxi   Wtxt  
De ne pt          yt    
Randomly sample  yt according to pt
Receive bandit feedback  yt   yt 
Initialize update indicator nt    
if  yt   yt then

  Initialization              aI       
  for                   do
 
 
 
 
 
 
 
 
 
 
 

 yt   arg maxi   yt Wtxt  
gt    
   yt   eyt     xt
pt yt
zt    pt yt gt
mt    Wt   zt Wt   gt 

 

Figure   Plot of the loss functions in   for different values of  

where           Note that       recovers the binary hinge loss  and       recovers the squared hinge
loss  Meanwhile  for any                
max        and   is an upper bound on   loss 
             See Figure   for   plot of the different
functions in the family 
Here  we de ne   multiclass version of the loss in   as

                       max

   

         

 

Hence                            is the classical multiclass hinge loss and                           is the
squared multiclass hinge loss 
     regret bound that holds siOur algorithm has        
 
multaneously for all loss functions in this family  with   in
  range that ensure that                    
              
We also show that there exists   setting of the parameters of the algorithm that gives   mistake upper bound of
              where    is the cumulative hinge loss
of the competitor  which is never worse that the best bounds
in Kakade et al   

  Second Order Banditron Algorithm
This section introduces our algorithm for bandit multiclass
online learning  called Second Order Banditron Algorithm
 SOBA  described in Algorithm  
SOBA makes   prediction using the  greedy strategy  At
each iteration    with probability       it predicts  yt  
arg maxi   Wtxt    with the remaining probability   it
selects   random action in     As discussed in Kakade
et al    randomization is essential for designing bandit multiclass learning algorithms  If we deterministically
output   label and make   mistake  then it is hard to make an
update since we do not know the identity of yt  However 

 zT

    

  zt

end if

if mt    

   nsms     then

Turn on update indicator nt    

end if
Update At   At    ntztzT
Update            ntgt
Set Wt    mat   
     

 
 
 
 
 
 
 
  end for
Remark  matrix At is of dimension kd   kd  and vector
   is of dimension kd  in line   the matrix multiplication
results in   kd dimensional vector  which is reshaped to
matrix Wt  of dimension       

 

   nszszT

Perceptronstyle updates        
corrected covariance matrix At   aI   

if randomization is used  we can estimate yt and perform
online stochastic mirror descent type updates  Bubeck  
CesaBianchi   
SOBA keeps track of two model parameters  cumulative
   nsgs   Rkd and
   
Rkd kd  The classi er Wt is computed by matricizing over
the matrixvector product   
       Rkd  The weight
vector    is standard in designing online mirror descent
type algorithms  ShalevShwartz    Bubeck   CesaBianchi    The matrix At is standard in designing online learning algorithms with adaptive regularization  CesaBianchi et al    Crammer et al    McMahan  
Streeter    Duchi et al    Orabona et al   
The algorithm updates its model  nt     only when the
following conditions hold simultaneously    the predicted
label is correct  yt   yt  and   the  cumulative regulars  nsms  mt  is positive if this
update were performed  Note that when the predicted label
is correct we know the identity of the true label 
As we shall see  the set of iterations where nt     includes all iterations where  yt   yt    yt  This fact is cru 

ized negative margin     

Ef cient Online Bandit Multiclass Learning

cial to the mistake bound analysis  Furthermore  there are
some iterations where  yt   yt    yt but we still make an
update  This idea is related to  online passiveaggressive
algorithms   Crammer et al      in the full information setting  where the algorithm makes an update even
when it predicts correctly but the margin is too small 
Let   now describe our algorithm more in details  Throughout  suppose all the examples are  bounded   xt      
As outlined above  we associate   timevarying regularizer
  is
Rt        
   
  kd   kd matrix and

At  where At   aI   

   nszszT

zt    pt yt gt  

 

 pt yt

   yt   eyt     xt  

Note that this timevarying regularizer is constructed by
scaled versions of the updates gt  This is critical  because
in expectation this becomes the correct regularizer  Indeed 
it is easy to verify that  for any     Rk   
Et yt    yt  gt       yt   eyt     xt 
Et yt    yt       zt            yt   eyt     xt   
In words  this means that in expectation the regularizer contains the outer products of the updates  that in turn promote
the correct class and demotes the wrong one  We stress
that it is impossible to get the same result with the estimator proposed in Kakade et al    Also  the analysis
is substantially different from the Online Newton Step approach  Hazan et al    used in Hazan   Kale  
In reality  we do not make an update in all iterations in
which  yt   yt  since the algorithm need to maintain the
   msns     which is crucial to the
proof of Lemma   Instead  we prove   technical lemma
that gives an explicit form on the expected update ntgt and
expected regularization ntztzT

invariant that   

    De ne

qt        

nsms   mt      

ht    yt   yt    qt yt   yt   

Lemma   For any     Rkd 
Et   nt      gt    ht       eyt     yt     xt   
Et nt      zt    ht       eyt     yt     xt   

The proof of Lemma   is deferred to the end of Subsection  
Our last contribution is to show how our second order algorithm satis es   mistake bound for an entire family of

loss functions  Finally  we relate the performance of the
algorithm that predicts  yt to the  greedy algorithm 
Putting all together  we have our expected mistake bound
for SOBA   
Theorem   SOBA has the following expected upper bound
on the number of mistakes  MT   for any     Rk   and any
        min 

  maxi  ui     

 

   MT            
 

 

     

  

 

       
    
  zT

    

  zt       

         xt  yt  is the cumulative
   are rows of

where           
 loss of the linear predictor    and  ui  
  
In particular  setting             ln  
   MT                    

have

   

 
 

 

  and         we

 dT ln     

Note that  differently from previous analyses  Kakade
et al    Crammer   Gentile    Hazan   Kale 
  we do not need to assume   bound on the norm of
the competitor  as in the full information Perceptron and
Second Order Perceptron algorithms  In Appendix    we
also present an adaptive variant of SOBA that sets exploration rate    dynamically  which achieves   regret bound
within   constant factor of that using optimal tuning of  
We prove Theorem   in the next Subsection  while in Subsection   we prove   mistake bound with respect to the
hinge loss  that is not fully covered by Theorem  

  Proof of Theorem  
Throughout the proofs     Wt  gt  and zt   should be
thought of as kd     vectors  We  rst show the following lemma  Note that this is   statement over any sequence
and no expectation is taken 
Lemma   For any     Rkd  with the notation of Algorithm   we have 

    

nt      gt         zt 
      

    

ntgT

   

  gt  

    

 Throughout the paper  expectations are taken with respect to

the randomization of the algorithm 

Ef cient Online Bandit Multiclass Learning

Proof  First  from line   of Algorithm   it can be seen
 by induction  that SOBA maintains the invariant that

Proof  Using Lemma   with     we get that

    

nsms    

 

    

nt        gt           zt 
      

    

  gt  

ntgT

   

    

   nszszT

We next reduce the proof to the regret analysis of online
least squares problem  For iterations where nt     deso that gt    tzt  From the algorithm 
 ne       pt yt
At   aI   
    and Wt is the ridge regression solution based on data collected in time   to           
Wt     
   ns szs 
By perstep analysis in online least squares   see      
Orabona et al   See Lemma   for   proof  we have
that if an update is made at iteration         nt     then

    

    

   nsgs      

 
 

    
 Wt   zt          zT
 
     Wt 
 
At   

 
     Wt 

  zt   

     zt       
At  

 
 

Otherwise nt     in which case we have Wt    Wt
and At    At 
Denoting by kt       zT
formula  kt  
 zT
  zt
     such that nt    

    
  zt  by ShermanMorrison
  Summing over all rounds    

    

 

 
 

    

 

nt Wt   zt       kt        zt       
 
 
   
   
   

 
     WT  

AT  

    

We also have by de nition of mt 

  zt  

we have the stated bound 

    
  zT
   ntmt    

 Wt   zt       kt        zt       
  mt        gt         zt     
Putting all together and using the fact that  
diction  yt  de ned as  MT   
 yt   yt 
Theorem   For any     Rk    and any        
  maxi  ui      the expected number of mistakes
min 
committed by  yt can be bounded as

We can now prove the following mistake bound for the pre 

  

 

    MT           

         

where         

linear predictor   

 

    
     
    
     

 

 

 

  zt 

    

     ntzT
     

   
       
dk  ln          

     

 

         xt  yt  is the  loss of the

Taking expectations  using Lemma   and the fact that
pt yt    

  and that At is positive de nite  we have

 

            
         

ht           eyt     yt     xt 
ht         eyt     yt     xt 

 

 
 

   

  zt   

    

  ntzT

      

vide both sides by       to have

    
   ht  to both sides and diAdd the terms         
htf       eyt     yt     xt 
       

ht           
       
       
     Taking   close look
where              
at the function    we observe that the two roots of the
quadratic function are   and  
    respectively  Setting
      the function is negative in    
    and positive in
  maxi  ui    then
    Additionally  if        
for all                  ei   ej    xt     
    Therefore 
we have that

     

    

  ntzT

    

  zt 

   

  

 

 

 

        eyt     yt     xt 

       xt yt      xt yt  
       xt yt      xt yt  

  yt

   xt            xt  yt   

     xt yt   max
where the  rst equality is from algebra  the  rst inequality is from that         in    
    the second
inequality is from that   is monotonically decreasing 
Putting together the two constraints on   and noting that
 MT   

The second statement follows from Lemma   below 

   ht  we have the  rst bound 

Ef cient Online Bandit Multiclass Learning

    

  ntzT

    

Lemma   If                   then
  zt    dk ln   

         
Speci cally  if         the right hand side is   dk ln    
Proof  Observe that

     

ntzT

    

    
      ln   

  zt   ln  AT 
   
     

  
     

 yt yt 

pt yt

   

   yt 

  yt    yt

In this case   yt    yt  therefore
 Wt   gt      making mt     This implies that
   
   nsms   mt     guaranteeing nt    
  yt    yt    yt  In this case  nt is set to   if and only if
qt           

   nsms   mt    

This gives that nt   Gt   Ht 
Second  we have the following two equalities 

Et   Ht      gt 
  Et   yt   yt 

pt yt

 yt   yt      eyt     yt     xt 

   yt   yt      eyt     yt     xt   

Et   Gt      gt 
  Et   yt   yt 

pt yt

 yt   yt qt       eyt     yt     xt 

is

the

statement

second
identi 
      eyt     yt     xt  with

   yt   yt qt       eyt     yt     xt   
The  rst statement follows from adding up the two equalities above 
The
proof
for
cal 
except
replacing
      eyt     yt     xt 
  FallBack Analysis
The loss function   is an interpolation between the hinge
and the squared hinge losses  Yet  the bound becomes vacuous for       Hence  in this section we show that SOBA
also guarantees                      mistake bound
             the multiclass hinge loss of the competitor 
assuming       is known  Thus the algorithm achieves
  mistake guarantee no worse than the sharpest bound implicit in Kakade et al   
Theorem   Set         and denote by MT the number
of mistakes done by SOBA  Then SOBA has the following
guarantees 

where the  rst inequality is   wellknown fact from linear
algebra       Hazan et al    Lemma   Given that the
AT is kd   kd  the second inequality comes from the fact
that  AT  is maximized when all its eigenvalues are equal
to tr AT  
 
Finally  using Jensen   inequality  we have that 

   nt zt 

     

  
   

   yt yt  

pt yt

   

            
    

  ntzT

    

  zt        ln   

     
         

     

If         then the right hand side is     ln    
is at most dk ln   under the conditions on          

      which

Proof of Theorem   Observe that by triangle inequality 
 yt   yt     yt    yt     yt    yt  Summing over
   taking expectation on both sides  we conclude that

  MT         MT         

 

The  rst statement follows from combining the above inequality with Theorem  
For the second statement   rst note that from Theorem  
and Equation   we have

  MT            

 

    
     
               

 

   

       
dk  ln          

     

      ln  

     

 

    

 

 

where the second inequality is from that       and
Lemma   with         The statement is concluded by
the setting of            ln  
Proof of Lemma   We show the lemma in two steps  Let
Gt   qt    yt    yt    yt  and Ht    yt    yt    yt 
First  we show that nt   Gt   Ht  Recall that SOBA
maintains the invariant   hence   
   nsms     From
line   of SOBA  we see that nt     only if  yt   yt  Now
consider two cases 

  If            

     dk      ln     then with
 

parameter setting     min    dk          ln  
one has the following expected mistake bound 

   

  MT          
                       ln      

 Assuming the knowledge of      it would be possible to
reduce the dependency on      in both bounds  However such
assumption is extremely unrealistic and we prefer not to pursue it 

Ef cient Online Bandit Multiclass Learning

  If            

     dk      ln     then with
  one

parameter setting     min            ln  
has the following expected mistake bound 

 

  MT                   

       dT ln     

         xt  yt  is the hinge loss of

Proof  Recall that  MT the mistakes made by  yt  that is
 yt   yt  Adding to both sides of   the term
   ht  and dividing both sides by   and plugging

  

        we get that for all      

ht             eyt     yt     xt 

          yt   eyt     xt 

    
     

ln  

the linear classi er   

where         
  
    
ht           
       
    
    
     
         

ht  

   

 

 

 

 

    
     

ln    

      xt  yt        

 

       

     

ht  

inequality

uses Lemma

the  rst
inequality

 
from CauchySchwarz

the
where
that
second
      eyt     yt     xt            eyt     yt     xt   
       and that           eyt     yt     xt   
      xt  yt 

is

Taking    

   

dk 
  ln  

       ht   

         we have

 

 

ln  

          
ht   

ht   
         

       
ht         
   
         
           
inequality                   and the setting of
        Solving the inequality and using the fact that
  MT         MT             
   ht         we have
             
      

inequality is due to the elementary

          

        
      ln  
 

  MT               

      ln  
 

where the last

   

ln    

 

 

                 ln              

The theorem follows from Lemma   in Appendix    taking
       
  Empirical Results
We tested SOBA to empirically validate the theoretical
 ndings  We used three different datasets from Kakade
et al    SynSep  SynNonSep  Reuters 
The  rst two are synthetic  with   samples in    and
  classes  SynSep is constructed to be linearly separable  while SynNonSep is the same dataset with   random label noise  Reuters  is generated from the RCV 
dataset  Lewis et al    extracting the   examples that have exactly one label from the set  CCAT 
ECAT  GCAT  MCAT  It contains   features  We
also report the performance on Covtype from LibSVM
repository  We report averages over   different runs 
SOBA  as the Newtron algorithm  has   quadratic complexity in the dimension of the data  while the Banditron and
the Perceptron algorithm are linear  Following the long tradition of similar algorithms  Crammer et al    Duchi
et al    Hazan   Kale    Crammer   Gentile 
  to be able to run the algorithm on large datasets 
we have implemented an approximated diagonal version of
SOBA  named SOBAdiag  It keeps in memory just the diagonal of the matrix At  Following Hazan   Kale  
we have tested only algorithms designed to work in the
fully adversarial setting  Hence  we tested the Banditron
and the PNewtron  the diagonal version of the Newtron algorithm in Hazan   Kale   The multiclass Perceptron algorithm was used as   fullinformation baseline 
In the experiments  we only changed the exploration rate  
leaving  xed all the other parameters the algorithms might
have 
In particular  for the PNewtron we set      
      and       as in Hazan   Kale   In
SOBA    is  xed to   in all the experiments  We explore
the effect of the exploration rate   in the  rst row of Figure
  We see that the PNewtron algorithm  thanks to the exploration based on the softmax prediction  can achieve very
good performance for   wide range of  
It is important to note that SOBAdiag has good performance on all four datasets for   value of   close to   For
bigger values  the performance degrades because the best
possible error rate is lower bounded by   
    due to explo 

 https www csie ntu edu tw cjlin 

libsvmtools datasets 

 We were unable to make the PNewtron work on Reuters 
For any setting of   the error rate is never better than   The
reason might be that the dataset RCV  has   features  while
the one reported in Kakade et al    Hazan   Kale  
has   hence the optimal setting of the   other parameters
of PNewtron might be different  For this reason we prefer not to
report the performance of PNewtron on Reuters 

SynSep

Banditron
PNewtron
SOBAdiag
Perceptron

 

 

 

 

 

 

 
 
 
 
 
 
 
 
 

 

   

   

   

   

SynSep

Banditron  

   
   
PNewtron  
SOBAdiag      
Perceptron

   

   

   

   

 

 

 
 
 
 
 
 
 
 

   

   

   

Ef cient Online Bandit Multiclass Learning

SynNonSep

Banditron
PNewtron
SOBAdiag
Perceptron

Covtype

Banditron
PNewtron
SOBAdiag
Perceptron

 

 

 

 

 

 

 
 
 
 
 
 
 
 
 

 

 

   

   

   

   

 

   

   

   

   

Covtype

Banditron  

   
   
PNewtron  
SOBAdiag      
Perceptron

SynNonSep

Banditron  

   
   
PNewtron  
SOBAdiag      
Perceptron

 

 

 

 

 

 

 
 
 
 
 
 
 
 
 

 

 
 
 
 
 
 
 
 
 

 

 

 

 

 

 

 

 

 

   

 

 

 
 
 
 
 
 
 
 

   

Reuters 

Banditron
SOBAdiag
Perceptron

   

   

   

Reuters 

   
Banditron  
SOBAdiag      
Perceptron

 

 

 

 

 

 

 

 
 
 
 
 
 
 
 

 
   

   

 

 

 
 
 
 
 
 
 
 

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

   

number of examples

number of examples

number of examples

number of examples

Figure   Error rates vs 
logarithmic in all the plots  while the yaxis is logarithmic in the plots in the second row  Figure best viewed in colors 

the value of the exploration rate    top row  and vs 

the number examples  bottom row  The xaxis is

ration  For smaller values of exploration  the performance
degrades because the algorithm does not update enough  In
fact  SOBA updates only when  yt   yt  so when   is too
small the algorithms does not explore enough and remains
stuck around the initial solution  Also  SOBA requires an
initial number of updates to accumulate enough negative

terms in the   ntmt in order to start updating also when

 yt is correct but the margin is too small 
The optimal setting of   for each algorithm was then used
to generate the plots in the second row of Figure   where
we report the error rate over time  With the respective optimal setting of   we note that the performance of PNewtron
does not seem better than the one of the Multiclass Perceptron algorithm  and on par or worse to the Banditron   one 
On the other hand  SOBAdiag has the best performance
among the bandits algorithms on   datasets out of  
The  rst dataset  SynSep  is separable and with their optimal setting of   all the algorithms converge with   rate of
    as can be seen from the loglog plot  but the
roughly     
bandit algorithms will not converge to zero error rate  but
to   
    However  SOBA has an initial phase in which the
error rate is high  due to the effect mentioned above 
On the second dataset  SynNonSep  SOBAdiag outperforms all
the other algorithms  including the fullinformation Perceptron  achieving an error rate close to
the noise level of   This is due to SOBA being   secondorder algorithm  while the Perceptron is    rstorder algorithm    similar situation is observed on Covtype  On the
last dataset  Reuters  SOBAdiag achieves performance
better than the Banditron 

  Discussion and Future Work
In this paper  we study the problem of online multiclass
learning with bandit feedback  We propose SOBA  an algo 
     with respect to  
rithm that achieves   regret of      
 
loss of the competitor  This answers   COLT open problem
posed by  Abernethy   Rakhlin    Its key ideas are to
apply   novel adaptive regularizer in   second order online
learning algorithm  coupled with updates only when the
predictions are correct  SOBA is shown to have competitive performance compared to its precedents in synthetic
and real datasets  in some cases even better than the fullinformation Perceptron algorithm  There are several open
questions we wish to explore 
Is it possible to design ef cient algorithms with mis 
 
take bounds that depend on the loss of the competitor      

  MT                kdL       kd  This type of

bound occurs naturally in the full information multiclass
online learning setting   see      Theorem   or in multiarmed bandit setting        Neu   
  Are there ef cient algorithms that have    nite mistake
bound in the separable case 
 Kakade et al    provides an algorithm that performs enumeration and plurality
vote to achieve    nite mistake bound in the  nite dimensional setting  but unfortunately the algorithm is impractical  Notice that it is easy to show that in SOBA  yt makes  
logarithmic number of mistakes in the separable case  with
  constant rate of exploration  yet it is not clear how to decrease the exploration over time in order to get   logarithmic number of mistakes for  yt 

Acknowledgments  We thank Claudio Gentile for suggesting the original plan of attack for this problem  and
thank the anonymous reviewers for thoughtful comments 

Ef cient Online Bandit Multiclass Learning

References
Abernethy     and Rakhlin     An ef cient bandit algorithm
for     regret in online multiclass prediction  In COLT 
 

Agarwal     Hsu     Kale     Langford     Li     and
Schapire        Taming the monster    fast and simple
algorithm for contextual bandits  ICML   

Auer     CesaBianchi     and Gentile     Adaptive and
selfcon dent online learning algorithms     Comput 
Syst  Sci     

Auer     CesaBianchi     Freund     and Schapire       
The nonstochastic multiarmed bandit problem  SIAM   
Comput    January  

Bubeck     and CesaBianchi     Regret analysis of
stochastic and nonstochastic multiarmed bandit problems  FnTML     

CesaBianchi     and Lugosi     Prediction  learning  and

games  Cambridge University Press   

CesaBianchi     Conconi     and Gentile       secondorder Perceptron algorithm  SIAM Journal on Computing     

Crammer     and Gentile     Multiclass classi cation with
bandit feedback using adaptive regularization  Machine
learning     

Crammer     Dekel     Keshet     ShalevShwartz    
and Singer     Online passiveaggressive algorithms 
JMLR   Mar   

Crammer     Kulesza     and Dredze     Adaptive regularization of weight vectors  In NIPS  pp     

Kakade        ShalevShwartz     and Tewari     Ef 
cient bandit algorithms for online multiclass prediction 
In ICML  pp    ACM   

Kivinen     and Warmuth     Exponentiated gradient verInformation

sus gradient descent for linear predictors 
and Computation    January  

Langford     and Zhang     The epochgreedy algorithm for
multiarmed bandits with side information  In NIPS  
pp     

Lewis        Yang     Rose        and Li     RCV 
  new benchmark collection for text categorization research  JMLR   Apr   

McMahan    Brendan and Streeter  Matthew  Adaptive bound optimization for online convex optimization 
COLT   

Mohri     and Rostamizadeh    

Perceptron mistake

bounds  arXiv preprint arXiv   

Neu     Firstorder regret bounds for combinatorial semi 

bandits  In COLT  pp     

Orabona     CesaBianchi     and Gentile     Beyond
logarithmic bounds in online learning  In AISTATS  pp 
   

Orabona     Crammer     and CesaBianchi       generalized online mirror descent with applications to classi 
 cation and regression  Machine Learning   
   

Rakhlin     and Sridharan     BISTRO  An ef cient
In

relaxationbased method for contextual bandits 
ICML   

Duchi     Hazan     and Singer     Adaptive subgradient
methods for online learning and stochastic optimization 
JMLR   Jul   

Rosenblatt     The Perceptron    probabilistic model for
information storage and organization in the brain  Psychological review     

Duda        and Hart        Pattern classi cation and scene

analysis  John Wiley   

ShalevShwartz     Online learning and online convex op 

timization  FnTML     

Dud       Hsu        Kale     Karampatziakis     Langford     Reyzin     and Zhang     Ef cient optimal
learning for contextual bandits  In UAI   pp   
   

Hazan     and Kale     Newtron  an ef cient bandit alIn NIPS  pp 

gorithm for online multiclass prediction 
   

Syrgkanis  Vasilis  Krishnamurthy  Akshay  and Schapire 
Robert  Ef cient algorithms for adversarial contextual
learning  In ICML  pp       

Syrgkanis  Vasilis  Luo  Haipeng  Krishnamurthy  Akshay 
and Schapire  Robert   
Improved regret bounds for
oraclebased adversarial contextual bandits  In NIPS  pp 
     

Hazan     Agarwal     and Kale     Logarithmic regret algorithms for online convex optimization  Machine
Learning     

Valizadegan     Jin     and Wang     Learning to trade off
between exploration and exploitation in multiclass bandit prediction  In KDD  pp    ACM   

Ef cient Online Bandit Multiclass Learning

Wang     Jin     and Valizadegan       potentialbased
framework for online multiclass learning with partial
feedback  In AISTATS  pp     

