Robust Budget Allocation via Continuous Submodular Functions

Matthew Staib   Stefanie Jegelka  

Abstract

The optimal allocation of resources for maximizing in uence  spread of information or coverage 
has gained attention in the past years  in particular in machine learning and data mining  But in
applications  the parameters of the problem are
rarely known exactly  and using wrong parameters can lead to undesirable outcomes  We hence
revisit   continuous version of the Budget Allocation or Bipartite In uence Maximization problem introduced by Alon et al    from   robust optimization perspective  where an adversary may choose the least favorable parameters
within   con dence set  The resulting problem
is   nonconvexconcave saddle point problem
 or game  We show that this nonconvex problem can be solved exactly by leveraging connections to continuous submodular functions  and by
solving   constrained submodular minimization
problem  Although constrained submodular minimization is hard in general  here  we establish
conditions under which such   problem can be
solved to arbitrary precision  

  Introduction
The optimal allocation of resources for maximizing in uence  spread of information or coverage  has gained attention in the past few years  in particular in machine
learning and data mining  Domingos   Richardson   
Kempe et al    Chen et al    Gomez Rodriguez  
Sch olkopf    Borgs et al   
In the Budget Allocation Problem  one is given   bipartite
in uence graph between channels   and people     and the
task is to assign   budget      to each channel   in   with
the goal of maximizing the expected number of in uenced
people      Each edge            between channel   and
 Massachusetts Institute of Technology  Correspondence
to  Matthew Staib  mstaib mit edu  Stefanie Jegelka  stefje mit edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

person   is weighted with   probability pst that       an
advertisement on radio station   will in uence person   to
buy some product  The budget      controls how many independent attempts are made via the channel   to in uence
the people in     The probability that   customer   is in uenced when the advertising budget is   is

It                

    pst     

 

and hence the expected number of in uenced people is

      Pt   It    We write                to make the
dependence on the probabilities pst explicit  The total budget   must remain within some feasible set   which may
encode        total budget limitPs             We allow
the budgets   to be continuous  as in  Bian et al   
Since its introduction by Alon et al    several works
have extended the formulation of Budget Allocation and
provided algorithms  Bian et al    Hatano et al   
Maehara et al    Soma et al    Soma   Yoshida 
  Budget Allocation may also be viewed as in uence maximization on   bipartite graph  where information
spreads as in the Independent Cascade model  For integer
   Budget Allocation and In uence Maximization are NPhard  Yet  constantfactor approximations are possible  and
build on the fact that the in uence function is submodular
in the binary case  and DRsubmodular in the integer case
 Soma et al    Hatano et al    If   is continuous 
the problem is   concave maximization problem 
The formulation of Budget Allocation assumes that the
transmission probabilities are known exactly  But this is
rarely true in practice  Typically  the probabilities pst 
and possibly the graph itself  must be inferred from observations  Gomez Rodriguez et al    Du et al   
Narasimhan et al    Du et al    Netrapalli  
Sanghavi    In Section   we will see that   misspeci 
cation or point estimate of parameters pst can lead to much
reduced outcomes    more realistic assumption is to know
con dence intervals for the pst  Realizing this severe de 
 ciency  recent work studied robust versions of In uence
Maximization  where   budget   must be chosen that maximizes the worstcase approximation ratio over   set of possible in uence functions  He   Kempe    Chen et al 
  Lowalekar et al    The resulting optimization
problem is hard but admits bicriteria approximations 

Robust Budget Allocation via Continuous Submodular Functions

In this work  we revisit Budget Allocation under uncertainty from the perspective of robust optimization  Bertsimas et al    BenTal et al    We maximize the
worstcase in uence   not approximation ratio   for   in  
con dence set centered around the  best guess        posterior mean  This avoids pitfalls of the approximation ratio
formulation  which can be misled to return poor worstcase
budgets  as demonstrated in Appendix    while also allowing us to formulate the problem as   maxmin game 

max
   

min

           

 

where an  adversary  can arbitrarily manipulate   within
the con dence set    With    xed          is concave in   
However  the in uence function         is not convex  and
not even quasiconvex  in the adversary   variables pst 
The new  key insight we exploit in this work is that        
has the property of continuous submodularity in     in contrast to previously exploited submodular maximization in  
  and can hence be minimized by generalizing techniques
from discrete submodular optimization  Bach    The
techniques in  Bach    however  are restricted to box
constraints  and do not directly apply to our con dence
sets  In fact  general constrained submodular minimization
is hard  Svitkina   Fleischer    Goel et al    Iwata
  Nagano    We make the following contributions 

  We present an algorithm with optimality bounds for
Robust Budget Allocation in the nonconvex adversarial scenario  

  We provide the  rst results for continuous submodular minimization with box constraints and one more
 nice  constraint  and conditions under which the algorithm is guaranteed to return   global optimum 

  Background and Related Work
We begin with some background material and  along the
way  discuss related work 

  SUBMODULARITY OVER THE INTEGER LATTICE

AND CONTINUOUS DOMAINS

Submodularity is perhaps best known as   property of set
functions    function            de ned on subsets
      of   ground set   is submodular if for all sets
           it holds that                              
           similar de nition extends to functions de ned
over   distributive lattice         the integer lattice  Such  
function   is submodular if for all           it holds that
 
For the integer lattice and vectors             denotes the
coordinatewise maximum and       the coordinatewise

                                     

minimum  Submodularity has also been considered on
continuous domains    Rd  where  if   is also twicedifferentiable  the property of submodularity means that all
offdiagonal entries of the the Hessian are nonpositive      
      
 xi xj     for all        Topkis    Theorem  
These functions may be convex  concave  or neither 
Submodular functions on lattices can be minimized by  
reduction to set functions  more precisely  ring families
 Birkhoff    Combinatorial algorithms for submodular optimization on lattices are discussed in  Khachaturov
et al    More recently  Bach   extended results
based on the convex Lov asz extension  by building on connections to optimal transport  The subclass of   convex
functions admits strongly polynomial time minimization
 Murota    Kolmogorov   Shioura    Murota  
Shioura    but does not apply in our setting 
Similarly  results for submodular maximization extend to
integer lattices        Gottschalk   Peis    Stronger
results are possible if the submodular function also satis 
 es diminishing returns  for all        coordinatewise 
and   such that     ei      it holds that        ei         
     ei       For such DRsubmodular functions  many
approximation results for the set function case extend  Bian
et al    Soma   Yoshida    Soma et al    In
particular  Ene   Nguyen   show   generic reduction
to set function optimization that they apply to maximization  In fact  it also applies to minimization 
Proposition     DRsubmodular function   de ned
on Qn
  ki  can be minimized in strongly polynomial
time      log     
log   log      EO      log     
logO   log    where     maxi ki and EO is the time
complexity of evaluating    Here   ki                ki 
In particular  the time complexity is logarithmic in    For
general lattice submodular functions  this is not possible
without further assumptions 

  RELATED PROBLEMS
  sister problem of Budget Allocation is In uence Maximization on general graphs  where   set of seed nodes
is selected to start   propagation process  The in uence
function is still monotone submodular and amenable to
the greedy algorithm  Kempe et al    but it cannot
be evaluated explicitly and requires approximation  Chen
et al    Stochastic Coverage  Goemans   Vondr ak 
  is   version of Set Cover where the covering sets
Si     are random    variant of Budget Allocation can be
written as stochastic coverage with multiplicity  Stochastic
Coverage has mainly been studied in the online or adaptive setting  where logarithmic approximation factors can
be achieved  Golovin   Krause    Deshpande et al 
  Adamczyk et al   

Robust Budget Allocation via Continuous Submodular Functions

ear combination of monomials of the formQi xci

Our objective function   is   signomial in           lini   General signomial optimization is NPhard  Chiang    but
certain subclasses are tractable  posynomials with all nonnegative coef cients can be minimized via Geometric Programming  Boyd et al    and signomials with   single negative coef cient admit sum of squareslike relaxations  Chandrasekaran   Shah    Our problem   
constrained posynomial maximization  is not in general
  geometric program  Some work addresses this setting
via monomial approximation  Pascual   BenIsrael   
Ecker    but  to our knowledge  our algorithm is the
 rst that solves this problem to arbitrary accuracy 

  ROBUST OPTIMIZATION
Two prominent strategies of addressing uncertainty in parameters of optimization problems are stochastic and robust optimization 
If the distribution of the parameters
is known  stochastic optimization  formulations such as
valueat risk  VaR  and conditional valueat risk  CVaR 
 Rockafellar   Uryasev      apply 
In contrast 
robust optimization  BenTal et al    Bertsimas et al 
  assumes that the parameters  of the cost function and
constraints  can vary arbitrarily within   known con dence
set    and the aim is to optimize the worstcase setting      

min

 

sup

                     Ay     

 

Here  we will only have uncertainty in the cost function 
In this paper we are principally concerned with robust maximization of the continuous in uence function      but
mention some results for the discrete case  While there
exist results for robust and CVaR optimization of modular  linear  functions  Nikolova    Bertsimas   Sim 
  submodular objectives do not in general admit such
optimization  Maehara    but variants admit approximations  Zhang et al    The brittleness of submodular optimization under noise has been studied in  Balkanski
et al      Hassidim   Singer   
Approximations for robust submodular and in uence optimization have been studied in  Krause et al    He  
Kempe    Chen et al    Lowalekar et al   
where an adversary can pick among    nite set of objective
functions or remove selected elements  Orlin et al   

  Robust and Stochastic Budget Allocation
The unknown parameters in Budget Allocation are the
transmission probabilities pst or edge weights in   graph 
If these are estimated from data  we may have posterior
distributions or    weaker assumption  con dence sets for
the parameters  For ease of notation  we will work with
the failure probabilities xst       pst instead of the pst

directly  and write         instead of        
  Stochastic Optimization
If    posterior  distribution of the parameters is known   
simple strategy is to use expectations  We place   uniform prior on xst  and observe nst independent observations drawn from Ber xst  If we observe  st failures and
and  st successes  the resulting posterior distribution on
the variable Xst is Beta     st       st  Given such  
posterior  we may optimize

max

              or
max
   

         

 

 

Proposition   Problems   and   are concave maximization problems over the  convex  set   and can be
solved exactly 

Concavity of   follows since it is an expectation over concave functions  and the problem can be solved by stochastic
gradient ascent or by explicitly computing gradients 
Merely maximizing expectation does not explicitly account
for volatility and hence risk  One option is to include variance  BenTal   Nemirovski    Bertsimas et al   
Atamt urk   Narayanan   

min

                  pVar        

 

but in our case this CVaR formulation seems dif cult 
Fact   For   in the nonnegative orthant 

pVar         need not be convex or concave  and need

not be submodular or supermodular 

the term

This observation does not rule out   solution  but the apparent dif culties further motivate   robust formulation that  as
we will see  is amenable to optimization 

  Robust Optimization
The focus of this work is the robust version of Budget Allocation  where we allow an adversary to arbitrarily set the
parameters   within an uncertainty set     This uncertainty
set may result  for instance  from   known distribution  or
simply assumed bounds  Formally  we solve

max
   

min

           

 

where    RS
  is   convex set with an ef cient projection oracle  and   is an uncertainty set containing an estimate    
In the sequel  we use uncertainty sets    
     Box                   where   is   distance  or divergence  from the estimate     and Box       is the box
        lst  ust  The intervals  lst  ust  can be thought of

Robust Budget Allocation via Continuous Submodular Functions

as either con dence intervals around     or  if  lst  ust   
    enforce that each xst is   valid probability 
Common examples of uncertainty sets used in Robust Optimization are Ellipsoidal and Dnorm uncertainty sets
 Bertsimas et al    Our algorithm in Section   applies to both 
Ellipsoidal uncertainty  The ellipsoidal or quadratic uncertainty set is de ned by
            Box                            
where   is the covariance of the random vector   of probabilities distributed according to our Beta posteriors  In our
case  since the distributions on each xst are independent 
  is actually diagonal  Writing     diag  we have

      nx   Box             
where Rst       xst    xst 
st  
Dnorm uncertainty  The Dnorm uncertainty set is similar to an  ball around     and is de ned as

Rst xst       

      nx        Box        

xst    xst    ust    xst cst         

cst      

      nx   Box                

Essentially  we allow an adversary to increase  xst up to
some upper bound ust  subject to some total budget  
across all terms xst  The set      can be rewritten as
Rst xst       
where Rst xst     xst    xst ust    xst  is the fraction
of the interval  xst  ust  we have used up in increasing xst 
The minmax formulation maxy   minx           has
several merits  the model is not tied to   speci   learning
algorithm for the probabilities   as long as we can choose  
suitable con dence set  Moreover  this formulation allows
to fully hedge against   worstcase scenario 

  Optimization Algorithm
As noted above  the function         is concave as   function of   for  xed    As   pointwise minimum of concave
functions          minx           is concave  Hence  if
we can compute subgradients of       we can solve our
maxmin problem via the subgradient method  as outlined
in Algorithm  
  subgradient gy          at   is given by the gradient of
        for the minimizing      arg minx               

Algorithm   Subgradient Ascent

Input  suboptimality tolerance     initial feasible
budget      
Output   optimal budget   for Problem  
repeat

       arg minx            
       ryI          
                  
        maxy            
                   kg     
       projY                
         

 

until                 

min

min

 

           

              max

gy   ryI       Hence  we must be able to compute   
for any    We also obtain   duality gap  for any       we
have
              max
   
This means we can estimate the optimal value    and
use it in Polyak   stepsize rule for the subgradient method
 Polyak   
But         is not convex in    and not even quasiconvex  For example  standard methods  Wainwright   Chiang    Chapter   imply that                  
       px  is not quasiconvex on   
  Moreover  the
abovementioned signomial optimization techniques do not
apply for an exact solution either  So  it is not immediately
clear that we can solve the inner optimization problem 
The key insight we will be using is that         has   different bene cial property  while not convex          as  
function of   is continuous submodular 
Lemma   Suppose we have       differentiable functions fi          for                  either all nonincreasing or all nondecreasing  Then          Qn
   fi xi  is  
continuous supermodular function from Rn to   
Proof  For       the resulting function is modular and
therefore supermodular  In the case       we simply need
to compute derivatives  The mixed derivatives are

  

 xi xj

      xi     xj    Yk    

fk xk 

 

By monotonicity      and     have the same sign  so their
product is nonnegative  and since each fk is nonnegative 
the entire expression is nonnegative  Hence        is continuous supermodular by Theorem   of  Topkis   
Corollary   The in uence function         de ned in
Section   is continuous submodular in   over the nonnegative orthant  for each      

Robust Budget Allocation via Continuous Submodular Functions

Proof  Since submodularity is preserved under summation 
it suf ces to show that each function It    is continuous
submodular  By Lemma   since fs      zy    is nonnegative and monotone nondecreasing for          the
product         xy   
is continuous supermodular in   
Flipping the sign and adding   constant term yields It   
which is hence continuous submodular 
Conjecture   Strong duality holds      

st

max
   

min

              min
   
then
duality

holds 

max

           

 

the

strong

duality

If
gap
maxy             minx           in Equation  
is zero at optimality 
If         were quasiconvex in   
strong duality would hold by Sion   minmax theorem  but
this is not the case  In practice  we observe that the duality
gap always converges to zero 
Bach   demonstrates how to minimize   continuous submodular function      subject to box constraints
    Box       up to an arbitrary suboptimality gap    
The constraint set   in our Robust Budget Allocation problem  however  has box constraints with an additional constraint           This case is not addressed in any previous work  Fortunately  for   large class of functions   
there is still an ef cient algorithm for continuous submodular minimization  which we present in the next section 

  Constrained Continuous Submodular Function

Minimization

We next address an algorithm for minimizing   monotone
continuous submodular function      subject to box constraints     Box       and   constraint          

 

 

minimize     
    

        
    Box      

If   and   were convex  the constrained problem would
be equivalent to solving  with the right Lagrange multipler
     

minimize             
    
    Box      

Although   and   are not necessarily convex here  it turns
out that   similar approach indeed applies  The main idea
of our approach bears similarity with  Nagano et al   
for the set function case  but our setting with continuous
functions and various uncertainty sets is more general  and
requires more argumentation  We outline our theoretical
results here  and defer further implementation details and
proofs to the appendix 
Following  Bach    we discretize the problem  for  
suf ciently  ne discretization  we will achieve arbitrary accuracy  Let   be an interpolation mapping that maps the

  ki  into Box        Qn

discrete setQn
  li  ui  via the
componentwise interpolation functions Ai    ki     li  ui 
We say Ai is  ne if Ai xi       Ai xi      for all
xi               ki     and we say the full interpolation
function   is  ne if each Ai is  ne 
This mapping yields functions       Qn
    Qn

  ki      and
  ki      via                and       
           is lattice submodular  on the integer lattice 
This construction leads to   reduction of Problem   to  
submodular minimization problem over the integer lattice 

 

minimize              
    

  ki 

   Qn

Ideally  there should then exist     such that the associated
minimizer    yields   close to optimal solution for the
constrained problem  Theorem   below states that this is
indeed the case 
Moreover    second bene   of submodularity is that we can
 nd the entire solution path for Problem   by solving  
single optimization problem 
Lemma   Suppose   is continuous submodular  and
suppose the regularizer   is strictly increasing and separable        Pn
   Ri xi  Then we can recover   minimizer    for the induced discrete Problem   for any
      by solving   single convex optimization problem 
The problem in question arises from   relaxation    that
extends     in each coordinate   to   function on distributions over the domain  ki  These distributions are represented via their inverse cumulative distribution functions
    which take the coordinate xi as input  and output the
probability of exceeding xi  The function    is an analogue
of the Lov asz extension of set functions to continuous submodular functions  Bach    it is convex and coincides
with     on lattice points 
Formally  this resulting single optimization problem is 

    

   Rki 

ji  aixi   xi 

   Qn

  Pki 

minimize     Pn
refers to the set of ordered vectors     Rk that
where Rk
 
satisfy           zk  the notation    xi  denotes the
xith coordinate of the vector     and the aixi are strictly
convex functions given by

 

 

aixi     

 
 

        

   xi      

   xi    

 

Problem   can be solved by FrankWolfe methods
 Frank   Wolfe    Dunn   Harshbarger   
LacosteJulien    Jaggi    This is because the
greedy algorithm for computing subgradients of the Lov asz

Robust Budget Allocation via Continuous Submodular Functions

extension can be generalized  and yields   linear optimization oracle for the dual of Problem   We detail the relationship between Problems   and   as well as how
to implement the FrankWolfe methods  in Appendix   
Let   be the optimal solution for Problem   For any
  we obtain   rounded solution    for Problem   by
thresholding  we set       max             ki  
             or zero if          for all    Each    is
the optimal solution for Problem   with       We use
the largest parameterized solution    that is still feasible 
     the solution    where   solves

min      
    

     
         

 

This   can be found ef ciently via binary search or   linear scan 
Theorem   Let   be continuous submodular and monotone decreasing  with  Lipschitz constant    and let  
be strictly increasing and separable  Assume all entries
       of the optimal solution   of Problem   are distinct  Let           be the thresholding corresponding to the optimal solution   of Problem   mapped
back into the original continuous domain     Then    is
feasible for the continuous Problem   and is      
approximate solution 

            

min

  Box           

    

Theorem   implies an algorithm for solving Problem  
to  optimality    set           compute   which
solves Problem      nd the optimal thresholding of
  by determining the smallest   for which       
   and   map    back into continuous space via the
interpolation mapping   

Optimality Bounds  Theorem   is proved by comparing    and    to the optimal solution on the discretized
mesh

     

     

argmin
  ki      

  Qn

Beyond the theoretical guarantee of Theorem   for any
problem instance and candidate solution    we can compute   bound on the gap between      and         The
following two bounds are proved in the appendix 

  We can generate   discrete point    satisfying
                              

  The Lagrangian yields the bound

                          

Improvements  The requirement in Theorem   that the
elements of   be distinct may seem somewhat restrictive 
but as long as   has distinct elements in the neighborhood
of our particular   this bound still holds  We see in Section   that in practice    almost always has distinct
elements in the regime we care about  and the bounds of
Remark   are very good 
If   is DRsubmodular and   is af ne in each coordinate 
then Problem   can be represented more compactly via
the reduction of Ene   Nguyen   and hence problem   can be solved more ef ciently  In particular  the
in uence function         is DRsubmodular in   when for
each             or         
  Application to Robust Budget Allocation
The above algorithm directly applies to Robust Allocation with the uncertainty sets in Section   The ellipsoidal uncertainty set     corresponds to the constraint that
        Rst xst      with Rst       xst    xst 
st  
and     Box    By the monotonicity of         there
is never incentive to reduce any xst below  xst  so we can
replace Box    with Box      On this interval  each
Rst is strictly increasing  and Theorem   applies 
For Dnorm sets  we have Rst xst     xst    xst ust  
 xst  Since each Rst is monotone  Theorem   applies 

Runtime and Alternatives  Since the core algorithm
is FrankWolfe  it is straightforward to show that Problem   can be solved to  suboptimality in time
       log    where   is the miniIf   has dismum derivative of the functions Ri 
tinct elements separated by  
then choosing    
  results in an exact solution to   in time
       log   
Noting that           is submodular for all   one could
instead perform binary search over   each time converting
the objective into   submodular set function via Birkhoff  
theorem and solving submodular minimization      via one
of the recent fast methods  Chakrabarty et al    Lee
et al    However  we are not aware of   practical implementation of the algorithm in  Lee et al    The
algorithm in  Chakrabarty et al    yields   solution in
expectation  This approach also requires care in the precision of the search over   whereas our approach searches
directly over the      elements of  

  Experiments
We evaluate our Robust Budget Allocation algorithm on
both synthetic test data and   realworld bidding dataset
from Yahoo  Webscope  yah  to demonstrate that our
method yields real improvements  For all experiments  we

Robust Budget Allocation via Continuous Submodular Functions

 

 

 

 

 

 

Dnorm       

 

 

Dnorm       

 

 

 

 

 

 

Ellipsoidal       

 

 

Ellipsoidal       

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Dnorm       

 

 

 

Dnorm       

 

 

 

 

 

 

 

 

 

 

 

 

 

Ellipsoidal       

 

 

Ellipsoidal       

 

 

Figure   Visualization of the sorted values of         blue dots 
with comparison to the particular Lagrange multiplier    orange
line  In most regimes there are no duplicate values  so that Theorem   applies  The theorem only needs distinctness at  

used Algorithm   as the outer loop  For the inner submodular minimization step  we implemented the pairwise
FrankWolfe algorithm of  LacosteJulien   Jaggi   
In all cases  the feasible set of budgets   is      RS
   
Ps             where the speci   budget   depends on
the experiment  Our code is available at git io vHXkO 

  Synthetic
On the synthetic data  we probe two questions    how often does the distinctness condition of Theorem   hold  so
that we are guaranteed an optimal solution  and   what is
the gain of using   robust versus nonrobust solution in an
adversarial setting  For both settings  we set         and
        and discretize with       We generated true
probabilties pst  created Beta posteriors  and built both Ellipsoidal uncertainty sets      and Dnorm sets     
  OPTIMALITY
Theorem   and Remark   demand that the values       
be distinct at our chosen Lagrange multiplier   and  under
this condition  guarantee optimality  We illustrate this in
four examples  for Ellipsoidal or   Dnorm uncertainty set 
and   total in uence budget         Figure   shows
all elements of   in sorted order  as well as   horizontal
line indicating our Lagrange multiplier   which serves as
  threshold  Despite some plateaus  the entries        are
distinct in most regimes  in particular around   the regime
that is needed for our results  Moreover  in practice  on the
Yahoo data  we observe later in Figure   that both solutiondependent bounds from Remark   are very good  and all
solutions are optimal within   very small gap 

Figure   Comparison of worstcase expected in uences for Dnorm uncertainty sets       left  and ellipsoidal uncertainty
sets       right  for different total budget bounds    For any
particular adversary budget   we compare minx            
for each candidate allocation   

  ROBUSTNESS AND QUALITY
Next  we probe the effect of   robust versus nonrobust solution for different uncertainty sets and budgets   of the
adversary  We compare our robust solution with using
  point estimate for         ynom   argmaxy           
treating estimates as ground truth  and the stochastic solution yexpect   argmaxy             as per Section  
These two optimization problems were solved via standard
 rstorder methods using TFOCS  Becker et al   
Figure   demonstrates that indeed  the alternative budgets
are sensitive to the adversary and the robustlychosen budget yrobust performs better  even in cases where the other
budgets achieve zero in uence  When the total budget   is
large  yexpect performs nearly as well as yrobust  but when
resources are scarce    is small  and the actual choice
seems to matter more  yrobust performs far better 

  Yahoo  data
To evaluate our method on realworld data  we formulate
  Budget Allocation instance on advertiser bidding data
from Yahoo  Webscope  yah  This dataset logs bids on
  different phrases by advertising accounts  We map
the phrases to channels   and the accounts to customers    
with an edge between   and   if   corresponding bid was
made  For each pair        we draw the associated transmission probability pst uniformly from     We bias
these towards zero because we expect people not to be easily in uenced by advertising in the real world  We then
generate an estimate  pst and build up   posterior by gener 

Robust Budget Allocation via Continuous Submodular Functions

 

 

 

 

 

 

 

Figure   Convergence properties of FrankWolfe  FW  versus
the optimal value attained with our scheme  SFM 

  Conclusion
We address the issue of uncertain parameters  or  model
misspeci cation  in Budget Allocation or Bipartite In uence Maximization  Alon et al    from   robust optimization perspective  The resulting Robust Budget Allocation is   nonconvexconcave saddle point problem  Although the inner optimization problem is nonconvex  we
show how continuous submodularity can be leveraged to
solve the problem to arbitrary accuracy   as can be veri 
 ed with the proposed bounds on the duality gap  In particular  our approach extends continuous submodular minimization methods  Bach    to more general constraint
sets  introducing   mechanism to solve   new class of constrained nonconvex optimization problems  We con rm on
synthetic and real data that our method  nds highquality
solutions that are robust to parameters varying arbitrarily in
an uncertainty set  and scales up to graphs with over  
edges 
There are many compelling directions for further study 
The uncertainty sets we use are standard in the robust optimization literature  but have not been applied to      Robust
In uence Maximization  it would be interesting to generalize our ideas to general graphs  Finally  despite the inherent nonconvexity of our problem   rstorder methods are
often able to  nd   globally optimal solution  Explaining
this phenomenon requires further study of the geometry of
constrained monotone submodular minimization 

Acknowledgements
We thank the anonymous reviewers for their helpful suggestions  We also thank MIT Supercloud and the Lincoln
Laboratory Supercomputing Center for providing computational resources  This research was conducted with Government support under and awarded by DoD  Air Force Of 
 ce of Scienti   Research  National Defense Science and
Engineering Graduate  NDSEG  Fellowship    CFR    
and also supported by NSF CAREER award  

Figure   Convergence properties of our algorithm on real data 
In the  rst plot      and     refer to primal and dual values  with
dual gap shown on the second plot  The third plot demonstrates
that the problemdependent suboptimality bounds of Remark  
   for    and   for Lagrangian  are very small  good  for all
inner iterations of this run 

ating nst samples from Ber pst  where nst is the number
of bids between   and   in the dataset 
This transformation yields   bipartite graph with      
          and more than   edges that we
use for Budget Allocation  In our experiments  the typical
gap between the naive ynom and robust yrobust was  
  expected in uenced people  We plot convergence of
the outer loop in Figure   where we observe fast convergence of both primal in uence value and the dual bound 

  Comparison to  rstorder methods
Given the success of  rstorder methods on nonconvex
problems in practice  it is natural to compare these to our
method for  nding the worstcase vector    On one of our
Yahoo problem instances with Dnorm uncertainty set  we
compared our submodular minimization scheme to FrankWolfe with  xed stepsize as in  LacosteJulien    implementing the linear oracle using MOSEK  MOSEK ApS 
 
Interestingly  from various initializations  FrankWolfe  nds an optimal solution  as veri ed by comparing
to the guaranteed solution of our algorithm  Note that  due
to nonconvexity  there are no formal guarantees for FrankWolfe to be optimal here  motivating the question of global
convergence properties of FrankWolfe in the presence of
submodularity 
It is important to note that there are many cases where  rstorder methods are inef cient or do not apply to our setup 
These methods require either   projection oracle  PO  onto
or linear optimization oracle  LO  over the feasible set  
de ned by     and      The Dnorm set admits   LO via
linear programming  but we are not aware of any ef cient
LO for Ellipsoidal uncertainty  nor PO for either set  that
does not require quadratic programming  Even more  our
algorithm applies for nonconvex functions      which induce nonconvex feasible sets     Such nonconvex sets may
not even admit   unique projection  while our algorithm
achieves provable solutions 

Robust Budget Allocation via Continuous Submodular Functions

References
Yahoo  Webscope dataset ydataysm advertiserbids 
URL http research yahoo com 

    
Academic Relations 

Adamczyk  Marek  Sviridenko  Maxim  and Ward  Justin 
Submodular Stochastic Probing on Matroids  Mathematics of Operations Research     

Alon  Noga  Gamzu  Iftah  and Tennenholtz  Moshe  Optimizing Budget Allocation Among Channels and In uencers  In WWW   

Atamt urk  Alper and Narayanan  Vishnu  Polymatroids and
meanrisk minimization in discrete optimization  Operations Research Letters     

Bach  Francis  Submodular Functions  From Discrete to

Continous Domains  arXiv   

Balkanski  Eric  Rubinstein  Aviad  and Singer  Yaron  The

power of optimization from samples  In NIPS   

Balkanski  Eric  Rubinstein  Aviad  and Singer  Yaron  The
In STOC 

limitations of optimization from samples 
 

Becker  Stephen    Cand es  Emmanuel    and Grant 
Michael    Templates for convex cone problems with
applications to sparse signal recovery  Mathematical
programming computation     

BenTal  Aharon and Nemirovski  Arkadi  Robust solutions of Linear Programming problems contaminated
with uncertain data  Mathematical Programming   
   

BenTal  Aharon  El Ghaoui  Laurent  and Nemirovski 
Princeton University

Arkadi  Robust Optimization 
Press   

Bertsimas  Dimitris and Sim  Melvyn  Robust discrete optimization and network  ows  Mathematical programming     

Bertsimas  Dimitris  Brown  David    and Caramanis 
Constantine  Theory and Applications of Robust Optimization  SIAM Review     

Best  Michael    and Chakravarti  Nilotpal  Active set algorithms for isotonic regression    unifying framework 
Mathematical Programming     

Bian  Andrew An  Mirzasoleiman  Baharan  Buhmann 
Joachim    and Krause  Andreas  Guaranteed Nonconvex Optimization  Submodular Maximization over
Continuous Domains  In AISTATS   

Birkhoff  Garrett  Rings of sets  Duke Mathematical Jour 

nal     

Borgs  Christian  Brautbar  Michael  Chayes  Jennifer  and
Lucier  Brendan  Maximizing Social In uence in Nearly
Optimal Time  In SODA   

Boyd  Stephen  Kim  SeungJean  Vandenberghe  Lieven 
and Hassibi  Arash    tutorial on geometric programming  Optimization and engineering   
 

Chakrabarty  Deeparnab  Lee  Yin Tat  Sidford  Aaron  and
Wong  Sam Chiuwai  Subquadratic submodular function minimization  In STOC   

Chandrasekaran  Venkat and Shah  Parikshit  Relative Entropy Relaxations for Signomial Optimization  SIAM
Journal on Optimization     

Chen  Wei  Wang  Yajun  and Yang  Siyu  Ef cient in   

ence maximization in social networks  In KDD   

Chen  Wei  Wang  Chi  and Wang  Yajun  Scalable In 
 uence Maximization for Prevalent Viral Marketing in
Largescale Social Networks  In KDD   

Chen  Wei  Lin  Tian  Tan  Zihan  Zhao  Mingfei  and
Zhou  Xuren  Robust in uence maximization  In KDD 
 

Chiang  Mung  Geometric Programming for Communication Systems  Commun  Inf  Theory     
Deshpande  Amol  Hellerstein  Lisa  and Kletenik  Devorah  Approximation Algorithms for Stochastic Submodular Set Cover with Applications to Boolean Function
Evaluation and MinKnapsack  ACM Trans  Algorithms 
   

Domingos  Pedro and Richardson  Matt  Mining the net 

work value of customers  In KDD   

Du  Nan  Song  Le  Gomez Rodriguez  Manuel  and Zha 
Hongyuan  Scalable in uence estimation in continuoustime diffusion networks  In NIPS   

Du  Nan  Liang  Yingyu  Balcan  MariaFlorina  and Song 
Le  In uence function learning in information diffusion
networks  In ICML   

Dunn  Joseph    and Harshbarger     Conditional gradient algorithms with open loop step size rules  Journal
of Mathematical Analysis and Applications   
   

Ecker  Joseph  Geometric Programming  Methods  Computations and Applications  SIAM Review   
   

Ene  Alina and Nguyen  Huy      Reduction for Optimizing Lattice Submodular Functions with Diminishing
Returns  arXiv   

Frank  Marguerite and Wolfe  Philip 

An algorithm
for quadratic programming  Naval Research Logistics
Quarterly     

Goel  Gagan  Karande  Chinmay  Tripathi  Pushkar  and
Wang  Lei  Approximability of combinatorial problems
with multiagent submodular cost functions  In FOCS 
 

Goemans  Michel and Vondr ak  Jan  Stochastic Covering
and Adaptivity  In LATIN   Theoretical Informatics 
Springer Berlin Heidelberg   

Golovin  Daniel and Krause  Andreas  Adaptive Submodularity  Theory and Applications in Active Learning and
Stochastic Optimization 
Journal of Arti cial Intelligence     

Robust Budget Allocation via Continuous Submodular Functions

Gomez Rodriguez  Manuel and Sch olkopf  Bernhard  In 
 uence maximization in continuous time diffusion networks  In ICML   

Gomez Rodriguez  Manuel  Leskovec  Jure  and Krause 
Andreas  Inferring networks of diffusion and in uence 
In KDD   

Gottschalk  Corinna and Peis  Britta  Submodular function maximization on the bounded integer lattice  In Approximation and Online Algorithms   th International
Workshop  WAOA   

Hassidim  Avinatan and Singer  Yaron  Submodular optimization under noise  arXiv preprint arXiv 
 

Hatano  Daisuke  Fukunaga  Takuro  Maehara  Takanori 
and Kawarabayashi  Kenichi  Lagrangian Decomposition Algorithm for Allocating Marketing Channels 
In
AAAI   

He  Xinran and Kempe  David  Robust in uence maxi 

mization  In KDD   

Iwata  Satoru and Nagano  Kiyohito  Submodular function minimization under covering constraints  In FOCS 
 

Jaggi  Martin  Revisiting FrankWolfe  ProjectionFree

Sparse Convex Optimization  In ICML   

Kempe  David  Kleinberg  Jon  and Tardos   Eva  Maximizing the Spread of In uence Through   Social Network 
In KDD   

Khachaturov  Vladimir    Khachaturov  Roman    and
Khachaturov  Ruben    Supermodular programming on
 nite lattices  Computational Mathematics and Mathematical Physics     

Kolmogorov  Vladimir and Shioura  Akiyoshi  New algorithms for convex cost tension problem with application
to computer vision  Discrete Optimization   
 

Krause  Andreas  McMahan    Brendan  Guestrin  Carlos 
and Gupta  Anupam  Robust submodular observation selection  Journal of Machine Learning Research   Dec 
   

LacosteJulien  Simon  Convergence Rate of FrankWolfe

for NonConvex Objectives  arXiv   

LacosteJulien  Simon and Jaggi  Martin  On the global linear convergence of FrankWolfe optimization variants 
In NIPS   

Lee  Yin Tat  Sidford  Aaron  and Wong  Sam Chiuwai 
  faster cutting plane method and its implications for
combinatorial and convex optimization  In FOCS   
Lowalekar  Meghna  Varakantham  Pradeep  and Kumar 
Akshat  Robust In uence Maximization   Extended Abstract  In AAMAS   

Maehara  Takanori  Risk averse submodular utility maximization  Operations Research Letters   
 

Maehara  Takanori  Yabe  Akihiro  and Kawarabayashi 
Kenichi  Budget Allocation Problem with Multiple Advertisers    Game Theoretic View  In ICML   

MOSEK ApS  MOSEK MATLAB Toolbox  
URL http docs mosek com 

 
toolbox index html 

Murota  Kazuo  Discrete convex analysis  SIAM   
Murota  Kazuo and Shioura  Akiyoshi  Exact bounds for
steepest descent algorithms of lconvex function minimization  Operations Research Letters   
 

Nagano  Kiyohito  Kawahara  Yoshinobu  and Aihara 
Kazuyuki  Sizeconstrained submodular minimization
through minimum norm base  In ICML   

Narasimhan  Harikrishna  Parkes  David    and Singer 
Yaron  Learnability of in uence in networks  In NIPS 
 

Netrapalli  Praneeth and Sanghavi  Sujay  Learning the

graph of epidemic cascades  In SIGMETRICS   

Nikolova  Evdokia  Approximation algorithms for reliable stochastic combinatorial optimization  In APPROX 
 

Orlin  James    Schulz  Andreas  and Udwani  Rajan  RoIn

bust monotone submodular function maximization 
IPCO   

Pascual  Luis    and BenIsrael  Adi  Constrained maximization of posynomials by geometric programming 
Journal of Optimization Theory and Applications   
   

Polyak  Boris    Introduction to Optimization  Number  

QA        

Rockafellar    Tyrrell and Uryasev  Stanislav  Optimization of conditional valueat risk  Journal of risk   
   

Rockafellar    Tyrrell and Uryasev  Stanislav  Conditional
valueat risk for general loss distributions  Journal of
banking    nance     

Soma  Tasuku and Yoshida  Yuichi    Generalization of
Submodular Cover via the Diminishing Return Property
on the Integer Lattice  In NIPS   

Soma  Tasuku  Kakimura  Naonori  Inaba  Kazuhiro  and
Kawarabayashi  Kenichi  Optimal Budget Allocation  Theoretical Guarantee and Ef cient Algorithm  In
ICML   

Svitkina  Zoya and Fleischer  Lisa  Submodular approximation  Samplingbased algorithms and lower bounds 
SIAM Journal on Computing     

Topkis  Donald    Minimizing   submodular function on

  lattice  Operations research     

Wainwright  Kevin and Chiang  Alpha 

Fundamental
Methods of Mathematical Economics  McGrawHill Education   

Zhang  Peng  Chen  Wei  Sun  Xiaoming  Wang  Yajun 
and Zhang  Jialin  Minimizing seed set selection with

Robust Budget Allocation via Continuous Submodular Functions

probabilistic coverage guarantee in   social network  In
KDD   

