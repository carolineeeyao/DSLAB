Warped Convolutions  Ef cient Invariance to Spatial Transformations

Jo ao    Henriques   Andrea Vedaldi  

Abstract

Convolutional Neural Networks  CNNs  are extremely ef cient  since they exploit the inherent
translationinvariance of natural images  However  translation is just one of   myriad of useful spatial transformations  Can the same ef 
ciency be attained when considering other spatial invariances  Such generalized convolutions
have been considered in the past  but at   high
computational cost  We present   construction
that is simple and exact  yet has the same computational complexity that standard convolutions
enjoy  It consists of   constant image warp followed by   simple convolution  which are standard blocks in deep learning toolboxes  With
  carefully crafted warp  the resulting architecture can be made equivariant to   wide range of
twoparameter spatial transformations  We show
encouraging results in realistic scenarios  including the estimation of vehicle poses in the Google
Earth dataset  rotation and scale  and face poses
in Annotated Facial Landmarks in the Wild   
rotations under perspective 

  Introduction
  crucial aspect of current deep learning architectures is the
encoding of invariances  This fact is epitomized in the success of convolutional neural networks  CNN  where equivariance to image translation is key  translating the input
results in   translated output  When invariances are present
in the data  encoding them explicitly in an architecture provides an important source of regularization  which reduces
the amount of training data required for learning 
Invariances may also be used to improve the ef ciency of
implementations  For instance    convolutional layer requires orders of magnitude less memory  by reusing  lters

 Visual Geometry Group  University

of Oxford 
Jo ao    Henriques

United Kingdom 
 joao robots ox ac uk 

Correspondence to 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

across space  and less computation  due to their limited
support  compared to   fullyconnected layer  Its local and
predictable memory access pattern also makes better use of
modern hardware   caching mechanisms 
The success of CNNs indicates that translation invariance
is an important property of images  However  this does
not explain why translation equivariant operators work well
for image understanding  The common interpretation is
that such operators are matched to the statistics of natural images  which are well known to be translation invariant  Hyv arinen et al    However  natural image
statistics are also  largely  invariant to other transformations such as isotropic scaling and rotation  which suggests
that alternative neural network designs may also work well
with images  Furthermore  in speci   applications  invariances other than translation may be more appropriate 
Therefore  it is natural to consider generalizing convolutional architectures to other image transformations  and this
has been the subject of extensive study  Kanazawa et al 
  Bruna et al    Cohen   Welling    Unfortunately these approaches do not possess the same memory
and speed bene ts that CNNs enjoy  The reason is that  ultimately  they have to transform  warp  an image or  lter
several times  Kanazawa et al    Marcos et al   
Dieleman et al    incurring   high computational burden  Another approach is to consider   basis of  lters
 analogous to eigenimages  encoding the desired invariance  Cohen   Welling    Bruna et al    Cohen
  Welling    Although they are able to handle transformations with many pose parameters  in practice most
recent proposals are limited to very coarsely discretized
transformations  such as horizontal vertical  ips and  
rotations  Dieleman et al    Cohen   Welling   
In this work we consider generalizations of CNNs that
overcome these disadvantages  Well known constructions
in group theory enable the extension of convolution to general transformation groups  Folland    However  this
generality usually comes at an increased computational
cost or complexity  Here we show that  by making appropriate assumptions  we can design convolution operators that are equivariant to   large class of twoparameter
transformations while reducing to   standard convolution
in   warped image space  The  xed image warp can be

Warped Convolutions  Ef cient Invariance to Spatial Transformations

implemented using bilinear resampling    simple and fast
operation that has been popularized by spatial transformer
networks  Jaderberg et al    Heckbert    and is
part of most deep learning toolboxes  Unlike previous proposals  the proposed warped convolutions can handle continuous transformations  such as  ne rotation and scaling 
This makes generalized convolution easily implementable
in neural networks  reusing fast convolution algorithms on
GPU hardware  such as Winograd  Lavin    or the Fast
Fourier Transform  Lyons   

  Generalizing convolution
  Discrete and continuous convolution

We start by looking at the basic building block of CNNs 
     the convolution operator  This operator computes the
inner product of an image     RN   with   translated
version of the  lter     RM     producing   new image
as output 

            

             

 

 cid 

 

where           are twodimensional vectors of indexes 
and the summation ranges inside the extents of both arrays 
Over the next sections it will be more convenient to translate the image   instead of the  lter     This alternative
form of eq    is obtained by the substitution           
 

             

            

 cid 

 

In the neural network literature  this is often written using
the crosscorrelation convention  Goodfellow et al   
by considering the re ected  lter             

            

            

 

 cid 

 

To handle continuous deformations of the input  it is more
natural to express eq    as an integral over continuous
 
rather than discrete inputs 

            

               dx 

 
where               are functions of continuous inputs
in    The realvalued    vectors           now play the
role of the indexes        Equation   reduces to the
discrete case of eq    if we de ne   and   as the sum of
delta functions on grids  Dirac comb  Intermediate values
can be obtained by interpolation  such as bilinear  which
amounts to convolution of the delta functions with   triangle  lter  Jaderberg et al    Importantly  such continuous images can be deformed by   rich set of continuous
transformations of the input coordinates  whereas strictly
discrete operations would be more limiting 

  Convolution on groups

The standard convolution operator of eq    can be interpreted as applying the  lter to translated versions of the
image  We wish to replace translations with other image
transformations    belonging to   group   
In the context of machine learning models for images  this generalized  group  convolution can be understood to exhaustively
search for   pattern at various poses             rotation
angles or scale factors   Dieleman et al    Kanazawa
et al   
Following standard derivations  Folland    the most
common way of generalising convolution to transformations other than translations starts from the Haar integral 
Given   measure   over   group    one can de ne the integral of   real function             written 

 

          

 

The  left  Haar measure is the most natural choice for  
it is the only measure  up to scaling factors  that is  left 
invariant to group translation  In other words    satis es
the equation 

 

 

        

   hg        

          

 

 

Mirroring eq    the group convolution of two functions   
and    is de ned as 

 

      

 

        

   tg             

 

From the viewpoint of statistical learning    key property of
convolution is equivariance  Consider the  left  translation
operator

Lh       

   cid         

 

Then 
Lemma    Folland    Convolution is equivariant with
group translations  in the sense that Lh commutes with  
 

 

Lh      

 

          Lh       

 

      

 Due to the Haar invariance property  this de nition is equivalent to the following one  also commonly found in the literature 

 

 
 

      

 

        

           

        

The equivalence mirrors the one between eq    and eq    and
can be easily proved 

      

 

        

 

   tg      tg 

        

   tg       

      

Proof  Lh      
 
     tg                 Lh       

        

 

                       

      

 

  From groups to images
The functions    and    above have been de ned on groups 
In applications  however  we are interested in images      
functions           de ned on   subset   of the real plane
  
The connection between the two function types is easy to
establish  The assumption is that   acts  on the image domain           is   group of transformations of   We can
then de ne the   operator as 

          gx 

where        is an arbitrary pivot point  Note that the
values of    depend only on the values of   on the orbit of
        the set Gx     gx           Therefore we
typically set the domain   of   to be equal to Gx 
By this de nition  left translation of    by   corresponds to
warping the image   by the transformation   
Lh                         tx     cid         

We can then update eq    to express group convolution as
  function of images on the real plane 

 

    

 

       

  tgx             

 

Warped Convolutions  Ef cient Invariance to Spatial Transformations
 

and group convolution reduces to the standard notion of
convolution  

on    

 

      

 

    exp     

Iw       Fw    du 

 

 

 

We refer to this standard convolution in warped space
 eq    as warped convolution 

Discussion  Note that the result is an image whose dimensionality   is that of the vector space     in the following 
we mainly work in the case       By far  the strongest
requirement is that the map is additive  this is the same as
requiring the transformation group   to be Abelian  in the
sense that transformations commute  hg   gh 
In section   we will show   variety of useful image transformations that respect this property  The advantage of introducing this restriction is that calculations simplify tremendously  ultimately enabling   simple and ef cient implementation of the operator as discussed below 

  Warped convolutions
Our main contribution is to note that certain group convolutions can be implemented ef ciently by   standard convolution  by prewarping the input image and  lter appropriately  The warp is the same for any image  depending
solely on the nature of the relevant transformations  and
can be written in closed form  This result allows one to
implement very ef cient group convolutions using simple
computational blocks  as shown in section  

  Standard convolutions with exponential maps

  Warped convolution layer

In the de nitions of sections   and   while we could
reduce the functions    and    to images   and     the result of convolution is still   function de ned over   group 
One needs therefore to understand how to represent such
functions and calculate the corresponding integrals 
We note here that
the simplest case is when   is  
Lie group parameterised by the exponential map exp  
       where   is   subset of RP   in such   way
that exp is smooth  bijective and additive  exp         
exp    exp    Then 

 

 

            

   exp    du 

 

 

Hence we can de ne the warped image

We can now reinterpret these results in terms of   new neural network convolutional layer  The input of the layer is an
image   and the learnable parameters are the coef cients of
the  lter Fw  The output is   new  image       Fw    de 
 ned on the vector space     This image is obtained by  rst
warping   using the exponential map and then by convolving the result with Fw in the standard sense 

     Fw         exp     

 

Fw   

 

The most important property of this layer is equivariance 
if we warp the image by the transformation     exp   
then the convolution result translates by   

         Fw         Fw       

    exp   

Iw         exp        exp     

      

 This means that   de nes   mapping    cid    and that
the group multiplication hg corresponds to function composition
 hg       gx 

Note that the output action equivalent to warping the input
is simply to translate the result  as for standard convolution  The second most important property is that this operator can be implemented ef ciently as the combination of
warping and standard convolution 

Warped Convolutions  Ef cient Invariance to Spatial Transformations

  Implementation and intuition

Algorithm   Warped Convolution

The warp  exponential map  that is applied to the input image eq    can be implemented as follows  We start with
an arbitrary pivot point    in the image  and then sample
all possible transformations of that point   gx          
For discrete images    will be implemented as      grid of
discrete transformations       rotations and scales at regular intervals  and  gx  will be      grid as well  referred
to as the warp grid  Finally  sampling the input image at the
points  gx   for example  by bilinear interpolation  yields
the warped image 
An illustration is given in       for various transformations
 each one is discussed in more detail in section   The red
dot shows the pivot point    and the two arrows pointing
away from it show the original axes of the sampled grid
of parameters  The grids were generated by sampling the
transformation parameters at regular intervals  Note that
the warp grids are independent of the image contents   they
can be computed once of ine and then applied to any image 
The steps for implementing   warped convolution block are
outlined in algorithm   The main advantage of implementing group convolution as warped convolution is that it replaces   large number of warping operations  one per group
element  with   single warp 

  Discussion
  Interpretation as    ltering operator in image

space

When        we can often interpret group convolution
as an integration over image space  instead of over group
elements  For this  we introduce the map       exp     
and assume that it is smooth  invertible  and surjective on
the image domain   Surjectivity means that   acts transitively on   in the sense that every point       can be
reached from    by   transformation    Injectivity means
that this transformation is unique 
Next 
exp    exp        exp    Hence

let     exp    and note that exp         

      

 

        

Iw       Fw    du
    exp        exp      du 

 
 

 

 

 

Let the  lter    be the re ection  of   around the pivot
point    by the group           gx            It
 This is well de ned because   is invertible  In fact  if    
gx    exp            then         and       
     

Grid generation  of ine 

  Compute the    warp grid     gu    by applying   twoparameter spatial transformation         
        to   single pivot point    using     
grid of parameters                           
                             

Warped convolution

  Resample input image   using the warp grid    by

bilinear interpolation 

  Convolve warped image Iw with   learned  lter Fw 

By eq    and for appropriate transformations  these steps
are equivalent to group convolution  which performs an exhaustive search across the posespace of transformations 
but at   much lower computational cost 

follows that 

      

 

        

 

    exp       exp      du 

We can now use the change of variable         to
write

      

 

        

           du

 

 
 

 

 cid cid cid cid    

dx

 cid cid cid cid  dx 

 

 

 

  hx     

 

Thus we see that the group convolution amounts to applying   certain  lter    to the warped image        The  lter
elements are reweighed by the determinant of the Jacobian
of   which accounts for the stretching and shrinking of
space due to the nonlinear map  In practice  both the re 
 ection and Jacobian can be absorbed into   learned  lter 
making such calculations unnecessary  Nevertheless  they
offer   complementary view of warped convolutions 

  Ef ciency vs  generality

By reducing to standard convolution  warped convolution allows one to take full advantage of modern convolution implementations  Lavin    Lyons    including those with lower computational complexity      
FFT  Lyons    However  while warped convolution
works with an important class of transformations  including the ones considered in previous works Kanazawa et al 
  Cohen   Welling   Marcos et al   
nontrivial restrictions are imposed on the transformation
group  it must be Abelian and have only two parameters 
By contrast 
the grouptheoretic convolution operator
of eq    does not make  almost  any restriction on the

Warped Convolutions  Ef cient Invariance to Spatial Transformations

    translation

    scale aspect ratio

    scale rotation

       rotation  yaw pitch 

Figure   First row  Sampling grids that de ne the warps associated with different spatial transformations  Second row  An example
image     after warping with each grid  bd  Third row    small translation is applied to each warped image  which is then mapped
back to the original space  by an inverse warp  Translation in one axis of the appropriate warped space is equivalent to     horizontal
scaling      planar rotation         rotation around the vertical axis 

transformation group  Unfortunately  it is in general significantly more dif cult to compute ef ciently than the special
case we consider here  To understand some of the implementation challenges  consider specializing eq    to   discrete group   such as   discrete set of planar rotations  In
this case the Haar measure is trivial and equal to   and one
has 

  tgx        

 cid 

   

    

 

       

this equation has complexity
Direct computation of
     where     is the cardinality of the discrete group 
Assuming that     is in the order of       where   is the
resolution of the input image  as it would be for standard
convolution  one would obtain   complexity of       In
practice  since usually the support of        lter is much
smaller than the image  this complexity might reduce to
         which is the complexity for the spatial domain

implementation of convolution  however  compared to the
standard case  this has two major disadvantages  First  the
image is sampled in   spatiallyvarying manner  using bilinear or other interpolation  which foregoes the bene   of
the regular  predictable  and local pattern of computations
in standard convolution  This makes highperformance implementation of the naive algorithm dif cult  particularly
on GPUs  Secondly  it precludes the use of faster convolution routines such as Winograd   algorithm  Lavin   
or the Fast Fourier Transform  Lyons    the later having lower computational complexity than exhaustive search
       log     The development of analogues of the FFT
for other general groups remains the subject of active research  Tygert    Li   Yang    which we sidestep
by reusing highly optimized standard convolutions 
In practice  most recent works focus on very coarse transformations that do not change the  lter support and can

Warped Convolutions  Ef cient Invariance to Spatial Transformations

be implemented strictly via permutations  like horizontal vertical  ips and   rotations  Dieleman et al   
Cohen   Welling    Such dif culties may explain
why group convolutions are not as widespread as CNNs 

  Examples of spatial transformations
We now give some concrete examples of twoparameter
spatial transformations that obey the conditions of section   and can be useful in practice 

  Scale and aspect ratio

Visual object detection tasks require predicting the extent
of an object as   bounding box  While the location can
be found accurately by   standard CNN  which is equivariant to translation  the size prediction could similarly bene  
from equivariance to horizontal and vertical scale  equivalently  scale and aspect ratio 
Such   spatial transformation  from which   warp can be
constructed  is given by 

 cid 

 cid    su 

  su 

gu     

 

The   constant controls the total degree of scaling applied 
Notice that the output must be exponential in the scale parameters    this ensures the additive structure of the exponential map  exp          exp    exp    The resulting
warp grid can be visualized in         In this case  the domain of the image must be       
  since   pivot    in one
quadrant cannot reach another quadrant by any amount of
 positive  scaling 

  Scale and rotation  logpolar warp 

Planar scale and rotation are perhaps the most obvious
spatial transformations in images  and are   natural test
case for works on spatial transformations  Kanazawa et al 
  Marcos et al    Rotating   point   by    radians
and scaling it by    around the origin  can be performed
with

 cid  su   cid   cid  cos atan           

su   cid   cid  sin atan           

 cid 

gu     

 

 

where atan  is the standard  quadrant inverse tangent
function  atan  The domain in this case must exclude
the origin            since   pivot        cannot
reach any other points in the image by rotation or scaling 
The resulting warp grid can be visualized in        
It
is interesting to observe that it corresponds exactly to the
logpolar domain  which is used in the signal processing

 

Iw

Warp

CNN

Soft argmax

Scale bias

  

Figure   Equivariant pose estimation strategy used in the experiments  section   With an appropriate warp and   standard CNN 
the shaded block becomes equivalent to   groupequivariant CNN 
which performs exhaustive searches across posespace instead of
imagespace 

literature to perform correlation across scale and rotation
 Tzimiropoulos et al    Reddy   Chatterji    In
fact  it was the source of inspiration for this work  which
can be seen as   generalization of the logpolar domain to
other spatial transformations 

     sphere rotation under perspective

We will now tackle   more dif cult spatial transformation 
in an attempt to demonstrate the generality of our result 
The transformations we will consider are yaw and pitch rotations in    space  as seen by   perspective camera  In
the experiments  section   we will show how to apply it to
face pose estimation 
In order to maintain additivity  the rotated    points must
remain on the surface of   sphere  We consider   simpli ed
camera and world model  whose only hyperparameters are
  focal length    the radius of   sphere    and its distance
from the camera center    The equations for the spatial
transformation corresponding to yaw and pitch rotation under this model are in appendix   
The corresponding warp grid can be seen in         It can
be observed that the grid corresponds to what we would expect of      rendering of   sphere with   discrete mesh  An
intuitive picture of the effect of the warp grid in such cases
is that it wraps the    image around the surface of the   
object  so that translation in the warped space corresponds
to moving between vertexes of the    geometry 

  Experiments
  Architecture

As mentioned in section   group convolution can perform an exhaustive search for patterns across spatial transformations  by varying pose parameters  For tasks where
invariance to that transformation is important  it is usual to
pool the detection responses across all poses  Marcos et al 
  Kanazawa et al   
In the experiments  however  we will test the framework in
pose prediction tasks  As such  we do not want to pool the
detection responses       with   max operation  but rather
 nd the pose with the strongest response       an argmax
operation  To perform this operation in   differentiable

Warped Convolutions  Ef cient Invariance to Spatial Transformations

manner  we implement   soft argmax operation  de ned as
follows 

mn cid 

ij

      

 
 

 ij   

      

 
 

 ij   

 

mn cid 

ij

where       Rm   is the softmax over all spatial locations  and  ij    indexes the element at        The outputs are the two spatial coordinates of the maximum value 
         
Our base architecture then consists of the following blocks 
outlined in       First  the input image is warped with  
pregenerated grid  according to section   The warped
image is then processed by   standard CNN  which is now
equivariant to the spatial transformation that was used to
generate the warp grid    soft argmax  eq    then  nds
the maximum over posespace  To ensure the pose prediction is well registered to the reference coordinate system   
learnable scale and bias are applied to the outputs  multiple predictions can be linearly combined into   single one
at this stage  Training proceeds by minimizing the    loss
between the predicted pose and ground truth pose 

  Google Earth

For the  rst task in our experiments  we will consider aerial
photos of vehicles  which have been used in several works
that deal with rotation invariance  Liu et al    Schmidt
  Roth    Henriques et al   

Dataset  The Google Earth dataset  Heitz   Koller   
contains bounding box annotations  supplemented with angle annotations from  Henriques et al    for   vehicles in   large images  We use the  rst   for training and
the rest for validation  Going beyond these previous works 
we focus on the estimation of both rotation and scale parameters  The object scale is taken to be the diagonal length
of the bounding box  Due to its small size  we augment the
dataset during training  by randomly rotating the images
uniformly over   and scaling them by up to  
Implementation          image is cropped around
each vehicle  and then fed to   network for pose prediction  The proposed method  Warped CNN  follows the architecture of section    visualized in       The CNN
block contains   convolutional layers with        lters 
with     and   output channels respectively  We use
dilation factors of     and   respectively    trous convolution  Chen et al    which increases the receptive
 eld and resolution without adding paramenters  There is
  batch normalization and ReLU layer after each convolution  and         maxpooling operator  stride   after
the second one  The CNN block outputs response maps

Table   Results of scale and rotation pose estimation of vehicles
in the Google Earth dataset  errors in pixels and degrees  resp 

ROT  ERR 

SCALE ERR 

CNN FC
CNN SOFTARGMAX
WARPED CNN
 DIELEMAN ET AL   

 
 
 
 

 
 
 
 

over    posespace  which in this case consists of rotation
and scale  All networks are trained for   epochs using
the ADAM solver  Kingma   Ba    and implemented
in MatConvNet  Vedaldi   Lenc    Angular error is
taken modulo   due to annotation ambiguity  We report
the average validation error over   runs 

Baselines and results  The results of the experiments are
presented in table   which shows angular and scale error in the validation set  To verify whether the proposed
warped convolution is indeed responsible for   boost in performance  rather than other architectural details  we compare it against   number of baselines with different components removed  The  rst baseline  CNN softargmax  consists of the same architecture but without the warp  section   This is   standard CNN  with the soft argmax at
the end  Since CNNs are equivariant to translation  rather
than scale and rotation  we observe   drop in performance 
For the second baseline  CNN FC  we replace the soft
argmax with   fullyconnected  FC  layer  to allow   prediction that is not equivariant with translation  Due to the
larger number of parameters  there is over tting and   large
drop in performance  We also compare against the method
of  Dieleman et al    which applies the same CNN to
  rotations and  ips of the image  combining the result
with   FC layer  Just like with CNN FC  there is over tting on this small dataset  which requires very  ne angular predictions  The proposed Warped CNN achieves the
best results  except for scale prediction where  Dieleman
et al    performs better  Our method has the same runtime performance as the CNN baselines  since the cost of  
single warp is negligible  however  Dieleman et al   
is   slower  since it applies the same CNN to multiple
transformed images 

  Faces

We now turn to face pose estimation in unconstrained photos  which requires handling more complex    rotations
under perspective 

Dataset  For this task we use the Annotated Facial Landmarks in the Wild  AFLW  dataset  Koestinger et al 
 
It contains about    faces found in Flickr photos  and includes yaw  leftright  and pitch  updown  an 

Warped Convolutions  Ef cient Invariance to Spatial Transformations

Table   Results of yaw and pitch pose estimation of faces on the
AFLW dataset  error in degrees 

YAW ERR 

PITCH ERR 

CNN FC
STN  JADERBERG ET AL   
WARPED CNN

 
 
 

 
 
 

notations  We removed   faces with yaw larger than  
degrees       facing away from the camera  resulting in  
set of   samples    of the faces were set aside for
validation 

Implementation  The region in each face   bounding box
is resized to         image  which is then processed by
the network  Recall that our simpli ed    model of yaw
and pitch rotation  section   assumes   spherical geometry  Although   person   head roughly follows   spherical
shape  the sample images are centered around the face  not
the head  As such  we use an af ne Spatial Transformer
Network  STN   Jaderberg et al    as    rst step  to
center the image correctly  Similarly  because the optimal
camera parameters       and    are dif cult to set by hand 
we let the network learn them  by computing their derivatives numerically  which has   low overhead  since they are
scalars  The rest of the network follows the same diagram
as before       The main CNN has   convolutional layers  the  rst two with    lters  the others being   The
numbers of output channels are       and   respectively          maxpooling with   stride of   is performed
after the  rst layer  and there are ReLU nonlinearities between the others  As for the STN  it has   convolutional
layers       with     and   output channels respectively  and     maxpooling  stride   between them  The
remaining experimental settings are as in section  

Baselines and results  The angular error of the proposed
equivariant pose estimation  Warped CNN  is shown in table   along with   number of baselines  The goal of
these experiments is to demonstrate that it is possible to
achieve equivariance to complex    rotations  To compare
with nonequivariant models  we test two baselines with
the same CNN architecture  where the softargmax is replaced with   fullyconnected  FC  layer  We include the
Spatial Transformer Network  Jaderberg et al    and
CNN FC  which is   standard CNN of equivalent  slightly
larger  capacity  We observe that neither the FC or the STN
components account for the performance of the warped
convolution  which better exploits the natural    rotation
equivariance of the data 

  Conclusions
In this work we show that it is possible to reuse highly optimized convolutional blocks  which are equivariant to image
translation  and coax them to exhibit equivariance to other
operators  including    transformations  This is achieved
by   simple warp of the input image  implemented with offthe shelf components of deep networks  and can be used
for image recognition tasks involving   large range of image transformations  Compared to other works  warped
convolutions are simpler  relying on highly optimized convolution routines  and can  exibly handle many types of
continuous transformations  Studying generalizations that
support more than two parameters seems like   fruitful direction for future work  In addition to the practical aspects 
our analysis offers some insights into the fundamental relationships between arbitrary image transformations and convolutional architectures 

   Spatial transformation for    sphere

rotation under perspective

Our simpli ed model consists of   perspective camera with
focal length   and all other camera parameters equal to
identity  at   distance   from   centered sphere of radius
   see        
     point   in imagespace corresponds to the    point

 
Raycasting it along the   axis  it will intersect the sphere
surface at the    point

              

   

 
 cid   cid 

            

     

   
 cid   cid   

 

If the argument of the squareroot is negative  the ray does
not intersect the sphere and so the point transformation is
unde ned  This means that the domain of the image  
should be restricted to the sphere region 
In practice  in
such cases we simply leave the point unmodi ed  Then 
the yaw and pitch coordinates of the point   on the surface
of the sphere are

 cid 

   cid 

 cid 

    cos cid    

 cid 

 cid 

 cid 

      atan 

 

    
      

 

 

These polar coordinates are now rotated by the spatial
transformation parameters   cid           Converting them
back to      point   cid 
  cid       sin  cid 
  cos  cid 
  sin  cid 
Finally  projection of   cid  into imagespace yields

   cos  cid 

        

    sin  cid 

gu         
  cid 

 

   cid 
    cid 

   

 

Warped Convolutions  Ef cient Invariance to Spatial Transformations

References
Bruna  Joan  Szlam  Arthur  and LeCun  Yann  Learning
stable group invariant representations with convolutional
networks  arXiv preprint arXiv   

Chen  LiangChieh  Papandreou  George  Kokkinos  Iasonas  Murphy  Kevin  and Yuille  Alan    Semantic image segmentation with deep convolutional nets and fully
In Proceedings of the   Internaconnected CRFs 
tional Conference on Learning Representations   

Cohen  Taco and Welling  Max  Learning the Irreducible
In ProRepresentations of Commutative Lie Groups 
ceedings of the  st International Conference on Machine Learning   

Cohen  Taco and Welling  Max  Group equivariant convolutional networks  In Proceedings of the  rd International Conference on Machine Learning   

Dieleman  Sander  Willett  Kyle    and Dambre  Joni 
Rotationinvariant convolutional neural networks for
galaxy morphology prediction  Monthly notices of the
royal astronomical society     

Folland  Gerald      course in abstract harmonic analysis 

CRC Press   

Goodfellow  Ian  Bengio  Yoshua  and Courville  Aaron 

Deep learning  MIT Press   

Heckbert  Paul    Fundamentals of texture mapping and
image warping  Master   thesis  University of California 
Berkeley   

Heitz  Geremy and Koller  Daphne  Learning spatial context  Using stuff to  nd things  In European Conference
on Computer Vision  pp    Springer   

Henriques        Martins     Caseiro     and Batista    
Fast training of pose detectors in the fourier domain 
In Advances in Neural Information Processing Systems 
 

Hyv arinen  Aapo  Hurri  Jarmo  and Hoyer  Patrick    Natural Image Statistics    Probabilistic Approach to Early
Computational Vision  volume   Springer Science  
Business Media   

Jaderberg  Max  Simonyan  Karen  Zisserman  Andrew 
In Advances in
et al  Spatial transformer networks 
Neural Information Processing Systems  pp   
 

Kanazawa  Angjoo  Sharma  Abhishek  and Jacobs  David 
Locally scaleinvariant convolutional neural networks 
arXiv preprint arXiv   

Kingma  Diederik   and Ba  Jimmy Lei  Adam    method
for stochastic optimization  In Proceedings of the  
International Conference on Learning Representations 
 

Koestinger  Martin  Wohlhart  Paul  Roth  Peter    and
Bischof  Horst  Annotated facial landmarks in the wild 
  largescale  realworld database for facial landmark
localization  In IEEE International Workshop on Benchmarking Facial Image Analysis Technologies   

Lavin  Andrew  Fast algorithms for convolutional neural

networks  arXiv preprint arXiv   

Li  Yingzhou and Yang  Haizhao 

Interpolative butter  

factorization  arXiv preprint arXiv   

Liu  Kun  Skibbe  Henrik  Schmidt  Thorsten  Blein 
Thomas  Palme  Klaus  Brox  Thomas  and Ronneberger  Olaf  RotationInvariant HOG Descriptors Using Fourier Analysis in Polar and Spherical Coordinates 
International Journal of Computer Vision   
  February   ISSN     doi 
     

Lyons  Richard    Understanding digital signal process 

ing  Pearson Education   

Marcos  Diego  Volpi  Michele  and Tuia  Devis  Learning
rotation invariant convolutional  lters for texture classi 
 cation  arXiv preprint arXiv   

Reddy     Srinivasa and Chatterji  Biswanath    An
FFTbased technique for translation  rotation  and scaleinvariant image registration  IEEE Transactions on Image Processing     

Schmidt  Uwe and Roth  Stefan  Learning rotationaware
features  From invariant priors to equivariant descripIn Computer Vision and Pattern Recognition
tors 
 CVPR    IEEE Conference on  pp   
 

Tygert  Mark  Fast algorithms for spherical harmonic expansions  iii  Journal of Computational Physics   
   

Tzimiropoulos  Georgios  Argyriou  Vasileios  Zafeiriou 
Stefanos  and Stathaki  Tania  Robust FFTbased scaleinvariant image registration with image gradients  IEEE
Transactions on Pattern Analysis and Machine Intelligence     

Vedaldi     and Lenc     MatConvNet   Convolutional
In Proceeding of the

Neural Networks for MATLAB 
ACM Int  Conf  on Multimedia   

Acknowledgements  This research was funded by ERC
 IDIU 

