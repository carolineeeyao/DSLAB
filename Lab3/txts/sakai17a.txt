SemiSupervised Classi cation

Based on Classi cation from Positive and Unlabeled Data

Tomoya Sakai     Marthinus Christoffel du Plessis Gang Niu   Masashi Sugiyama    

Abstract

Most of the semisupervised classi cation methods developed so far use unlabeled data for regularization purposes under particular distributional assumptions such as the cluster assumption  In contrast  recently developed methods of
classi cation from positive and unlabeled data
 PU classi cation  use unlabeled data for risk
evaluation       label information is directly extracted from unlabeled data 
In this paper  we
extend PU classi cation to also incorporate negative data and propose   novel semisupervised
classi cation approach  We establish generalization error bounds for our novel methods and
show that the bounds decrease with respect to
the number of unlabeled data without the distributional assumptions that are required in existing
semisupervised classi cation methods  Through
experiments  we demonstrate the usefulness of
the proposed methods 

  Introduction

Collecting   large amount of labeled data is   critical bottleneck in realworld machine learning applications due to the
laborious manual annotation 
In contrast  unlabeled data
can often be collected automatically and abundantly      
by   web crawler  This has led to the development of various semisupervised classi cation algorithms over the past
decades 

To leverage unlabeled data in training  most of the existing semisupervised classi cation methods rely on particular assumptions on the data distribution  Chapelle et al 
  For example  the manifold assumption supposes that
samples are distributed on   lowdimensional manifold in
the data space  Belkin et al    In the existing framework  such   distributional assumption is encoded as   reg 

 The University of Tokyo  Japan  RIKEN  Japan  Correspon 

dence to  Tomoya Sakai  sakai ms   utokyo ac jp 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

ularizer for training   classi er and biases the classi er toward   better one under the assumption  However  if such  
distributional assumption contradicts the data distribution 
the bias behaves adversely  and the performance of the obtained classi er becomes worse than the one obtained with
supervised classi cation  Cozman et al    Sokolovska
et al    Li   Zhou    Krijthe   Loog   

Recently  classi cation from positive and unlabeled data
 PU classi cation  has been gathering growing attention
 Elkan   Noto    du Plessis et al      Jain
et al    which trains   classi er only from positive and
unlabeled data without negative data  In PU classi cation 
the unbiased risk estimators proposed in du Plessis et al 
    utilize unlabeled data for risk evaluation  implying that label information is directly extracted from unlabeled data without restrictive distributional assumptions 
unlike existing semisupervised classi cation methods that
utilize unlabeled data for regularization  Furthermore  theoretical analysis  Niu et al    showed that PU classi 
 cation  or its counterpart  NU classi cation  classi cation
from negative and unlabeled data  is likely to outperform
classi cation from positive and negative data  PN classi 
 cation       ordinary supervised classi cation  depending
on the number of positive  negative  and unlabeled samples  It is thus naturally expected that combining PN  PU 
and NU classi cation can be   promising approach to semisupervised classi cation without restrictive distributional
assumptions 

In this paper  we propose   novel semisupervised classi 
cation approach by considering convex combinations of the
risk functions of PN  PU  and NU classi cation  Without
any distributional assumption  we theoretically show that
the con dence term of the generalization error bounds decreases at the optimal parametric rate with respect to the
number of positive  negative  and unlabeled samples  and
the variance of the proposed risk estimator is almost always
smaller than the plain PN risk function given an in nite
number of unlabeled samples  Through experiments  we
analyze the behavior of the proposed approach and demonstrate the usefulness of the proposed semisupervised classi cation methods 

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

  Background

  PU Classi cation

In this section  we  rst introduce the notation commonly
used in this paper and review the formulations of PN  PU 
and NU classi cation 

  Notation

Let random variables     Rd and       be
equipped with probability density         where   is   positive integer  Let us consider   binary classi cation problem
from   to    given three sets of samples called the positive     negative     and unlabeled     data 

  

XP    xP
XN    xN
XU    xU

   nP
   nN
   nU

  

  

       pP                 
       pN                 
               PpP       NpN   

where

            

            

are the classprior probabilities for the positive and negative
classes such that            
Let     Rd     be an arbitrary realvalued decision
function for binary classi cation  and classi cation is performed based on its sign  Let           be   loss function such that     generally takes   small value for large
margin     yg    Let RP    RN    RU      and
RU      be the risks of classi er   under loss  

RP      EP     
RN      EN     
RU        EU      RU        EU     
where EP  EN  and EU denote the expectations over
pP    pN    and      respectively  Since we do not
have any samples from        
the true risk       
Ep     yg    which we want to minimize  should be
recovered without using         as shown below 

  PN Classi cation

In PU classi cation  we do not have labeled data for the
negative class  but we can use unlabeled data drawn from
marginal density      The goal of PU classi cation is
to train   classi er using only positive and unlabeled data 
The basic approach to PU classi cation is to discriminate  
and   data  Elkan   Noto    However  naively classifying   and   data causes   bias 

To address this problem  du Plessis et al      proposed   risk equivalent to the PN risk but where pN    is
not included  The key idea is to utilize unlabeled data to
evaluate the risk for negative samples in the PN risk  Replacing the second term in Eq    with 

   EN        EU           EP     
we obtain the risk in PU classi cation  the PU risk  as

   PRC

       RU     

RPU         EP          EU     
       EP        ande               

where RC
is   composite loss function 

 

NonConvex Approach 

If the loss function satis es

             

 

the composite loss function becomese             

We thus obtain the nonconvex PU risk as

RNPU       PRP      RU           

 

This formulation can be seen as costsensitive classi cation
of   and   data with weight     du Plessis et al   

The ramp loss used in the robust support vector machine
 Collobert et al   

       

 
 

max  min        

 

In standard supervised classi cation  PN classi cation  we
have both positive and negative data       fully labeled data 
The goal of PN classi cation is to train   classi er using
labeled data 

The risk in PN classi cation  the PN risk  is de ned as

satis es the condition   However 
the use of the
ramp loss  and any other losses that satisfy the condition   yields   nonconvex optimization problem  which
may be solved locally by the concaveconvex procedure
 CCCP   Yuille   Rangarajan    Collobert et al   
du Plessis et al   

RPN         EP           EN     

   PRP       NRN   

 

Convex Approach 
satis es

If   convex surrogate loss function

which is equal to      but         is not included  If we
use the hinge loss function         max         the
PN risk coincides with the risk of the support vector machine  Vapnik   

               

 

 The equation comes from the de nition of the marginal den 

sity         PpP       NpN   

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

the composite loss function becomes   linear function

           see Table   in du Plessis et al    We

thus obtain the convex PU risk as

RCPU       PRL

       RU     

where RL
       EP      is the risk with the linear loss
 Lin          This formulation yields the convex optimization problem that can be solved ef ciently 

  NU Classi cation

As   mirror of PU classi cation  we can consider NU classi cation  The risk in NU classi cation  the NU risk  is
given by

   NRC

RNU         EN          EU     
       EN        is the risk function with

where RC
the composite loss  Similarly to PU classi cation  the nonconvex and convex NU risks are expressed as

       RU     

RNNU       NRN      RU           
RCNU       NRL

       RU     

 

 

where RL

       EN      is the risk with the linear loss 

  SemiSupervised Classi cation Based on

PN  PU  and NU Classi cation

In this section  we propose semisupervised classi cation
methods based on PN  PU  and NU classi cation 

  PUNU Classi cation

  naive idea to build   semisupervised classi er is to combine the PU and NU risks  For         let us consider  
linear combination of the PU and NU risks 

  
PUNU           RPU       RNU   

We refer to this combined method as PUNU classi cation 

If we use   loss function satisfying the condition   the
nonconvex PUNU risk   
NPUNU    can be expressed as

  
NPUNU           PRP       NRN   

  EU                 
              

Here    
NPUNU    agrees with RPN    due to the condition   Thus  when       PUNU classi cation is reduced to ordinary PN classi cation 

On the other hand        is still effective when the condition   is satis ed  Its risk   
CPUNU    can be expressed
as

  
CPUNU           PRL

        NRL

    

  EU                 

Here                    can be regarded as  
loss function for unlabeled samples with weight  

When       unlabeled samples incur the same loss for
the positive and negative classes  On the other hand  when
            smaller loss is incurred for the negative
class than the positive class  Thus  unlabeled samples tend
to be classi ed into the negative class  The opposite is true
when          

  PNU Classi cation

Another possibility of using PU and NU classi cation in
semisupervised classi cation is to combine the PN and
PU NU risks  For         let us consider linear combinations of the PN and PU NU risks 

  
PNPU           RPN       RPU   
  
PNNU           RPN       RNU   

In practice  we combine PNPU and PNNU classi cation
and adaptively choose one of them with   new tradeoff
parameter         as

PNU       

  

PNPU   
PNNU   

  

     
     

We refer to the combined method as PNU classi cation 
Clearly  PNU classi cation with           corresponds to NU  PN  and PU classi cation  As   gets
large small  the effect of the positive negative classes is
more emphasized 

In the theoretical analyses in Section   we denote the
combinations of the PN risk with the nonconvex PU NU
risks by   
NPNNU  and that with the convex
PU NU risks by   

NPNPU and   

CPNPU and   

CPNNU 

  Practical Implementation

We have so far only considered the true risks    with
respect to the expectations over true data distributions 
When   classi er is trained from samples in practice  we

placed with corresponding sample averages 

use the empirical risks bR where the expectations are remodel given by        Pb

More speci cally  in the theoretical analysis in Section  
and experiments in Section   we use   linearin parameter
   wj            
where   denotes the transpose    is the number of basis

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

functions                  wb  is   parameter vector  and
                        is   basis function vector 
The parameter vector   is learned in order to minimize the
 regularized empirical risk 

min

  bR           

where       is the regularization parameter 

  Theoretical Analyses

In this section  we theoretically analyze the behavior of
the empirical versions of the proposed semisupervised
classi cation methods  We  rst derive generalization error bounds and then discuss variance reduction  Finally 
we discuss whether PUNU or PNU classi cation is more
promising  All proofs can be found in Appendix   

  Generalization Error Bounds

Let   be   function class of bounded hyperplanes 
            hw         kwk   Cw           
where Cw and    are certain positive constants  Since  
regularization is always included  we can naturally assume
that the empirical risk minimizer   belongs to   certain   
Denote by           sign    the zeroone loss
and        Ep     yg    the risk of   for binary
classi cation       the generalization error of    In the following  we study upper bounds of      holding uniformly
for all        We respectively focus on the  scaled  ramp
and squared losses for the nonconvex and convex methods
due to limited space  Similar results can be obtained with  
little more effort if other eligible losses are used  For convenience  we de ne   function as
 cP  cN  cU    cP   nP   cN   nN   cU nU 

NonConvex Methods    key observation is
that
            and consequently              Note
that by de nition we have

  

NPUNU        

NPNPU        

NPNNU          

The theorem below can be proven using the Rademacher
analysis  see  for example  Mohri et al    Ledoux  
Talagrand   

Theorem   Let       be the loss for de ning the empirical risks  For any       the following inequalities hold
separately with probability at least       for all       

NPUNU      Cw               
NPNPU      Cw                 
NPNNU      Cw                 

        bR 
        bR 
        bR 
where Cw     CwC      ln 

Theorem   guarantees that when       is used       can
be bounded from above by two times the empirical risks 
NPNNU    plus

      bR 

the corresponding con dence terms of order

NPUNU     bR 
NPNPU    and  bR 
Op nP    nN    nU 

Since nP  nN  and nU can increase independently  this is already the optimal convergence rate without any additional
assumption  Vapnik    Mendelson   

Convex Methods  Analogously  we have      
      for the squared loss  However  it is too loose when
        Fortunately  we do not have to use       if we
work on the generalization error rather than the estimation
error  To this end  we de ne the truncated  scaled  squared
loss  TS    as

 TS         

   

         
otherwise 

so that        TS    is much tighter  For  TS   
RCPU    and RCNU    need to be rede ned as follows
 see du Plessis et al   

RCPU       PR 
RCNU       NR 

       RU     
       RU     

where   

     and   

     are simply RP    and RN   

       the composite losse TS       TS       TS   
The conditione TS         means the loss of convexity 

but the equivalence is not lost  indeed  we still have

  

CPUNU        

CPNPU        

CPNNU          

Theorem   Let  TS    be the loss for de ning the empirical risks  where RCPU    and RCNU    are rede ned 
For any       the following inequalities hold separately
with probability at least       for all       

CPUNU         
CPNPU         
CPNNU         

        bR 
        bR 
        bR 
      CwC      ln 

              
              
              

where    

Theorem   ensures that when  TS    is used  for evaluating the empirical risks rather than learning the empirical
risk minimizers       can be bounded from above by four
times the empirical risks plus con dence terms in the optimal parametric rate  As  TS            Theorem   is
valid  but weaker  if all empirical risks are             

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

  Variance Reduction

Our empirical risk estimators proposed in Section   are all
unbiased  The next question is whether their variance can

be smaller than that of bRPN         whether XU can help

reduce the variance in estimating      To answer this
question  pick any   of interest  For simplicity  we assume
that nU     to illustrate the maximum variance reduction that could be achieved  Due to limited space  we only
focus on the nonconvex methods 

Similarly to RP    and RN    let  
corresponding variance 

     and  

     be the

 
       VarP     

 
       VarN     
where VarP and VarN denote the variance over pP   
and pN    Moreover  denote by       
    nP
and       
    nN for short  and let Var be the
    pP xP
variance over pP xP
nN    
  xU

    pN xN

nP     pN xN

  

  

      xU

nU 

Theorem   Assume nU     For any  xed    let
  
 NPUNU   argmin

NPUNU     

   

       

 

Var bR 

 NPUNU

 

   

have

Then  we

by bR 

ther  Var bR 

NPUNU      Var bRPN   

Furfor all
     NPUNU       if          or for all
       NPUNU     if         
Theorem   guarantees that the variance is always reduced
NPUNU    if   is close to  NPUNU  which is optimal
for variance reduction  The interval of such good   values has the length min                  In
particular  if         or          the length is  
Theorem   Assume nU     For any  xed    let
       
 NPNPU  argmin
       
       
       

 NPNNU  argmin

NPNNU     

NPNPU     

   

   

 

 

Var bR 
Var bR 

   NPNNU  if         

Then  we have  NPNPU       if         or  NPNNU  
NPNPU     
for all        NPNPU  if     

    if          Additionally  Var bR 
Var bRPN   
    or Var bR 
NPNNU      Var bRPN    for all    
Theorem   implies that the variance of bRPN    is reN PNPU    if         or bR 
duced by either bR 

 Being  xed means   is determined before seeing the data for
evaluating the empirical risk  For example  if   is trained by some
learning method  and the empirical risk is subsequently evaluated
on the validation test data    is regarded as  xed in the evaluation 

NPNNU   

can reduce the variance 

As   corollary of Theorems   and  

if          where   should be close to  NPNPU or
 NPNNU  The range of such good   values is of length
min                  In particular  if     
NPNPU    given any         can reduce the variN PNNU    given any        

    bR 
ance  and if          bR 
variance achievable by bR 
bR 
Nevertheless  bR 
NPNPU    and bR 
wider range of nice   values than bR 

the minimum
NPNPU    and
NPNNU    at their optimal  NPUNU   NPNPU  and
 NPNNU is exactly the same  namely              
NPNNU    have   much

NPUNU    bR 

If we further assume that               the condition in
Theorems   and   as to whether         or         will
be independent of    Also  it will coincide with the condition in Theorem   in Niu et al    where the minimizers

NPUNU   

of bRPN    bRPU    and bRNU    are compared 

   nal remark is that learning is uninvolved in Theorems  
and   such that     can be any loss that satis es      
        and   can be any  xed decision function  For
instance  we may adopt     and pick some   resulted
from some other learning methods  As   consequence  the

variance ofbIPN    over the validation data can be reduced 

and then the crossvalidation should be more stable  given
that nU is suf ciently large  Therefore  even without being
minimized  our proposed risk estimators are themselves of
practical importance 

  PUNU vs  PNU Classi cation

We discuss here which approach  PUNU or PNU classi 
cation  is more promising according to stateof theart theoretical comparisons  Niu et al    which are based on
estimation error bounds 

Let bgPN  bgPU  and bgNU be the minimizers of bRPN   
bRPU    and bRNU    respectively 

Let  PU PN  
   nP    nU   nN  and  NU PN
 
   nN    nU   nP  The  nitesample comparisons state that if  PU PN      NU PN     PN classi cation is more promising than PU  NU  classi cation 

       bgPN      bgPU     bgPN      bgNU  otherwise

PU  NU  classi cation is more promising than PN classi 
cation  cf  Section   in Niu et al   

Suppose that nU is not suf ciently large against nP and nN 
According to the  nitesample comparisons  PN classi cation is most promising  and either PU or NU classi cation

is the second best         bgPN      bgPU      bgNU 
or   bgPN      bgNU      bgPU  On the other hand 

if nU is suf ciently large  nU     which is faster
than nP  nN     we have the asymptotic comparisons   
NU PN  

PU PN   limnP nN nU   PU PN   

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

limnP nN nU   NU PN  and  
NU PN     From
the last equation  if  
NU PN     implying that PU  PN  classi cation is more promising than PN

PU PN 
PU PN     then  

Similarly  when  

PU PN     and  

 NU  classi cation         bgPU      bgPN      bgNU 
NU PN       bgNU   
  bgPN      bgPU   cf  Section   in Niu et al   

In realworld applications  since we do not know whether
the number of unlabeled samples is suf ciently large or not 
  practical approach is to combine the best methods in both
the  nitesample and asymptotic cases  PNU classi cation
is the combination of the best methods in both cases  but
PUNU classi cation is not 
In addition  PUNU classi 
cation includes the worst one in its combination in both
cases  From this viewpoint  PNU classi cation would be
more promising than PUNU classi cation  as demonstrated
in the experiments shown in the next section 

  Experiments

In this section  we  rst numerically analyze the proposed
approach and then compare the proposed semisupervised
classi cation methods against existing methods  All experiments were carried out using   PC equipped with two
 GHz Intel  Xeon        CPUs 

  Experimental Analyses

Here  we numerically analyze the behavior of our proposed
approach  Due to limited space  we show results on two out
of six data sets and move the rest to Appendix   

Common Setup  As   classi er  we use the Gaussian

kernel model        Pn

   wi exp kx   xik 
where     nP   nN   wi  
   are the parameters 
 xi  
     XP XN  and       is the Gaussian bandwidth 
The bandwidth candidates are              
median kxi   xjkn
     The classi er trained by miniber of labeled samples for training is   where the classprior was   In all experiments  we used the squared loss
for training  We note that the classprior of test data was
the same as that of unlabeled data 

mizing the empirical PN risk is denoted bybgPN  The num 

Variance Reduction in Practice  Here  we numerically
investigate how many unlabeled samples are suf cient in
practice such that the variance of the empirical PNU risk
PNU     

is smaller than that of the PN risk  Var bR 
Var bRPN    given    xed classi er   
As the  xed classi er  we used the classi erbgPN  where
and PNU risks  Var bRPN bgPN  and Var bR 
PNU bgPN  we

the hyperparameters were determined by  vefold crossvalidation  To compute the variance of the empirical PN

repeatedly drew additional nV

      positive  nV

     

 
 
 
 
 
 
 
 

 
 

 
 
 
 
 

 

 

 

 

 

      
      
      

 

 

         

nv
 

 
 
 
 
 
 
 
 

 
 

 
 
 
 
 

 

 

 

 

 

 

 

 

         

nv
 

    Phoneme       

    Magic       

Figure   Average and standard error of
the ratio between
the variance of empirical PNU risk and that of PN risk 
Var  bR 
PNU bgPN  Var  bRPN bgPN  as   function of the number
of unlabeled samples over   trials  Although the variance reduction is proved for an in nite number of samples  it can be observed with    nite number of samples 

negative  and nV
  unlabeled samples from the rest of the
data set  The additional samples were also used for ap 

Eqs  and  

Figure   shows the ratio between the variance of
the PN risk 
the empirical PNU risk and that of

proximatingb   bgPN  andb   bgPN  to compute          in
Var bR 
PNU bgPN  Var bRPN bgPN  The number of unla 

beled samples for validation nV
  increases from   to  
We see that with   rather small number of unlabeled samples  the ratio becomes less than   That is  the variance
of the empirical PNU risk becomes smaller than that of the
PN risk  This implies that although the variance reduction
is proved for an in nite number of unlabeled samples  it can
be observed under    nite number of samples in practice 

Compared to when        and   the effect of variance
reduction is small when        This is because if we
assume               when nP   nN and       
we have  NPNPU    NPNNU      because         
See Theorem   That is  the PNU risk is dominated by

the PN risk  implying that Var bR 

Note that the classprior is not the only factor for variance reduction  for example  if        nP   nN  and
              then  NPNPU      because         
and the variance reduction will be large 

PNU      Var bRPN   

PNU Risk in Validation  As discussed in Section   the
empirical PNU risk will be   reliable validation score due
to its having smaller variance than the empirical PN risk 
We show here that the empirical PNU risk is   promising
alternative to   validation score 

To focus on the effect of validation scores only  we trained
two classi ers by using the same risk       the empirical
PN risk  We then tune the classi ers with the empirical
PN   respectively 
The number of validation samples was the same as in the
previous experiment 

PN and PNU risks denoted bybgPN

PN andbgPNU

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 

 

 
 

 
 
 
 
 

 

 

 

 

 

 

      
      
      

 

 

         

nv
 

 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 

 

 
 

 
 
 
 
 

 

 

 

 

 

 

 

         

nv
 

    Phoneme       

    Magic       

Figure   Average and standard error of the ratio between the misclassi cation rates of bgPNU
PN as   function of unlabeled
samples over   trials  In many cases  the ratio becomes less
than   implying that the PNU risk is   promising alternative to
the standard PN risk in validation if unlabeled data are available 

PN and bgPN

PNU

PUNU

ER

LapSVM

SMIR

WellSVM

  VM

 

 

 

 

 

 
 
 
 
 
 

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 

Banana
Phoneme

Magic

Image

Susy

ijcnn 

Waveform
German

   

Spambase
covtype

phishing
Splice

   

Coil 

   

Figure   Average computation time over   trials for benchmark
data sets when nL    

ofbgPNU
PN and that ofbgPN
than        bgPNU
In particular  when        and  bgPNU

Figure   shows the ratio between the misclassi cation rate
PN  The number of unlabeled samples for validation increases from   to   With   rather
small number of unlabeled samples  the ratio becomes less
PN 
PN improved substantially  the large improvement tends to give the large
variance reduction  cf  Figure   This result shows that
the use of the empirical PNU risk for validation improved
the classi cation performance given   relatively large size
of unlabeled data 

PN achieves better performance thanbgPN

  Comparison with Existing Methods

Next  we numerically compare the proposed methods
against existing semisupervised classi cation methods 

Common Setup  We compare our methods against  ve
conventional semisupervised classi cation methods  entropy regularization  ER   Grandvalet   Bengio   
the Laplacian support vector machine  LapSVM   Belkin
et al    Melacci   Belkin    squaredloss mutual information regularization  SMIR   Niu et al   
the weakly labeled support vector machine  WellSVM   Li
et al    and the safe semisupervised support vector
machine    VM   Li   Zhou   

Among the proposed methods  PNU classi cation and

Table   Average and standard error of the misclassi cation rates
of each method over   trials for benchmark data sets  Boldface
numbers denote the best and comparable methods in terms of average misclassi cations rate according to   ttest at   signi cance
level of   The bottom row gives the number of best comparable
cases of each method 

Data set nL

PNU

PUNU

ER

LapSVM SMIR WellSVM   VM

Banana
     

                             
                             

Phoneme

     

                             
                             

Magic
     

Image
     

Susy
     

                             
                             

                             
                             

                             
                             

German
     

                             
                             

Waveform                              
                             

     

ijcnn 
     

   
     

                             
                             

                             
         
                   

covtype
     

                             
                             

Spambase                              
                             

     

Splice
     

                             
                             

phishing
     

                             
                             

   

     

                             
                             

Coil 

     

   

     

                             
                             

                             
                             

 Best Comp 

 

 

 

 

 

 

 

PUNU classi cation with the squared loss were tested 

Data Sets  We used sixteen benchmark data sets taken
from the UCI Machine Learning Repository  Lichman 
  the SemiSupervised Learning book  Chapelle et al 
  the LIBSVM  Chang   Lin    the ELENA
Project  and   paper by Chapelle   Zien   Each
feature was scaled to     Similarly to the setting in Section   we used the Gaussian kernel model for all methods  The training data is  xi  
     XP  XN  XU  where
    nP   nN   nU  We selected all hyperparameters with
validation samples of size    nV
      For training  we drew nL labeled and nU     unlabeled samples 
The classprior of labeled data was set at   and that of unlabeled samples was set at        that were assumed to
be known  In practice  the classprior      can be estimated

    nV

 In preliminary experiments  we tested other loss functions
such as the ramp and logistic losses and concluded that the difference in loss functions did not provide noticeable difference 

 https www elen ucl ac be neural 

nets Research Projects ELENA elena htm

 http olivier chapelle cc lds 

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

Table   Average and standard error of misclassi cation rates over
  trials for the Places   data set  Boldface numbers denote the
best and comparable methods in terms of the average misclassi 
cation rate according to   ttest at   signi cance level of  

Data set

nU

  

   

PNU

ER

LapSVM

SMIR

WellSVM

                           
                       
   
   
   

                   

                           
                       
   
   
   

                   

 
 
 
 
 
 

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 

 

 

 

PNU

ER

LapSVM

Arts

Deserts

Fields

Stadiums Platforms Temples

Arts

Deserts

Fields

                           
                       
   
   
   

                   

Figure   Average computation time over   trials for the Places
  data set when nU    

Stadiums

                           
                       
   
   
   

                   

Platforms

                           
                       
   
   
   

                   

Temples

                           
                       
   
   
   

                   

by methods proposed       by Blanchard et al    Ramaswamy et al    or Kawakubo et al   

Table   lists the average and standard error of the misclassi cation rates over   trials and the number of
best comparable performances of each method in the bottom row  The superior performance of PNU classi cation
over PUNU classi cation agrees well with the discussion
in Section   With the     data set  which well satis es the lowdensity separation principle  the WellSVM
achieved the best performance  However  in the Banana
data set  where the two classes are highly overlapped  the
performance of WellSVM was worse than the other methods  In contrast  PNU classi cation achieved consistently
better comparable performance and its performance did
not degenerate considerably across data sets  These results show that the idea of using PU classi cation in semisupervised classi cation is promising 

Figure   plots the computation time  which shows that the
fastest computation was achieved using the proposed methods with the square loss 

Image Classi cation  Finally  we used the Places  
data set  Zhou et al    which contains   million images in   scene classes  We used    dimensional feature vector extracted from each image by AlexNet under the
framework of Caffe  which is available on the project website  We chose two similar scenes to construct binary classi cation tasks  see the description of data sets in Appendix
   We drew   labeled and nU unlabeled samples from
each task  the classprior of labeled and unlabeled data
were respectively set at   and      mP mP   mN 
where mP and mN respectively denote the number of total
samples in positive and negative scenes  We used   linear

 http caffe berkeleyvision org 
 http places csail mit edu 

classi er                 where   is the weight vector
and    is the offset  in the SMIR  the linear kernel model
is used  see Niu et al    for details 

We selected hyperparameters in PNU classi cation by applying  vefold crossvalidation with respect to    
PNU   
with the zeroone loss  where   was set at Eq  or
Eq  with               The classprior      
       was estimated using the method based on energy distance minimization  Kawakubo et al   

Table   lists the average and standard error of the misclassi cation rates over   trials  where methods taking more
than   hours were omitted and indicated as      The results
show that PNU classi cation was most effective  The average computation times are shown in Figure   revealing
again that PNU classi cation was the fastest method 

  Conclusions

In this paper  we proposed   novel semisupervised classi cation approach based on classi cation from positive
and unlabeled data  Unlike most of the conventional methods  our approach does not require strong assumptions on
the data distribution such as the cluster assumption  We
theoretically analyzed the variance of risk estimators and
showed that unlabeled data help reduce the variance without the conventional distributional assumptions  We also
established generalization error bounds and showed that
the con dence term decreases with respect to the number of positive  negative  and unlabeled samples without
the conventional distributional assumptions in the optimal
parametric order  We experimentally analyzed the behavior
of the proposed methods and demonstrated that one of the
proposed methods  termed PNU classi cation  was most
effective in terms of both classi cation accuracy and computational ef ciency  It was recently pointed out that PU
classi cation can behave undesirably for very  exible models and   modi ed PU risk has been proposed  Kiryo et al 
  Our future work is to develop   semisupervised
classi cation method based on the modi ed PU classi cation 

SemiSupervised Classi cation Based on Classi cation from Positive and Unlabeled Data

Acknowledgements

TS was supported by JSPS KAKENHI     GN was
supported by the JST CREST program and Microsoft Research Asia  MCdP and MS were supported by the JST
CREST program 

References

Belkin     Niyogi     and Sindhwani     Manifold regularization    geometric framework for learning from
labeled and unlabeled examples  Journal of Machine
Learning Research     

Kiryo     Niu     du Plessis        and Sugiyama    
Positiveunlabeled learning with nonnegative risk estimator  arXiv preprint arXiv   

Krijthe        and Loog     Robust semisupervised least
squares classi cation by implicit constraints  Pattern
Recognition     

Ledoux     and Talagrand     Probability in Banach

Spaces  Isoperimetry and Processes  Springer   

Li       and Zhou       Towards making unlabeled data
never hurt  IEEE Transactions on Pattern Analysis and
Machine Intelligence     

Blanchard     Lee     and Scott     Semisupervised novelty detection  Journal of Machine Learning Research 
   

Li       Tsang        Kwok        and Zhou       Convex and scalable weakly labeled SVMs  Journal of Machine Learning Research     

Chang       and Lin       LIBSVM    library for support vector machines  ACM Transactions on Intelligent Systems and Technology      Software available at http www csie ntu edu 
tw cjlin libsvm 

Chapelle     and Zien     Semisupervised classi cation
by low density separation  In AISTATS  pp     

Chapelle     Sch lkopf     and Zien      eds  Semi 

Supervised Learning  MIT Press   

Collobert     Sinz     Weston     and Bottou     Trading

convexity for scalability  In ICML  pp     

Cozman        Cohen     and Cirelo       

supervised learning of mixture models 
   

SemiIn ICML  pp 

Lichman     UCI machine learning repository    URL

http archive ics uci edu ml 

Melacci     and Belkin     Laplacian support vector machines trained in the primal  Journal of Machine Learning Research     

Mendelson     Lower bounds for the empirical minimization algorithm  IEEE Transactions on Information Theory     

Mohri     Rostamizadeh     and Talwalkar     Founda 

tions of Machine Learning  MIT Press   

Niu     Jitkrittum     Dai     Hachiya     and
Sugiyama     Squaredloss mutual information regularization    novel informationtheoretic approach to semisupervised learning 
In ICML  volume   pp   
 

du Plessis        Niu     and Sugiyama     Analysis of
learning from positive and unlabeled data  In NIPS  pp 
   

Niu     du Plessis        Sakai     Ma     and Sugiyama 
   Theoretical comparisons of positiveunlabeled learning against positivenegative learning  In NIPS   

du Plessis        Niu     and Sugiyama     Convex formulation for learning from positive and unlabeled data 
In ICML  volume   pp     

Ramaswamy        Scott     and Tewari     Mixture proportion estimation via kernel embedding of distributions 
In ICML   

Elkan     and Noto     Learning classi ers from only positive and unlabeled data  In SIGKDD  pp     

Grandvalet     and Bengio     Semisupervised learning by

entropy minimization  In NIPS  pp     

Jain     White     and Radivojac     Estimating the class
prior and posterior from noisy positives and unlabeled
data  In NIPS   

Kawakubo     du Plessis        and Sugiyama     Computationally ef cient classprior estimation under class
balance change using energy distance  IEICE Transactions on Information and Systems      
 

Sokolovska     Capp     and Yvon     The asymptotics
of semisupervised learning in discriminative probabilistic models  In ICML  pp     

Vapnik        Statistical Learning Theory  John Wiley  

Sons   

Vapnik       The Nature of Statistical Learning Theory 

SpringerVerlag  New York  NY  USA   

Yuille        and Rangarajan     The concaveconvex pro 

cedure  CCCP  In NIPS  pp     

Zhou     Lapedriza     Xiao     Torralba     and Oliva 
   Learning deep features for scene recognition using
places database  In NIPS  pp     

