Dropout Inference in Bayesian Neural Networks with Alphadivergences

Yingzhen Li   Yarin Gal    

Abstract

To obtain uncertainty estimates with realworld
Bayesian deep learning models  practical inference approximations are needed  Dropout variational inference  VI  for example has been used
for machine vision and medical applications 
but VI can severely underestimates model uncertainty  Alphadivergences are alternative divergences to VI   KL objective  which are able
to avoid VI   uncertainty underestimation  But
these are hard to use in practice  existing techniques can only use Gaussian approximating distributions  and require existing models to be
changed radically  thus are of limited use for
practitioners  We propose   reparametrisation
of the alphadivergence objectives  deriving  
simple inference technique which  together with
dropout  can be easily implemented with existing models by simply changing the loss of the
model  We demonstrate improved uncertainty estimates and accuracy compared to VI in dropout
networks  We study our model   epistemic uncertainty far away from the data using adversarial
images  showing that these can be distinguished
from nonadversarial images by examining our
model   uncertainty 

  Introduction
Deep learning models have been used to obtain stateof 
theart results on many tasks  Krizhevsky et al   
Szegedy et al    Sutskever et al    Sundermeyer
et al    Mikolov et al    Kalchbrenner   Blunsom    and in many pipelines these models have replaced the more traditional Bayesian probabilistic models
 Sennrich et al    But unlike deep learning models 
Bayesian probabilistic models can capture parameter uncertainty and its induced effects over predictions  capturing
the models  ignorance about the world  and able to convey
their increased uncertainty on outof data examples  This

 University of Cambridge  UK  The Alan Turing Institute 

UK  Correspondence to  Yingzhen Li  yl cam ac uk 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

information can be used  for example  to identify when   vision model is given an adversarial image  studied below 
or to tackle many problems in AI safety  Amodei et al 
  With model uncertainty at hand  applications as farreaching as safety in selfdriving cars can be explored  using models which can propagate their uncertainty up the
decision making pipeline  Gal    With deterministic
deep learning models this invaluable uncertainty information is often lost 
Bayesian deep learning   an approach to combining
Bayesian probability theory together with deep learning  
allows us to use stateof theart models and at the same
time obtain model uncertainty  Gal    Gal   Ghahramani      Originating in the     Neal    MacKay 
  Denker   LeCun    Bayesian neural networks
 BNNs  in particular have started gaining in popularity
again  Graves    Blundell et al    HernandezLobato   Adams    BNNs are standard neural networks  NNs  with prior probability distributions placed
over their weights  Given observed data 
inference is
then performed to  nd what are the more likely and less
likely weights to explain the data  But as easy it is to
formulate BNNs  is as dif cult to perform inference in
them  Many approximations have been proposed over the
years  Denker   LeCun    Neal    Graves   
Blundell et al    HernandezLobato   Adams   
Hern andezLobato et al    some more practical and
some less practical    practical approximation for inference in Bayesian neural networks should be able to scale
well to large data and complex models  such as convolutional neural networks  CNNs   Rumelhart et al   
LeCun et al    Much more importantly perhaps  it
would be impractical to change existing model architectures that have been well studied  and it is often impractical
to work with complex and cumbersome techniques which
are dif cult to explain to nonexperts  Many existing approaches to obtain model con dence often do not scale to
complex models or large amounts of data  and require us to
develop new models for existing tasks for which we already
have well performing tools  Gal   
One possible solution for practical inference in BNNs is
variational inference  VI   Jordan et al      ubiquitous
technique for approximate inference  Dropout variational
distributions in particular    mixture of two Gaussians with

Dropout Inference in Bayesian Neural Networks with Alphadivergences

with randomly masked weights cid    our proposed objective

 cid   yn    cid    xn 
 cid 

logsum exp

    

to VI   objective

are

small standard deviations  and with one component  xed at
zero  can be used to obtain   practical inference technique
 Gal   Ghahramani      These have been used for machine vision and medical applications  Kendall   Cipolla 
  Kendall et al    Angermueller   Stegle   
Yang et al    Dropout variational inference can be
implemented by adding dropout layers  Hinton et al   
Srivastava et al    before every weight layer in the NN
model  Inference is then carried out by Monte Carlo  MC 
integration over the variational distribution  in practice implemented by simulating stochastic forward passes through
the model at test time  referred to as MC dropout  Although dropout VI is   practical technique for approximate
inference  it also has some major limitations  Dropout VI
can severely underestimate model uncertainty  Gal   
Section       property many VI methods share  Turner
  Sahani    This can lead to devastating results in applications that must rely on good uncertainty estimates such
as AI safety applications 
thereAlternative objectives
fore needed 
Blackbox  divergence minimisation
 Hern andezLobato et al    Li   Turner    Minka 
  is   class of approximate inference methods extending on VI  approximating EP   energy function  Minka 
  as well as the Hellinger distance  Hellinger   
These were proposed as   solution to some of the dif 
culties encountered with VI  However  the main dif culty
with  divergences is that the divergences are hard to use in
practice  Existing inference techniques only use Gaussian
approximating distributions  with the density over the approximation having to be evaluated explicitly many times 
The objective offers   limited intuitive interpretation which
is dif cult to explain to nonexperts  and of limited use
for engineers  Gal    Section   Perhaps more
importantly  current  divergence inference techniques require existing models and codebases to be changed radically to perform inference in the Bayesian counterpart to
these models  To implement   complex CNN structure with
the inference and code of  Hern andezLobato et al   
for example  one would be required to reimplement many
alreadyimplemented software tools 
In this paper we propose   reparametrisation of the induced  divergence objectives  and by relying on some
mild assumptions  justi ed below  derive   simple approximate inference technique which can easily be implemented with existing models  Further  we rely on the
dropout approximate variational distribution and demonstrate how inference can be done in   practical way   requiring us to only change the loss of the NN     and
to perform multiple stochastic forward passes at training
time  Precisely  given    some standard NN loss such
as cross entropy or the Euclidean loss  and    cid    xn  

  
  set of   stochastic dropout network outputs on input xn

is 
        
 

 cid 

 

with     real number    the set of network weights to
be optimised  and an    regulariser over   By selecting
      this objective directly optimises the perpoint predictive loglikelihood  while picking       would focus
on increasing the training accuracy  recovering VI 
Speci   choices of   will result in improved uncertainty estimates  and accuracy  compared to VI in dropout BNNs 
without slowing convergence time  We demonstrate this
through   myriad of applications  including an assessment
of fully connected NNs in regression and classi cation  and
an assessment of Bayesian CNNs  Finally  we study the
uncertainty estimates resulting from our approximate inference technique  We show that our models  uncertainty
increases on adversarial images generated from the MNIST
dataset  suggesting that these lie outside of the training data
distribution  This in practice allows us to tellapart such
adversarial images from nonadversarial images by examining epistemic model uncertainty 

  Background
We review background in Bayesian neural networks and
approximate variational inference  In the next section we
discuss  divergences 

  Bayesian Neural Networks
Given training inputs                 xN  and their corresponding outputs                 yN  in parametric
Bayesian regression we would like to infer   distribution
over parameters   of   function           that could have
generated the outputs  Following the Bayesian approach  to
 nd parameters that could have generated our data  we put
some prior distribution over the space of parameters   
This distribution captures our prior belief as to which parameters are likely to have generated our outputs before
observing any data  We further need to de ne   probability distribution over the outputs given the inputs         
For classi cation tasks we assume   softmax likelihood 

  cid       cid    Softmax       

or   Gaussian likelihood for regression  Given   dataset
      we then look for the posterior distribution over the
space of parameters          This distribution captures
how likely the function parameters are  given our observed
data  With it we can predict an output for   new input point
   by integrating

              

                 

 

 cid 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

One way to de ne   distribution over   parametric set of
functions is to place   prior distribution over   neural network   weights      Wi  
   resulting in   Bayesian NN
 MacKay    Neal    Given weight matrices Wi
and bias vectors bi for layer    we often place standard matrix Gaussian prior distributions over the weight matrices 
  Wi       Wi       and often assume   point estimate
for the bias vectors for simplicity 

  Approximate Variational Inference in Bayesian

Neural Networks

In approximate inference  we are interested in  nding the
distribution of weight matrices  parametrising our functions  that have generated our data  This is the posterior
over the weights given our observables              
which is not tractable in general  Existing approaches to
approximate this posterior are through variational inference  as was done in Hinton   Van Camp   Barber
  Bishop   Graves   Blundell et al   
We need to de ne an approximating variational distribution
    parametrised by variational parameters   and then
minimise          the KL divergence  Kullback   Leibler 
  Kullback    between the approximating distribution and the full posterior 

KL cid          cid 
 cid 
      cid 

   

 cid 

   log              KL     

   log   yi    xi      KL     

  

where       is slightly abused here to denote equality up
to an additive constant         variational parameters  

  Dropout Approximate Inference

Given    deterministic  neural network  stochastic regularisation techniques in the model  such as dropout  Hinton
et al    Srivastava et al    can be interpreted
as variational Bayesian approximations in   Bayesian NN
with the same network structure  Gal   Ghahramani 
    This is because applying   stochastic regularisation technique is equivalent to multiplying the NN weight
matrices Mi by some random noise     with   new noise
realisation for each data point  The resulting stochastic
weight matrices Wi    iMi can be seen as draws from the
approximate posterior over the BNN weights  replacing the
deterministic NN   weight matrices Mi  Our set of variational parameters is then the set of matrices      Mi  
  
For example  dropout can be seen as an approximation to
Bayesian NN inference with dropout approximating distributions  where the rows of the matrices Wi distribute according to   mixture of two Gaussians with small variances

 cid 
 cid 

and the mean of one of the Gaussians  xed at zero  The uncertainty in the weights induces prediction uncertainty by
marginalising over the approximate posterior using Monte
Carlo integration 

                  

 

                     
                

  cid 

          cid   

   
 

  

with  cid        where    is the Dropout distribu 

tion  Gal    Given its popularity  we concentrate on
the dropout stochastic regularisation technique throughout
the rest of the paper  although any other stochastic regularisation technique could be used instead  such as multiplicative Gaussian noise  Srivastava et al    or dropConnect
 Wan et al   
Dropout VI is an example of practical approximate inference  but it also underestimates model uncertainty  Gal 
  Section   This is because minimising the KL divergence between    and         penalises    for
placing probability mass where         has no mass 
but does not penalise    for not placing probability mass
at locations where         does have mass  We next
discuss  divergences as an alternative to the VI objective 

  Blackbox  divergence minimisation
In this section we provide   brief review of the black box alpha  BB  Hern andezLobato et al    method upon
which the main derivation in this paper is based  Consider
approximating the following distribution 

    

 
 

  

fn 

 cid 

 

In Bayesian neural networks context  these factors fn 
represent the likelihood terms   yn xn              
and the approximation target    is the exact posterior
        Popular methods of approximate inference include variational inference  VI   Jordan et al    and
expectation propagation  EP   Minka    where these
two algorithms are special cases of power EP  Minka 
  that minimises Amari    divergence  Amari   
       in   local way 

        

 

     

   

      

 

 cid 

 cid 

 cid 

We provide details of  divergences and local approximation methods in the appendix  and in the rest of the paper
we consider three special cases in this rich family 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

  Exclusive KL divergence 

         KL        Eq

  Hellinger distance 
          Hel         

  Inclusive KL divergence 

 

log

 cid 

  
  

 cid 
 cid   cid cid     cid   
 cid 
 cid 

 cid 

  

         KL        Ep

log

  
  

 

Since       is used in VI and       is used in EP  in
later sections we will also refer to these alpha settings as
the VI value  Hellinger value  and EP value  respectively 
PowerEP  though providing   generic variational framework  does not scale with big data  It maintains approximating factors attached to every likelihood term fn 
resulting in space complexity       for the posterior approximation which is clearly undesirable  The recently proposed stochastic EP  Li et al    and BB   Hern andezLobato et al    inference methods reduce this memory
overhead to    by sharing these approximating factors 
Moreover  optimisation in BB  is done by descending the
so called BB  energy function  where Monte Carlo  MC 
methods and automatic differentiation are also deployed to
allow fast prototyping 
BB  has been successfully applied to Bayesian neural
networks for regression  classi cation  Hern andezLobato
et al    and modelbased reinforcement learning  Depeweg et al    They all found that using    cid    often
returns better approximations than the VI case  The reasons for the worse results of VI are two fold  From the
perspective of inference  due to the zeroforcing behaviour
of exclusive KL discussed before  VI often  ts to   local
mode of the exact posterior and is overcon dent in prediction  On hyperparameter learning point of view  as the
variational lowerbound is used as    biased  approximation
to the maximum likelihood objective  the learned model
could be biased towards oversimpli ed cases  Turner  
Sahani    These problems could potentially be addressed by using  divergences  For example  inclusive
KL encourages the coverage of the support set  referred
as masscovering  and when used in local divergence minimisation  Minka    it can    an approximation to  
mode of    with better estimates of uncertainty  Moreover the BB  energy provides   better approximation to
the marginal likelihood as well  meaning that the learned
model will be less biased and thus  tting the data distribution better  Li   Turner    Hellinger distance seems
to provide   good balance between zeroforcing and masscovering  and empirically it has been found to achieve the
best performance 

Given the success of  divergence methods  it is   natural
idea to extend these algorithms to other classes of approximations such as dropout  However this task is nontrivial 
First  the original formulation of BB  energy is an ad hoc
adaptation of powerEP energy  see appendix  which applies to exponential family   distributions only  Second 
the energy function offers   limited intuitive interpretation
to nonexperts  thus of limited use for practitioners  Third
and most importantly    naive implementation of BB  using dropout would bring in   prohibitive computational burden  To see this  we  rst review the BB  energy function
in the general case  Li   Turner    given    cid   

 cid cid 

 cid 

 

          
 

log Eq

fn     

 

    

 

 cid cid 

 

 

 

log

 
 

 cid cid 

 cid 

 cid 

One could verify that this is the same energy function as
presented in  Hern andezLobato et al    by considering   an exponential family distribution 
In practice  
might be intractable  hence an MC approximation is introduced 

 cid cid 
 cid        This is   biased approximation as the

fn cid     cid     
  cid     

           
LMC
 

with
expectation in   is computed before taking the logarithm 
But empirically Hern andezLobato et al    showed
that the bias introduced by the MC approximation is often dominated by the variance of the samples  meaning that
the effect of the bias is negligible  When       it returns
the variational free energy  the VI objective 

       LVFE      KL       cid 

Eq  log fn     

 

 

 

 

 

    LMC

VFE becomes
VFE as the

and the corresponding MC approximation LMC
an unbiased estimator of LVFE  Also LMC
number of samples      
The original paper  Hern andezLobato et al    proposed   naive implementation which directly evaluates the

MC estimation   with samples  cid        However
masked weight matrices  cid      for different data points 

as discussed before  dropout implicitly samples different

This indicates that the naive approach  when applied to
dropout approximation  would gather all these samples for
all   datapoints in   minibatch           sets of neural
network weight matrices in total  which brings prohibitive
cost if the network is wide and deep  Interestingly  the minimisation of the variational free energy       with the
dropout approximation can be computed very ef ciently 
The main reason for this success is due to the additive structure of the variational free energy  no evaluation of   density is required if the  regulariser  KL      can be computed approximated ef ciently  In the following section we

Dropout Inference in Bayesian Neural Networks with Alphadivergences

propose an improved version of BB  energy to allow applications with dropout and other  exible approximation
structures 

exp   yn     xn       see  LeCun et al   
Swapping fn  for this last expression  and approximating the expectation over   using Monte Carlo sampling  we
obtain our proposed minimisation objective 

    New Reparameterisation of BB  Energy
We propose   reparamterisation of the BB  energy to reduce the computational overhead  First we denote     as
  freeform  cavity distribution   see appendix  and write
the approximate posterior   as

 cid     

 cid   

  

 
Zq

 

   

  

    

 
where we assume Zq     is the normalising constant
to ensure     valid distribution  When        the unnormalised density in   converges to     for every  
and Zq     by the assumption of Zq      Van Erven   Harremo es    Hence        when       
and this happens for example when we choose       or
      as well as when   grows sublinearly to   
Now we rewrite the BBalpha energy in terms of    

 

  cid   
 cid   
 cid 
 cid 
 cid   

log Zq

  

  

 

   

 
Zq

  

  
  fn   
     
 

 cid   cid 
 cid     
   fn   cid 
 cid     
 cid 
 cid 
 cid 
 cid 

log      fn 

   
 

  

   

log

 

          
 

 

 cid 
 cid 
 cid 

 

log

 cid cid 

     
 

 

 
 

     
 

 

 

            
 

log      fn       

     
where        represents the   enyi divergence    enyi
  see appendix  of order   Furthermore  provided
            which holds when assuming Zq  
  we have          KL        KL      as
      This means that for   constant   that scales sub 
 
linearly with    in large data settings we can further approximate the BB  energy as
               KL         
 
Note that here we also use the fact that now         Critically  the proposed reparameterisation is continuous in  
and by taking       the variational freeenergy   is recovered 
Given   loss function            loss in regression or
cross entropy in classi cation  we can de ne the  unnormalised  likelihood term fn      yn xn     

log Eq  fn   

 cid 

 

 cid 

 

 LMC
        KL        const

 

   
 

logsum exp   yn    cid    xn 
samples from the approximate posterior  cid        This

with logsum exp being the logsum exp operator over  

objective function also approximates the marginal likelihood  Therefore  compared to the original formulation  
the improved version   is considerably simpler  both to
implement and to understand  has   similar form to standard objective functions used in deep learning research  yet
remains an approximate Bayesian inference algorithm 
To gain some intuitive understanding of this objective  we
observe what it reduces to for different   and   settings 
By selecting       the perpoint predictive loglikelihood
log Eq   yn xn    is directly optimised  On the other
hand  picking the VI value       would focus on increasing the training accuracy Eq log   yn xn    The
Hellinger value could be used to achieve   balance between
reducing training error and improving predictive likelihood  which has been found to be desirable  Hern andezLobato et al    Depeweg et al    Lastly  for
      the logsum exp disappears  the    cancel out  and
the original  stochastic  VI objective is recovered 
In summary  our proposal modi es the loss function by
multiplying it by   and then performing logsum exp with
  sum over multiple stochastic forward passes sampled
from the BNN approximate posterior  The remaining KLdivergence term  between   and the prior    can often be
approximated  It can be viewed as   regulariser added to
the objective function  and reduces to   norm regulariser
for certain popular   choices  Gal   

  Dropout BB 

We now provide   concrete example where the approximate
distribution is de ned by dropout  With dropout VI  MC
samples are used to approximate the expectation          
which in practice is implemented as performing stochastic
forward passes through the dropout network        given an
input    the input is fed through the network and   new
dropout mask is sampled and applied at each dropout layer 
This gives   stochastic output     sample from the dropout
network on the input      similar approximation is used
in our case as well  where to implement the MC sampling
in eq    we perform multiple stochastic forward passes

 fn  does not need to be   normalised density of yn unless

one would like to optimise the associated hyper parameters 

 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

 

 

 

 
 

 
 

 

 

 

yn 

yT

  log

through the network 
Recall the neural network       is parameterised by the
variable   In classi cation  cross entropy is often used as
the loss function               yT log      where the
label yn is   onehot binary vector  and the network output
  xn    Softmax    xn  encodes the probability vector of class assignments  Applying the reformulated BB 
energy   with   Bayesian equivalent of the network  we
 cid 
arrive at the objective function
     
 cid 
 
  cid    xn 

 cid 
   cid    xn 
 cid 

pi Mi 

  Mi 

 cid 

 cid 

 LMC
       

 cid 
 cid 
with    cid    xn  

 
 

 

 

 

   being   stochastic network outputs
on input xn  pi equals to one minus the dropout rate of
the ith layer  and the    regularization terms coming from
an approximation to the KLdivergence  Gal        
we raise network probability outputs to the power   and
average them as an input to the standard cross entropy loss 
Taking    cid    can be viewed as training the neural network
with an adjusted  power  loss  regularized by an    norm 
Implementing this induced loss with Keras  Chollet   
is as simple as   few lines of Python    code snippet is
given in Figure   with more details in the appendix 
In regression problems 
the loss function is de ned as
  and the likelihood term can
              
be interpreted as                     Plugging this
into the energy function returns the following objective
 yn     cid    xn 
 LMC
           
 

          
 cid 

logsum exp

 

 cid 

 cid   
 cid 

 

 

pi Mi 
 

 
   

 

 

log    

 

with    cid    xn  

   being   stochastic forward passes on
input xn  Again  this is reminiscent of the    objective in
standard deep learning  and can be implemented by simply passing the input through the dropout network multiple
times  collecting the stochastic outputs  and feeding the set
of outputs through our new BBalpha loss function 

def softmax cross ent with mc logits alpha 

def loss   true  mc logits 

  mc logits  MC samples of shape MxKxD
mc log softmax   mc logits  

    max mc logits  axis  keepdims True 

mc log softmax   mc log softmax    

logsumexp mc log softmax   

mc ll     sum   true mc log softmax 
return  alpha    logsumexp alpha    

mc ll        log      mc 

return loss

Figure   Code snippet for our induced classi cation loss 

  Regression

The  rst experiment considers Bayesian neural network regression with approximate posterior induced by dropout 
We use benchmark UCI datasets  that have been tested
in related literature  The model is   singlelayer neural network with   ReLU units for all datasets except
for Protein and Year  which use   units  We consider
          in order to examine the effect of masscovering zeroforcing behaviour in dropout  MC approximation with       samples is also deployed to compute
the energy function  Other initialisation settings are largely
taken from  Li   Turner   
We summarise the test negative loglikelihood  LL  and
RMSE with standard error  across different random splits 
the lower the better  for selected datasets in Figure   and  
respectively  The full results are provided in the appendix 
Although optimal   may vary for different datasets  using
nonVI values has signi cantly improved the testLL performances  while remaining comparable in test error metric  In particular        produced overall good results
for both test LL and RMSE  which is consistent with previous  ndings  We also compare with   BNN with   Gaussian approximation  VIG   Li   Turner      BNN
with HMC  and   sparse Gaussian process model with  
inducing points  Bui et al    In testLL metric our
best dropout model outperforms the Gaussian approximation method on almost all datasets  and for some datasets
is on par with HMC which is the current gold standard
for Bayesian neural works  and with the GP model that is
known to be superior in regression 

  Classi cation

  Experiments
We test the reparameterised BB  on Bayesian NNs with
the dropout approximation  We assess the proposed inference in regression and classi cation tasks on standard
benchmarking datasets  comparing different values of  
This last experiment leads us to propose   technique that
could be used to identify adversarial image attacks  In the
appendix we further provide   study of run time tradeoff 

We further experiment with   classi cation task  comparing
the accuracy of the various   values on the MNIST benchmark  LeCun   Cortes    We assessed   fully connect
NN with   hidden layers and   units in each layer  We
used dropout probability   and           Again 
we use       samples at training time for all   values 

 http archive ics uci edu ml datasets 

html

Dropout Inference in Bayesian Neural Networks with Alphadivergences

Figure   Negative testLL results for Bayesian NN regression 

Figure   Test RMSE results for Bayesian NN regression 

and Ktest     samples at test time  We use weight decay
  which is equivalent to prior lengthscale         Gal
  Ghahramani      We repeat each experiment three
times and plot mean and standard error  Test RMSE as well
as test log likelihood are given in Figure   As can be seen 
Hellinger value       gives best test RMSE  with test
log likelihood matching that of the EP value       The
VI value       underperforms according to both metrics 
We next assess   convolutional neural network model
 CNN  For this experiment we use the standard CNN example given in  Chollet    with   convolution  lters 
  hidden units at the top layer  and dropout probability
  before each fullyconnected layer  Other settings are as
before  Average test accuracy and test log likelihood are
given in Figure   In this case  VI value       seems to
supersede the EP value       and performs similarly to
the Hellinger value       according to both metrics 

  Detecting Adversarial Examples

The third set of experiments considers adversarial attacks
on dropouttrained Bayesian neural networks  We test the
hypothesis that certain techniques for generating adversarial examples will give images that lie outside of the image

manifold       far from the data distribution  note though
that there exist techniques that will guarantee the images
staying near the data manifold  by minimising the perturbation used to construct the adversarial example  By assessing the BNN uncertainty  we should see increased uncertainty for adversarial images if they indeed lie outside of the
training data distribution  The tested models are fully connected networks with   hidden layers of   units trained
using dropout rate   and different alpha values  These
models are also compared to   benchmark MLP with the
same architecture but trained by maximum likelihood  The
adversarial examples are generated on MNIST test data that
is normalised to be in the range     For the dropout
trained networks we perform MC dropout at test time with
Ktest     MC samples 
The  rst attack in consideration is the Fast Gradient Sign
 FGS  method  Goodfellow et al    This is an untargeted attack  which attempts to reduces the maximum
value of the predicted class label probability

xadv           sgn   max

 

log       

We use the single gradient step FGS implemented in Cleverhans  Papernot et al    with the stepsize   varied

    NN test accuracy

    NN test log likelihood

    CNN test accuracy

    CNN test log likelihood

Figure   MNIST test accuracy and test log likelihood for   fully
connected NN in   classi cation task 

Figure   MNIST test accuracy and test log likelihood for   convolutional neural network in   classi cation task 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

Figure   Untargeted attack  classi cation accuracy results as  
function of perturbation stepsize  The adversarial examples are
shown for  from top to bottom  MLP and BNN trained with
dropout and          

Figure   Targeted attack  classi cation accuracy results  on both
original and target class  as   function of the number of iterative
gradient steps  Note the log scale xaxis in the left panel 

between   and   The left panel in Figure   demonstrates the classi cation accuracy on adversarial examples 
which shows that the dropout networks  especially the one
trained with       are signi cantly more robust to adversarial attacks compared to the deterministic NN  For
example  for       the adversarial samples still visually close to the original class  and the BNN trained with
      achieves an accuracy level almost   times higher
than the MLP and around   higher than the VItrained
version  More interestingly  the test data examples and adversarial images can be toldapart by investigating the uncertainty representation of the dropout models  In the right
panel of Figure   we depict the predictive entropy computed on the neural network output probability vector  and
show example corresponding adversarial images below the
axis for each corresponding stepsize  Clearly the deterministic NN model produces overcon dent predictions on adversarial samples       it predicts the wrong label very con 
 dently even when the input is still visually close to digit
        While dropout models  though producing
wrong labels  are very uncertain about their predictions 
This uncertainty keeps increasing as we move away from
the data manifold  Hence the dropout networks are much
more immunised from noisecorrupted inputs  as they can
be detected using uncertainty estimates in this example 
The second attack we consider is   targeted version of FGS
 Goodfellow et al    Carlini   Wagner    which
maximises the predictive probability of   selected class instead  As an example  we    class   as the target and apply
the iterative gradientbase attack to all nonzero digits in
test data  At step    the adversarial output is computed as

adv   xt 
xt

adv       sgn   log   ytarget xt 

adv  

where the stepsize   is  xed at   in this case  Results are
presented in the left panel of Figure   and again dropout

trained models are more robust to this attack compared with
the MLP  Similarly these adversarial examples could be detected by the Bayesian neural networks  uncertainty  by examining the predictive entropy  By visually inspecting the
generated adversarial examples in the right panel of Figure   it is clear that the MLP overcon dently classi es  
digit   to class   On the other hand  the dropout models
are still fairly uncertain about their predictions even after
  gradient steps  More interestingly  running this iterative
attack on dropout models produces   smooth interpolation
between different digits  and when the model is con dent
on predicting the target class  the corresponding adversarial
images are visually close to digit zero 
These initial results suggest that assessing the epistemic
uncertainty of classi cation models can be used as   viable technique to identify adversarial examples  We would
note though that we used this experiment to demonstrate
our techniques  uncertainty estimates  and much more research is needed to solve the dif culties faced with adversarial inputs 

  Conclusions
We presented   practical extension of the BBalpha objective which allows us to use the technique with dropout approximating distributions  The technique often supersedes
existing approximate inference techniques  even sparse
Gaussian processes  and is easy to implement    code
snippet for our induced loss is given in the appendix 

Acknowledgements

We thank Rich Turner  Nicolas Papernot  and the reviewers
for comments  YL thanks the Schlumberger Foundation
FFTF fellowship for supporting her PhD study 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

References
Amari  Shunichi  DifferentialGeometrical Methods in Statistic 

Springer  New York   

Amodei  Dario  Olah  Chris  Steinhardt  Jacob  Christiano  Paul 
Schulman  John  and Mane  Dan  Concrete problems in ai
safety  arXiv preprint arXiv   

Angermueller    and Stegle     Multitask deep neural network to
predict CpG methylation pro les from lowcoverage sequencing data  In NIPS MLCB workshop   

Barber  David and Bishop  Christopher    Ensemble learning in
Bayesian neural networks  NATO ASI SERIES   COMPUTER
AND SYSTEMS SCIENCES     

Blundell  Charles  Cornebise  Julien  Kavukcuoglu  Koray  and
In

Wierstra  Daan  Weight uncertainty in neural network 
ICML   

Bui  Thang    Hern andezLobato  Daniel  Li  Yingzhen 
Hern andezLobato  Jos   Miguel  and Turner  Richard    Deep
gaussian processes for regression using approximate expectaIn Proceedings of The  rd International
tion propagation 
Conference on Machine Learning  ICML   

Carlini  Nicholas and Wagner  David  Towards evaluating the robustness of neural networks  arXiv preprint arXiv 
 

Chollet  Francois 

Keras 
fchollet keras   

https github com 

Denker  John and LeCun  Yann  Transforming neuralnet output
levels to probability distributions  In Advances in Neural Information Processing Systems   Citeseer   

Depeweg  Stefan  Hern andezLobato  Jos   Miguel  DoshiVelez 
Finale  and Udluft  Steffen  Learning and policy search in
stochastic dynamical systems with bayesian neural networks 
arXiv preprint arXiv   

Gal  Yarin  Uncertainty in Deep Learning  PhD thesis  University

of Cambridge   

Gal  Yarin and Ghahramani  Zoubin  Bayesian convolutional neural networks with Bernoulli approximate variational inference 
ICLR workshop track     

Gal  Yarin and Ghahramani  Zoubin  Dropout as   Bayesian approximation  Representing model uncertainty in deep learning 
ICML     

Goodfellow  Ian    Shlens  Jonathon  and Szegedy  Christian  Explaining and harnessing adversarial examples  arXiv preprint
arXiv   

Graves  Alex  Practical variational inference for neural networks 
In Advances in Neural Information Processing Systems  pp 
   

Hern andezLobato  Jos   Miguel  Li  Yingzhen  Hern andezLobato  Daniel  Bui  Thang  and Turner  Richard    Blackbox
alpha divergence minimization  In Proceedings of The  rd International Conference on Machine Learning  pp   
 

Hinton  Geoffrey   and Van Camp  Drew  Keeping the neural
networks simple by minimizing the description length of the
weights  In COLT  pp    ACM   

Hinton  Geoffrey    Srivastava  Nitish  Krizhevsky  Alex 
Sutskever  Ilya  and Salakhutdinov  Ruslan    Improving neural networks by preventing coadaptation of feature detectors 
arXiv preprint arXiv   

Jordan  Michael    Ghahramani  Zoubin  Jaakkola  Tommi    and
Saul  Lawrence    An introduction to variational methods for
graphical models  Machine learning     

Kalchbrenner  Nal and Blunsom  Phil  Recurrent continuous

translation models  In EMNLP   

Kendall  Alex and Cipolla  Roberto  Modelling uncertainty in
deep learning for camera relocalization  In   IEEE International Conference on Robotics and Automation  ICRA  pp 
  IEEE   

Kendall  Alex  Badrinarayanan  Vijay  and Cipolla  Roberto 
Bayesian segnet  Model uncertainty in deep convolutional
encoderdecoder architectures for scene understanding  arXiv
preprint arXiv   

Krizhevsky  Alex  Sutskever  Ilya  and Hinton  Geoffrey    Imagenet classi cation with deep convolutional neural networks 
In Advances in neural information processing systems  pp 
   

Kullback  Solomon  Information theory and statistics  John Wiley

  Sons   

Kullback  Solomon and Leibler  Richard    On information and
suf ciency  The annals of mathematical statistics   
   

LeCun  Yann and Cortes  Corinna  The mnist database of hand 

written digits   

LeCun  Yann  Boser  Bernhard  Denker  John    Henderson 
Donnie  Howard  Richard    Hubbard  Wayne  and Jackel 
Lawrence    Backpropagation applied to handwritten zip code
recognition  Neural Computation     

LeCun  Yann  Chopra  Sumit  Hadsell  Raia  Ranzato     and
Huang       tutorial on energybased learning  Predicting
structured data     

Li  Yingzhen and Turner  Richard      enyi divergence variational

inference  In NIPS   

Hellinger  Ernst  Neue begr undung der theorie quadratischer formen von unendlichvielen ver anderlichen  Journal   ur die reine
und angewandte Mathematik     

Li  Yingzhen  Hern andezLobato  Jos   Miguel  and Turner 
Richard    Stochastic expectation propagation  In Advances
in Neural Information Processing Systems  NIPS   

HernandezLobato  Jose Miguel and Adams  Ryan  Probabilistic
backpropagation for scalable learning of Bayesian neural networks  In ICML   

MacKay  David JC    practical Bayesian framework for backpropagation networks  Neural Computation   
 

Dropout Inference in Bayesian Neural Networks with Alphadivergences

Mikolov  Tom      Kara at  Martin  Burget  Luk       Cernock    Jan 
and Khudanpur  Sanjeev  Recurrent neural network based language model  In Eleventh Annual Conference of the International Speech Communication Association   

Minka  Tom  Divergence measures and message passing  Techni 

cal report  Microsoft Research   

Minka       Expectation propagation for approximate Bayesian
In Conference on Uncertainty in Arti cial Intelli 

inference 
gence  UAI   

Minka       Power EP  Technical Report MSRTR 

Microsoft Research   

Neal  Radford    Bayesian learning for neural networks  PhD

thesis  University of Toronto   

Papernot  Nicolas  Goodfellow 

man  Reuben  and McDaniel  Patrick 
an adversarial machine learning library 
arXiv   

Ian  Sheatsley  Ryan  Feincleverhans   
arXiv preprint

  enyi  Alfr ed  On measures of entropy and information  Fourth
Berkeley symposium on mathematical statistics and probability     

Rumelhart  David    Hinton  Geoffrey    and Williams  Ronald   
Learning internal representations by error propagation  Technical report  DTIC Document   

Sennrich  Rico  Haddow  Barry  and Birch  Alexandra  Edinburgh
neural machine translation systems for wmt   In Proceedings
of the First Conference on Machine Translation  pp   
Berlin  Germany  August   Association for Computational
Linguistics 

Srivastava  Nitish  Hinton  Geoffrey  Krizhevsky  Alex  Sutskever 
Ilya  and Salakhutdinov  Ruslan  Dropout    simple way to
prevent neural networks from over tting  The Journal of Machine Learning Research     

Sundermeyer  Martin  Schl uter  Ralf  and Ney  Hermann  LSTM
In INTERSPEECH 

neural networks for language modeling 
 

Sutskever  Ilya  Vinyals  Oriol  and Le  Quoc VV  Sequence to

sequence learning with neural networks  In NIPS   

Szegedy  Christian  Liu  Wei  Jia  Yangqing  Sermanet  Pierre 
Reed  Scott  Anguelov  Dragomir  Erhan  Dumitru  Vanhoucke  Vincent  and Rabinovich  Andrew  Going deeper with
convolutions  arXiv preprint arXiv   

Turner  RE and Sahani     Two problems with variational expectation maximisation for timeseries models  Inference and
Estimation in Probabilistic TimeSeries Models   

Van Erven  Tim and Harremo es  Peter 

and KullbackLeibler divergence 
Transactions on     

  enyi divergence
Information Theory  IEEE

Wan     Zeiler     Zhang     LeCun     and Fergus     Regularization of neural networks using dropconnect  In ICML 
 

Yang  Xiao  Kwitt  Roland  and Niethammer  Marc  Fast predictive image registration  arXiv preprint arXiv 
 

