Communicationef cient Algorithms for

Distributed Stochastic Principal Component Analysis

Dan Garber   Ohad Shamir   Nathan Srebro  

Abstract

We study the fundamental problem of Principal
Component Analysis in   statistical distributed
setting in which each machine out of   stores
  sample of   points sampled        from   single unknown distribution  We study algorithms
for estimating the leading principal component
of the population covariance matrix that are both
communicationef cient and achieve estimation
error of the order of the centralized ERM solution that uses all mn samples  On the negative side  we show that in contrast to results obtained for distributed estimation under convexity assumptions  for the PCA objective  simply
averaging the local ERM solutions cannot guarantee error that is consistent with the centralized
ERM  We show that this unfortunate phenomena
can be remedied by performing   simple correction step which correlates between the individual
solutions  and provides an estimator that is consistent with the centralized ERM for suf cientlylarge    We also introduce an iterative distributed
algorithm that is applicable in any regime of   
which is based on distributed matrixvector products  The algorithm gives signi cant acceleration
in terms of communication rounds over previous
distributed algorithms  in   wide regime of parameters 

  Introduction
Principal Component Analysis  PCA   Pearson   
Hotelling    Jolliffe    is one of the most celebrated and popular techniques in data analysis and ma 

Israel
Institute

Institute 

 Technion  
 Weizmann

Institute of Technology  Haifa 

IsIsrael
Illinois  USA  CorresponDan Garber  dangar technion ac il  Ohad
Srebro

rael
 Toyota Technological
dence to 
Shamir  ohad Shamir weizmann ac il  Nathan
 nati ttic edu 

of Science  Rehovot 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

NPN

chine learning  For data that consists of   vectors in
Rd       xN  with normalized covariance matrix     
   xix     The PCA method  nds the kdimensional
 
subspace  which corresponds to the span of the top   principal components  such that the projection of the data onto
the subspace has largest variance       it is the solution to
the optimization problem 

  Rd    WT   Ik  XWk 
   

max

 

 

PCA is often considered in   statistical setting in which the
assumption is that the input vectors are not arbitrary but
sampled        from some  xed but unknown distribution
with certain general characteristics    Then  it is often of
interest to use the observed sample to estimate the top  
principal components of the population covariance matrix 
rather then that of the sample  which leads to the modi ed
optimization problem 

max

  Rd    WT   IkEx   xx  Wk 

   

Of course the empirical estimation problem   and the
population estimation problem   are well connected  and
it is wellknown that under mild assumptions on the distribution   and given   suf ciently large sample  we can
guarantee small estimation error in   by solving optimization problem  
In this work we consider the problem of estimating the  rst
principal component             in   statistical and distributed setting  We assume the availability of   machines 
each of which stores   sample of   vectors sampled      
from    xed distribution   over Rd  and we are interested
in algorithms that can be applied ef ciently to solve Problem   for       with estimation error that approaches
that of   centralized algorithm  which has access to all mn
samples and does not pay for communication between machines  Indeed  when considering the ef ciency of algorithms  we will mainly focus on the amount of communication between machines they require  since this is often
the most expensive resource in distributed computing  We
note that the        assumption is standard in many applications of PCA  and can be leveraged to get more ef cient
algorithms than when the data partition is arbitrary  Also 
we will make   standard assumption that the population covariance matrix has   nonzero additive gap between the

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

 rst and second eigenvalues  which makes the problem of
estimating the leading principal component meaningful 
  main challenge that often arises in many computational
settings of principal components is that it leads to inherently nonconvex optimization problems  While many
times these problems turn out to admit ef cient algorithms 
the rich toolbox of optimization and statistical estimation
procedures developed for convex problems often cannot be
directly applied to problems such as   and   Instead 
one often needs to consider   specialized and more involved
analysis  to get analogous convergence results for the PCA
problem  This for instance was the case in   recent wave
of results that applied concepts such as stochastic gradient updates  Balsubramani et al    Shamir      Jain
et al      Allen Zhu   Li      and variance reduction  Shamir        Garber   Hazan    Garber
et al    Allen Zhu   Li      to the PCA problem 
This is also the case in our distributed setting  For instance 
 Zhang et al    proposed communicationef cient algorithms for   distributed statistical estimation settings 
similar to ours  but under convexity assumptions  The authors show that under their assumptions  in   wide regime
of parameters  namely when the permachine sample size
  is large enough  then   simple averaging of the empirical
risk minimizers  ERM  computed locally on each machine 
leads to estimation error of the population parameters of
the order the centralized ERM solution  While averaging
makes perfect sense in   convex setting  it is clear that it
can completely fail in   nonconvex setting 
Indeed  we
show that already for the PCA problem with       simply
averaging the local ERM solutions  and normalizing to obtain   unit vector as required  cannot improve signi cantly
over the estimation error of any single machine  We then
show that   simple    to the above scheme  namely correlating the directions of individual ERM solutions  remedies this phenomena and results in estimation error similar
to that of the centralized ERM solution  Much like the results of  Zhang et al    this result only holds in the
regime when the permachine sample size   is suf ciently
large  As discussed  due to the inherent nonconvexity of
the PCA objective  this approach requires   novel analysis
tailored to the PCA problem  In this context  we view this
work as an initiation of   research effort to understand how
to ef ciently aggregate statistical estimators in   distributed
nonconvex setting 
  second line of results for distributed estimation under
convexity assumptions consider iterative algorithms that
perform multiple communication rounds and are based on
distributed gradient computations  some examples include
 Shamir et al    Zhang   Lin    Lee et al   
Shamir      Jaggi et al    Reddi et al    The
bene   of these methods is that     they provide meaningful
estimation error guarantees in   much wider regime of pa 

rameters than the  oneshot  aggregation methods  namely
in terms of the number of samples per machine  and    
due to their iterative nature  they allow to approximate the
centralized ERM solution arbitrary well  Unfortunately 
these methods  all of which rely heavily on convexity assumption  cannot be directly applied to the PCA problem 
Towards designing ef cient distributed iterative methods
for our PCA setting  we consider the application of the
recently proposed method of Shiftand Invert power iterations       for PCA  Garber   Hazan    Garber et al 
  The     method reduces the problem of computing
the leading eigenvector of   real positive semide nite matrix to that of approximately solving   small number      
polylogarithmic in the problem parameters  of systems of
linear equations  These in turn  could be ef ciently solved
by arbitrary distributed convex solvers  We show that coupling the     method with the stochastic preconditioning
technique for linear systems proposed in  Zhang   Lin 
  and well known fast gradient methods such as the
conjugate gradient method  gives stateof theart guarantees in terms of communication costs  and provides   signi cant improvement over distributed variants of classical
fast eigenvector algorithms such as power iterations and the
faster Lanczos algorithm  Much like its convex counterparts  which only rely on distributed gradient computations
and simple vector aggregations  our iterative method only
relies on distributed matrixvector products       it requires
each machine to only send products of its local empirical
covariance matrix with some input vector 
Beyond the results described so far   Liang et al   
Boutsidis et al    studied distributed algorithms for
PCA in   deterministic setting in which the partition of
the data across machines is arbitrary and communication
is measured in terms of number of transmitted bits  The
approximation guarantees provided in these works are in
terms of the projection of the data onto the leading principal components  instead of alignment between the estimate
and the optimal solution  studied in this paper  Applying
these results to our setting will give   number of communication rounds that scales like poly  where   is the
desired error and   is the population eigengap  In our setting    will scale with the inverse of the size of the sample 
          mn  which for these algorithms will result in
amount of communication that is polynomial in the size of
the data  In contrast  we will be interested in algorithms
whose communication costs does not scale with   at all  In
this context we note that  by focusing on algorithms that
either perform simple aggregation of local ERM solutions 
or perform only distributed matrixvector products with the
empirical covariance matrix  we can circumvent the need to
measure communication explicitly in terms of the number
of bits transmitted  which often burdens the analysis of natural algorithms  such as those proposed here 

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

  Preliminaries
  Notation and problem setting
We write vectors in Rd in boldface lowercase letters      
   matrices in boldface uppercase letters          and
scalars are written as lightface letters          We let   
  denote the standard Euclidean norm for vectors and the
spectral norm for matrices 
We consider the following statistical distributed setting 
Let   be   distribution over vectors in Rd with squared
  norm at most    for some       We consider   setting
in which   machines  numbered     are each given  
dataset of   samples drawn        from    We let    denote
  leading eigenvector of the population covariance matrix
    Ex   xx  Our goal is to ef ciently  mainly in
terms of communication   nd an estimate   for          
unit vector that maximizes the product        with high
probability  Towards this end  we assume that the population covariance matrix   has   nonzero eigengap       
                  where     denotes the ith
largest eigenvalue of   symmetric real matrix  Note that
    is necessary for    to be uniquely de ned  up to
sign 
In addition  we let  Xi denote the empirical covariance matrix of the sample stored on machine   for every        
      Xi    
  are the
samples stored on machine    We let    denote the empirical covariance matrix of the union of points across all
machines            
Our model of communication assumes that the   machines
work in rounds during which   central machine          
machine   can send   single vector in Rd to all other machines  or every machine can send either the leading eigenvector of its local empirical covariance matrix  or the product of   single input vector with its local covariance  to machine   We will measure communication complexity in
terms of number of such rounds required to achieve   certain estimation error 

mPm

nPn

  where     

       

       

       

 Xi 

  

  THE CENTRALIZED SOLUTION
Our primary benchmark for measuring performance will be
the centralized empirical risk minimizer which is the leading eigenvector of the aggregated empirical covariance matrix    
The following standard result bounds the error of the centralized ERM 

Lemma    Risk of centralized ERM  Fix         Suppose that     and let     denote the leading eigenvector
of                arg maxv kvk      Xv  Then it holds     
at least       that

               ERM     

    ln     

mn 

 

 

Lemma   is   direct consequence of the following standard concentration argument for random matrices  and the
DavisKahan sin  theorem  whose proof is given in the
appendix for completeness 
Theorem    Matrix Hoeffding  see  Tropp    Let  
be   distribution over vectors with squared   norm at most
nPn
   and let     Ex   xx  Let       
   xix    
where      xn are sampled        from    Then  it holds
that       Pr        Xk           exp    
   
Theorem    DavisKahan sin  theorem  Let      be
symmetric real     matrices with leading eigenvectors vX
and vY respetively  Also  suppose that            
        Then it holds that    XvY     kX Yk 
 

  Informal statement of main results and previous

   

algorithms

We now informally describe our main results  followed by  
detailed description of previous approaches that are directly
applicable to our setting  The algorithmic results  both new
and old  are summarized in Table  

  MAIN RESULTS
Failure of simple averaging of local ERM solutions We
show that   natural approach of simply averaging the individual leading eigenvectors of the empirical covariance
matrices  Xi  and normalizing the obtain   unit vector 
cannot signi cantly improve  beyond logarithmic factors 
over the performance of any of the individual eigenvectors 
More concretely  if we let      
  denote the leading eigenvector of  Xi for any         and we denote their average
by        
    then there exists   distribution  
over vectors with magnitude    and covariance eigengap       such that

mPm

        

        ED          

            
    

See Theorem   in Section   for the complete and formal
argument 

  successful single communication round algorithm via
correlation of individual ERM solutions We show that
if prior to averaging the local ERM solutions  as suggested
above  we correlate their directions by aligning them according to any single machine  say machine number  
     we let        
    then this
guarantees that for any              at least       
   ln  dm
   
        
          
      

mPm
   ln  dm
   
    

   sign     

   
       

 mn

 

 

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

Method
Centralized ERM
Distributed Power Method
Distributed Lanczos
 Hotpotato  SGD
Average of ERMs with sign xing  Theorem  
Distributed Shift Invert   precond  linear systems  Theorem  

                

 ERM      ln  
 mn  
 ERM         
 ERM         

  ERM 

  ERM          ln   
     

 ERM         

  communcation rounds

 

   

     

 

 

   min        

Table   Comparison of estimation error and number of communication rounds  For simplicity we    the failure probability to      
and assume mn is in the regime in which Lemma   is meaningful       mn      ln    The     suppresses logarithmic factors
in            ERM  For the result of Theorem   we assume the regime          The subconstant    factors could be made  in
principle  arbitrary small in all relevant results by trading approximation with communication 

See Theorem   in Section   for the complete and formal
result 
In particular  in the likely scenario when           

we have that      at least                        
 ERM                 ERM      where  ERM    is de 
 up to polylog factors  when          ln dm   

 ned in Eq    Another related interpretation of the results is that the bound in Eq    is comparable with  ERM

We also show   matching lower bound that the bound in
Eq    is tight  up to polylog factors  for this aggregation
method 

  multi communication round algorithm We present  
distributed algorithm based on the Shiftand Invert framework for leading eigenvector computation  Garber  
Hazan    Garber et al    which is applied to explicitly solving the centralized ERM problem  We show
that for any         when mn      ln           
when Lemma   is meaningful  the algorithm produces  
solution   such that      at least       

              ERM              

 

where  ERM    is de ned in Eq    The algorithm performs overall    pb    distributed matrixvector
products with the centralized empirical covariance matrix
     The     notation hides polylogarithmic factors in
          ERM    See Theorem   in Section   for the
complete and formal result 
We note that in particular  under our assumption that mn  
    it holds that the number of distributed matrixvector products is upper bounded by       Moreover 
in the regime        we can see that the number
of distributed matrixvector products depends only polylogarithmically on the problem parameters 
In general  the subconstant    factor in   could be
made arbitrarily small by trading the approximation error

      on each round  each machine   sends the product of an

input vector in Rd with its local covariance matrix  Xi 

with the number of distributed matrixvector products 

  PREVIOUS ALGORITHMS
Distributed versions of classical iterative algorithms 
Classical fast iterative algorithms for computing the leading eigenvector of   positive semide nite matrix  such as
the wellknown Power Method and the Lanczos Algorithm  require iterative multiplications of the input matrix      in our case  with the current estimate 
It is thus
straightforward to implement these algorithms in our distributed setting  by multiplying the same vector with the
covariance matrices at each machine  and averaging the
result  Thus  by wellknown convergence guarantees of
these two methods  we will have that for    xed    
these methods produce   unit vector   such that  for any
                             at least        after    ln      rounds for the Power Method and
     ln      for the Lanczos Algorithm  where

    denote the leading eigenvalue and eigengap of    
respectively  Moreover  in the regime of mn in which
Lemma   is meaningful  we can replace     with  
in the above bounds  and the result will still hold with high
probability 
Simple calculations show that in the regime of mn in which
Lemma   is meaningful  it holds that our Shiftand Invertbased algorithm outperforms distributed Lanczos  in terms
of worstcase guarantees  whenever        
 

 Hot potato  SGD  Another straightforward approach is
to apply   sequential algorithm for direct risk minimization that can process the datapoints one by one  such as
stochastic gradient descent  SGD  by passing its state from
one machine to the next  after completing   full pass over
the machine   data  Clearly  this process of making   full
pass over the data of   certain machine before sending the
 nal estimate to the next one  requires overall   communication rounds in order to make   full pass over all mn
points  SGD for PCA was studied in several results in
recent years  Balsubramani et al    Shamir       

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

Jain et al      Allen Zhu   Li      For instance
applying the result of  Jain et al      in this way will
result in    nal estimate   satisfying

                  ln  

 mn       at least  

 

We note that in the regime in which the bound in   is
meaningful it holds that the number of communication
rounds of our Shiftand Invertbased algorithm is upperbounded by       which for suf ciently large   dominates the communication complexity of SGD 

  Single Communication Round Algorithms

via ERM on Each Machine

In this section we consider distributed algorithms that require only   single round of communication  Naturally for
this regime  all algorithms will be based on aggregating the
ERM solutions of the individual machines       each machine   only sends the leading eigenvector of its empirical covariance matrix  Xi to   centralized machine  without
loss of generality  machine   which it turn combines them
to   single unit vector in some manner 

  Simple averaging of eigenvectors fail
Perhaps the simplest method to aggregate the individual
eigenvectors of each machine is to average them  and then
normalize to obtain   unit vector  For instance  in the
distributed statistical setting considered in  Zhang et al 
  in which the objective is strongly convex  it was
shown that simply averaging the individual ERM solutions
leads  in   meaningful regime of parameters  to estimation
error of the order of the centralized ERM solution  However  here we show that for PCA  in which the objective is
certainly not convex  this approach fails practically in any
regime  in the sense that the error of the returned aggregated solution can be no better than that returned by any
single machine 
Theorem   There exists   distribution over vectors in   
with   norm bounded by   universal constant for which the
eigengap in the covariance matrix is               such
that if each machine   returns an estimate      
  which is
an unbiased leading eigenvector of  Xi       both outcomes
     
  are equally likely  then the aggregated vector
mPm
        
       
                

      

         

satis es

   

     

 

The proof is given in the appendix 

 

 

   

 

 mn

    

  Averaging with Sign Fixing
As evident from the statement of Theorem   an important
assumption is that each machine produces an unbiased estimate  in the sense that the sign of the outcome is uniform
and independent of the other machines  This hints that correlating the signs of the different estimates can circumvent
the lower bound result in Theorem   It turns out that this
is indeed the case  as captured by the following theorem 
Theorem   Let  wi be the leading eigenvector of  Xi for
any         and consider the unit vector
   sign            wi
   sign            wik

Then  for any         it holds      at least       that
   log  dm
   

   log  dm
   

    Pm
kPm
               

For ease of presentation  throughout the rest of this section
we denote the correlated vector  wi   sign            wi for
any        
The main step towards proving Theorem   is to consider
each  wi as an approximately unbiased perturbation of the
true leading eigenvector    and to upper bound the magnitude of this perturbation  This is carried out in the following much more general and selfcontained lemma  which
might be of independent interest  The proof is given in the
appendix 
Lemma   Let   be   positive semide nite matrix with
some  xed leading eigenvector      leading eigenvalue  
and an eigengap                 Let    be some
positive semide nite matrix such that        Ak    
Then there is   unique leading eigenvector     of    such
that      vi     and

                              

ck      Ak 
 
where   denotes the pseudoinverse  and   is   positive numerical constant 

 

Lemma   is central to the proof of the following Lemma 
of which the proof of Theorem   is an easy consequence 
We defer the proof of both the Lemma and that of Theorem
  to the appendix 
Lemma   The following two conditions hold with probability at least      exp   cb  for some numerical
constants          
  The leading eigenvalue of every  Xi is simple      
   Xi       Xi     
leading eigen 
  Fixing   
vectors  vi
  of
such that
    vi
maxi   vi
   

there
           vi
           

             Xm 

exist unique

  and    
mPm
      log dm   
 

 mn

           log dm   

  

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

  Lower Bound for Sign Fixing
We now show that the result of Theorem   is tight up to
polylogarithmic factors and cannot be improved in general 
Theorem   For any         and       there exist  
distribution over vectors in Rd  of norm at most   universal
constant  with eigengap   in the covariance matrix  such
that for any number of machines   and for permachine
sample size any   suf ciently larger than   the aggregated vector        
   even after sign  xing with
the population eigenvector    satis es

        

mPm
          

 

 mn

 

   

        

     

The proof is given in the appendix 

    Multiround Algorithm based on

Shiftand Invert Iterations

In this section we move on to consider distributed algorithms that perform multiple communication rounds  The
main motivation  beyond improving some polylogarithmic
factors in the estimation error  is to obtain   result that does
not require the permachine sample size   to grow with the
number of machines    as in the result of Theorem  
Towards this end we consider the use of the Shiftand 
Invert metaalgorithm  originally described in  Garber  
Hazan    Garber et al    to explicitly solve the
centralized ERM objective        nd   unit vector that is an
approximate solution to maxv kvk      Xv 
Throughout this section we let     denote the leading
eigenvalue and eigengap of     respectively  Also  we assume without loss of generality that             all data
points lie in the unit Euclidean ball 
Since our approach is to approximate the population risk
by approximating the empirical risk  we state the following simple lemma for completeness    proof is given in the
appendix 
Lemma    Risk of approximatedERM for PCA  Let  
be   unit vector such that               for some  xed
    where     is the leading eigenvector of     Then it
holds that                             
  The Shiftand Invert metaalgorithm
The Shiftand Invert algorithm  Garber   Hazan   
Garber et al    ef ciently reduces the problem of
computing the leading eigenvector of   positive semidefinite matrix    to that of approximatelysolving   polylogarithmic number of linear systems        nding approximate minimizers of convex quadratic optimization problems of the form

min

  Rd         

 
 

                 

 

where         is   shifting parameter  The algorithm is
essentially based on applying power iterations to   shifted
and inverted matrix         where the shifting parameter   is carefully chosen  The algorithm that implements
this reduction  originally described in  Garber   Hazan 
  is given below  see Algorithm  

failure probability  

Algorithm   SHIFTAND INVERT POWER METHOD
  Input  estimate   for the gap   accuracy        
  ln    
   
  Set          ln                
   
    
  Set      minn  
  Set           
      random unit vector       
  repeat
 
 
 

            Ms             
for         do
Find approx  minimizer    wt of       wt   
such that    wt     

   wt      

   

end for

 
  ws    wm    wm  
 

 

 

Find approx  minimizer   vs of     ws    such
that kvs     

  wsk    

    vs                  

        
   
  until       
               Mf              
  for         do
 

Find approx  minimizer    wt of        wt    such
that    wt     

   wt      
  end for
  Return  wf    wm    wm  
Lemma    Ef cient reduction of top eigenvector to convex optimization  originally Theorem   in  Garber  
Hazan    Suppose that                      
and suppose that the estimate   in Algorithm   satis es
        Then  with probability at least       
Algorithm    nds   unit vector wf such that           
      and the total number of optimization problems of
the form   solved during the run of the algorithm  is upper bounded by   ln      ln    ln   
   Moreover  throughout the run of the algorithm it holds that
                   
Remark 
the purpose of the repeatuntil loop in Algorithm   is to ef ciently  nd   shifting parameter      such
that                    for some universal constants
            When   satis es    
  ln     
we can directly  nd         such   shifting parameter  by

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

simply estimating     from the data of   single machine 
Also  we can take     to be the leading eigenvector of any
single machine  since this will already have   constant correlation with     Thus  for such    the total number of
optimization problems can be reduced to   ln   
Algorithm   is   metaalgorithm in the sense that the choice
of solver for the optimization problems min     is unspeci ed  and any solver will do    simple calculation
shows that   naive application of either the conjugate gradient method or Nesterov   accelerated gradient method to
solve these optimization problems in   distributed manner 
     the computation of the gradient vector is distributed

across machines  will require overall       commu 

nication rounds  which does not give any improvement over
the distributed Lanczos approach  described in Subsection
  However  this can be substantially improved by taking advantage of the fact that the data on all machines is
sampled       
In particular 
we present below an approach based on applying   preconditioner to the optimization Problem   in the spirit of
the one described in  Zhang   Lin   

from the same distribution 

  Faster Distributed Approximation of Linear

Systems via Local Preconditioning

Let             for some shift parameter     and de 
 ne the preconditioning matrix             where
  is required so   is invertible  Consider now solving the
following modi ed quadratic problem 
         

    MC           

 

 
 

Note that if    is the optimal solution to Problem       

                       

then           is the optimal solution to Problem  
The idea behind choosing   this way is very intuitive  Ideally we could have chosen        making the condition number of      equal to             which is the
best we can hope for  The problem of course is that this
requires us to explicitly compute    which is more
challenging then just computing the leading eigenvector of
    The next best thing is thus to choose   based only
on the data available on any single machine  which allows
computing    without additional communication overhead  and leads to the choice described above  The following lemma  rephrased from  Zhang   Lin    quanti es
exactly how such   choice of   helps in improving the condition number of the new optimization problem  Problem
  The proof is given in the appendix 
Lemma   Suppose that                  Then         
is  smooth and   
 strongly convex  In particular                    Moreover   xing      Rd 

if we let             then it holds that         wk  
               wk 
In particular  for any
        if we set      pln        then the above
holds with probability at least      where this probability
depends only on the randomness in    

  SOLVING THE PRECONDITIONED LINEAR

SYSTEMS

We now discuss the application of gradientbased algorithms for  nding an approximate minimizer of the preconditioned problem  Problem   in our distributed setting  Towards this end we require   distributed implementation for the  rstorder oracle of               computation of the value and gradient vector at   queried point 
  straightforward implementation of the  rstorder oracle
in our distributed setting is given in Algorithm  

Algorithm   Distributed FirstOrder Oracle for        
  Input  shift parameter     regularization parameter

  send          to machines              for    
  for        do
 

      vector     Rd  query vector     Rd
              executed on machine  
send  ri    Xi    to machine    executed on each
machine   

  end for
  aggregate       
  compute            

 ri  executed on machine  
                     
  compute                              
  return                    

       executed on machine  
 executed on machine  

mPm

  

We have the following lemma  the proof of which is deferred to the appendix 
Lemma   Fix some         and     Rd  and let
          be as in Lemma   Fix     Consider the
following twostep algorithm 
  Apply either the conjugate gradient method or Nesterov   accelerated method with the distributed  rstorder oracle described in Algorithm   to  nd      Rd
such that           miny Rd            

  Return            

     

 

      it holds that
Then  for      
              wk     and the total number distributed matrixvector products with the empirical covariance matrix    required to compute    is upperbounded by
     kwk       
             ln   

 

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

  Putting it all together
We now state our main result for this section  which is  
simple consequence of the previous lemmas  The full proof
is given in the appendix 
Theorem   Fix         and         Suppose that
mn     ln      Set      pln        Applying the Shiftand Invert algorithm  Algorithm   with the
parameters      and applying the algorithm in Lemma
  with the parameter   to approximately solve the linear
systems  yields with probability at least         unit vector
wf such that                  after executing at most

 pn

  spln     
  ln   

 ln   
   ln   

   ln pln     
 pn  
          
 pn 

distributed matrixvector products with the empirical covariance matrix    

  Experiments
To validate some of our theoretical  ndings we conducted experiments with singleround algorithms on synthetic data  We generated synthetic datasets using two distributions  For both distributions we used the covariance
matrix          with   being   random       orthonormal matrix and   is diagonal satisfying       
                                  
           One dataset was generated according to the
normal distributions        and for the second datasets
we generated samples by taking           where
          In both cases we set      
Beyond the singleround algorithms that are based on
aggregating the individual ERM solutions described so
far  we propose an additional natural aggregation approach  based on aggregating the individual projection matrices  More concretely  letting      
   denote the leading eigenvectors of the individual machines  let      
mPm
  We then take the  nal estimate   to
 
be the leading eigenvector of the aggregated matrix    
Note that as with the sign xing based aggregation  this
approach also resolves the signambiguity in the estimates
produced by the different machines  which circumvents the
lower bound result of Theorem  
For both datasets we  xed the number of machines to
      We tested the estimation error       the value
        where    is the leading eigenvector of   and
  is the estimator  of  ve benchmarks vs  the permachine
sample size   
the centralized solution     the average
of the individual  unbiased  ERM solutions  normalized to
unit norm the average of ERM solutions with sign xing 
and the leading eigenvector of the averaged projection ma 

       

        

    

trix  We also plotted the average loss of the individual ERM
solutions  Results are averaged over   independent runs 
The results for the normal distribution appear in Figure  
The results for the uniformbased distribution are very similar and are deferred to the appendix  We can see that  as
our lower bound in Theorem   suggests  simply averaging
and normalizing the individual ERM solutions has significantly worse performance than the centralized ERM solution  Perhaps surprisingly  the performance of this estimator is even worse than the average error of an estimate
computed using only   single machine  We see that both
aggregation methods that are based on correlating the individual ERM solutions  namely the sign xingbased estimator  and the proposed averagingof projections heuristic 
are asymptotically consistent with the centralized ERM 
In particular  the averagingof projections scheme  at least
empirically  signi cantly outperforms the sign xing approach  which justi es further theoretical investigation of
this heuristic  For the sign  xing approach  we can see that
as suggested by our bounds  the estimator is not consistent
with the centralized ERM solution for small values of   

 

 

 

 

 

 

 

 

 

 
 
 
 
 

 
 

 
 
 

 

 

 

 

centralized ERM
avg  of ERMs
signfix avg  of ERMs 
projection avg 
avg  machine loss

 

 

 

Figure   Estimation error vs  the permachine sample size   for
  normal distribution 

 
 

  Discussion
We presented communicationef cient algorithms for distributed statistical estimation of principal components  Focusing on our results for methods based on   single communication round  we initiated   study of how to correctly aggregate distributed ERM solutions in   nonconvex setting 
An important takehome message of our work is that in  
nonconvex setting  simply averaging the local solutions is
not   good idea  On the positive side  we show that   very
simple correction       sign xing  is possible by leveraging the speci   structure of the problem at hand  It is thus
interesting to develop   richer theory of how to perform
such aggregations in more involved nonconvex problems 

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

References
Eigenvalues

and

eigenvectors

of

    matrices 

http www math harvard edu archive 
   fall exhibits dmatrices 

Allen Zhu  Zeyuan and Li  Yuanzhi  Even faster SVD decomposition yet without agonizing pain 
In Advances
in Neural Information Processing Systems   Annual
Conference on Neural Information Processing Systems
  December     Barcelona  Spain  pp   
     

Allen Zhu  Zeyuan and Li  Yuanzhi  Fast global conver 

gence of online PCA  CoRR  abs     

Balsubramani  Akshay  Dasgupta  Sanjoy  and Freund 
Yoav  The fast convergence of incremental PCA 
In
Advances in Neural Information Processing Systems  
 th Annual Conference on Neural Information Processing Systems   pp     

Boutsidis  Christos  Woodruff  David    and Zhong  Peilin 
Optimal principal component analysis in distributed and
streaming models 
In Proceedings of the  th Annual
ACM SIGACT Symposium on Theory of Computing  pp 
  ACM   

Garber  Dan and Hazan  Elad  Fast and simple pca via
convex optimization  arXiv preprint arXiv 
 

Garber  Dan  Hazan  Elad  Jin  Chi  Kakade  Sham   
Musco  Cameron  Netrapalli  Praneeth  and Sidford 
Aaron  Faster eigenvector computation via shiftand 
invert preconditioning  CoRR  abs   

Golub  Gene   and Pereyra  Victor  The differentiation
of pseudoinverses and nonlinear least squares problems
whose variables separate  SIAM Journal on numerical
analysis     

Hotelling     Analysis of   complex of statistical variables

into principal components     Educ  Psych     

Jaggi  Martin  Smith  Virginia  Tak ac  Martin  Terhorst 
Jonathan  Krishnan  Sanjay  Hofmann  Thomas  and Jordan  Michael    Communicationef cient distributed
dual coordinate ascent  In Advances in Neural Information Processing Systems  pp     

Jain  Prateek  Jin  Chi  Kakade  Sham    Netrapalli  Praneeth  and Sidford  Aaron  Matching matrix bernstein with little memory  Nearoptimal  nite sample guarantees for oja   algorithm 
arXiv preprint
arXiv     

Jain  Prateek  Jin  Chi  Kakade  Sham    Netrapalli  Praneeth  and Sidford  Aaron  Matching matrix bernstein with little memory  Nearoptimal  nite sample guarantees for oja   algorithm 
arXiv preprint
arXiv     

Jolliffe  IT  Principal component analysis    Spring 

verlag  New York   

Lee  Jason    Ma  Tengyu  and Lin  Qihang  Distributed
stochastic variance reduced gradient methods  CoRR 
abs   

Liang  Yingyu  Balcan  MariaFlorina    Kanchanapally 
Improved distributed

Vandana  and Woodruff  David 
principal component analysis  In NIPS   

Magnus  Jan    On differentiating eigenvalues and eigen 

vectors  Econometric Theory     

Pearson     On lines and planes of closest    to systems of
points in space  Philosophical Magazine   
 

Reddi  Sashank    Konecn    Jakub  Richt arik  Peter 
  oczos  Barnab as  and Smola  Alexander    AIDE 
fast and communication ef cient distributed optimization  CoRR  abs   

Shamir  Ohad    stochastic PCA and SVD algorithm with
an exponential convergence rate  In Proceedings of the
 nd International Conference on Machine Learning 
ICML   Lille  France    July   pp   
 

Shamir  Ohad  Convergence of stochastic gradient descent
for PCA  In Proceedings of the  nd International Conference on Machine Learning  ICML   New York
City  NY  USA  June     pp       

Shamir  Ohad  Withoutreplacement sampling for stochastic gradient methods  In Advances in Neural Information
Processing Systems   Annual Conference on Neural
Information Processing Systems   December  
  Barcelona  Spain  pp       

Shamir  Ohad  Fast stochastic algorithms for svd and pca 
Convergence properties and convexity  In Proceedings of
The  rd International Conference on Machine Learning  pp       

Shamir  Ohad  Srebro  Nathan 

and Zhang  Tong 
Communicationef cient distributed optimization using
an approximate newtontype method  In Proceedings of
the  th International Conference on Machine Learning 
ICML   Beijing  China    June   pp   
   

Communicationef cient Algorithms for Distributed Stochastic Principal Component Analysis

Tropp  Joel    Userfriendly tail bounds for sums of random matrices  Foundations of Computational Mathematics     

Yu  Yi  Wang  Tengyao  and Samworth  Richard      useful variant of the davis kahan theorem for statisticians 
Biometrika     

Zhang  Yuchen and Lin  Xiao  Disco  Distributed optimization for selfconcordant empirical loss  In Proceedings of the  nd International Conference on Machine
Learning  ICML  pp     

Zhang  Yuchen  Duchi  John    and Wainwright  Martin   
Communicationef cient algorithms for statistical optimization  Journal of Machine Learning Research   
   

