Evaluating Bayesian Models with Posterior Dispersion Indices

Alp Kucukelbir   Yixin Wang   David    Blei  

Abstract

Probabilistic modeling is cyclical  we specify  
model  infer its posterior  and evaluate its performance  Evaluation drives the cycle  as we revise our model based on how it performs  This
requires   metric  Traditionally  predictive accuracy prevails  Yet  predictive accuracy does not
tell the whole story  We propose to evaluate  
model through posterior dispersion  The idea is
to analyze how each datapoint fares in relation to
posterior uncertainty around the hidden structure 
This highlights datapoints the model struggles
to explain and provides complimentary insight
to datapoints with low predictive accuracy  We
present   family of posterior dispersion indices
 PDI  that capture this idea  We show how   PDI
identi es patterns of model mismatch in three real
data examples  voting preferences  supermarket
shopping  and population genetics 

  Introduction
Probabilistic modeling is    exible approach to analyzing
structured data  Three steps de ne the approach  First  we
specify   model  this captures our structural assumptions
about the data  Then  we infer the hidden structure  this
means computing  or approximating  the posterior  Last  we
evaluate the model  this helps build better models down the
road  Blei   
How do we evaluate models  Decades of re ection have led
to deep and varied forays into model checking  comparison 
and criticism  Gelman et al    But   common theme
permeates all approaches to model evaluation  the desire to
generalize well 
In machine learning  we traditionally use two complementary tools  predictive accuracy and crossvalidation  Predictive accuracy is the target evaluation metric  Cross 

 Columbia University  New York City  USA  Correspondence

to  Alp Kucukelbir  alp cs columbia edu 

Proceedings of the      International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright   by
the author   

validation captures   notion of generalization and justi es
holding out data  This simple combination has fueled the
development of myriad probabilistic models  Bishop   
Murphy   
Does predictive accuracy tell the whole story  The predictive accuracy of an observation is its perdatapoint likelihood averaged over the posterior  In this sense  predictive
accuracy reports   mean value for each datapoint  it ignores
how each perdatapoint likelihood varies with respect to the
posterior 
Main idea  We propose to evaluate probabilistic models
through the idea of posterior dispersion  analyzing how each
datapoint fares in relation to posterior uncertainty around
the hidden structure  To capture this  we propose   family of
posterior dispersion indices  PDI  These are perdatapoint
quantities  each   variance to mean ratio of the datapoint  
likelihood with respect to the posterior    PDI highlights
observations whose likelihoods exhibit the most uncertainty
under the posterior 
Consider   model        and the likelihood of   datapoint
  xn     It depends on some hidden structure   that we
seek to infer  Since   is random  we can view the likelihood
of each datapoint as   random variable  Predictive accuracy reports the average likelihood of each xn with respect
to the posterior         But this ignores how the likelihood changes under the posterior  How can we capture this
uncertainty and compare datapoints to each other 
To answer this  we appeal to various forms of dispersion 
such as the variance of the likelihood under the posterior 
We propose   family of dispersion indices in Section  
they have the following form 

PDI   variance of likelihood under posterior
mean of likelihood under posterior
    jx   xn    
  jx   xn    

 

PDIs compliment predictive accuracy  Here is   mental
picture  Consider   nuclear power plant where we monitor
the temperature of   pool of water  We train   probabilistic
model  the posterior represents our uncertainty around some
safe temperature  say   degrees  Suppose we receive   high
measurement thigh  Figure   Its likelihood varies rapidly

Evaluating Bayesian Models with Posterior Dispersion Indices

 
 
 
 
 
 
 

 
 
 
 
 
 
 

 

 

 

posterior
likelihood of thigh measurement
likelihood of tzero measurement

 

Figure     mental picture of how PDI identify different types of mismatch  While both measurements  thigh and tzero  exhibit low
predictive accuracy    PDI differentiates them by also considering how their perdatapoint likelihoods vary under the posterior  See text for
more details 

across plausible posterior values for    This datapoint is
reasonably well modeled  but is sensitive to the posterior 
Now imagine the thermostat breaks and we receive   zero
measurement tzero  This zero datapoint is poorly modeled 
Both datapoints may have similar predictive accuracy values under the model   See Section   for how this can
occur  But the high measurement is different than the zero
measurement    PDI differentiates these measurements by
considering not only their predictive accuracy scores  but
also how their perdatapoint likelihoods vary with respect
to the posterior 
Section   presents an empirical study of model mismatch in
three realworld examples  voting preferences  supermarket
shopping  and population genetics  In each case    PDI
provides insight beyond predictive accuracy and highlights
potential directions for improvement 
Related work  This paper relates to   constellation of ideas
from statistical model criticism 
The  rst connection is to analysis of variance  PDI bears
similarity to ANOVA  which is   frequentist approach to
evaluating explanatory variables in linear regression  Davison    Gelman et al    cemented the idea of
studying predictive accuracy of probabilistic models at the
data level  Vehtari et al    and Betancourt   give
upto date overviews of these ideas  PDIs add to this body
of work by considering the variance of each datapoint in
context of its predictive accuracy 
The second connection is to model comparison  Recent
research  such as Gelman et al    Vehtari et al   
and Piironen   Vehtari   explore the relationship
between cross validation and information criteria  such as
the widely applicable information criterion  WAIC   Watanabe    Vehtari et al    WAIC offers an intuitive
connection to cross validation  Vehtari   Lampinen   
Watanabe    we draw inspiration from it in this paper
too  However our focus is on evaluation at the datapoint
level  not at the dataset level  In this sense  PDIs and information criteria are complimentary tools 
The third connection is to   body of work from the ma 

chine learning community  Gretton et al    and
Chwialkowski et al    developed effective kernelbased
methods for independence and goodnessof   tests  Recently  Lloyd   Ghahramani   visualized smooth regions of data space that the model fails to explain  In contrast  we focus directly on the datapoints  which can live in
highdimensional spaces that may be dif cult to visualize 
   nal connection is to scoring rules  While the literature on
scoring rules originally focused on probability forecasting
 Winkler    Dawid    recent advances draw new
connections to decision theory  divergence measures  and
information theory  Dawid   Musio    We discuss
how PDIs    into this picture in the conclusion 

  Posterior Dispersion Indices
  posterior dispersion index  PDI  highlights datapoints
that exhibit the most uncertainty with respect to the hidden
structure of   model  Here is the road map for this section 
  small case study illustrates how   PDI gives more insight
beyond predictive accuracy  De nitions  theory  and another small analysis give further insight    straightforward
algorithm leads into the empirical study 

    outliers 

Hayden   considers the number of days each      president stayed in of ce  he submits that   of presidents may
be outliers  Figure   plots the data  Oneterm presidents
stay in of ce for around   days  twoterm presidents
approximately double that  Yet many presidents deviate
from this  two bump  trend 
  reasonable model for such data is   mixture of negative
binomial distributions  Consider the parameterization of
the negative binomial with mean  cid  and variance  cid     cid cid 
Posit gamma priors on the  nonnegative  latent variables 
Set the prior on  cid  to match the mean and variance of the
data  Robbins    Choose an uninformative prior on  cid 
Three mixtures make sense  two for the typical trends and
one for the rest 

    Poisson likelihood is too underdispersed 

Evaluating Bayesian Models with Posterior Dispersion Indices

 
 
 
 
 

 
 

 
 
 
 

 

 

 

Washington
Tyler
VanBuren
Monroe
Adams
Adams
Madison
Jackson
Harrison
Jefferson

Hayes
McKinley
Taylor
Roosevelt
Lincoln
Buchanan
Filmore
Pierce
Cleveland
Cleveland
Harrison
Grant
Johnson
Gar eld
Arthur
Polk

Harding
Coolidge
Kennedy
Hoover
Truman
Eisenhower
Roosevelt
Nixon
Wilson
Johnson
Taft

Reagan
Carter
Ford

Clinton
Bush

Bush

Figure   The number of days each      president stayed in of ce  Typical durations are easy to identify  gray lines indicate oneand
twoterm stays  Appendix   presents numerical values 

matched to that of data 

Gam cid     mean and variance

  cid    Dirichlet cid             

  cid      
  cid      
  xn    cid   cid   cid      
mates   cid          with
  cid          The  rst two clusters describe the

Gam cid                

posterior mean

esticorresponding

 cid kNB xn    cid     cid   

kD 

Fitting

this model

gives

The complete model is

kD 

kD 

two typical term durations  while the third  highlighted in
bold red  is   dispersed negative binomial that attempts to
describe the rest of the data 
We compute   PDI  de ned in Section   and the posterior
predictive density for each president   xn      Figure  
compares both metrics and sorts the presidents according to
the PDI 
Some presidents are clear outliers  Harrison   natural
death  Roosevelt   four terms  and Gar eld
  assassinated  However  there are three presidents
with worse predictive accuracy than Harrison  Coolidge 
Nixon  and Johnson    PDI differentiates Harrison from
these three because his likelihood is varying rapidly with
respect to the dispersed negative binomial cluster 
This PDI also calls attention to McKinley  
assassinated  and Arthur  
succeeded
Garfield  because they are close to the sharp negative
binomial cluster at   but not close enough to have good
predictive accuracy  They are datapoints whose likelihoods
are rapidly changing with respect to   peaked posterior  like

the high measurement in the nuclear plant example in the
introduction 
This case study suggests that predictive probability does
not tell the entire story  Datapoints can exhibit low predictive accuracy in different ways  We now turn to   formal
de nition of PDIs 

hood of the dataset factorizes as         DQ

  De nitions
Let     fxngN
  be   dataset with   observations    probabilistic model has two parts  The  rst is the likelihood 
  xn     It relates an observation xn to hidden patterns
described by   set latent random variables   If the observations are independent and identically distributed  the likelin   xn    
The second is the prior density    
It captures the
structure we expect from the hidden patterns  Combining the likelihood and the prior gives the joint density
                   Conditioning on observed data
gives the posterior density         
Treat the likelihood of each datapoint as   function of   To
evaluate the model  we analyze how each datapoint fares in
relation to the posterior density  Consider these expectations
and variances with respect to the posterior 
 cid        jx   xn    
 cid log        jx log   xn    
 cid          jx   xn    
log        jx log   xn    
 cid   

 

Each includes the likelihood in   slightly different fashion  The  rst expectation is   familiar object   cid    is the
posterior predictive density 
  PDI is   ratio of these variances to expectations  Taking
the ratio calibrates this quantity for each datapoint  Recall
the mental picture from the introduction  The variance of

Evaluating Bayesian Models with Posterior Dispersion Indices

PDI

log   xn     

 cid 
 cid 

 
 
 
 
 

 
 
 
 
 
 
 
 
 
 

 cid 
 cid 
 cid 

 
 
 
 
 
 
 

 
 
 

 
 
 
 
 

 
 

 
 
 
 

 

 

 

Reagan
Washington
McKinley
Truman
Harrison
Clinton
Gar eld
Arthur
Eisenhower
Roosevelt
Roosevelt

Taylor
Monroe
Filmore
Madison
Jackson
Wilson
Grant
Jefferson
Bush

Harding
Coolidge
Tyler
Kennedy
Hoover
Lincoln
Adams
Johnson
Johnson
Ford
Nixon

Buchanan
Pierce
Polk

Hayes
VanBuren
Adams
Cleveland
Harrison

Bush

Taft

Carter
Cleveland

Figure   PDI and log predictive accuracy of each president under   mixture of three negative binomials model  Presidents sorted by PDI 
The closer to zero  the better   Code in supplement 

the likelihood under the posterior highlights potential model
mismatch  dividing by the mean calibrates this spread to its
predictive accuracy 
Calibration puts all datapoints on   common scale  Imagine
  binary classi cation problem where each datapoint yn
lives in        The variances of the zero measurements may
be numerically quite different than the one measurements 
considering the mean renders these values comparable 
Related ratios also appear in classical statistics under   variety of forms  such as indices of dispersion  Hoel   
coef cients of variation  Koopmans et al    or the
Fano factor  Fano    They all quantify dispersion of
samples from   random process  PDIs extend these ideas by
connecting to the posterior density of   probabilistic model 
In this paper  we study   particular PDI  called the widely
applicable posterior dispersion index  WAPDI 

log   
log  cid   

WAPDI       cid   
 

 

Its form and name comes from the widely applicable information criterion WAIC    cid   
log   
WAIC measures generalization error 
it asymptotically
equates to leaveone one cross validation  Watanabe   

  log  cid       cid   

 

  WAPDI has two advantages  both are practically motivated  First  we hope the reader is computing an estimate
of generalization error  Gelman et al    suggests WAIC
because it is easy to compute and designed for common
machine learning models  Watanabe    Computing
WAIC gives WAPDI for free  Second  the variance is  
secondorder moment calculation  using the log likelihood
gives numerical stability to the computation 
 More on
computation in Section  
WAPDI compares the variance of the log likelihood to the
log posterior predictive  This gives insight into how the likelihood of   datapoint fares under the posterior distribution
of the hidden patterns  We now study this in more detail 

  Intuition  not all predictive probabilities are

created equal

  jx   xnew           xnew               Expecta 

The posterior predictive density is an expectation 

tions are integrals  areas under   curve  Different likelihood
and posterior combinations can lead to similar integrals 
  toy model illustrates this  Consider   gamma likelihood
with  xed shape  and place   gamma prior on the rate  The

Evaluating Bayesian Models with Posterior Dispersion Indices

 
 
 
 
 
 
 

         cid 

         

posterior   jx 
           
           

 

 

 

 

 

Figure   Not all predictive probabilities are created equal  The translucent curves are the two likelihoods multiplied by the posterior
 cropped  The posterior predictives           and           for each datapoint is the area under the curve  While both datapoints have the
same predictive accuracy  the likelihood for    has higher variance under the posterior     is more sensitive to the spread of the posterior
than    WAPDI captures this effect   Code in supplement 

model is

          NY

     Gam                 
Gam xn          

nD 

           CP

  xn 

which gives the posterior           Gam            
Now simulate   dataset of size       with       the
data have mean        Now consider an outlier at   We
can  nd another   value with essentially the same predictive
accuracy

log                 cid 
log                 cid 

Yet their WAPDI values differ by an order of magnitude

WAPDI           cid 
WAPDI           cid 

In this case  WAPDI highlights        as   more severe
outlier than        even though they have the same
predictive accuracy  What does that mean  Figure   depicts
the difference 
The following lemma explains how WAPDI measures this
effect   Proof in Appendix   
Lemma   If log   xn     is at least twice differentiable
and the posterior         has  nite  rst and second moments  then   secondorder Taylor approximation gives

 cid log  

 xn     jx cid    jx 

 
log   jx   xn    

WAPDI     cid 

 

 

Corollary   WAPDI highlights datapoints whose likelihood is rapidly changing at the posterior mean estimate
of the latent variables     jx  is constant across   

Looking back at Figure   the likelihood            
indeed changes rapidly under the posterior  WAPDI reports
the ratio of this rateof change to the area under the curve 
In this speci   example  only the numerator matters  since
the denominator is effectively the same for both datapoints 

Corollary   Equation   is zero if and only if the posterior
mean coincides with the maximum likelihood estimate of  
for datapoint xn     jx  is positive for  nite    

For most interesting models  we do not expect such   coincidence  However  in practice  we  nd WAPDI to be close
to zero for datapoints that match the model well  With that 
we now turn to computation 

  Computation

Calculating WAPDI is straightforward  The only requirement are samples from the posterior  This is precisely the
output of an Markov chain Monte Carlo  MCMC  sampling
algorithm   We used the noU turn sampler  Hoffman  
Gelman    for the analyses above  Other inference
procedures  such as variational inference  give an analytic
approximation to the posterior  Jordan et al    Blei
et al    Drawing samples from an approximate posterior also works   We use this approach for the empirical
study in Section  
Equipped with   samples from the posterior  Monte Carlo
integration  Robert   Casella    gives unbiased estimates of the quantities in Equation   The variance of
these estimates decreases as      we assume   is suf 
 ciently large to cover the posterior  Gelman et al   
We default to       in our experiments  Algorithm  
summarizes these steps 

Evaluating Bayesian Models with Posterior Dispersion Indices

Algorithm   Calculating WAPDI 
Input  Data     fxngN
    model       
Output  WAPDI for each datapoint xn 
Draw   samples   gS
       
for   in               do

  from posterior  approximation 

Estimate log  cid     cid   
Store and return

log    from samples   gS
   

WAPDI       cid   

log   
log  cid   

 

end

  Experimental Study
We now explore three real data examples using modern
machine learning models  voting preferences  supermarket
shopping  and population genetics 

  Voting preferences    hierarchical logistic

regression model

In   CBS conducted        nationwide survey of voting
preferences  Citizens indicated their preference towards the
Democratic or Republican presidential candidate  Each individual also declared their gender  age  race  education level 
and the state they live in      individuals participated 
Gelman   Hill   study this data through   hierarchical
logistic regression model  They begin by modeling gender 
race  and state  the state variable has   hierarchical prior 
This model is easy to    using automatic differentiation
variational inference  ADVI  within Stan  Kucukelbir et al 
  Carpenter et al     Model and inference details
in Appendix   

VOTE  
 
SEX  
 
RACE  
 
STATE WA WA NY WI NY NY NY NY MA MA

     
 
 
     

 
 
 

 
 
 

 
 
 

 
 
 

 
 
 

 

Table   Lowest predictive accuracy 

 
 

VOTE  
SEX  

 
       
           
RACE                    
STATE WY WY WY WY WY WY WY DC DC NV

 
 

 
 

 

Table   Worst WAPDI values 

Tables   and   show the individuals with the lowest predictive accuracy and WAPDI  The nationwide trend predicts
that females     who identify as black     have   strong preference to vote democratic     predictive accuracy identi es
the few individuals who defy this trend  However  there is
not much to do with this information  the model identi es  
nationwide trend that correctly describes most female black
voters  In contrast  WAPDI points to parts of the dataset
that the model fails to describe  these are datapoints that we
might try to explain better with   revised model 
Most of the individuals with poor WAPDI live in Wyoming 
the District of Columbia  and Nevada  We focus on
Wyoming and Nevada  The average WAPDI for Wyoming
and Nevada are  cid  and  cid  these are baselines that
we seek to improve   The closer to zero  the better 
Consider expanding the model by modeling age  Introducing age into the model with   hierarchical prior reveals
that older voters tend to vote Republican  This helps explain Wyoming voters  their average WAPDI improves from
 cid  to  cid  however Nevada   average WAPDI remains unchanged  This means that Nevada   voters may
not follow the national agedependent trend  Now consider
removing age and introducing education in   similar way 
Education helps explain voters from both states  the average
WAPDI for Wyoming and Nevada improve to  cid  and
 cid 
WAPDI thus captures interesting datapoints beyond what
predictive accuracy reports  As expected  predictive accuracy still highlights the same female black voters in both
expanded models  WAPDI illustrates   deeper way to evaluate this model 

  Supermarket shopping    hierarchical Poisson

factorization model

Market research  rm IRi hosts an anonymized dataset of
customer shopping behavior at      supermarkets  Bronnenberg et al    The dataset tracks      checkout 
sessions  each session contains   basket of purchased items 
An inventory of     items range across categories such as
carbonated beverages  toiletries  and yogurt 
What items do customers tend to purchase together  To
study this  consider   hierarchical Poisson factorization
 HPF  model  Gopalan et al    HPF models the quantities of items purchased in each session with   Poisson
likelihood  its rate is an inner product between   session  
preferences     and the item attributes   Hierarchical priors
on   and   simultaneously promote sparsity  while accounting for variation in session size and item popularity  Some
sessions contain only   few items  others are large purchases 
 Model and inference details in Appendix   
   dimensional HPF model discovers intuitive trends   

Evaluating Bayesian Models with Posterior Dispersion Indices

few stand out  Snackcraving customers like to buy Doritos
tortilla chips along with Lay   potato chips  Morning birds
typically pair Cheerios cereal with   skim milk  Yoplait
fans tend to purchase many different  avors at the same
time  Tables   and   show the top  ve items in two of these
twenty trends 

Category

Item Description
Brand      skim milk milk rfg skim lowfat
cold cereal
Cheerios  cereal
Diet Coke  soda
carbonated beverages
Brand      skim milk milk rfg skim lowfat
Brand      skim milk milk rfg skim lowfat

Table   Morning bird trend 

Item Description
Yoplait  raspberry  avor
Yoplait  peach  avor
Yoplait  strawberry  avor
Yoplait  blueberry  avor
Yoplait  blackberry  avor

Category
yogurt rfg
yogurt rfg
yogurt rfg
yogurt rfg
yogurt rfg

Table   Yoplait fan trend 

Sessions where   customer purchases many items from different categories have low predictive accuracy  This makes
sense as these customers do not exhibit   trend  mathematically  there is no combination of item attributes   that
explain buying items from disparate categories  For example  the session with the lowest predictive accuracy contains
  items ranging from coffee to hot dogs 
WAPDI highlights   different aspect of the HPF model  Sessions with poor WAPDI contain similar items but exhibit
many purchases of   single item  Table   shows an example of   session where   customer purchased   blackberry
Yoplait yogurts  but only   few of the other  avors 

Item Description
Yoplait  blackberry  avor
Yoplait  strawberry  avor
Yoplait  raspberry  avor
Yoplait  peach  avor
Yoplait  cherry  avor
Yoplait  mango  avor

Quantity

 
 
 
 
 
 

Table     session with poor WAPDI value 

This indicates that the Poisson likelihood assumption may
not be  exible enough to model customer purchasing behavior  Perhaps   negative binomial likelihood could model
this kind of spiked activity better  Another option might
be to keep the Poisson likelihood but increase the hierarchy of the probabilistic model  this approach may identify
item attributes that explain such purchases  In either case 

WAPDI identi es   valuable aspect of the data that the HPF
struggles to capture  sessions with spiked activity  This is  
concrete direction for model revision 

  Population genetics    mixed membership model

Do all people who live nearby have similar genomes  Not
necessarily  Population genetics considers how individuals
exhibit ancestral patterns of mutations  Begin with   individuals and   locations on the genome  For each location 
report whether each individual reveals   mutation  This
gives an     cid     dataset   where xnl               We
assume two speci   forms of mutation    encodes   missing
observation 
Mixed membership models offer   way to study this
 Pritchard et al    Assume   ancestral populations  cid 
these are the mutation probabilities of each location  Each
individual mixes these populations with weights   these are
the mixing proportions  Place   beta prior on the mutation
probabilities and   Dirichlet prior on the mixing proportions 
We study   dataset of       individuals from four geographic locations and focus on         locations on the
genome  Figure   shows how these individuals mix      
ancestral populations   Data  model  and inference details
in Appendix   
WAPDI reveals three interesting patterns of mismatch here 
First  individuals with poor WAPDI values have many missing observations  the worst   of WAPDI have     missing values  in contrast to   for the lowest   of predictive scores  We may consider directly modeling these
missing observations 
Second  ASW has two individuals with poor WAPDI  their
mutation patterns are outliers within the group  While the
average individual reveals   mutations away from the
median genome  these individuals show   and   mutations  This points to potential mishaps while gathering or
preprocessing the data 
Last  MEX exhibits good predictive accuracy  yet poor
WAPDI values compared to other groups  Based on predictive accuracy  we may happily accept these patterns  Yet
WAPDI highlights   serious issue with the inferred populations  The blue and red populations are almost twice as
correlated across genes   as the other possible combinations   and   In other words  the blue and red
populations represent similar patterns of mutations at the
same locations  These populations  as they stand  are not
necessarily interpretable  Revising the model to penalize
correlation may be   direction worth pursuing 

Evaluating Bayesian Models with Posterior Dispersion Indices

ASW

CEU

MEX

YRI

WAPDI

log   xn     

 
 
 
 
 
 
 
 

 

 
 

 cid 
 cid 
 cid 
 cid 
 cid 
 cid 

 cid 

Figure   Individuals of African ancestry in southwest       ASW  and Mexican ancestry in Los Angeles  MEX  exhibit   mixture of two
populations  In contrast  Utah residents with European ancestry  CEU  and members of the Yoruba group in Nigeria  YRI  are mostly
uniform 

  Discussion
  posterior dispersion index  PDI  identi es informative
forms of model mismatch that compliments predictive accuracy  By highlighting which datapoints exhibit the most
uncertainty under the posterior    PDI offers   new perspective into evaluating probabilistic models  Here  we show
how one particular PDI  the widely applicable posterior dispersion index  WAPDI  reveals promising directions for
model improvement across   range of models and applications 
The choice of WAPDI is practically motivated  it comes
for free as part of the calculation of WAIC  This highlights
how PDIs are complimentary to tools such as predictive
accuracy  cross validation  and information criteria  While
PDIs and predictive accuracy assess model mismatch at the
datapoint level  cross validation and information criteria
indicate model mismatch at the dataset level 
PDIs provide   relative comparison of datapoints with respect to   model  Can PDIs be thresholded to identify  problematic  datapoints  One approach in this direction draws
inspiration from posterior predictive checks  PPCs   Rubin 
  Gelman et al      PPC works by hallucinating
data from the posterior predictive and comparing properties
of the hallucinated data to the observed dataset  Comparing
PDI values in this way could lead to   meaningful way of
thresholding PDIs 
There are several research directions  One is to extend the

notion of   PDI to nonexchangeable data  Another is to
leverage the bootstrap to extend this idea beyond probabilistic models  Computationally  ideas from importance
sampling could reduce the variance of PDI computations for
very high dimensional models 
  promising direction is to study PDIs under the viewpoint
of scoring rules  Dawid   Musio    Understanding
the decision theoretic properties of   PDI as   loss function
could lead to alternative objectives for inference 
Finally  we end on   reminder that PDIs are simply another
tool in the statistician   toolbox  The design and criticism of
probabilistic models is still   careful  manual craft  While
good tools can help  an overarching obstacle remains to
pursue their adoption by practitioners  To this end  making
these tools easier to use and more automatic can only help 

Acknowledgments
We thank Dustin Tran  Maja Rudolph  David Mimno  Aki
Vehtari  Josh Vogelstein  and Rajesh Ranganath for their
insightful comments  This work is supported by NSF
IIS  ONR    DARPA PPAML
FA  DARPA SIMPLEX     
  and the Alfred    Sloan Foundation 

Evaluating Bayesian Models with Posterior Dispersion Indices

References
Betancourt  Michael    uni ed treatment of predictive
model comparison  arXiv preprint arXiv 
 

Bishop  Christopher    Pattern Recognition and Machine

Learning  Springer New York   

Blei  David    Build  compute  critique  repeat  Data
analysis with latent variable models  Annual Review of
Statistics and Its Application     

Blei  David    Kucukelbir  Alp  and McAuliffe  Jon   
Variational inference    review for statisticians  arXiv
preprint arXiv   

Bronnenberg  Bart    Kruger  Michael    and Mela  Carl   
The IRi marketing data set  Marketing Science   
 

Carpenter  Bob  Gelman  Andrew  Hoffman  Matt  Lee 
Daniel  Goodrich  Ben  Betancourt  Michael  Brubaker 
Marcus    Guo  Jiqiang  Li  Peter  and Riddell  Allen 
Stan    probabilistic programming language  Journal of
Statistical Software   

Chwialkowski  Kacper  Strathmann  Heiko  and Gretton 
Arthur    kernel test of goodness of     arXiv preprint
arXiv   

Davison  Anthony Christopher  Statistical models  Cam 

bridge University Press   

Dawid        Probability Forecasting  John Wiley   Sons 

Inc    ISBN  

Dawid  Alexander Philip and Musio  Monica  Theory and
applications of proper scoring rules  Metron   
   

Fano  Ugo 

Ionization yield of radiations II  Physical

Review     

Gelman  Andrew and Hill  Jennifer  Data analysis using regression and multilevel hierarchical models  Cambridge
University Press   

Gelman  Andrew  Meng  XiaoLi  and Stern  Hal  Posterior predictive assessment of model  tness via realized
discrepancies  Statistica Sinica     

Gopalan  Prem  Hofman  Jake    and Blei  David    Scalable recommendation with hierarchical Poisson factorization  UAI   

Gretton  Arthur  Fukumizu  Kenji  Teo  Choon    Song 
Le  Sch lkopf  Bernhard  and Smola  Alex      kernel
statistical test of independence  NIPS   

Hayden  Robert      dataset that is   outliers    Stat

Educ     

Hoel  Paul    On indices of dispersion  The Annals of

Mathematical Statistics     

Hoffman  Matthew   and Gelman  Andrew  The NoU Turn
sampler  Journal of Machine Learning Research   
   

Jordan  Michael    Ghahramani  Zoubin  Jaakkola  Tommi   
and Saul  Lawrence    An introduction to variational
methods for graphical models  Machine Learning   
   

Koopmans  Lambert    Owen  Donald    and Rosenblatt 
JI  Con dence intervals for the coef cient of variation
for the normal and log normal distributions  Biometrika 
   

Kucukelbir  Alp  Ranganath  Rajesh  Gelman  Andrew  and
Blei  David    Automatic variational inference in Stan 
NIPS   

Lloyd  James   and Ghahramani  Zoubin  Statistical model

criticism using kernel two sample tests  NIPS   

Murphy  Kevin    Machine Learning    Probabilistic Per 

spective  MIT Press   

Piironen  Juho and Vehtari  Aki  Comparison of Bayesian
predictive methods for model selection  Statistics and
Computing  pp     

Pritchard  Jonathan    Stephens  Matthew  and Donnelly 
Peter  Inference of population structure using multilocus
genotype data  Genetics     

Robbins  Herbert  The empirical Bayes approach to statistical decision problems  Annals of Mathematical Statistics 
 

Robert  Christian   and Casella  George  Monte Carlo

statistical methods  Springer   

Gelman  Andrew  Carlin  John    Stern  Hal    Dunson 
David    Vehtari  Aki  and Rubin  Donald    Bayesian
Data Analysis  CRC Press   

Rubin  Donald    Bayesianly justi able and relevant frequency calculations for the applied statistician  The Annals of Statistics     

Gelman  Andrew  Hwang  Jessica  and Vehtari  Aki  Understanding predictive information criteria for Bayesian
models  Statistics and Computing     

Vehtari  Aki and Lampinen  Jouko  Bayesian model assessment and comparison using crossvalidation predictive
densities  Neural Computation     

Evaluating Bayesian Models with Posterior Dispersion Indices

Vehtari  Aki  Ojanen  Janne  et al    survey of Bayesian
predictive methods for model assessment  selection and
comparison  Statistics Surveys     

Vehtari  Aki  Tolvanen  Ville  Mononen  Tommi  and
Winther  Ole  Bayesian leaveone out crossvalidation approximations for Gaussian latent variable models  arXiv
preprint arXiv   

Vehtari  Aki  Gelman  Andrew  and Gabry  Jonah  Practical
Bayesian model evaluation using leaveone out crossvalidation and WAIC  arXiv preprint arXiv 
 

Watanabe  Sumio  Asymptotic equivalence of Bayes cross
validation and widely applicable information criterion in
singular learning theory  Journal of Machine Learning
Research     

Watanabe  Sumio  Bayesian cross validation and WAIC
for predictive prior design in regular asymptotic theory 
arXiv preprint arXiv   

Winkler  Robert    Scoring rules and the evaluation of

probabilities  Test     

