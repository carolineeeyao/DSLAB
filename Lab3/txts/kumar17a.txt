Resourceef cient Machine Learning in   KB RAM for the Internet of Things

Ashish Kumar   Saurabh Goyal   Manik Varma  

Abstract

This paper develops   novel treebased algorithm  called Bonsai  for ef cient prediction on
IoT devices   such as those based on the Arduino Uno board having an   bit ATmega  
microcontroller operating at   MHz with no native  oating point support    KB RAM and  
KB readonly  ash  Bonsai maintains prediction accuracy while minimizing model size and
prediction costs by      developing   tree model
which learns   single  shallow  sparse tree with
powerful nodes      sparsely projecting all data
into   lowdimensional space in which the tree is
learnt  and     jointly learning all tree and projection parameters  Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on
slow microcontrollers  can    in KB of memory 
has lower battery consumption than all other algorithms while achieving prediction accuracies
that can be as much as   higher than stateof theart methods for resourceef cient machine
learning  Bonsai is also shown to generalize to
other resource constrained settings beyond IoT
by generating signi cantly better search results
as compared to Bing      ranker when the model
size is restricted to   bytes  Bonsai   code can
be downloaded from  BonsaiCode 

  Introduction
Objective  This paper develops   novel treebased algorithm  called Bonsai  which can be trained on   laptop  or
the cloud  and can then be shipped onto severely resource
constrained Internet of Things  IoT  devices 
Resource constrained devices  The Arduino Uno board
has an   bit ATmega   microcontroller operating at  
MHz with   KB SRAM and   KB readonly  ash mem 

 Microsoft Research  Bangalore  India  CSE Department  IIT

Delhi  India  Correspondence to   manik microsoft com 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

ory  The BBC Micro Bit has     bit ARM Cortex    microcontroller operating at   MHz with   KB SRAM and
  KB readonly  ash  Neither provides hardware support for  oating point operations  Billions of such tiny IoT
microcontrollers have been deployed in the world  Meunier
et al    Before deployment  the OS and all application
code and data are burnt onto  ash  leaving only   few KB
for storing the trained ML model  prediction code  feature
extraction code and associated data and parameters  After deployment  the only writable memory available is the
  KB  Uno  or   KB  Micro Bit  of SRAM which might
not be suf cient to hold even   single feature vector 
The Internet of Things    number of applications have
been developed for consumer  enterprise and societal IoT
including predictive maintenance  intelligent healthcare 
smart cities and housing  etc  The dominant paradigm for
these applications  given the severe resource constraints of
IoT devices  has been that the IoT device is dumb   it just
senses its environment and transmits the sensor readings to
the cloud where all the decision making happens 
Motivating scenarios  This paper proposes an alternative
paradigm where the IoT device can make predictions locally without necessarily connecting to the cloud  This enables many scenarios  beyond the pale of the traditional
paradigm  where it is not possible to transmit data to the
cloud due to latency  bandwidth  privacy and energy concerns  For instance  consider   microcontroller implanted
in the brain which warns patients about impending seizures
so that they can call for help  pull over if they are driving 
etc  Making predictions locally would allow the device to
work everywhere irrespective of cloud connectivity  Furthermore  alerts could be raised more quickly with local
predictions than if all the sensor readings had to be  rst
transmitted to the cloud  In addition  since the energy required for executing an instruction might be much lower
than the energy required to transmit   byte  making predictions locally would extend battery life signi cantly thereby
avoiding repeated brain surgery and might also prevent
brain tissue damage due to excess heat dissipation from the
communicating radio  Finally  people might not be willing
to transmit such sensitive data to the cloud  These characteristics are shared by many other scenarios including implants in the heart  precision agriculture on disconnected
farms  smart spectacles for the visually impaired  etc 

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

Tree algorithms  Tree algorithms are general and can be
used for classi cation  regression  ranking and other problems commonly found in the IoT setting  Even more importantly  they are ideally suited to IoT applications as they can
achieve good prediction accuracies with prediction times
and energies that are logarithmic in the number of training
points  Unfortunately  they do not directly    on tiny IoT
devices as their space complexity is linear rather than logarithmic  In particular  learning shallow trees  or aggressively pruning deep trees or large ensembles  to    in just  
few KB often leads to poor prediction accuracy 
Bonsai  This paper develops   novel tree learner  called
Bonsai  designed speci cally for severely resource constrained IoT devices based on the following contributions 
First  Bonsai learns   single  shallow  sparse tree so as to
reduce model size but with powerful nodes for accurate
prediction  Second  both internal and leaf nodes in Bonsai
make nonlinear predictions  Bonsai   overall prediction
for   point is the sum of the individual node predictions
along the path traversed by the point  Path based prediction allows Bonsai to accurately learn nonlinear decision
boundaries while sharing parameters along paths to further
reduce model size  Third  Bonsai learns   sparse matrix
which projects all data points into   lowdimensional space
in which the tree is learnt  This allows Bonsai to    in   few
KB of  ash  Furthermore  the sparse projection is implemented in   streaming fashion thereby allowing Bonsai to
tackle IoT applications where even   single feature vector
might not    in   KB of RAM  Fourth  rather than learning
the Bonsai tree node by node in   greedy fashion  all nodes
are learnt jointly  along with the sparse projection matrix 
so as to optimally allocate memory budgets to each node
while maximising prediction accuracy 
Implementation  Another contribution is an ef cient implementation of Bonsai which reduces its prediction costs
on the Arduino and Micro Bit to be even lower than that of
an unoptimized linear classi er  This allows Bonsai to enjoy the prediction accuracy of   nonlinear classi er while
paying less than linear costs  This paper does not focus on
the system and implementation details due to space limitations but the interested reader is referred to the publically
available source code  BonsaiCode 
Results  These contributions allow Bonsai to make predictions in milliseconds even on slow microcontrollers    
in   few KB of  ash and extend battery life beyond all
other algorithms  Furthermore  it is demonstrated on multiple benchmark datasets that Bonsai   prediction accuracies
can approach those of uncompressed kNN classi ers  RBFSVMs  single hidden layer neural networks and gradient
boosted decision tree ensembles whose models might take
many MB of RAM  It is also demonstrated that Bonsai  
prediction accuracies for   given model size can be as much

as   higher than stateof theart methods for resourceef cient machine learning  Finally  Bonsai is shown to generalize to other resource constrained settings beyond IoT by
producing signi cantly better search results than Bing     
ranker when the model size is restricted to   bytes 

  Related Work
The literature on resourceef cient machine learning is vast
and specialized solutions have been developed for reducing the prediction costs of kNN algorithms  Kusner et al 
    Wang et al    SVMs  Hsieh et al    Jose
et al    Le et al    Li et al    deep learning  Iandola et al    Han et al    Yang et al   
Denton et al    Wu et al    Rastegari et al   
Hubara et al    Shankar et al    Ioannou et al 
    model compression  Bucilua et al    Ba  
Caruana    feature selection  Kusner et al      Xu
et al      Nan et al    Wang et al    and
applications such as face detection  Viola   Jones   
Resourceef cient tree classi ers are particularly germane
to this paper  The standard approach is to greedily grow
the decision tree ensemble node by node until the prediction budget is exhausted    popular alternative is to  rst
learn the random forest or gradient boosted decision tree
ensemble to maximize prediction accuracy and then use
pruning techniques to meet the budget constraints  Duda
et al    Dekel et al    Nan et al    Li   
Breiman et al    Zhang   Hueichuen    Sherali
et al    Kulkarni   Sinha    Rokach   Maimon 
  Joly et al    Unfortunately  such techniques are
fundamentally limited as they attempt to approximate complex nonlinear decision boundaries using   small number
of axisaligned hyperplanes  This can lead to poor prediction accuracies as observed in Section  
Tree models have also been developed to learn more complex decision boundaries by moving away from learning
axisaligned hyperplanes at internal nodes and constant
predictors at the leaves  For instance   Breiman   
Murthy et al    Kontschieder et al    learnt more
powerful branching functions at internal nodes based on
oblique cuts and full hyperplanes while  Utgoff   
Hsieh et al    learnt more powerful leaf node predictors based on linear classi ers  kernelized SVMs  etc  Bonsai achieves better budget utilization than such models by
learning shorter trees  typically depth   or lower  and by
sharing the parameters between leaf node predictors 
The models closest to Bonsai are Decision Jungles  Shotton et al    and LDKL  Jose et al    Bonsai improves upon LDKL by learning its tree in   lowdimensional space  learning sparse branching functions and
predictors and generalizing the model to multiclass classi 

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

 cation  ranking  etc  Decision Jungles are similar to Bonsai in that they share node parameters using   DAG structure  Unfortunately  Decision Jungles need to learn deep
tree ensembles with many nodes as they use weak constant
classi ers as leaf node predictors  Bonsai can have lower
model size and higher accuracy as it learns   single  shallow
tree in   lowdimensional space with nonlinear predictors 
Note that while tree based costsensitive feature selection
methods are not directly relevant  their performance is nevertheless empirically compared to Bonsai   in Section  

  The Bonsai Model for Ef cient Prediction
Overview  Bonsai learns   single  shallow sparse tree
whose predictions for   point   are given by

 cid 

      

Ik     cid 

  Zx   tanh   cid 

  Zx 

 

 

where   denotes the elementwise Hadamard product    is  
user tunable hyperparameter    is   sparse projection matrix and Bonsai   tree is parameterized by Ik  Wk and Vk
where Ik    is an indicator function taking the value   if
node   lies along the path traversed by   and   otherwise
and Wk and Vk are sparse predictors learnt at node    The
prediction function is designed to minimize the model size 
prediction time and prediction energy  while maintaining
prediction accuracy  even at the expense of increased training costs  The function is also designed to minimize the
working memory required as the Uno provides only   KB
of writeable memory for storing the feature vector  programme variables and intermediate computations 
Streaming sparse projection  Bonsai projects each
input feature vector   into   low  DD dimensional
dimensional space using   learnt sparse projection matrix
        Bonsai uses  xed point arithmetic for all math
computation  including Zx  when implemented on the IoT
device so as to avoid  oating point overheads  Note that   
could be as low as   for many binary classi cation applications  This has the following advantages  First  it reduces
Bonsai   model size as all tree parameters are now learnt
in the lowdimensional space  Second  when    is small 
Zx could be stored directly in the microcontroller   registers thereby reducing prediction time and energy  Third 
learning the projection matrix jointly with the tree parameters improves prediction accuracy  Fourth  since Zx can
be computed in   streaming fashion  this allows Bonsai to
tackle IoT applications where even   single feature vector
cannot    in   KB of SRAM  This is critical since standard tree implementations are unable to handle   streaming feature vector   the entire feature vector needs to be
streamed for the root node to determine whether to pass the
point down to the left or right child and therefore the vector
is unavailable for processing at subsequent nodes  Some

implementations work around this limitation by simultaneously evaluating the branching function at all nodes as the
vector is streamed but this increases the prediction costs
from logarithmic to linear which might not be acceptable 
Branching function at internal nodes  Bonsai computes
Ik by learning   sparse vector   at each internal node such
that the sign of  cid Zx determines whether point   should
be branched to the node   left or right child  Using more
powerful branching functions than the axisaligned hyperplanes in standard decision trees allows Bonsai to learn
shallow trees which can    in   few KB  Of course  this
is not   novel idea  and is insuf cient in itself to allow  
single  shallow decision tree to make accurate predictions 
Node predictors  Decision trees  random forests and
boosted tree ensembles are limited to making constant predictions at just the leaf nodes  This restricts their prediction accuracy when there are very few leaves  In contrast 
for   multiclass  multilabel or regression problem with  
targets  Bonsai learns matrices        and        at both
leaf and internal nodes so that each node predicts the vector   cid Zx tanh   cid Zx  Note that the functional form
of the node predictor was chosen as it was found to work
well empirically  other forms could be chosen if found to
be more appropriate  Further note that   and   will reduce to vectors for binary classi cation  ranking and singletarget regression  Bonsai   overall predicted vector is given
by   and is the sum of the individual vectors predicted
by the nodes lying along the path traversed by    This allows Bonsai to accurately learn nonlinear decision boundaries using shallow trees with just   few nodes  Furthermore  path based prediction allows parameter sharing and
therefore reduces model size as compared to putting independent classi ers of at least equal complexity in the leaf
nodes alone  For instance    depth   Bonsai tree with  
internal and   leaf nodes stores     and     matrices
with overall predictions being the sum of   terms depending on the path taken  If parameters were not shared and
each leaf node independently learnt     and     matrices
to make predictions of at least equal complexity  then   total of             and     matrices would need to be
stored thereby exceeding the memory budget  As an implementation detail  note that Bonsai uses the approximation
tanh        if         and signum    otherwise in order
to avoid  oating point computation 

  Training Bonsai
Notation  Bonsai learns   balanced tree of user speci ed
height   with        internal nodes and    leaf nodes  The
parameters that need to be learnt include         the sparse
projection matrix                        the parameters of the branching function at each internal node  and    
                     and                     

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

the predictor parameters at each node  Let            
denote   matrix obtained by stacking all the parameters together except for    Finally  it is assumed that   training points  xi   
   have been provided and that bud 
  
   
get constraints BZ and    on the projection matrix and
tree parameters have been speci ed depending on the  ash
memory available on the IoT device 
Optimization problem  Bonsai   parameters are learnt as

min
  

         

Tr cid   

 
 

  
 

Tr   cid   

Tr   cid     

Tr ZZ cid 

  
 

 

  xi  yi    xi      

 

 

  
 

 
 

  cid 

  

       cid   cid    BZ cid cid      

where   xi  is Bonsai   prediction for point xi as given
in   and   is an appropriately chosen loss function for
classi cation  regression  ranking  etc  For instance     
max      yiy xi  with yi       for binary classi cation and     maxy   yi     cid   xi          cid 
    
with                   cid       and yi     for
multiclass classi cation  It is worth emphasizing that the
optimization problem is formulated such that all parameters are learnt jointly subject to the budget constraints  This
leads to signi cantly higher prediction accuracies than if  
were  rst learnt independently  say using sparse PCA  and
then   was learnt afterwards  see Section  
Algorithm  Optimizing   over the space of all balanced
trees of height   is   hard  nonconvex problem  Tree growing algorithms typically optimize such problems by greedily growing the tree   node at   time starting from the root 
Unfortunately  this leads to   suboptimal utilization of the
memory budget in Bonsai   case as it is not clear   priori
how much budget to allocate to each node  For instance 
it is not apparent whether the budget should be distributed
equally between all nodes or whether the root node should
be allocated more budget and  if so  by how much 
Algorithm   Joint learning of nodes  Bonsai therefore
learns all node parameters jointly with the memory budget for each node being determined automatically as part
of the optimization  The dif culty with joint learning is
that   node   ancestors need to be learnt before it can
be determined which training points will reach the node 
Furthermore  the path traversed by   training point is  
sharply discontinuous function of   and   thereby rendering gradient based techniques ineffective  Various approaches have been proposed in the literature for tackling
these dif culties  Jose et al    Kontschieder et al 
  Norouzi et al    Xu et al    Ioannou et al 
    Bonsai follows the approach of  Jose et al   

  Ij   cid         tanh    cid 

and smooths the objective function by initially allowing
points to traverse multiple paths in the tree 
In particular  the indicator function Ik    is relaxed to Ik     
 
    parent node in   balanced tree           and the parameter    controls the  delity of the approximation  Gradients can now be computed as

  Zx cid  where    cid   

 cid  is

 

   Ik         Ik      
 ZIk     

   Ik      

    Zx

    lx cid 

 cid 

 

 

 

         

  Zx    

  Ck      tanh    cid 

where    
     
if node   is an ancestor of node   and   otherwise and
Ck        if node   is in the right subtree of node   and  
otherwise  Of course  allowing   point to traverse multiple
paths increases prediction costs  Some approaches therefore allow multiple paths during training but select   single path during prediction  Xu et al    Ioannou et al 
    At each node    point   is greedily branched to the
child node having the greatest Ik    Unfortunately  this
can lead to   drop in accuracy as the model learnt during
training is different from the one used for prediction 
Bonsai therefore follows an alternative strategy where   
is tuned during training to ensure that points gradually start
traversing at most   single path as optimization progresses 
In particular     is initialized to   small value  such as  
so as to ensure that tanh values are not saturated  As optimization progresses     is gradually increased so that tanh
tends to the signum function and Ik    goes back to being
an indicator function by the time convergence is reached 
This allows Bonsai to directly use the learnt model for prediction and was found to empirically lead to good results 
Algorithm   Gradient descent with iterative hard
thresholding  Various gradient based approaches  including those based on alternating minimization  were tried for
optimizing     gradient descent based algorithm with
iterative hard thresholding  IHT  was empirically found
to yield the best solutions  Gradient descent was chosen
over stochastic gradient descent as it removed the burden of
step size tuning  led to slightly better prediction accuracies
while keeping training time acceptable  For instance  training times range from   minutes for USPS  to   minutes
for MNIST  on   single core of   laptop with an Intel Core
    processor at   GHz with   GB of RAM  Stochastic gradient descent could be utilized for larger datasets or
if training costs also needed to be minimized  The algorithm proceeds iteratively based on the following gradient
and IHT steps in each iteration 
Algorithm   Gradient step  Given feasible Zt and   
with   feasible allocation of the memory budget to various
nodes at time step    Bonsai applies   updates of gradient descent keeping the support of   and    xed so that

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

the budget allocations to nodes remain unchanged and the
memory constraints are never violated  The update equations at each time step are
Zt    Zt     
             

  ZJ  Zt     supp Zt 
    Zt     supp   

 
 

with step sizes    and   being chosen according to the
Armijo rule and  supp indicating that the gradient was being computed only for the nonzero entries        and
      iterations were found to work well for binary and
multiclass classi cation respectively  This allows Bonsai
to decrease the objective function value without changing
the budget allocation of various nodes 
Algorithm   IHT step  In order to improve the budget allocation  Bonsai performs   single gradient update with unrestricted support  This violates the memory constraints and
Bonsai therefore projects the solution onto the feasible set
by retaining the parameters with the largest magnitudes
   ZJ  Zt           
Zt       TBZ Zt         
      Zt           
         TB           

where Tk is an operator returning   of its arguments which
have the largest magnitudes while setting the rest to   This
allows Bonsai to move to another feasible solution with
even lower objective function value by improving the memory budget distribution across nodes 
Algorithm   Convergence  In general  projected gradient
descent based algorithms might oscillate for nonconvex
problems  However   Blumensath   Davies    prove
that for smooth objective functions  gradient descent algorithms with IHT do indeed converge to   saddle point solution  Furthermore  if the objective function satis es the Restricted Strong Convexity  RSC  property in   local region 
then projected gradient descent with IHT will converge to
the local minimum in that region  Jain et al    In practice  it was observed that the algorithm generally converged
to   good solution soon and therefore was terminated after
      iterations were reached 
Algorithm   Initialization   retraining     and  
could be set randomly  Prediction accuracy gains of up to
  could be observed if Bonsai was initialized by taking
  steps of gradient descent without any budget constraints
followed by   hard thresholding step  Further gains of  
could be observed by taking another   steps of gradient descent with  xed support after termination  This helped in
 netuning Bonsai   parameters once the memory budget
allocation had been  nalized across the tree nodes 
More details about the optimization can be found in the
supplementary material by clicking here 

  Experiments
Datasets  Experiments were carried out on   number of
publically available binary and multiclass datasets including Chars    Campos et al    CIFAR   Krizhevsky 
  MNIST  LeCun et al    WARD  Yang et al 
  USPS  Hull    Eye  Kasprowski   Ober 
  RTWhale  RTW  and CUReT  Varma   Zisserman    Binary versions of these datasets were downloaded from  Jose et al    Bing      Ranking is   proprietary dataset where ground truth annotations specifying
the relevance of querydocument pairs have been provided
on   scale of   Table   lists these datasets  statistics 
Baseline algorithms  Bonsai was compared to stateof theart algorithms for resourceef cient ML spanning
tree  kNN  SVM and single hidden layer neural network
algorithms including Decision Jungles  Shotton et al 
  Pohlen  Feature Budgeted Random Forests  BudgetRF   Nan et al    Gradient Boosted Decision Tree
Ensemble Pruning  Tree Pruning   Dekel et al   
Pruned Random Forests  BudgetPrune   Nan et al   
Local Deep Kernel Learning  LDKL   Jose et al   
Neural Network Pruning  NeuralNet Pruning   Han et al 
  and Stochastic Neighbor Compression  SNC   Kusner et al      The differences between some of these
algorithms and Bonsai is brie   discussed in Section  
Publically available implementations of all algorithms were
used taking care to ensure that published results could be
reproduced thereby verifying the code and hyperparameter
settings  Note that Bonsai is not compared to deep convolutional neural networks as they have not yet been demonstrated to    on such tiny IoT devices  In particular  convolutions are computationally expensive  drain batteries
and produce intermediate results which do not    in   KB
RAM  Implementing them on tiny microcontrollers is still

Table   Dataset statistics   the number after the dataset
name represents the number of classes so as to distinguish
between the binary and multiclass versions of the dataset 

Dataset
   Ranking
Chars   
CIFAR 
WARD 
USPS 
MNIST 
Eye 
RTWhale 
CUReT 
MNIST 
Chars   

  Train
 
 
 
 
 
 
 
 
 
 
 

  Test
 
 
 
 
 
 
 
 
 
 
 

  Features
 
 
 
 
 
 
 
 
 
 
 

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

Figure   Multiclass   Ranking Datasets   Bonsai dominates over the stateof theart resourceef cient ML algorithms
by as much as   on Chars    and   on CUReT  BonsaiOpt   gains are even higher  Some methods do not
appear on the graphs as their accuracies were not high enough to fall within the yaxis limits  Bonsai also dominates Bing  
FastRank    ranker  Figure best viewed magni ed 

Figure   Binary Datasets   Bonsai dominates over stateof theart resourceef cient ML algorithms with gains of   on
RTWhale  and   on Eye  in the   KB range  BonsaiOpt   gains are even higher  Figure best viewed magni ed 

an open research problem  Bonsai   performance was however compared to that of uncompressed single hidden layer
neural networks without convolutions  Gradient Boosted
Decision Trees  GBDT  kNN classi ers and RBFSVMs 
Hyperparameters  The publically provided training set
for each dataset was subdivided into   for training and
  for validation  The hyperparameters of all algorithms were tuned on the validation set  Once the hyperparameters had been  xed  the algorithms were trained on
the full training set and results were reported on the publically available test set 
Evaluation  IoT applications would like to maximize their
prediction accuracies using the best model that might   
within the available  ash memory while minimizing their
prediction times and energies  Accuracies of all algorithms
are therefore presented for   range of model sizes  Some

of the algorithms were implemented on the Uno and their
prediction times and energies were compared to Bonsai   
Implementation  Results are presented throughout for an
unoptimized implementation of Bonsai for   fair comparison with the other methods  For instance    bytes were
used to store  oating point numbers for all algorithms  all
 oating point operations were simulated in software  etc 
However  results are also presented for an optimized implementation of Bonsai  called BonsaiOpt  where numbers
were stored in     byte  xed point format  tanh was approximated  all  oating point operations were avoided  etc 
Comparison to uncompressed methods  The results in
Tables   and   demonstrate that Bonsai   prediction accuracies could compete with those of uncompressed kNN 
GBDT  RBFSVM and neural network classi ers with signi cantly larger model sizes  On RTWhale  Chars   

 Chars   Model Size  KB Accuracy    BonsaiOptBonsaiNeuralNet PruningSNCDecision JungleBudgetPruneBudgetRF CUReT Model Size  KB Accuracy    BonsaiOptBonsaiNeuralNet PruningSNCDecision JungleBudgetPruneBudgetRF MNIST Model Size  KB Accuracy    BonsaiOptBonsaiNeuralNet PruningSNCDecision JungleBudgetPruneBudgetRF    RankingModel Size  KB nDCG   BonsaiFastRank RTWhale Model Size  KB Accuracy  Eye Model Size  KB Accuracy  WARD Model Size  KB Accuracy  MNIST Model Size  KB Accuracy  Chars   Model Size  KB Accuracy  CIFAR Model Size  KB Accuracy  USPS Model Size  KB Accuracy  Legend   BonsaiOptBonsaiGBDTTree PruningLDKLLDKL   NeuralNet PruningSNCDecision JungleBudgetPruneBudgetRFResourceef cient Machine Learning in   KB RAM for the Internet of Things

Table   Binary Datasets   Bonsai can sometimes outperform uncompressed methods with signi cantly larger models 

Dataset

RTWhale 
Chars   
Eye 
WARD 
CIFAR 
USPS 
MNIST 

Bonsai  
 KB  KB
 
 
 
 
 
 
 
 
 
 
 
 
 
 

GBDT  

kNN  

RBFSVM  

NeuralNet  

    KB 
      KB 
      KB 
    KB 
    KB 
      KB 
    KB 

      KB 
      KB 
      KB 
      KB 
      KB 
      KB 
    KB 

    KB 
      KB 
      KB 
      KB 
    KB 
      KB 
    KB 

    KB 
      KB 
    KB 
    KB 
      KB 
      KB 
    KB 

Table   Multiclass Datasets   Bonsai can sometimes outperform uncompressed methods with signi cantly larger models 

Dataset
Chars   
CUReT 
MNIST 

Bonsai  

    KB 
    KB 
      KB 

GBDT  

    KB 
    KB 
    KB 

kNN  

      KB 
      KB 
    KB 

RBFSVM  
      KB 
      KB 
    KB 

NeuralNet  
    KB 
    KB 
    KB 

Table   The effect of Bonsai   components   Performing
sparse PCA independently before training is not as effective as Bonsai   joint optimization of the projection matrix 

Method

Accuracy

 

Model
size
 KB 

Bonsai with random initialization
and without retraining
Bonsai without retraining
Bonsai
Bonsai with sparse PCA
Tree Pruning with sparse PCA
Decision Jungle with sparse PCA
RBFSVM with sparse PCA

 
 
 
 
 
 
 

 
 
 
 
 
 
 

and Chars    Bonsai   accuracies were higher than all
other methods by     and   while its model
size was lower by        and    respectively  Bonsai   accuracies were lower by       on the other
datasets with model size gains varying from    to    
Note that  while BonsaiOpt   accuracies were similar to
Bonsai    its model sizes would be even lower 
Comparison to resourceef cient ML algorithms  The
results in Figures   and   demonstrate that Bonsai   prediction accuracies dominate those of stateof theart resourceef cient ML algorithms for all model sizes  In fact  Bonsai
could outperform all other algorithms  including tree algorithms by as much as   on Char    and   on
CUReT  for   given model size  For binary datasets  the
largest gains were observed in the   KB regime including   on RTWhale  and   on Eye  Of course 
BonsaiOpt   gains were even higher on both binary and

multiclass datasets  These results validate Bonsai   model 
showing it to be accurate and compact and demonstrate that
Bonsai   optimization algorithm yields good solutions 
   ranking  Bonsai was shown to generalise to other
resourceconstrained scenarios beyond IoT by ranking documents in response to queries on Bing  Bonsai was trained
by replacing the classi cation gradients with ranksensitive
gradients approximating nDCG  Burges    As can be
seen in Figure   using     byte model  Bonsai could
outperform Bing   FastRank    ranker by   In fact 
Bonsai could achieve almost the same ranking accuracy as
FastRank but with      smaller model 
Prediction on the Arduino Uno  Table   presents the prediction costs per test point for the highest accuracy models
with size less than   KB for   few methods that were implemented on the Arduino Uno  The BonsaiOpt model was  
more ef cient implementation of the chosen Bonsai model 
The results indicate that BonsaiOpt could be signi cantly
more accurate  faster and energyef cient as compared to
other algorithms including an unoptimized linear classi er 
Transmitting the test feature vector to the cloud  whenever
possible  and running uncompressed GBDT might sometimes yield higher accuracies but would also consume    
   more energy which might not be feasible 
Bonsai   components  The contribution of Bonsai   components on the Chars    dataset is presented in Table   Modest reductions in accuracy were observed without proper initialization or retraining  Learning   projection matrix independently via sparse PCA before training reduced accuracy signi cantly as compared to Bonsai  
joint training of the projection matrix and tree parameters 
Other tree and uncompressed methods also did not bene  
much by training in the sparse PCA space 

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

Table   Prediction costs per test point on the Arduino Uno with the highest accuracy model of size less than   KB   The
BonsaiOpt model was   more ef cient implementation of the chosen Bonsai model  BonsaiOpt was signi cantly more
accurate  faster and energyef cient than all other methods  Transmitting the test feature vector to the cloud  whenever
possible  and running uncompressed GBDT might sometimes yield higher accuracies but would also consume     
more energy which might not be feasible in many IoT applications 

Dataset

Eye 

RTWhale 

Chars   

WARD 

CIFAR 

USPS 

MNIST 

Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 
Model Size  KB 
Accuracy  
Prediction Time  ms 
Prediction Energy  mJ 

BonsaiOpt Bonsai Linear LDKL NeuralNet Cloud GBDT
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Pruning
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

  Conclusions
This paper proposed an alternative IoT paradigm  centric
to the device rather than the cloud  where ML models run
on tiny IoT devices without necessarily connecting to the
cloud thereby engendering local decision making capabilities  The Bonsai tree learner was developed towards this
end and demonstrated to be fast  accurate  compact and
energyef cient at prediction time  Bonsai was deployed
on the Arduino Uno board as it could    in   few KB of
 ash  required only   bytes of writable memory for binary classi cation and   bytes for     class problem 
handled streaming features and made predictions in milliseconds taking only milliJoules of energy  Bonsai   prediction accuracies could be as much as   higher as com 

pared to stateof theart resourceef cient ML algorithms
for    xed model size and could even approach and outperform those of uncompressed models taking many MB of
RAM  Bonsai achieved these gains by developing   novel
model based on   single  shallow  sparse tree learnt in  
lowdimensional space  Predictions made by both internal and leaf nodes and the sharing of parameters along
paths allowed Bonsai to learn complex nonlinear decision
boundaries using   compact representation  Bonsai   code
is available from  BonsaiCode  and is part of Microsoft  
ELL machine learning compiler for IoT devices 

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

Acknowledgements
We are grateful to Yeshwanth Cherapanamjeri  Ofer Dekel 
Chirag Gupta  Prateek Jain  Ajay Manchepalli  Nagarajan Natarajan  Praneeth Netrapalli  Bhargavi Paranjape 
Suresh Parthasarathy  Vivek Seshadri  Rahul Sharma  Harsha Vardhan Simhadri  Manish Singh and Raghavendra
Udupa for many helpful discussions and feedback 

References
The right whale dataset  https www kaggle com 

  whaledetection challenge data 

Ba     and Caruana     Do deep nets really need to be deep 

In NIPS   

Blumensath     and Davies        Iterative thresholding for
sparse approximations  Journal of Fourier Analysis and
Applications     

BonsaiCode 

Code for Bonsai 

http www 

manikvarma org code Bonsai download 
html 

Breiman     Random forests  ML   

Breiman     Friedman     Stone        and Olshen       
Classi cation and regression trees  In CRC press   

Bucilua     Caruana     and NiculescuMizil     Model
compression  In Proceedings of the  th ACM SIGKDD
international conference on Knowledge discovery and
data mining   

Burges        From ranknet to lambdarank to lambdamart 

An overview  Learning     

Campos        Babu        and Varma     Character

recognition in natural images  In VISAPP   

Dekel     Jacobbs     and Xiao     Pruning decision

forests  In Personal Communications   

Denton        Zaremba     Bruna     LeCun     and Fergus     Exploiting linear structure within convolutional
networks for ef cient evaluation  In NIPS   

Duda        Hart        and Stork        Pattern Classi 

cation  John Wiley and Sons   nd edition   

Hubara     Courbariaux     Soudry     ElYaniv     and
Bengio     Quantized neural networks  Training neural networks with low precision weights and activations 
CoRR  abs   

Hull          database for handwritten text recognition re 

search  IEEE PAMI     

Iandola        Moskewicz        Ashraf     Han    
Dally        and Keutzer     Squeezenet  Alexnetlevel
accuracy with    fewer parameters and  MB model
size  CoRR  abs   

Ioannou     Robertson     Cipolla     and Criminisi    
Deep roots  Improving cnn ef ciency with hierarchical
 lter groups  arXiv preprint arXiv     

Ioannou     Robertson     Kontschieder     Zikicand   
Shotton     Brown     and Criminisi     Decision forests  convolutional networks and the models inbetween  arXiv preprint arXiv     

Jain     Tewari     and Kar     On iterative hard thresholding methods for highdimensional mestimation  In
NIPS   

Joly     Schnitzler     Geurts     and Wehenkel       
based compression of random forest models  In ESANN 
 

Jose     Goyal     Aggrwal     and Varma     Local deep
kernel learning for ef cient nonlinear svm prediction 
In ICML    https manikvarma github 
io code LDKL download html 

Kasprowski     and Ober     Eye movement in biometrics 

In eccv   

Kontschieder     Fiterau     Criminisi     and Bulo       

Deep neural decision forests  In ICCV   

Krizhevsky     Learning multiple layers of features from

tiny images  Technical report   

Kulkarni        and Sinha        Pruning of random forest
In ICDSE 

classi ers    survey and future directions 
 

Kusner        Chen     Zhou     Xu        Weinberger 
      and Chen     Featurecost sensitive learning with
submodular trees of classi ers  In AAAI     

Han     Mao     and Dally        Deep compression 
Compressing deep neural networks with pruning  trained
quantization and huffman coding  In ICLR   

Kusner        Tyree     Weinberger        and Agrawal 
   Stochastic neighbor compression  In ICML     
http mkusner github io code 

Hsieh        Si     and Dhillon     Fast prediction for large 

scale kernel machines  In NIPS   

Le     Sarl os     and Smola     Fastfoodapproximating

kernel expansions in loglinear time  In ICML   

Resourceef cient Machine Learning in   KB RAM for the Internet of Things

LeCun     Bottou     Bengio     and Haffner     Gradientbased learning applied to document recognition  Proceedings of the IEEE     

Wang     Trapeznikov     and Saligrama     Ef cient
learning by directed acyclic graph for resource constrained prediction  In NIPS   

Li        Markov Random Field Modeling in Image Analy 

sis  SpringerVerlag   

Li     Yang     Zhang     and Jin     Fast and accurate

re ned nystr ombased kernel svm  In AAAI   

Meunier     Wood     Weiss     Huberty     Flannery 
   Moore     Hettenbach     and Lu     The internet
of things is now connecting the real economy  Technical
report  Morgan Stanley   

Wang     Chen     Chen     Rai     and Carin     Deep
In

distance metric learning with data summarization 
ECML PKDD   

Wu     Leng     Wang     Hu     and Cheng     Quantized convolutional neural networks for mobile devices 
In CVPR   

Xu     Weinberger        and Chapelle     The greedy
miser  Learning under testtime budgets  In ICML   

Murthy        Kasif     and Salzberg       system for

induction of oblique decision trees  JAIR     

Xu        Kusner        Weinberger        and Chen    

Costsensitive tree of classi ers  In ICML   

Nan     Wang     and Saligrama     Featurebudgeted ranIn ICML    http sites bu 

dom forest 
edu data code 

Yang     Li     Tian     Duan     and Gao     Groupsensitive multiple kernel learning for object categorization  In ICCV   

Yang     Moczulski     Denil     Freitas     Smola 
      Song     and Wang     Deep fried convnets  ICCV 
 

Zhang     and Hueichuen     Decision tree pruning via

integer programming  Technical report   

Nan     Wang     and Saligrama     Pruning random

forests for prediction on   budget  In NIPS   

Norouzi     Collins     Johnson        Fleet        and
Kohli     Ef cient nongreedy optimization of decision
trees  In NIPS   

Pohlen     LibJungle   Decision Jungle Library  https 

 bitbucket org geekStack libjungle 

Rastegari     Ordonez     Redmon     and Farhadi    
Xnornet  Imagenet classi cation using binary convolutional neural networks  In ECCV   

Rokach     and Maimon     Data mining with decision

trees  theory and applications  World scienti     

Shankar     Robertson     Ioannou     Criminisi     and
Cipolla     Re ning architectures of deep convolutional
neural networks  In CVPR   

Sherali        Hobeika        and Jeenanunta     An
optimal constrained pruning strategy for decision trees 
INFORMS Journal on Computing     

Shotton     Sharp     Kohli     Nowozin     Winn    
and Criminisi     Decision jungles  Compact and rich
models for classi cation  In NIPS   

Utgoff        Perceptron trees    case study in hybrid con 

cept representations  Connection Science     

Varma     and Zisserman       statistical approach to
IJCV   

texture classi cation from single images 
   

Viola     and Jones        Robust realtime face detection 

IJCV     

