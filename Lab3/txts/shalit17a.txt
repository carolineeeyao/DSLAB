Estimating individual treatment effect  generalization bounds and algorithms

Uri Shalit     Fredrik    Johansson     David Sontag    

Abstract

There is intense interest in applying machine
learning to problems of causal inference in  elds
such as healthcare  economics and education 
In particular 
individuallevel causal inference
has important applications such as precision
medicine  We give   new theoretical analysis and family of algorithms for predicting individual treatment effect  ITE  from observational
data  under the assumption known as strong ignorability  The algorithms learn    balanced 
representation such that the induced treated and
control distributions look similar  and we give
  novel and intuitive generalizationerror bound
showing the expected ITE estimation error of  
representation is bounded by   sum of the standard generalizationerror of that representation
and the distance between the treated and control distributions induced by the representation 
We use Integral Probability Metrics to measure
distances between distributions  deriving explicit
bounds for the Wasserstein and Maximum Mean
Discrepancy  MMD  distances  Experiments on
real and simulated data show the new algorithms
match or outperform the stateof theart 

  Introduction
Making predictions about causal effects of actions is   central problem in many domains  For example    doctor deciding which medication will cause better outcomes for  
patient    government deciding who would bene   most
from subsidized job training  or   teacher deciding which
study program would most bene     speci   student 
In
this paper we focus on the problem of making these predictions based on observational data  Observational data is
 CIMS  New York University  New
York  NY    IMES  MIT  Cambridge  MA  
 CSAIL  MIT  Cambridge  MA  
Correspondence
to  Uri Shalit  shalit cs nyu edu  Fredrik    Johansson
 fredrikj mit edu  David Sontag  dsontag csail mit edu 

 Equal contribution

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright  
by the author   

data which contains past actions  their outcomes  and possibly more context  but without direct access to the mechanism which gave rise to the action  For example we might
have access to records of patients  context  their medications  actions  and outcomes  but we do not have complete
knowledge of why   speci   action was applied to   patient 
The hallmark of learning from observational data is that
the actions observed in the data depend on variables which
might also affect the outcome  resulting in confounding 
For example  richer patients might better afford certain
medications  and job training might only be given to those
motivated enough to seek it  The challenge is how to untangle these confounding factors and make valid predictions 
Speci cally  we work under the common simplifying assumption of  nohidden confounding  assuming that all
the factors determining which actions were taken are observed  In the examples above  it would mean that we have
measured   patient   wealth or an employee   motivation 
As   learning problem  estimating causal effects from observational data is different from classic learning in that in
our training data we never see the individuallevel effect 
For each unit  we only see their response to one of the possible actions   the one they had actually received  This is
close to what is known in the machine learning literature as
 learning from logged bandit feedback   Strehl et al   
Swaminathan   Joachims    with the distinction that
we do not have access to the model generating the action 
Our work differs from much work in causal inference in
that we focus on the individuallevel causal effect  cspeci   treatment effects  Shpitser   Pearl   Pearl
  rather than the average or population level  Our
main contribution is to give what is  to the best of our
knowledge  the  rst generalizationerror  bound for estimating individuallevel causal effect  where each individual is identi ed by its features    The bound leads naturally to   new family of representationlearning based algorithms  Bengio et al    which we show to match or
outperform stateof theart methods on several causal effect inference tasks 

 Our use of the term generalization is different from its use in
the study of transportability  where the goal is to generalize causal
conclusion across distributions  Bareinboim   Pearl   

Estimating individual treatment effect  generalization bounds and algorithms

       cid 

function         cid 

We frame our results using the NeymanRubin potential
outcomes framework  Rubin    as follows  We assume that for   unit with features         and an action
 also known as treatment or intervention          there
are two potential outcomes     and    For each unit we
only observe one of the potential outcomes  according to
treatment assignment 
if       we observe        if
      we observe        this is known as the consistency assumption  For example    can denote the set of lab
tests and demographic factors of   diabetic patient       
denote the standard medication for controlling blood sugar 
      denotes   new medication  and    and    indicate the
patient   blood sugar level if they were to be given medications       and       respectively 
We will denote                              
We are interested in learning the function      
 
                                 is the expected
treatment effect of       relative to       on   unit with
characteristics    or the Individual Treatment Effect  ITE 
Our goal is to  nd an estimate   of   such that some loss
  is small  For example  for  
patient with features    we attempt to predict which of two
treatments will have   better outcome  The fundamental
problem of causal inference is that for any   in our data we
only observe    or    but never both 
As mentioned above  we make an important  nohidden
confounders  assumption 
in order to make the conditional causal effect identi able  We formalize this assumption by using the standard strong ignorability condition 
              and                   for all    Strong
ignorability is   suf cient condition for the ITE function
      to be identi able  Imbens   Wooldridge    Pearl 
  Rolling    see proof in the supplement  The validity of strong ignorability cannot be assessed from data 
and must be determined by domain knowledge and understanding of the causal relationships between the variables 
One approach to the problem of estimating the function
      is by learning the two functions      and     
using samples from   Yt       This is similar to   standard machine learning problem of learning from  nite samples  However  there is an additional source of variance at
work here  For example  if mostly rich patients received
treatment       and mostly poor patients received treatment       we might have an unreliable estimation of
     for poor patients  In this paper we upper bound this
additional source of variance using an Integral Probability Metric  IPM  measure of distance between two distributions           and           also known as the
control and treated distributions  In practice we use two
speci   IPMs  the Maximum Mean Discrepancy  Gretton

 Also known as Conditional Average Treatment Effect  CATE 

Figure   Neural network architecture for ITE estimation    is
  loss function  IPMG is an integral probability metric  Note that
only one of    and    is updated for each sample during training 

et al    and the Wasserstein distance  Villani   
Cuturi   Doucet    We show that the expected error
in learning the individual treatment effect function       is
upper bounded by the error of learning    and    plus the
IPM term  In the randomized controlled trial setting  where
       the IPM term is   and our bound naturally reduces
to   standard learning problem of learning two functions 
The bound we derive points the way to   family of algorithms based on the idea of representation learning  Bengio et al    Jointly learn hypotheses for both treated
and control on top of   representation which minimizes  
weighted sum of the factual loss  the standard supervised
machine learning objective  and the IPM distance between
the control and treated distributions induced by the representation  This can be viewed as learning the functions   
and    under   constraint that encourages better generalization across the treated and control populations  In the
Experiments section we apply algorithms based on neural
nets as representations and hypotheses  along with MMD
or Wasserstein distributional distances over the representation layer  see Figure   for the basic architecture 
In his foundational text on causality  Pearl   writes 
 Whereas in traditional learning tasks we attempt to generalize from one set of instances to another  the causal modeling task is to generalize from behavior under one set of
conditions to   another set  Causal models should therefore be chosen by   criterion that challenges their stability
against changing conditions   emphasis ours  We believe
our work points the way to one such stability criterion  for
causal inference in the strongly ignorable case 

  Related work
Much recent work in machine learning for causal inference focuses on causal discovery  with the goal of discovering the underlying causal graph or causal direction from
data  Hoyer et al    Maathuis et al    Trianta llou   Tsamardinos    Mooij et al    We focus
on the case when the causal setup is simple and known
to be of the form               with no hidden confounders  Under the causal model we assume  the most
common goal of causal effect inference as used in the ap 

 IPM 	  	  Estimating individual treatment effect  generalization bounds and algorithms

plied sciences is to obtain the average treatment effect 
AT     Ex            We will brie   discuss how some
standard statistical causal effect inference methods relate to
our proposed method  Note that most of these approaches
assume some form of ignorability 
One of the most widely used approaches to estimating ATE
is covariate  or backdoor  adjustment  also known as the
Gcomputation formula  Robins    Pearl   
In
their basic version  covariate adjustment methods aim to
estimate the functions           and are therefore
natural candidates for estimating ITE as well as ATE  using the estimates of mt    Most previous work on this
subject focused on asymptotic consistency  Belloni et al 
  Athey et al    Chernozhukov et al    and
so far there has not been much work on the generalizationerror of such   procedure  One view of our results is that
we point out   previously unaccounted for source of variance when using covariate adjustment to estimate ITE  We
suggest   new type of regularization  by learning representations with reduced IPM distance between treated and control  enabling   new type of biasvariance tradeoff 
Another widely used family of statistical methods used in
causal effect inference are weighting methods  Methods
such as inverse propensity score weighting  Austin   
reweight the units in the observational data so as to make
the treated and control populations more comparable  and
have been used for estimating conditional effects as well
 Cole et al    The major challenge  especially in
highdimensional cases  is controlling the variance of the
estimates  Swaminathan   Joachims    Doubly robust methods go further and combine propensity score reweighting and covariate adjustment in clever ways to reduce model bias  Funk et al   
Adapting machine learning methods for causal effect inference  and in particular for individual level treatment effect 
has gained much interest recently  For example Wager  
Athey   Athey   Imbens   discuss how treebased methods can be adapted to obtain   consistent estimator with semiparametric asymptotic convergence rate 
Recent work has also looked into how machine learning
methods can help detect heterogeneous treatment effects
when some data from randomized experiments is available
 Taddy et al    Peysakhovich   Lada    Neural
nets have also been used for this purpose  exempli ed in
early work by Beck et al    and more recently by
Hartford et al     work on deep instrumental variables  Our work differs from all the above by focusing
on the generalizationerror aspects of estimating individual
treatment effect  as opposed to asymptotic consistency  and
by focusing solely on the observational study case  with no
randomized components or instrumental variables 
Our work has strong connections with work on domain

adaptation  In particular  estimating ITE requires prediction of outcomes over   different distribution from the observed one  Our ITE error upper bound has similarities with
generalization bounds in domain adaptation given by BenDavid et al    Mansour et al    BenDavid et al 
  Cortes   Mohri   These bounds employ distribution distance metrics such as the Adistance or the discrepancy metric  which are related to the IPM distance we
use  Our algorithm is similar to   recent algorithm for domain adaptation by Ganin et al    and in principle
other domain adaptation methods       Daum   III  
Pan et al    Sun et al    could be adapted for
use in ITE estimation as presented here 
Finally  our paper builds on Johansson et al    where
we showed   connection between covariate shift and the
task of estimating counterfactuals  We proposed learning  
representation of the data that makes the treated and control
distributions more similar   tting   linear ridgeregression
model on top of it  We bounded the relative error of  tting
  ridgeregression using the distribution with reverse treatment assignment versus  tting   ridgeregression using the
factual distribution  Unfortunately  the relative error bound
is not at all informative regarding the absolute quality of
the representation  In this paper we focus on   related but
more substantive task  estimating the individual treatment
effect  building on the counterfactual error term  We provide an informative bound on the absolute quality of the
representation  We also derive   much more  exible family
of algorithms  including nonlinear hypotheses and much
more powerful distribution metrics in the form of IPMs
such as the Wasserstein and MMD distances  Finally  we
conduct signi cantly more thorough experiments including
  realworld dataset and outof sample performance  and
show our methods outperform previously proposed ones 

  Estimating ITE  Error bounds
In this section we prove   bound on the expected error in
estimating the individual treatment effect for   given representation  and   hypothesis de ned over that representation 
The bound is expressed in terms of   the expected loss
of the model when learning the observed outcomes   as  
function of   and    denoted        standing for  Factual 
  an Integral Probability Metric  IPM  distance between
the distribution of treated and control units  The term   
is the classic machine learning generalizationerror  and in
turn can be upper bounded using the empirical error and
model complexity terms  applying standard machine learning theory  ShalevShwartz   BenDavid   

  Problem setup

We will employ the following assumptions and notations 
The most important notations are in the Notation box in the

Estimating individual treatment effect  generalization bounds and algorithms

supplement  The space of covariates is   bounded subset
    Rd  The outcome space is        Treatment   is  
binary variable  We assume there exists   joint distribution
              such that              and          
        for all        strong ignorability  The treated
and control distributions are the distribution of the features
  conditioned on treatment  pt                and
pt                respectively 
Throughout this paper we will discuss representation functions of the form            where   is the representation space  We make the following assumption about  
Assumption   The representation   is   twicedifferentiable  oneto one function  Without loss of generality we will assume that   is the image of   under  
We then have           as the inverse of   such that
        for all        

                  pt 

The representation   pushes forward the treated and control distributions into the new space    we denote the induced distribution by   
De nition   De ne pt 
       
          to be the treated and control distributions
induced over    For   oneto one   the distributions
      can be obtained by the standard
      and pt 
pt 
change of variables formula  using the determinant of the
Jacobian of    
Let           be   representation function  and    
            be an hypothesis de ned over the representation space    Let                be   loss function  We de ne two complimentary loss functions  one is
the standard machine learning loss  which we will call the
factual loss      as it relates to observable quantities  The
other is the expected loss with respect to the distribution
where the treatment assignment is  ipped  which we call
the counterfactual loss   CF  
De nition
unit
and
 
    Yt           Yt   dYt  The expected factual
and counterfactual losses of   and   are 

for
the
 cid        

  The
pair

expected
      

treatment

loss

 cid 

is 

 cid 

 cid 

          

 cid                 dxdt 

  

 CF        

  

 cid                     dxdt 

If   denotes patients  features      treatment  and Yt   potential outcome such as mortality  we think of    as measuring
how well do   and   predict mortality for the patients and
doctors  actions sampled from the same distribution as our
data sample   CF measures how well our prediction with
  and   would do in    topsyturvy  world where the patients are the same but the doctors are inclined to prescribe

exactly the opposite treatment than the one the realworld
doctors would prescribe 
De nition   The expected factual treated and control
losses are 

 cid 
 cid 

   
         

   
         

 cid        pt    dx 
 

 cid        pt    dx 
 

                  

For             it is immediate to show that           
    
De nition   The treatment effect  ITE  for unit   is 

       

                      

Let                 by an hypothesis  For example 
we could have that                   
De nition   The treatment effect estimate of the hypothesis   for unit   is 

                          

De nition   The expected Precision in Estimation of Heterogeneous Effect  PEHE  Hill   loss of   is 
                    dx 

 PEHE      

 cid 

 

 

When                    we will also use the notation
 PEHE         PEHE    

Our proof relies on the notion of an Integral Probability
Metric  IPM  which is   class of metrics between probability distributions  Sriperumbudur et al      uller 
  For two probability density functions      de ned
over     Rd  and for   function family   of functions
           we have that

IPMG         sup
   

                ds

Integral probability metrics are always symmetric and obey
the triangle inequality  and trivially satisfy IPMG        
  For rich enough function families    we also have that
IPMG                    and then IPMG is   true
metric  Examples of function families   for which IPMG
is   true metric are the family of bounded continuous functions  the family of  Lipschitz functions  Sriperumbudur
et al    and the unitball of functions in   universal
reproducing kernel Hilbert space  Gretton et al   

  Bounds

We  rst state   Lemma bounding the counterfactual loss   
key step in obtaining the bound on the error in estimating

 cid cid cid cid cid 

 

 cid cid cid cid   

Estimating individual treatment effect  generalization bounds and algorithms

individual treatment effect  We then give the main Theorem  The proofs and details are in the supplement 
Let             be the marginal probability of treatment 
By the strong ignorability assumption           
Lemma   Let           be   oneto one representation
function  with inverse   Let                 be an
hypothesis  Let   be   family of functions            Assume there exists   constant        such that for  xed    
    the perunit expected loss functions  cid        
 De nition   obey  
  

   cid              We have 

 CF        
        
       IPMG
and    

 cid pt 

              
    pt 

 

 cid   

       

 

 

are as in De nitions   and  

where  CF      
Theorem   Under the conditions of Lemma   and assuming the loss   used to de ne  cid    in De nitions   and   is
the squared loss  we have 
 PEHE       

 cid CF                     
 cid   

         

 

         IPMG

    pt 

 

 cid   

 cid pt 

 cid 

 

 cid 

 

where    and  CF are de ned        the squared loss  and
  is the variance of the outcomes Yt  see De nition   
 
in Appendix for detailed de nition 

The main idea of the proof is showing that  PEHE is upper
bounded by the sum of the expected factual loss    and
expected counterfactual loss  CF   However  we cannot estimate  CF   since we only have samples relevant to      We
therefore bound the difference  CF      using an IPM 
Choosing   small function family   makes the bound
tighter  However  choosing too small   family could result in an incomputable bound  For example  for the minimal choice      cid         cid        we will have to
evaluate an expectation term of    over pt 
    and of   
over pt 
    We cannot in general evaluate these expectations  since by assumption when       we only observe
   and the same for       and    In addition  for some
function families there is no known way to ef ciently compute the IPM distance or its gradients  Here  we use two
function families for which there are available optimization tools  The  rst is the family of  Lipschitz functions 
which leads to IPM being the Wasserstein distance  Villani    denoted Wass       The second is the family
of norm  reproducing kernel Hilbert space  RKHS  functions  leading to the MMD metric  Gretton et al    denoted MMD       Both the Wasserstein and MMD metrics
have consistent estimators which can be ef ciently computed for  nite samples  Sriperumbudur et al    and

have been used for various machine learning tasks in recent
years  Gretton et al      Cuturi   Doucet   
In order to explicitly evaluate the constant    in Theorem
  we have to make some assumptions about the elements
of the problem  For the Wasserstein case these are the loss
   the Lipschitz constants of   Yt    and    and the condition number of the Jacobian of   For the MMD case 
we make assumptions about the RKHS representability and
RKHS norms of       and the standard deviation of Yt   
The full details are given in the supplement  with the major
results stated in Theorems   and   In all cases we obtain
that making   smaller increases the constant    precluding trivial solutions such as making   arbitrarily small 
For an empirical sample  and   family of representations
and hypotheses  we can further upper bound    
and    
by their respective empirical losses and   model complexity term using standard arguments  ShalevShwartz   BenDavid    The IPMs we use can be consistently estimated from  nite samples  Sriperumbudur et al   
  arises from the fact that 
The negative variance term  
following Hill   Athey   Imbens   we de ne
the error  PEHE in terms of the conditional mean functions
mt    as opposed to  tting the random variables Yt 
Our results hold for any given   and   obeying the Theorem conditions  This immediately suggest an algorithm
in which we minimize the upper bound in Eq    with respect to   and   and either the Wasserstein or MMD IPM 
in order to minimize the error in estimating the individual
treatment effect  This leads us to Algorithm   below 

 

 

  Algorithm for estimating ITE
We propose   general framework called CFR  for Counterfactual Regression  for ITE estimation based on the theoretical results above  Our algorithm is an endto end  regularized minimization procedure which  ts both   balanced
representation of the data and   hypothesis for the outcome 
CFR draws on the same intuition as our previous work  Johansson et al    but overcomes the following limitations     Our previous theory requires   twostep optimization procedure and is speci   to linear hypotheses  it does
not support      deep neural networks     The treatment indicator might be washed out in the old model  if the learned
representation is highdimensional  see discussion below 
We assume there exists   distribution               over
                 such that strong ignorability holds 
We further assume we have   sample from that distribution
                 xn  tn  yn  where yi       xi  if ti    
yi       xi  if ti     This standard assumption means
that the treatment assignment determines which potential
outcome we see  Our goal is to  nd   representation    
      and hypothesis                 that will

Estimating individual treatment effect  generalization bounds and algorithms

minimize  PEHE     for                   
We parameterize     and       by deep neural networks
trained jointly  see Figure   This allows for learning complex nonlinear representations and hypotheses with large
 exibility 
In Johansson et al    we parameterized
      with   single network  concatenating   and   as input  In this case  if   is highdimensional  the in uence of
  on   might be lost during training  To combat this  we parameterize           and           as two
separate  heads  of the joint network  the former used to
estimate the outcome under treatment  and the latter under
control  This way  statistical power is shared in representation layers  while the effect of treatment is preserved in
the separate heads  Note that each sample is used to update
only the head corresponding to the observed treatment 
Our second contribution is to explicitly adjust for the bias
induced by treatment group imbalance  To this end  we
seek   representation   and hypothesis   that minimizes  
tradeoff between predictive accuracy and imbalance in the
representation space  using the following objective 

 
 

 cid  
   wi        xi  ti    yi            
    IPMG  xi   ti xi   ti   
wi   ti
   ti 

      ti
  is   model complexity term 

      where      

 cid  

 

 

min
  cid cid 

with
and

Note that             is simply the proportion of treated
units in the population  The weights wi compensate for the
difference in treatment group size in our sample  see Theorem   IPMG  is the  empirical  integral probability
metric           For most IPMs  we cannot compute the
factor    in   but treat it as part of the hyperparameter
  This makes our objective sensitive to the scaling of  
even for   constant   We therefore normalize   through
either projection or batchnormalization with  xed scale 
We refer to the model minimizing   with       as Counterfactual Regression  CFR  and the variant without balance regularization       as TreatmentAgnostic Representation Network  TARNet  Both models are trained
by minimizing   using stochastic gradient descent  as described in Algorithm   Both the prediction loss and the
penalty term IPMG  are computed for one minibatch
at   time  Details of how to obtain the gradient    with
respect to the empirical IPMs are in the supplement 

  Experiments
Evaluating causal inference algorithms is more dif cult
than many machine learning tasks  since we rarely have access to the ground truth treatment effect  Existing literature
mostly deals with this in two ways  One is by using  semi 

Algorithm   CFR  Counterfactual regression with integral
probability metrics
  Input  Factual sample                    xn  tn  yn 
scaling parameter       loss function     representation network    with initial weights    outcome network hV with initial weights    function
family   for IPM 

 cid  
   ti
      ti

  Compute      
 
  Compute wi   ti
  while not converged do
 
 

    for              

 

 

 cid 
  wij     cid hV   xij   tij   yij
 cid 
  wij     cid hV   xij   tij   yij
 cid 
 cid 

Sample minibatch                im                  
Calculate the gradient of the IPM term 
   xik  tij
      IPMG   xij  tij
Calculate the gradients of the empirical loss 
       
       
Obtain step size scalar or matrix   with standard
neural net methods      Adam  Kingma   Ba   
                                    
Check convergence criterion

 
 
 
 

 

 
 
  end while

synthetic datasets  where the outcome or treatment assignment are fully known  we use the semisynthetic IHDP
dataset from Hill   The other is using realworld
data from randomized controlled trials  RCT  The problem
with using data from RCTs is that there is no imbalance between treatment groups  making our method redundant  We
partially overcome this problem by using the Jobs dataset
from LaLonde   which includes both   randomized
and   nonrandomized component  We use both components for training  but only use the randomized component
for evaluation  This alleviates  but does not solve  the issue
of   completely randomized and balanced dataset being unsuited for our method 
We evaluate our framework CFR  and its variant without balancing regularization  TARNet  in the task of estimating ITE and ATE  Both versions are implemented 
as feedforward neural networks with   fullyconnected
exponentiallinear layers  Clevert et al    for the representation and   for the hypothesis  Layer sizes were   for
all layers used for Jobs and   and   for the representation and hypothesis used for IHDP  The model is trained
using Adam  Kingma   Ba    The hypothesis parameters are regularized with   small  cid  weight decay  For continuous data we use mean squared loss and for binary data 
we use logloss  While our theory does not immediately
apply to logloss  we were curious to see how our model
performs with it  We use the Wasserstein  CFRWASS  and
the squared linear MMD  CFRMMD  distances to penalize

 https github com clinicalml cfrnet

Estimating individual treatment effect  generalization bounds and algorithms

imbalance 
We compare our method to Ordinary Least Squares with
treatment as   feature  OLS  OLS with separate regressors for each treatment  OLS  knearest neighbor
 kNN  Targeted Maximum Likelihood  TMLE  which
is   doubly robust method  Gruber   van der Laan 
  Bayesian Additive Regression Trees  BART   Chipman et al    Chipman   McCulloch    Random Forests     For   Breiman    Causal Forests
    For   Wager   Athey    as well as the Balancing Linear Regression  BLR  and Balancing Neural Network  BNN  from Johansson et al    For classi cation tasks we substitute Logistic Regression  LR  for OLS 
Choosing hyperparameters for estimating PEHE is nontrivial  we detail our general procedure using   validation
set  in subsection    of the supplement 
We consider two different estimation tasks  One is withinsample  where the task is to estimate ITE for all units in
  sample for which the  factual  outcome of one treatment
is observed  This corresponds to the common scenario in
which   cohort is selected once and not changed  This task
is nontrivial  as we never observe the ITE for any unit  The
other is outof sample  where the goal is to estimate ITE for
units with no observed outcomes  This corresponds to the
problem of selecting the best treatment for   new patient 
Withinsample error is computed over both the training and
validation sets  outof sample error over the test set 

  Simulated outcome  IHDP

Hill   compiled   dataset for causal effect estimation based on the Infant Health and Development Program
 IHDP  in which the covariates come from   randomized
experiment studying the effects of specialist home visits on
cognitive test scores  The treatment groups have been made
imbalanced by removing   biased subset of the treated population  The dataset comprises   units   treated   
control  and   covariates measuring aspects of children
and their mothers  We use the simulated outcome implemented as setting     in the NPCI package  Dorie   
Following Hill   we use the noiseless outcome to
 cid  
compute the true effect  We report the estimated  nite 
 cid  
sample  PEHE loss  PEHE  Eq 
  and the absolute eri    xi     
ror in average treatment effect  ATE      
    xi      xi  The results of
   xi       
the experiments on IHDP are presented in Table    left 
We average over   realizations of the outcomes with
  train validation test splits 
We also investigate the effects of increasing imbalance between the original treatment groups by constructing biased subsamples of the IHDP dataset    logisticregression
propensity score model is    to form estimates           
of the conditional treatment probability  Then  repeatedly 

 

 

Figure   Outof sample ITE error versus IPM regularization for
CFR Wass  relative to the error at       on   realizations of
IHDP  with high        medium and low  arti cial  imbalance
between control and treated 

Figure   Policy risk on Jobs as   function of treatment inclusion
rate  Lower is better  Subjects are included in treatment in order
of their estimated treatment effect given by the various methods 
CFR Wass is similar to TARNet and is omitted to avoid clutter 

with probability   we remove the remaining control observation   that has            closest to   and with probability        we remove   random control observation  The
higher    the more imbalance  For each value of    we remove   observations from each set  leaving  

  Realworld outcome  Jobs

The study by LaLonde   is   widely used benchmark
in the causal inference community  where the treatment is
job training and the outcomes are income and employment
status after training  This dataset combines   randomized
study based on the National Supported Work program with
observational data to form   larger dataset  Smith   Todd 
  The presence of the randomized subgroup gives  
way to estimate the  ground truth  causal effect  The study
includes   covariates such as age and education  as well
as previous earnings  We construct   binary classi cation
task  called Jobs  where the goal is to predict unemployment  using the feature set of Dehejia   Wahba  
Following Smith   Todd   we use the LaLonde experimental sample   treated    control  and the PSID
comparison group   control  There were    
subjects unemployed by the end of the study  We average

 Imbalancepenalty PEHErelativeto       Treatmentinclusionrate OutofsamplepolicyriskBARTCausalForestsCFRMMDTARNetRandompolicyEstimating individual treatment effect  generalization bounds and algorithms

Table   Results on IHDP and Jobs withinsample  left  and outof sample  right  Lower is better   Not applicable 

Withinsample
 
 PEHE
     
     
     
     
     
     
     
     
     
     
     
     

OLS LR 
OLS LR 
BLR
kNN
TMLE
BART
  FOR 
  FOR 
BNN
TARNET
CFRMMD
CFRWASS

IHDP

 ATE

     
     
     
     
     
     
     
     
     
     
     
     

JOBS

RPOL

     
     
     
     
     
     
     
     
     
     
     
     

 ATT

     
     
     
     
     
     
     
     
     
     
     
     

Outof sample
 
 PEHE
     
     
     
     
     
     
     
     
     
     
     

OLS LR 
OLS LR 
BLR
kNN
TMLE
BART
  FOR 
  FOR 
BNN
TARNET
CFRMMD
CFRWASS

 

IHDP

 ATE

 

     
     
     
     
     
     
     
     
     
     
     

JOBS

RPOL

 

     
     
     
     
     
     
     
     
     
     
     

 ATT

 

     
     
     
     
     
     
     
     
     
     
     

treatment effect on the treated by ATT      cid 
       cid 

over   train validation test splits with ratios  
Because all the treated subjects   were part of the original
randomized sample    we can compute the true average
    yi  
 cid 
      yi  where   is the control group  We
        xi     
report the error  ATT    ATT      
   xi    We cannot evaluate  PEHE on this dataset  since
there is no ground truth for the ITE  Instead  in order
to evaluate the quality of ITE estimation  we use   measure we call policy risk  The policy risk is de ned as
the average loss in value when treating according to the
policy implied by an ITE estimator 
In our case  for  
model    we let the policy be to treat             if
                      and to not treat             otherwise  The policy risk is RPol                       
                                      which
we can estimate for the randomized trial subset of Jobs
by  RPol                                     
                                  See  gure  
for risk as   function of treatment threshold   aligned by
proportion of treated  and Table   for the risk when      

  Results

We note that indeed imbalance confers an advantage to using the IPM regularization term  as our theoretical results
indicate  see     
the results for CFRWASS and TARNet
on IHDP in Table   We also see in Figure   that even
for the harder case of increased imbalance        between treated and control  the relative gain from using our
method remains signi cant  On Jobs  our proposed methods are better than or competitive with stateof theart  but
we don   see   signi cant gain from using IPM penalties 
This might be because we evaluate the predictions only on  
randomized subset with treatment groups distributed identically  Nonlinear estimators perform signi cantly better
than linear ones in terms of individual effect  PEHE  On
the Jobs dataset  straightforward logistic regression does

remarkably well in estimating the ATT  However  being  
linear model  LR can only ascribe   uniform policy   in
this case   treat everyone  The more nuanced policies
offered by nonlinear methods achieve lower policy risk
in the case of Causal Forests and CFR  This emphasizes
the fact that estimating average effect and individual effect
can require different models  Speci cally  while smoothing
over many units may yield   good ATE estimate  this might
signi cantly hurt ITE estimation  knearest neighbors has
very good withinsample results on Jobs  because evaluation is performed over the randomized component  but suffers heavily in generalizing out of sample  as expected 

  Conclusion
In this paper we give   meaningful and intuitive errorbound for estimating individual treatment effect  Our
bound relates ITE estimation to the classic machine learning problem of learning from samples  along with methods
for measuring distributional distances from samples  The
bound lends itself naturally to the creation of learning algorithms  we focus on using neural nets as representations
and hypotheses  We apply our theoryguided approach to
both synthetic and realworld tasks  showing that in every
case our method matches or outperforms the stateof theart  Important open questions are theoretical considerations
in choosing the IPM weight   how to best derive con 
dence intervals for our model   predictions  and integrating our work with more complicated causal models such as
those with hidden confounding or instrumental variables 

ACKNOWLEDGMENTS

We thank Aahlad Puli for his assistance with the experiments  Sanjog Misra and   unter    Hitsch for suggesting
the policy risk evaluation  Jennifer Hill  Marco Cuturi and
Esteban Tabak for fruitful conversations  and Stefan Wager
for his help with the code for Causal Forests  DS and US
were supported by NSF CAREER award  

Estimating individual treatment effect  generalization bounds and algorithms

References
Athey  Susan and Imbens  Guido  Recursive partitioning for
heterogeneous causal effects  Proceedings of the National
Academy of Sciences     

Athey  Susan  Imbens  Guido    and Wager  Stefan 

Ef 
cient inference of average treatment effects in high dimenarXiv preprint
sions via approximate residual balancing 
arXiv   

Austin  Peter    An introduction to propensity score methods for
reducing the effects of confounding in observational studies 
Multivariate behavioral research     

Bareinboim  Elias and Pearl  Judea  Causal inference and the
datafusion problem  Proceedings of the National Academy
of Sciences     

Beck  Nathaniel  King  Gary  and Zeng  Langche 

Improving
quantitative studies of international con ict    conjecture 
American Political Science Review     

Belloni  Alexandre  Chernozhukov  Victor  and Hansen  Christian  Inference on treatment effects after selection among highdimensional controls  The Review of Economic Studies   
   

BenDavid  Shai  Blitzer  John  Crammer  Koby  Pereira  Fernando  et al  Analysis of representations for domain adaptation  Advances in neural information processing systems   
   

BenDavid  Shai  Blitzer  John  Crammer  Koby  Kulesza  Alex 
Pereira  Fernando  and Vaughan  Jennifer Wortman    theory
of learning from different domains  Machine learning   
   

Bengio  Yoshua  Courville  Aaron  and Vincent  Pierre  Representation learning    review and new perspectives  Pattern
Analysis and Machine Intelligence  IEEE Transactions on   
   

Breiman  Leo  Random forests  Machine learning   

 

Chernozhukov  Victor  Chetverikov  Denis  Demirer  Mert  Du 
    Esther  Hansen  Christian  et al  Double machine learnarXiv preprint
ing for treatment and causal parameters 
arXiv   

Chipman  Hugh and McCulloch  Robert  BayesTree  Bayesian
Additive Regression Trees  https cran rproject 
org web packages BayesTree   

Chipman  Hugh    George  Edward    and McCulloch  Robert   
BART  Bayesian additive regression trees  The Annals of Applied Statistics  pp     

Clevert  DjorkArn    Unterthiner  Thomas  and Hochreiter  Sepp 
Fast and accurate deep network learning by exponential linear
units  elus  International Conference on Learning Representations   

immunode ciency syndrome or death using marginal structural models  American Journal of Epidemiology   
   

Cortes  Corinna and Mohri  Mehryar  Domain adaptation and
sample bias correction theory and algorithm for regression 
Theoretical Computer Science     

Cuturi  Marco and Doucet  Arnaud  Fast computation of WasserIn Proceedings of The  st International

stein barycenters 
Conference on Machine Learning  pp     

Daum   III  Hal  Frustratingly easy domain adaptation  Conference of the Association for Computational Linguistics  ACL 
 

Dehejia  Rajeev   and Wahba  Sadek  Propensity scorematching
methods for nonexperimental causal studies  Review of Economics and statistics     

Dorie  Vincent  NPCI  Nonparametrics for Causal Inference 

https github com vdorie npci   

Funk  Michele Jonsson  Westreich  Daniel  Wiesen  Chris 
St urmer  Til  Brookhart    Alan  and Davidian  Marie  Doubly robust estimation of causal effects  American journal of
epidemiology     

Ganin  Yaroslav  Ustinova  Evgeniya  Ajakan  Hana  Germain 
Pascal  Larochelle  Hugo  Laviolette  Franc ois  Marchand 
Mario  and Lempitsky  Victor  Domainadversarial training
of neural networks  Journal of Machine Learning Research 
    URL http jmlr org papers 
  html 

Gretton  Arthur  Smola  Alex  Huang  Jiayuan  Schmittfull  Marcel  Borgwardt  Karsten  and Sch olkopf  Bernhard  Covariate
shift by kernel mean matching  Dataset shift in machine learning     

Gretton  Arthur  Borgwardt  Karsten    Rasch  Malte   
Sch olkopf  Bernhard  and Smola  Alexander    kernel twosample test     Mach  Learn  Res    March  
ISSN  

Gruber  Susan and van der Laan  Mark    tmle  An   package for

targeted maximum likelihood estimation   

Hartford  Jason  Lewis  Greg  LeytonBrown  Kevin  and Taddy 
Matt  Counterfactual prediction with deep instrumental variables networks  arXiv preprint arXiv   

Hill  Jennifer    Bayesian nonparametric modeling for causal inference  Journal of Computational and Graphical Statistics 
   

Hoyer  Patrik    Janzing  Dominik  Mooij  Joris    Peters  Jonas 
and Sch olkopf  Bernhard  Nonlinear causal discovery with additive noise models  In Advances in neural information processing systems  pp     

Imbens  Guido   and Wooldridge  Jeffrey    Recent developments in the econometrics of program evaluation  Journal of
economic literature     

Cole  Stephen    Hern an  Miguel    Robins  James    Anastos 
Kathryn  Chmiel  Joan  Detels  Roger  Ervin  Carolyn  Feldman  Joseph  Greenblatt  Ruth  Kingsley  Lawrence  et al  Effect of highly active antiretroviral therapy on time to acquired

Johansson  Fredrik    Shalit  Uri  and Sontag  David  Learning representations for counterfactual inference  In Proceedings of the  rd International Conference on Machine Learning  ICML   

Estimating individual treatment effect  generalization bounds and algorithms

Kingma  Diederik and Ba  Jimmy  Adam    method for stochastic optimization  International Conference on Learning Representations   

Strehl  Alex  Langford  John  Li  Lihong  and Kakade  Sham   
Learning from logged implicit exploration data  In Advances in
Neural Information Processing Systems  pp     

LaLonde  Robert    Evaluating the econometric evaluations of
training programs with experimental data  The American economic review  pp     

Sun  Baochen  Feng  Jiashi  and Saenko  Kate  Return of frustratingly easy domain adaptation  In Thirtieth AAAI Conference
on Arti cial Intelligence   

Swaminathan  Adith and Joachims  Thorsten  Batch learning
from logged bandit feedback through counterfactual risk minimization  Journal of Machine Learning Research   
   

Taddy  Matt  Gardner  Matt  Chen  Liyun  and Draper  David   
nonparametric bayesian analysis of heterogenous treatment effects in digital experimentation  Journal of Business   Economic Statistics     

Trianta llou  So   and Tsamardinos  Ioannis  Constraintbased
causal discovery from multiple interventions over overlapping
Journal of Machine Learning Research   
variable sets 
   

Villani    edric  Optimal transport  old and new  volume  

Springer Science   Business Media   

Wager  Stefan and Athey  Susan 

Estimation and inference of heterogeneous treatment effects using random
arXiv preprint arXiv  https 
forests 
github com susanathey causalTree   

Maathuis  Marloes    Colombo  Diego  Kalisch  Markus  and
  uhlmann  Peter  Predicting causal effects in largescale systems from observational data  Nature Methods   
 

Mansour  Yishay  Mohri  Mehryar  and Rostamizadeh  Afshin 
Domain adaptation  Learning bounds and algorithms   

Mooij  Joris    Peters  Jonas  Janzing  Dominik  Zscheischler 
Jakob  and Sch olkopf  Bernhard  Distinguishing cause from effect using observational data  methods and benchmarks  Journal of Machine Learning Research     

  uller  Alfred  Integral probability metrics and their generating
classes of functions  Advances in Applied Probability  pp   
   

Pan  Sinno Jialin  Tsang  Ivor    Kwok  James    and Yang 
Qiang  Domain adaptation via transfer component analysis 
Neural Networks  IEEE Transactions on     

Pearl  Judea  Causality  Cambridge university press   

Pearl  Judea  Detecting latent heterogeneity  Sociological Meth 

ods   Research  pp     

Peysakhovich  Alexander and Lada  Akos  Combining observational and experimental data to  nd heterogeneous treatment
effects  arXiv preprint arXiv   

Robins  James    new approach to causal inference in mortality
studies with   sustained exposure periodapplication to control
of the healthy worker survivor effect  Mathematical Modelling 
   

Rolling  Craig Anthony  Estimation of Conditional Average Treat 

ment Effects  PhD thesis  University of Minnesota   

Rubin  Donald    Causal inference using potential outcomes 

Journal of the American Statistical Association   

ShalevShwartz  Shai and BenDavid  Shai  Understanding machine learning  From theory to algorithms  Cambridge University Press   

Shpitser  Ilya and Pearl  Judea  Identi cation of conditional interventional distributions  In Proceedings of the Twentysecond
Conference on Uncertainty in Arti cial Intelligence  pp   
  UAI Press   

Smith  Jeffrey   and Todd  Petra    Does matching overcome
LaLonde   critique of nonexperimental estimators  Journal of
econometrics     

Sriperumbudur  Bharath    Fukumizu  Kenji  Gretton  Arthur 
Sch olkopf  Bernhard  Lanckriet  Gert RG  et al  On the empirical estimation of integral probability metrics  Electronic
Journal of Statistics     

