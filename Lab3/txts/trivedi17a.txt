KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

Rakshit Trivedi   Hanjun Dai   Yichen Wang   Le Song  

Abstract

The availability of large scale event data with time
stamps has given rise to dynamically evolving
knowledge graphs that contain temporal information for each edge  Reasoning over time in such
dynamic knowledge graphs is not yet well understood  To this end  we present KnowEvolve   
novel deep evolutionary knowledge network that
learns nonlinearly evolving entity representations
over time  The occurrence of   fact  edge  is modeled as   multivariate point process whose intensity function is modulated by the score for that
fact computed based on the learned entity embeddings  We demonstrate signi cantly improved
performance over various relational learning approaches on two large scale realworld datasets 
Further  our method effectively predicts occurrence or recurrence time of   fact which is novel
compared to prior reasoning approaches in multirelational setting 

  Introduction
Reasoning is   key concept in arti cial intelligence    host
of applications such as search engines  questionanswering
systems  conversational dialogue systems  and social networks require reasoning over underlying structured knowledge  Effective representation and learning over such knowledge has come to the fore as   very important task  In particular  Knowledge Graphs have gained much attention as
an important model for studying complex multirelational
settings  Traditionally  knowledge graphs are considered
to be static snapshot of multirelational data  However 
recent availability of large amount of event based interaction data that exhibits complex temporal dynamics in addition to its multirelational nature has created the need for
approaches that can characterize and reason over tempo 

 College of Computing  Georgia Institute of Technology  Correspondence to  Rakshit Trivedi  rstrivedi gatech edu  Le Song
 lsong cc gatech edu 

Proceedings of the   th International Conference on Machine
Learning  Sydney  Australia  PMLR     Copyright   by
the author   

Figure   Sample temporal knowledge subgraph between persons 
organizations and countries 

rally evolving systems  For instance  GDELT  Leetaru  
Schrodt    and ICEWS  Boschee et al    are two
popular event based data repository that contains evolving
knowledge about entity interactions across the globe 
Thus traditional knowledge graphs need to be augmented
into Temporal Knowledge Graphs  where facts occur  recur or evolve over time in these graphs  and each edge
in the graphs have temporal information associated with
it  Figure   shows   subgraph snapshot of such temporal
knowledge graph  Static knowledge graphs suffer from
incompleteness resulting in their limited reasoning ability 
Most work on static graphs have therefore focussed on advancing entityrelationship representation learning to infer
missing facts based on available knowledge  But these methods lack ability to use rich temporal dynamics available in
underlying data represented by temporal knowledge graphs 
Effectively capturing temporal dependencies across facts
in addition to the relational  structural  dependencies can
help improve the understanding on behavior of entities and
how they contribute to generation of facts over time  For
example  one can precisely answer questions like 
  Object prediction   Who  will Donald Trump mention

next 

  Subject

prediction 

 Which

country  will

provide material support to US next month 

  Time prediction   When  will Bob visit Burger King 

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

 People  entities  change over time and so do relationships 
When two entities forge   relationship  the newly formed
edge drives their preferences and behavior  This change
is effected by combination of their own historical factors
 temporal evolution  and their compatibility with the historical factors of the other entity  mutual evolution 
For instance  if two countries have tense relationships  they
are more likely to engage in con icts  On the other hand 
two countries forging an alliance are most likely to take
confrontational stands against enemies of each other  Finally  time plays   vital role in this process    country that
was once peaceful may not have same characteristics  
years in future due to various facts  events  that may occur
during that period  Being able to capture this temporal and
evolutionary effects can help us reason better about future relationship of an entity  We term this combined phenomenon
of evolving entities and their dynamically changing relationships over time as  knowledge evolution 
In this paper  we propose an elegant framework to model
knowledge evolution and reason over complex nonlinear interactions between entities in   multirelational setting  The
key idea of our work is to model the occurrence of   fact as
multidimensional temporal point process whose conditional
intensity function is modulated by the relationship score
for that fact  The relationship score further depends on the
dynamically evolving entity embeddings  Speci cally  our
work makes the following contributions 
  We propose   novel deep learning architecture that
evolves over time based on availability of new facts  The
dynamically evolving network will ingest the incoming
new facts  learn from them and update the embeddings of
involved entities based on their recent relationships and
temporal behavior 
  Besides predicting the occurrence of   fact  our architecture has ability to predict time when the fact may potentially occur which is not possible by any prior relational
learning approaches to the best of our knowledge 
  Our model supports Open World Assumption as missing
links are not considered to be false and may potentially
occur in future  It further supports prediction over unseen
entities due to its novel dynamic embedding process 
  The largescale experiments on two real world datasets
show that our framework has consistently and signi 
cantly better performance for link prediction than stateof arts that do not account for temporal and evolving
nonlinear dynamics 
  Our work aims to introduce the use of powerful mathematical tool of temporal point process framework for
temporal reasoning over dynamically evolving knowledge
graphs  It has potential to open   new research direction in
reasoning over time for various multirelational settings
with underlying spatiotemporal dynamics 

  Preliminaries
  Temporal Point Process

  temporal point process  Cox   Lewis    is   random process whose realization consists of   list of events
localized in time   ti  with ti      Equivalently    given
temporal point process can be represented as   counting
process        which records the number of events before
time   
An important way to characterize temporal point processes
is via the conditional intensity function       stochastic
model for the time of the next event given all the previous
events  Formally     dt is the conditional probability of
observing an event in   small window         dt  given the
history          tk tk      up to        

   dt     event in         dt      

 

    dN         

tn

where one typically assumes that only one event can happen
in   small window of size dt       dN          
From the survival analysis theory  Aalen et al    given
the history                 tn  for any     tn  we characterize the conditional probability that no event happens during

 tn     as           exp cid   cid   

      cid  Moreover  the

                

conditional density that an event occurs at time   is de ned
as  
 
The functional form of the intensity     is often designed
to capture the phenomena of interests  Some Common
forms include  Poisson Process  Hawkes processes  Hawkes 
  SelfCorrecting Process  Isham   Westcott   
Power Law and Rayleigh Process 
Rayleigh Process is   nonmonotonic process and is welladapted to modeling fads  where event likelihood drops
rapidly after rising to   peak  Its intensity function is      
        where       is the weight parameter  and the log
survival function is log               
  Temporal Knowledge Graph representation

We de ne   Temporal Knowledge Graph  TKG  as   multirelational directed graph with timestamped edges between
any pair of nodes  In   TKG  each edge between two nodes
represent an event in the real world and edge type  relationship  represent the corresponding event type  Further an
edge may be available multiple times  recurrence  We do
not allow duplicate edges and selfloops in graph  Hence 
all recurrent edges will have different time points and every
edge will have distinct subject and object entities 
Given ne entities and nr relationships  we extend traditional
triplet representation for knowledge graphs to introduce
time dimension and represent each fact in TKG as   quadruplet  es     eo     where es  eo             ne  es  cid  eo 

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

              nr         It represents the creation of
relationship edge   between subject entity es  and object
entity eo at time    The complete TKG can therefore be
represented as an ne   ne   nr       dimensional tensor where   is the total number of available time points 
Consider   TKG comprising of   edges and denote the
globally ordered set of corresponding   observed events as
     es     eo       
   where                        
  Evolutionary Knowledge Network
We present our uni ed knowledge evolution framework
 KnowEvolve  for reasoning over temporal knowledge
graphs  The reasoning power of KnowEvolve stems from
the following three major components 

    powerful mathematical tool of temporal point pro 

cess that models occurrence of   fact 

    bilinear relationship score that captures multirelational interactions between entities and modulates
the intensity function of above point process 

    novel deep recurrent network that learns nonlinearly
and mutually evolving latent representations of entities
based on their interactions with other entities in multirelational space over time 

  Temporal Process

Large scale temporal knowledge graphs exhibit highly heterogeneous temporal patterns of events between entities 
Discrete epoch based methods to model such temporal behavior fail to capture the underlying intricate temporal dependencies  We therefore model time as   random variable
and use temporal point process to model occurrence of fact 
More concretely  given   set of observed events   corresponding to   TKG  we construct   relationshipmodulated
multidimensional point process to model occurrence of these
events  We characterize this point process with the following
conditional intensity function 

 es eo
 

           ges eo

 

              

 

 

where           is the time of the current event and     
max tes  teo  is the most recent time point when either
subject or object entity was involved in an event before time
      represents intensity of event involving
   Thus   es eo
triplet  es     ej  at time   given previous time point    when
either es or eo was involved in an event  This modulates the
intensity of current event based on most recent activity on
either entities  timeline and allows to capture scenarios like
nonperiodic events and previously unseen events       
exp  ensures that intensity is positive and well de ned 
  Relational Score Function
The  rst term in   modulates the intensity function by
the relational compatibility score between the involved enti 

ties in that speci   relationship  Speci cally  for an event
 es     eo         occurring at time    the score term ges eo
is computed using   bilinear formulation as follows 

 

ges eo
 

       Rr   veo

   

      ves

 
where ves  ves   Rd represent latent feature embeddings of
entities appearing in subject and object position respectively 
Rr   Rd   represents relationship weight matrix which
attempts to capture interaction between two entities in the
speci   relationship space    This matrix is unique for each
relation in dataset and is learned during training    is time of
current event and    represent time point just before time
    therefore represent most recently
   ves
updated vector embeddings of subject and object entities
respectively before time    As these entity embeddings
evolve and update over time  ges eo
    is able to capture
cumulative knowledge learned about the entities over the
history of events that have affected their embeddings 
  Dynamically Evolving Entity Representations

    and veo

 

We represent latent feature embedding of an entity   at time
  with   lowdimensional vector ve    We add superscript
  and   as shown in Eq    to indicate if the embedding
corresponds to entity in subject or object position respectively  We also use relationshipspeci   lowdimensional
representation for each relation type 
The latent representations of entities change over time as
entities forge relationships with each other  We design novel
deep recurrent neural network based update functions to
capture mutually evolving and nonlinear dynamics of entities in their vector space representations  We consider an
event      es     eo          occurring at time    Also 
consider that event   is entity es   pth event while it is
entity eo   qth event  As entities participate in events in  
heterogeneous pattern  it is less likely that       although
not impossible  Having observed this event  we update the
embeddings of two involved entities as follows 
Subject Embedding 

ves
 tp     Ws
 tp     Wh    ves

hes

 tp    veo

  tp   tp    Whh   hes

 tp 
 tp    res

  

 

Object Embedding 

veo
 tq     Wo
 tq     Wh    veo

heo

 tq    ves

   tq   tq    Whh   heo

 tq 
 tq    reo

  

 
where  ves  veo   Rd  tp   tq   tm is the time of observed
event  For subject embedding update in Eq    tp  is the
time point of the previous event in which entity es was

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

Figure   Realization of Evolutionary Knowledge Network Architecture over   timeline  Here   cid cid    cid  and   may or may not be consecutive
time points  We focus on the event at time point   and show how previous events affected the embeddings of entities involved in this event 
prev represent previous time points in history before   cid    cid cid  hother
From Eq    and   tp      cid  and tq      cid cid  respectively  tes
stands for hidden layer for the entities  other than the ones in focus  involved in events at   cid  and   cid cid  res
prev      All other
notations mean exactly as de ned in text  We only label nodes  edges and embeddings directly relevant to event at time   for clarity 

prev      and reo

prev  teo

    Intensity Computation at time  

    Entity Embedding update after event observed at time  

Figure   One step visualization of KnowEvolve computations done in Figure   after observing an event at time     Best viewed in color 
involved  tp  is the timepoint just before time tp  Hence 
ves
 tp  represents latest embedding for entity es that was
updated after       th event for that entity  veo
 tp 
represents latest embedding for entity eo that was updated
any time just before tp   tm  This accounts for the fact that
entity eo may have been involved in some other event during
the interval between current     and previous        event
     Rc represent relationship embedding
of entity es  res
that corresponds to relationship type of the       th event
of entity es  Note that the relationship vectors are static
 tp    Rd is the hidden
and do not evolve over time  hes
layer  The semantics of notations apply similarly to object
embedding update in Eq   

units like LSTM or GRU in straightforward manner  In
our experiments  we choose       and    cid    but they
can be chosen differently  Below we explain the rationales
of our deep recurrent architecture that captures nonlinear
evolutionary dynamics of entities over time 
Reasoning Based on Structural Dependency  The hidden
layer  hes  reasons for an event by capturing the compatibility of most recent subject embedding with most recent
object embedding in previous relationship of subject entity 
This accounts for the behavior that within   short period of
time  entities tend to form relationships with other entities
that have similar recent actions and goals  This layer thereby
uses historical information of the two nodes involved in current event and the edges they both created before this event 
This holds symmetrically for hidden layer  heo 
Reasoning based on Temporal Dependency  The recurrent layer uses hidden layer information to model the intertwined evolution of entity embeddings over time  Speci 
cally this layer has two main components 
  Drift over time  The  rst term captures the temporal difference between consecutive events on respective dimension of each entity  This captures the external in uences

    Rd  Whh   Rd   and Wh   Rl     
Ws
are weight parameters in network learned during training 
  captures variation in temporal drift for subject and
Ws
object respectively  Whh is shared parameter that captures
recurrent participation effect for each entity  Wh is   shared
projection matrix applied to consider the compatibility of
entities in their previous relationships    represent simple
concatenation operator    denotes nonlinear activation
function  tanh in our case  Our formulations use simple
RNN units but it can be replaced with more expressive

   Wo

   Wo

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

that entities may have experienced between events and
allows to smoothly drift their features over time  This
term will not contribute anything in case when multiple
events happen for an entity at same time point       within
  day in our dataset  While tp   tp  may exhibit high
variation  the corresponding weight parameter will capture these variations and along with the second recurrent
term  it will prevent ves

 tp  to collapse 

  Relationspeci   Mutual Evolution  The latent features of both subject and object entities in uence each
other  In multirelational setting  this is further affected
by the relationship they form  Recurrent update to entity
embedding with the information from the hidden layer
allows to capture the intricate nonlinear and evolutionary
dynamics of an entity with respect to itself and the other
entity in   speci   relationship space 

  Understanding Uni ed View of KnowEvolve

Figure   and Figure   shows the architecture of knowledge evolution framework and one step of our model 
The updates to the entity representations in Eq    and  
are driven by the events involving those entities which
makes the embeddings piecewise constant      an entity
embedding remains unchanged in the duration between two
events involving that entity and updates only when an event
happens on its dimension  This is justi able as an entity  
features may update only when it forges   relationship with
other entity within the graph  Note that the  rst term in
Eq    and   already accounts for any external in uences 
Having observed an event at time    KnowEvolve considers it as an incoming fact that brings new knowledge about
the entities involved in that event  It computes the intensity of that event in Eq    which is based on relational
compatibility score in Eq    between most recent latent
embeddings of involved entities  As these embeddings are
piecewise constant  we use time interval term          in Eq 
  to make the overall intensity piecewise linear which is
standard mathematical choice for ef cient computation in
point process framework  This formulation naturally leads
to Rayleigh distribution which models time interval between
current event and most recent event on either entities  dimension  Rayleigh distribution has an added bene   of having  
simple analytic form of likelihood which can be further used
to  nd entity for which the likelihood reaches maximum
value and thereby make precise entity predictions 
  Ef cient Training Procedure
The complete parameter space for the above model is 
     Ve   ne  Rr   nr   We  Ws
    Wh 
Whh  Wr  Although KnowEvolve gains expressive
power from deep architecture  Table    Appendix    shows
that the memory footprint of our model is comparable to

   Wo

simpler relational models  The intensity function in   allows to use maximum likelihood estimation over all the facts
as our objective function  Concretely  given   collection of
facts recorded in   temporal window       we learn the
model by minimizing the joint negative log likelihood of
intensity function  Daley   VereJones    written as 

 cid 
 cid 

log

 tp   tp 

  

        cid 
 cid 
nr cid 
ne cid 
 cid 

  

 

 es eo
 

 cid 
 cid cid 
 cid   
ne cid 
 cid cid 

 

es 

eo 

happened events

 

 es eo
 

      

 cid 

survival term

The  rst term maximizes the probability of speci   type
of event between two entities  the second term penalizes
nonpresence of all possible types of events between all
possible entity pairs in   given observation window  We use
Back Propagation Through Time  BPTT  algorithm to train
our model  Previous techniques  Du et al    Hidasi
et al    that use BPTT algorithm decompose data into
independent sequences and train on minibatches of those
sequences  But there exists intricate relational and temporal dependencies between data points in our setting which
limits our ability to ef ciently train by decomposing events
into independent sequences  To address this challenge  we
design an ef cient Global BPTT algorithm  Algorithm  
Appendix    that creates minibatches of events over global
timeline in sliding window fashion and allows to capture
dependencies across batches while retaining ef ciency 
Intractable Survival Term  To compute the second survival term in   since our intensity function is modulated
by relationspeci   parameter  for each relationship we need
to compute survival probability over all pairs of entities 
Next  given   relation   and entity pair  es  eo  we denote
  es eo  as total number of events of type   involving either
es or eo in window         As our intensity function is
piecewiselinear  we can decompose the integration term
      into multiple time intervals where in 

tensity is constant 
     

  

 es eo
 

 cid   
 cid   
  es eo  cid 
  es eo  cid 

 es eo
 

  

 

  

 

 cid  tp 

tp

 es eo
 

     

       
   

     exp ves

 tp     Rr   veo

 tp 

  

 
The integral calculations in   for all possible triplets requires        computations    is number of entities and   is
the number of relations  This is computationally intractable

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

Algorithm   Survival Loss Computation in minibatch

Input  Minibatch    size    Batch Entity List bl
loss    
for       to       do
subj feat   Ep   ves
obj feat   Ep   veo
rel weight   Ep   Rr
  end   Ep    
subj surv     obj surv     total surv    
for       to bl size do

   
   

obj other   bl   
if obj other   Ep   es then

continue

end if
     max tes  teo 
subj surv      end          exp subj   eatT  
rel weight   obj other   eat 

end for
for       to bl size do

subj other   bl   
if subj other   Ep   eo then

continue

end if
     max tes  teo 
   end       
 
obj surv
exp subj other   eatT   rel weight   obj   eat 

 

end for
loss   subj surv   obj surv

end for

and also unnecessary  Knowledge tensors are inherently
sparse and hence it is plausible to approximate the survival
loss in   stochastic setting  We take inspiration from techniques like noise contrastive  Gutmann   Hyv arinen   
estimation and adopt   random sampling strategy to compute survival loss  Given   minibatch of events  for each
relation in the minibatch  we compute dyadic survival term
across all entities in that batch  Algorithm   presents the
survival loss computation procedure  While this procedure
may randomly avoid penalizing some dimensions in   relationship  it still includes all dimensions that had events on
them  The computational complexity for this procedure will
be     cid   cid    where   is size of minibatch and   cid  and   cid 
represent number of entities and relations in the minibatch 
  Experiments
  Temporal Knowledge Graph Data

We use two datasets  Global Database of Events  Language 
and Tone  GDELT   Leetaru   Schrodt    and Integrated Crisis Early Warning System  ICEWS   Boschee
et al    which has recently gained attention in learning
community  Schein et al    as useful temporal KGs 
GDELT data is collected from April     to Mar  

   temporal granularity of   mins  ICEWS dataset is
collected from Jan     to Dec      temporal granularity of   hrs  Both datasets contain records of events
that include two actors  action type and timestamp of event 
We use different hierarchy of actions in two datasets    top
level   relations for GDELT while last level   relations
for ICEWS    to test on variety of knowledge tensor con gurations  Note that this does not  lter any record from the
dataset  We process both datasets to remove any duplicate
quadruples  any monoactor events       we use only dyadic
events  and selfloops  We report our main results on full
versions of each dataset  We create smaller version of both
datasets for exploration purposes  Table    Appendix   
provide statistics about the data and Table    Appendix   
demonstrates the sparsity of knowledge tensor 
  Competitors

We compare the performance of our method with following
relational learning methods  RESCAL  Neural Tensor Network  NTN  Multiway Neural Network  ERMLP  TransE
and TransR  To the best of our knowledge  there are no existing relational learning approaches that can predict time for  
new fact  Hence we devised two baseline methods for evaluating time prediction performance       Multidimensional
Hawkes process  MHP  We model dyadic entity interactions as multidimensional Hawkes process similar to  Du
et al    Here  an entity pair constitutes   dimension
and for each pair we collect sequence of events on its dimension and train and test on that sequence  Relationship is not
modeled in this setup   ii  Recurrent Temporal Point Process  RTPP  We implement   simpli ed version of RMTPP
 Du et al    where we do not predict the marker  For
training  we concatenate static entity and relationship embeddings and augment the resulting vector with temporal
feature  This augmented unit is used as input to global RNN
which produces output vector ht  During test time  for  
given triplet  we use this vector ht to compute conditional
intensity of the event given history which is further used to
predict next event time  Appendix   provides implementation details of our method and competitors 
  Evaluation Protocol

We report experimental results on two tasks  Link prediction
and Time prediction 
Link prediction  Given   test quadruplet  es     eo     we
replace eo with all the entities in the dataset and compute the
conditional density des eo
    for the resulting quadruplets including the ground truth  We then sort
all the quadruplets in the descending order of this density to
rank the correct entity for object position  We also conduct
testing after applying the  ltering techniques described in
 Bordes et al      we only rank against the entities that
do not generate   true triplet  seen in train  when it replaces

   Ses eo

 

   es eo

 

 

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

    ICEWSraw

    ICEWS ltered

    GDELTraw

    GDELT ltered

Figure   Mean Average Rank  MAR  for Entity Prediction on both datasets 

    ICEWSraw

    ICEWS ltered

    GDELTraw

    GDELT ltered

Figure   Standard Deviation  STD  in MAR for Entity Prediction on both datasets 

    ICEWSraw

    ICEWS ltered

    GDELTraw

    GDELT ltered

Figure   HITS  for Entity Prediction on both datasets 

  exp ges  eo

 

   

 

 

 

 cid 

  where ges eo

ground truth object  We report Mean Absolute Rank  MAR 
Standard Deviation for MAR and HITS   correct entity
in top   predictions  for both Raw and Filtered Versions 
Time prediction  Give   test triplet  es     eo  we predict the expected value of next time the fact  es     eo 
can occur  This expectation is de ned by  Ees eo
     
    is computed using equation   We report Mean Absolute Error  MAE  between
the predicted time and true time in hours 
Sliding Window Evaluation  As our work concentrates
on temporal knowledge graphs  it is more interesting to
see the performance of methods over time span of test set
as compared to single rank value  This evaluation method
can help to realize the effect of modeling temporal and
evolutionary knowledge  We therefore partition our test set
in   different slides and report results in each window  For
both datasets  each slide included   weeks of time 
  Quantitative Analysis
Link Prediction Results  Figure       demonstrate
link prediction performance comparison on both datasets 
KnowEvolve signi cantly and consistently outperforms all
competitors in terms of prediction rank without any dete 

rioration over time  Neural Tensor Network   second best
performance compared to other baselines demonstrate its
rich expressive power but it fails to capture the evolving dynamics of intricate dependencies over time  This is further
substantiated by its decreasing performance as we move test
window further in time 
The second row represents deviation error for MAR across
samples in   given test window  Our method achieves significantly low deviation error compared to competitors making
it most stable  Finally  high performance on HITS  metric demonstrates extensive discriminative ability of KnowEvolve  For instance  GDELT has only   relations but
   events where many entities interact with each other in
multiple relationships  In this complex setting  other methods depend only on static entity embeddings to perform
prediction unlike our method which does effectively infers
new knowledge using powerful evolutionary network and
provides accurate prediction results 
Time Prediction Results  Figure   demonstrates that
KnowEvolve performs signi cantly better than other point
process based methods for predicting time  MHP uses   speci   parametric form of the intensity function which limits
its expressiveness  Further  each entity pair interaction is
modeled as an independent dimension and does not take

 WeekMARERMLPKnow EvolveNTNRESCALTransETransR WeekMARERMLPKnow EvolveNTNRESCALTransETransR WeekMARERMLPKnow EvolveNTNRESCALTransETransR WeekMARERMLPKnow EvolveNTNRESCALTransETransR WeekSTDEVERMLPKnow EvolveNTNRESCALTransETransR WeekSTDEVERMLPKnow EvolveNTNRESCALTransETransR WeekSTDEVERMLPKnow EvolveNTNRESCALTransETransR WeekSTDEVERMLPKnow EvolveNTNRESCALTransETransR WeekHITS ERMLPKnow EvolveNTNRESCALTransETransR WeekHITS ERMLPKnow EvolveNTNRESCALTransETransR WeekHITS ERMLPKnow EvolveNTNRESCALTransETransR WeekHITS ERMLPKnow EvolveNTNRESCALTransETransRKnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

    GDELT 

    ICEWS 

Figure   Time prediction performance  Unit is hours 

into account relational feature which fails to capture the
intricate in uence of different entities on each other  On the
other hand  RTPP uses relational features as part of input 
but it sees all events globally and cannot model the intricate
evolutionary dependencies on past events  We observe that
our method effectively captures such nonlinear relational
and temporal dynamics 
In addition to the superior quantitative performance  we
demonstrate the effectiveness of our method by providing
extensive exploratory analysis in Appendix   
  Related Work
In this section  we discuss relevant works in relational learning and temporal modeling techniques 
  Relational Learning

Among various relational learning techniques  neural embedding models that focus on learning lowdimensional
representations of entities and relations have shown stateof theart performance  These methods compute   score
for the fact based on different operations on these latent
representations  Such models can be mainly categorized
into two variants 
Compositional Models  RESCAL  Nickel et al   
uses   relation speci   weight matrix to explain triplets
via pairwise interactions of latent features  Neural Tensor
Network  NTN   Socher et al    is more expressive
model as it combines   standard NN layer with   bilinear
tensor layer   Dong et al    employs   concatenationprojection method to project entities and relations to lower
dimensional space  Other sophisticated models include
Holographic Embeddings  HoLE   Nickel et al     
that employs circular correlation on entity embeddings and
Neural Association Models  NAM   Liu et al     
deep network used for probabilistic reasoning 
Translation Based Models   Bordes et al    uses two
relationspeci   matrices to project subject and object entities and computes    distance to score   fact between two
entity vectors   Bordes et al    proposed TransE model
that computes score as   distance between relationspeci  
translations of entity embeddings   Wang et al    improved TransE by allowing entities to have distributed representations on relation speci   hyperplane where distance

between them is computed  TransR  Lin et al    extends this model to use separate semantic spaces for entities
and relations and does translation in the relationship space 
 Nickel et al      and  Yang et al    Toutanova  
Chen    contains comprehensive reviews and empirical
comparison of relational learning techniques respectively 
All these methods consider knowledge graphs as static models and lack ability to capture temporally evolving dynamics 
  Temporal Modeling

Temporal point processes have been shown as very effective tool to model various intricate temporal behaviors in
networks  Yang   Zha    Farajtabar et al     
Du et al      Wang et al               
Recently   Wang et al      Dai et al      proposed
novel coevolutionary feature embedding process that captures selfevolution and coevolution dynamics of users and
items interacting in   recommendation system  In relational
setting   Loglisci et al    proposed relational mining approach to discover changes in structure of dynamic network
over time   Loglisci   Malerba    proposes method to
capture temporal autocorrelation in data to improve predictive performance   Sharan   Neville    proposes summarization techniques to model evolving relationaltemporal
domains  Recently   Esteban et al    proposed multiway neural network architecture for modeling event based
relational graph  The authors draw   synergistic relation
between   static knowledge graph and an event set wherein
the knowledge graph provide information about entities participating in events and new events in turn contribute to
enhancement of knowledge graph  They do not capture the
evolving dynamics of entities and model time as discrete
points which limits its capacity to model complex temporal
dynamics   Jiang et al    models dependence of relationship on time to facilitate timeaware link prediction but
do not capture evolving entity dynamics 
  Conclusion
We propose   novel deep evolutionary knowledge network
that ef ciently learns nonlinearly evolving entity representations over time in multirelational setting  Evolutionary
dynamics of both subject and object entities are captured by
deep recurrent architecture that models historical evolution
of entity embeddings in   speci   relationship space  The
occurrence of   fact is then modeled by multivariate point
process that captures temporal dependencies across facts 
The superior performance and high scalability of our method
on large realworld temporal knowledge graphs demonstrate
the importance of supporting temporal reasoning in dynamically evolving relational systems  Our work establishes
previously unexplored connection between relational processes and temporal point processes with   potential to open
  new direction of research on reasoning over time 

 MethodsMAEMethodsKnowEvolveMHPER TPP MethodsMAEMethodsKnowEvolveMHPER TPPKnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

Acknowledgement
This project was supported in part by NSF IIS 
NIH BIGDATA    GM  NSF CAREER IIS 
  NSF IIS  EAGER  ONR   
  NVIDIA  Intel and Amazon AWS 
References
Aalen  Odd  Borgan  Ornulf  and Gjessing  Hakon  Survival and event history analysis    process point of view 
Springer   

Bordes  Antoine  Weston  Jason  Collobert  Ronan  and
Bengio  Yoshua  Learning structured embeddings of
knowledge bases  In Conference on Arti cial Intelligence 
number EPFLCONF   

Bordes  Antoine  Usunier  Nicolas  GarciaDuran  Alberto 
Weston  Jason  and Yakhnenko  Oksana  Translating embeddings for modeling multirelational data  In Advances
in neural information processing systems  pp   
 

Boschee  Elizabeth  Lautenschlager  Jennifer    Brien 
Sean  Shellman  Steve  Starz  James  and Ward  Michael 
Icews coded event data   

Cox       and Lewis         Multivariate point processes 
Selected Statistical Papers of Sir David Cox  Volume  
Design of Investigations  Statistical Methods and Applications     

Dai  Hanjun  Dai  Bo  and Song  Le  Discriminative embeddings of latent variable models for structured data  In
ICML     

Dai  Hanjun  Wang  Yichen  Trivedi  Rakshit  and Song 
Le  Deep coevolutionary network  Embedding user
and item features for recommendation  arXiv preprint
arXiv     

Daley       and VereJones     An introduction to the theory of point processes  volume II  general theory and
structure  volume   Springer   

Dong  Xin  Gabrilovich  Evgeniy  Heitz  Geremy  Horn 
Wilko  Lao  Ni  Murphy  Kevin  Strohmann  Thomas 
Sun  Shaohua  and Zhang  Wei  Knowledge vault   
webscale approach to probabilistic knowledge fusion 
In Proceedings of the  th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining 
pp     

Du  Nan  Wang  Yichen  He  Niao  and Song  Le  Time
sensitive recommendation from recurrent user activities 
In NIPS   

Du  Nan  Dai  Hanjun  Trivedi  Rakshit  Upadhyay  Utkarsh 
GomezRodriguez  Manuel  and Song  Le  Recurrent
marked temporal point processes  Embedding event history to vector  In KDD   

Esteban  Cristobal  Tresp  Volker  Yang  Yinchong  Baier 
Stephan  and Krompa  Denis  Predicting the coevolution
of event and knowledge graphs  In    th International Conference on Information Fusion  FUSION  pp 
   

Farajtabar  Mehrdad  Du  Nan  GomezRodriguez  Manuel 
Valera  Isabel  Zha  Hongyuan  and Song  Le  Shaping
social activity by incentivizing users  In NIPS   

Farajtabar  Mehrdad  Wang  Yichen  GomezRodriguez 
Manuel  Li  Shuang  Zha  Hongyuan  and Song  Le  Coevolve    joint point process model for information diffusion and network coevolution  In NIPS   

Gutmann  Michael   and Hyv arinen  Aapo  Noisecontrastive estimation of unnormalized statistical models 
with applications to natural image statistics  Journal of
Machine Learning Research   Feb   

Hawkes  Alan    Spectra of some selfexciting and mutually
exciting point processes  Biometrika     

Hidasi  Balazs  Karatzoglou  Alexandros  Baltrunas  Linas 
and Tikk  Domonkos  Sessionbased recommendations
with recurrent neural networks  In ICLR   

Isham     and Westcott       selfcorrecting pint process 

Advances in Applied Probability     

Jiang  Tingsong  Liu  Tianyu  Ge  Tao  Lei  Sha  Li  Suijan 
Chang  Baobao  and Sui  Zhifang  Encoding temporal
information for timeaware link prediction   

Leetaru  Kalev and Schrodt  Philip    Gdelt  Global data on
events  location  and tone  ISA Annual Convention   

Lin  Yankai  Liu  Zhiyuan  Sun  Maosong  and Zhu  Xuan 
Learning entity and relation embeddings for knowledge
graph completion   

Liu  Quan  Jiang  Hui  Evdokimov  Andrew  Ling  ZhenHua  Zhu  Xiaodan  Wei  Si  and Hu  Yu  Probabilistic
reasoning via deep learning  Neural association models 
arXiv     

Loglisci  Corrado and Malerba  Donato  Leveraging temporal autocorrelation of historical data for improving accuracy in network regression  Statistical Analysis and Data
Mining  The ASA Data Science Journal   
 

KnowEvolve  Deep Temporal Reasoning for Dynamic Knowledge Graphs

Wang  Zhen  Zhang  Jianwen  Feng  Jianlin  and Chen 
Zheng  Knowledge graph embedding by translating on
hyperplanes   

Yang  Bishan  Yih  Wentau  He  Xiaodong  Gao  Jianfeng 
and Deng  Li  Embedding entities and relations for learning and inference in knowledge bases  arXiv 
 

Yang  ShuangHong and Zha  Hongyuan  Mixture of mutually exciting processes for viral diffusion  In ICML  pp 
   

Loglisci  Corrado  Ceci  Michelangelo  and Malerba  Donato  Relational mining for discovering changes in evolving networks  Neurocomputing    Part   
 

Nickel  Maximilian  Tresp  Volker  and Kriegel  HansPeter    threeway model for collective learning on multirelational data  In Proceedings of the  th International
Conference on Machine Learning  ICML  pp   
   

Nickel  Maximilian  Murphy  Kevin  Tresp  Volker  and
Gabrilovich  Evgeniy    review of relational machine
learning for knowledge graphs  Proceedings of the IEEE 
   

Nickel  Maximilian  Rosasco  Lorenzo  and Poggio  Tomaso 

Holographic embeddings of knowledge graphs     

Schein  Aaron  Zhou  Mingyuan  Blei  David  and Wallach  Hanna  Bayesian poisson tucker decomposition for learning the structure of international relations 
arXiv   

Sharan  Umang and Neville  Jennifer  Temporalrelational
classi ers for prediction in evolving domains  In  
Eighth IEEE International Conference on Data Mining 
pp     

Socher  Richard  Chen  Danqi  Manning  Christopher   
and Ng  Andrew  Reasoning with neural tensor networks
for knowledge base completion  In Advances in Neural
Information Processing Systems  pp     

Toutanova  Kristina and Chen  Danqi  Observed versus
latent features for knowledge base and text inference 
 

Wang  Yichen  Du  Nan  Trivedi  Rakshit  and Song  Le 
Coevolutionary latent feature processes for continuoustime useritem interactions  In NIPS     

Wang  Yichen  Theodorou  Evangelos  Verma  Apurv  and
Song  Le    stochastic differential equation framework
for guiding online user activities in closed loop  arXiv
preprint arXiv     

Wang  Yichen  Xie  Bo  Du  Nan  and Song  Le  Isotonic

hawkes processes  In ICML     

Wang  Yichen  Williams  Grady  Theodorou  Evangelos  and
Song  Le  Variational policy for guiding point processes 
In ICML     

Wang  Yichen  Ye  Xiaojing  Zhou  Haomin  Zha 
Hongyuan  and Song  Le  Linking micro event history
to macro prediction in point process models  In AISTAT 
   

