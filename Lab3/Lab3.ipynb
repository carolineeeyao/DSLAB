{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "Ali Tejani, amt3639\n",
    "\n",
    "Caroline Yao, chy253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Linear Algebra in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace rank is 2\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1, 2, 3, 4])\n",
    "v2 = np.array([0, 1, 0, 1])\n",
    "v3 = np.array([1, 4, 3, 6])\n",
    "v4 = np.array([2, 11, 6, 15])\n",
    "subspace = np.column_stack((v1,v2,v3,v4))\n",
    "print \"Subspace rank is {}\".format(np.linalg.matrix_rank(subspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "[1 1 3 3] is in Span(v1,v2,v3,v4)\n",
      "[1 1 0 0] is not in Span(v1,v2,v3,v4)\n"
     ]
    }
   ],
   "source": [
    "vInS = np.array([1, 1, 3, 3])\n",
    "vNotInS = np.array([1, 1, 0, 0])\n",
    "s1 = np.concatenate((subspace,np.array([vInS]).T), axis=1)\n",
    "s2 = np.concatenate((subspace,np.array([vNotInS]).T), axis=1)\n",
    "print np.linalg.matrix_rank(s1)\n",
    "print np.linalg.matrix_rank(s2)\n",
    "print \"{} is {}in Span(v1,v2,v3,v4)\".format(vInS,'' if np.linalg.matrix_rank(s1) == 2 else 'not ')\n",
    "print \"{} is {}in Span(v1,v2,v3,v4)\".format(vNotInS,'' if np.linalg.matrix_rank(s2) == 2 else 'not ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace rank is 2\n"
     ]
    }
   ],
   "source": [
    "print \"Subspace dimension is {}\".format(np.linalg.matrix_rank(subspace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthonormal basis of S is\n",
      " ([-0.18257419 -0.36514837 -0.54772256 -0.73029674], \n",
      "[ 0.2236068  -0.67082039  0.67082039 -0.2236068 ])\n"
     ]
    }
   ],
   "source": [
    "subspace = np.column_stack((v1,v2))\n",
    "q,r = np.linalg.qr(subspace)\n",
    "e1 = q.T[0]\n",
    "e2 = q.T[1]\n",
    "print \"Orthonormal basis of S is\\n ({}, \\n{})\".format(e1,e2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08333333 -0.08333333  0.25        0.08333333] is the closest vector in S to z*\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1,0,0,0])\n",
    "zProje1 = np.dot(z,e1)*e1\n",
    "zProje2 = np.dot(z,e2)*e2\n",
    "zProjS = zProje1 + zProje2\n",
    "zProjS\n",
    "s1 = np.concatenate((subspace,np.array([zProjS]).T), axis=1)\n",
    "print \"{} is the closest vector in S to z*\".format(zProjS,'' if np.linalg.matrix_rank(s1) == 2 else 'not ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Scraping, Entropy and ICML papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader,stopwords,wordnet\n",
    "from nltk.util import ngrams\n",
    "corpus_path = \"txts\"\n",
    "wordlists = PlaintextCorpusReader(corpus_path, '.*')\n",
    "words = wordlists.words(fileids=wordlists.fileids())\n",
    "cfd = nltk.ConditionalFreqDist(ngrams(words,2))\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We show results In Proceedings of thresholds associated value due to units In practice In contrast our main sources In Advances In Proceedings Part Applications References Anderson John Generalized Linear Unit Circle Mechanism design simple way way In combination step As technical details In Advances In Advances In order assumption holds even higher order terms Note the ball following result states used In Section presents results In Advances In Joint learning rate In NIPS volume American Journal Machine Learning Representations of existing approaches reduce model learned using lower bound based search based active learning control using information processing systems In\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import itertools\n",
    "def generate_model(cfdist, word, num=100):\n",
    "    for i in range(num):\n",
    "        print word,\n",
    "#         word = cfdist[word].max()\n",
    "        i = random.randrange(sum(cfd[word].values()))\n",
    "        nextWord = next(itertools.islice(cfd[word].elements(), i, None))\n",
    "        cnt = 0\n",
    "        while (cfdist[word][nextWord] < 3 or nextWord in stops or len(wordnet.synsets(nextWord))<5) and cnt < 1000:\n",
    "            i = random.randrange(sum(cfd[word].values()))\n",
    "            nextWord = next(itertools.islice(cfd[word].elements(), i, None))\n",
    "            cnt += 1\n",
    "        word = nextWord\n",
    "# generate_model(cfd,\"Uncovering\")\n",
    "# print type(wordlists.words('achab17a.pdf.txt'))\n",
    "# print type(wordlists.words(fileids=wordlists.fileids()))\n",
    "# nltk.util.ngrams(words,2)\n",
    "generate_model(cfd,\"We\")\n",
    "# fd = nltk.FreqDist(words)\n",
    "# fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordnet.synsets('ftmgm'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
